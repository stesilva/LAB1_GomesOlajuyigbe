paperDOI;paperTitle;paperAbstract;paperAuthorID;paperAuthorName;conferenceWorkshopID;conferenceWorkshopName;conferenceWorkshopType;conferenceWorkshopEdition;conferenceWorkshopYear;conferenceWorkshopCity;journalID;journalName;jornalYear;jornalVolume;keywords
f134abeaf9bfd41f29b97aec675ec31895bf541d;High-performance medicine: the convergence of human and artificial intelligence;;['144758045'];['E. Topol'];;;;;;;5mk0bhd1;Nature Medicine;2019.0;25;['Computer Science', 'Medicine', 'Artificial Intelligence']
530a059cb48477ad1e3d4f8f4b153274c8997332;Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI;;['1379511816', '2058921025', '9221552', '1379511786', '3030006', '50449165', '39558258', '1402195255', '145337392', '2445552', '2091924780', '2098723448'];['Alejandro Barredo Arrieta', 'Natalia Díaz Rodríguez', 'J. Ser', 'Adrien Bennetot', 'S. Tabik', 'A. Barbado', 'S. García', 'S. Gil-Lopez', 'D. Molina', 'Richard Benjamins', 'Raja Chatila', 'Francisco Herrera'];;;;;;;h4atxzwd;Inf. Fusion;2019.0;58;['Computer Science', 'Artificial Intelligence']
e89dfa306723e8ef031765e9c44e5f6f94fd8fda;Explanation in Artificial Intelligence: Insights from the Social Sciences;;['144658641'];['Tim Miller'];;;;;;;2c457lii;Artif. Intell.;2017.0;267;['Computer Science', 'Artificial Intelligence']
8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c;Sparks of Artificial General Intelligence: Early experiments with GPT-4;Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks,;['121645690', '143754359', '2315830', '120962807', '2064595436', '1783184', '2212084492', '2109308930', '152244300', '23451726', '40900039', '2247662718', '78846919', '144884116'];['Sébastien Bubeck', 'Varun Chandrasekaran', 'Ronen Eldan', 'J. Gehrke', 'Eric Horvitz', 'Ece Kamar', 'Peter Lee', 'Y. Lee', 'Yuan-Fang Li', 'Scott M. Lundberg', 'Harsha Nori', 'Hamid Palangi', 'Marco Tulio Ribeiro', 'Yi Zhang'];;;;;;;wjqphmqh;ArXiv;2023.0;abs/2303.12712;['Computer Science']
21dff47a4142445f83016da0819ffe6dd2947f66;Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI);At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the;['9139705', '50487490'];['Amina Adadi', 'M. Berrada'];;;;;;;842l6o46;IEEE Access;2018.0;6;['Computer Science', 'Artificial Intelligence']
4b4279db68b16e20fbc56f9d41980a950191d30a;Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence;From the Publisher: Genetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits. Adaptation in Natural and Artificial Systems is the book that initiated this field of study, presenting the theoretical foundations and exploring applications. In its most familiar form, adaptation is a biological process, whereby organisms evolve by rearranging genetic material to survive in environments confronting them. In this now classic work, Holland presents a mathematical model that allows for the nonlinearity of such complex interactions. He demonstrates the model's universality by applying it to economics, physiological psychology, game theory, and artificial intelligence and then outlines the way in which this approach modifies the traditional views of mathematical genetics. Initially applying his concepts to simply defined artificial systems;['144404817'];['J. Holland'];;;;;;;71xhzrnr;Computer Science Bulletin (1992.0);1992.0;;['Computer Science', 'Engineering', 'Artificial Intelligence']
f92922a9fe4e6bb603291249796d80d09d1fd9f3;Impact of Artificial Intelligence in Customer Journey;The entire gamut of Customer journey is undergoing a massive transformation due to the rapid advancement of Artificial Intelligence (AI). Leveraging the power of AI , CRM & systems have refined the aspect of how businesses manage and optimize the customer journey. AI-powered systems have significant impact across various stages of the customer lifecycle by use of techniques such as machine learning to empower businesses to use systems that can analyse vast amounts of customer dataset in real-time, enabling them to gain deeper insights in customer behaviours, preferences, & sentiment. The AI-driven techniques help businesses to drive more personalized & targeted marketing campaigns, tailored recommendations, and extend efficient customer service leading ultimately to enhancing customer satisfaction and loyalty. Moreover, AI-powered systems have capabilities of offering predictive analytics which empower businesses to forecast customer behaviours and anticipate their needs. The capabilities help businesses in effective resource optimization and improve efficiency. For;['2319574187', '2319226126'];['Murali Krishna Pendyala', 'Vishnu Varma Lakkamraju'];;;;;;;eodvsxkz;International Journal of Innovative Science and Research Technology (IJISRT);2024.0;13;['Artificial Intelligence']
2633a948f06a02417a39c9ff4e9c948bbad460d7;Artificial Intelligence and the Future of Work;;['2345322820', '2345327280', '2345322880', '2345330491', '2345266364', '2078909624', '2345325714'];['Yuko Harayama', 'Michela Milano', 'Richard Baldwin', 'Céline Antonin', 'Janine Berg', 'Anousheh Karvar', 'Andrew Wyckoff'];;;;;;;gzhnzlvk;Computer Science Journal (2024.0);2024.0;59;['Computer Science', 'Artificial Intelligence']
7b72711ac2ea7bd7f519cac162a4a6578bbb7d0d;ARTIFICIAL INTELLIGENCE FOR THE REAL WORLD;;['7487965'];['Emily Garcia'];;;;;;;aiqlg65w;International Research Journal of Modernization in Engineering Technology and Science;2023.0;50;['Artificial Intelligence']
e1d2f2a717aa03280126f87c8e5fad695f52bf7c;Explainable Artificial Intelligence (XAI);Explainable Artificial Intelligence (XAI) has emerged as a critical facet in the realm of machine learning and artificial intelligence, responding to the increasing complexity of models, particularly deep neural networks, and the subsequent need for transparent decision making processes. This research paper delves into the essence of XAI, unraveling its significance across diverse domains such as healthcare, finance, and criminal justice. As a countermeasure to the opacity of intricate models, the paper explores various XAI methods and techniques, including LIME and SHAP, weighing their interpretability against computational efficiency and accuracy. Through an examination of real-world applications, the research elucidates how XAI not only enhances decision-making processes but also influences user trust and acceptance in AI systems. However, the paper also scrutinizes the delicate balance between interpretability and performance, shedding light on instances where the pursuit of accuracy may compromise explain-ability. Additionally, it navigates through the current challenges and limitations in;['2151645335', '2279449118', '2279513475', '2279448452'];['Ranu Sewada', 'Ashwani Jangid', 'Piyush Kumar', 'Neha Mishra'];;;;;;;r2zogil9;international journal of food and nutritional sciences;2023.0;49;['Artificial Intelligence']
9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a;Foundation models for generalist medical artificial intelligence;;['1557487144', '2047009195', '115517806', '2117715807', '1702139', '144758045', '1453104568'];['Michael Moor', 'Oishi Banerjee', 'Zahra F H Abad', 'H. Krumholz', 'J. Leskovec', 'E. Topol', 'P. Rajpurkar'];;;;;;;7nzlwwgg;Nature;2023.0;616;['Medicine', 'Artificial Intelligence']
5cde474869cb230a29b3ba0f6f685f5162b1a1a1;Revolutionizing healthcare: the role of artificial intelligence in clinical practice;;['1716508276', '2243408972', '50006545', '2243412243', '2078203152', '2159384173', '2003687008', '144882464', '5565754', '11708863', '12112205', '4884356', '6458651'];['Shuroug A. Alowais', 'Sahar S. Alghamdi', 'Nada Alsuhebany', 'Tariq Alqahtani', 'Abdulrahman I. Alshaya', 'Sumaya N Almohareb', 'Atheer Aldairem', 'Mohammed A. Alrashed', 'Khalid Bin saleh', 'H. Badreldin', 'Majed S. Al Yami', 'Shmeylan A. Al Harbi', 'Abdulkareem M. Albekairy'];;;;;;;3racrnsp;BMC Medical Education;2023.0;23;['Medicine', 'Artificial Intelligence']
f08060425aa8a212d74185ee23a08329b89abcd2;Scientific discovery in the age of artificial intelligence;;['46506460', '2427076', '93584228', '2153575781', '49454094', '2117941801', '89356020', '1563693999', '2226485816', '48860334', '2047844', '46354410', '2188778449', '2226475487', '143967473', '1764249', '1702139', '2110264337', '2613935', '2226493959', '2378027', '2159642226', '1738536', '2115854801', '3444569', '2228923747', '2181109681', '13027820', '1865800402', '2095762'];['Hanchen Wang', 'Tianfan Fu', 'Yuanqi Du', 'Wenhao Gao', 'Kexin Huang', 'Ziming Liu', 'P. Chandak', 'Shengchao Liu', 'Peter Van Katwyk', 'Andreea Deac', 'Anima Anandkumar', 'K. Bergen', 'Carla P. Gomes', 'Shirley Ho', 'Pushmeet Kohli', 'Joan Lasenby', 'J. Leskovec', 'Tie-Yan Liu', 'A. Manrai', 'Debora S. Marks', 'Bharath Ramsundar', 'Le Song', 'Jimeng Sun', 'Jian Tang', 'Petar Velickovic', 'Max Welling', 'Linfeng Zhang', 'Connor W. Coley', 'Y. Bengio', 'M. Zitnik'];;;;;;;uqhkftkz;Nature;2023.0;620;['Computer Science', 'Medicine', 'Artificial Intelligence']
8d984ee2eeabb630014f31fc759d4980830c4bdb;Can artificial intelligence help for scientific writing?;;['32433579', '4254919', '1738459585'];['Michele Salvagno', 'F. Taccone', 'A. Gerli'];;;;;;;cs3v1a5b;Critical Care;2023.0;27;['Medicine', 'Artificial Intelligence']
6f4486c3d8ccd638c2a6bcbfafa01b5a3225bcab;Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence;;['153016337'];['G. Cooper'];;;;;;;4wfrogvj;Journal of Science Education and Technology;2023.0;32;['Artificial Intelligence']
9dafa6c5c609348b46734fc8997b93b3587fec6e;Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education;Generative artificial intelligence (AI) is ushering in an era of potential transformation of journalism and media content. This essay considers one notable generative AI platform called ChatGPT made available to the public in 2022 for free use. ChatGPT allows users to enter text prompts and rapidly generates text responses drawn from its knowledge acquired via machine learning in engagement with the internet. This essay is coauthored by a human journalism and media professor in collaboration with ChatGPT. The essay demonstrates the capacity and limitations of ChatGPT and offers reflections on the implications of generative AI for journalism and media education.;['1795976'];['J. Pavlik'];;;;;;;2fbasmnd;Journalism & Mass Communication Educator;2023.0;78;['Artificial Intelligence']
288078127a3078332230442170f6745ed333c700;A Conversation on Artificial Intelligence, Chatbots, and Plagiarism in Higher Education;;['152378504', '2280373812'];['Michael R. King', 'chatGPT'];;;;;;;39zhnzs4;Cellular and Molecular Bioengineering;2023.0;16;['Medicine', 'Artificial Intelligence']
e251ba9fe7992fc07a01365a5f8f2b4d9020b875;Artificial intelligence in higher education: the state of the field;;['2168834', '46596152'];['H. Crompton', 'D. Burke'];;;;;;;qpupuzpq;International Journal of Educational Technology in Higher Education;2023.0;20;['Artificial Intelligence']
8d020275181c69e5e768c6ffc40e09710a6f54f1;Experimental evidence on the productivity effects of generative artificial intelligence;We examined the productivity effects of a generative artificial intelligence (AI) technology, the assistive chatbot ChatGPT, in the context of midlevel professional writing tasks. In a preregistered online experiment, we assigned occupation-specific, incentivized writing tasks to 453 college-educated professionals and randomly exposed half of them to ChatGPT. Our results show that ChatGPT substantially raised productivity: The average time taken decreased by 40% and output quality rose by 18%. Inequality between workers decreased, and concern and excitement about AI temporarily rose. Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment. Description Editor’s summary Automation has historically displaced human workers in factories (e.g., automotive manufacturing) or in performing routine computational tasks. Will generative artificial intelligence (AI) tools such as ChatGPT disrupt the labor market by making;['119462164', '123247135'];['Shakked Noy', 'Whitney Zhang'];;;;;;;ckme1dl8;Science;2023.0;381;['Medicine', 'Artificial Intelligence']
31f76619329aba7987394ccb8cac6c9a6dd58a56;Managing artificial intelligence;;['4429073'];['P. Krausman'];;;;;;;y36lkcez;The Journal of Wildlife Management;2023.0;90;['Artificial Intelligence']
eac11727ef9c7c29711cb1ba82ef6f011e8ad78d;New Era of Artificial Intelligence in Education: Towards a Sustainable Multifaceted Revolution;The recent high performance of ChatGPT on several standardized academic tests has thrust the topic of artificial intelligence (AI) into the mainstream conversation about the future of education. As deep learning is poised to shift the teaching paradigm, it is essential to have a clear understanding of its effects on the current education system to ensure sustainable development and deployment of AI-driven technologies at schools and universities. This research aims to investigate the potential impact of AI on education through review and analysis of the existing literature across three major axes: applications, advantages, and challenges. Our review focuses on the use of artificial intelligence in collaborative teacher–student learning, intelligent tutoring systems, automated assessment, and personalized learning. We also report on the potential negative aspects, ethical issues, and possible future routes for AI implementation in education. Ultimately, we find that the only way forward is to embrace the new technology, while;['2258772335', '2267275190', '2120620052'];['Firuz Kamalov', 'David Santandreu Calonge', 'Ikhlaas Gurrib'];;;;;;;76q0132n;Sustainability;2023.0;87;['Computer Science', 'Artificial Intelligence']
438ea4f6becaadca82c9f9904208a423a0cfeba0;Artificial Intelligence in Pharmaceutical Technology and Drug Delivery Design;Artificial intelligence (AI) has emerged as a powerful tool that harnesses anthropomorphic knowledge and provides expedited solutions to complex challenges. Remarkable advancements in AI technology and machine learning present a transformative opportunity in the drug discovery, formulation, and testing of pharmaceutical dosage forms. By utilizing AI algorithms that analyze extensive biological data, including genomics and proteomics, researchers can identify disease-associated targets and predict their interactions with potential drug candidates. This enables a more efficient and targeted approach to drug discovery, thereby increasing the likelihood of successful drug approvals. Furthermore, AI can contribute to reducing development costs by optimizing research and development processes. Machine learning algorithms assist in experimental design and can predict the pharmacokinetics and toxicity of drug candidates. This capability enables the prioritization and optimization of lead compounds, reducing the need for extensive and costly animal testing. Personalized medicine approaches can be facilitated through AI algorithms that analyze real-world;['50131730', '14569224', '2125366113', '1714594', '2189065687', '7573580'];['Lalitkumar K. Vora', 'A. Gholap', 'Keshava Jetha', 'R. Thakur', 'Hetvi K. Solanki', 'Vivek P. Chavda'];;;;;;;zpnc5o42;Pharmaceutics;2023.0;15;['Medicine', 'Artificial Intelligence']
10c64e5aaff9f70dffc8c29a577376d085e9340b;A Review of the Role of Artificial Intelligence in Healthcare;Artificial intelligence (AI) applications have transformed healthcare. This study is based on a general literature review uncovering the role of AI in healthcare and focuses on the following key aspects: (i) medical imaging and diagnostics, (ii) virtual patient care, (iii) medical research and drug discovery, (iv) patient engagement and compliance, (v) rehabilitation, and (vi) other administrative applications. The impact of AI is observed in detecting clinical conditions in medical imaging and diagnostic services, controlling the outbreak of coronavirus disease 2019 (COVID-19) with early diagnosis, providing virtual patient care using AI-powered tools, managing electronic health records, augmenting patient engagement and compliance with the treatment plan, reducing the administrative workload of healthcare professionals (HCPs), discovering new drugs and vaccines, spotting medical prescription errors, extensive data storage and analysis, and technology-assisted rehabilitation. Nevertheless, this science pitch meets several technical, ethical, and social challenges, including privacy, safety, the right to decide and try, costs,;['51273488', '2274559129', '2219616129', '2067184257', '1435635095', '3528287', '2220804070', '2083368779'];['Ahmed Al Kuwaiti', 'Khalid Nazer', 'Abdullah Al-Reedy', 'Shaher Z. Al-Shehri', 'A. Al-Muhanna', 'A. Subbarayalu', 'Dhoha Al Muhanna', 'Fahad A Al-Muhanna'];;;;;;;sk3wwp6x;Journal of Personalized Medicine;2023.0;13;['Medicine', 'Artificial Intelligence']
a1ab52ec816982a5a69665db6780b3b5d8ceb216;Artificial Intelligence in Medicine;Artificial Intelligence in Medicine is looking for novelty in the methodological and/or theoretical content of submitted papers. Such kind of novelty has to be mainly acknowledged in the area of AI and Computer Science. Methodological papers deal with the proposal of some strategy and related methods to solve some scientific issues in specific domains. They must show, usually through an experimental evaluation, how the proposed methodology can be applied to medicine, medicallyoriented human biology, and health care, respectively. They have also to provide a comparison with other proposals, and explicitly discuss elements of novelty. Theoretical papers focus on more fundamental, general and formal topics of AI and must show the novel expected effects of the proposed solution in some medical or healthcare field.;['2347353484'];['Andrew Cupples'];;;;;;;hwvv8aap;The Ulster Medical Journal;2023.0;92;['Medicine', 'Artificial Intelligence']
12c6be503e4e5b7c9cb1810152d4364f26628a8d;Data-centric Artificial Intelligence: A Survey;Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI . The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages;['1759658', '2122929218', '51238382', '47829900', '47653902', '2181946372', '2109724398'];['D. Zha', 'Zaid Pervaiz Bhat', 'Kwei-Herng Lai', 'Fan Yang', 'Zhimeng Jiang', 'Shaochen Zhong', 'Xia Hu'];;;;;;;xha46gwm;ACM Comput. Surv.;2023.0;57;['Computer Science', 'Artificial Intelligence']
22ff1f6f4df0497323ac03f446cbc49463128486;Appropriateness of Cardiovascular Disease Prevention Recommendations Obtained From a Popular Online Chat-Based Artificial Intelligence Model.;This study examines the appropriateness of artificial intelligence model responses to fundamental cardiovascular disease prevention questions.;['3914102', '2204252078', '4796976', '4159243', '2140404141', '2275501436'];['Ashish Sarraju', 'Dennis Bruemmer', 'E. V. Van Iterson', 'L. Cho', 'Fatima Rodriguez', 'Luke Laffin'];;;;;;;6conafin;JAMA;2023.0;47;['Medicine', 'Artificial Intelligence']
bb01d7be9b49c8a018e134c7f132c39b7d9973ad;Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence;;['47495965', '2999175', '1412328163', '2065671060', '2151319597', '144833154', '1704327', '9221552', '1423321194', '2098723448'];['Sajid Ali', 'Tamer Abuhmed', 'Shaker El-Sappagh', 'Khan Muhammad', 'J. Alonso-Moral', 'R. Confalonieri', 'Riccardo Guidotti', 'J. Ser', 'N. Díaz-Rodríguez', 'Francisco Herrera'];;;;;;;mi0vzml7;Inf. Fusion;2023.0;99;['Computer Science', 'Artificial Intelligence']
4583725945ff17f139215b210878b0a2e2d29bc2;Artificial Intelligence and Machine Learning in Clinical Medicine, 2023.;;['4815642', '5777361'];['C. Haug', 'J. Drazen'];;;;;;;8kh6e4ks;The New England journal of medicine;2023.0;388 13;['Medicine', 'Machine Learning', 'Artificial Intelligence']
de4b9bc12ddb6b9f6090c032ef5c6290bd64ef36;Artificial Intelligence;;['1697177', '32239759'];['Bart Verheij', 'M. Wiering'];;;;;;;w6ue9kob;Computer Science Bulletin (2017.0);2017.0;823;['Computer Science', 'Artificial Intelligence']
973650310963f8cdc39c71e79724513004adde2a;Trustworthy artificial intelligence;;['7441236', '2778848'];['M. Simion', 'Christoph Kelp'];;;;;;;60l25x8c;Asian Journal of Philosophy;2023.0;2;['Artificial Intelligence']
2eeff0f534d303581bc1199671600fbd04a2d01c;Empowering Education with Generative Artificial Intelligence Tools: Approach with an Instructional Design Matrix;This study focuses on the potential of generative artificial intelligence tools in education, particularly through the practical application of the 4PADAFE instructional design matrix. The objective was to evaluate how these tools, in combination with the matrix, can enhance education and improve the teaching–learning process. Through surveys conducted with teachers from the University of ESPE Armed Forces who participated in the MOOC course “Generative Artificial Intelligence Tools for Education: GPT Chat Techniques”, the study explores the impact of these tools on education. The findings reveal that generative artificial intelligence tools are crucial in developing massive MOOC virtual classrooms when integrated with an instructional design matrix. The results demonstrate the potential of generative artificial intelligence tools in university education. By utilizing these tools in conjunction with an instructional design matrix, educators can design and deliver personalized and enriching educational experiences. The devices offer opportunities to enhance the teaching–learning process and tailor;['2225364164', '1410071097', '2225325036', '2224113717'];['Lena Ivannova Ruiz-Rojas', 'Patricia Acosta-Vargas', 'Javier De-Moreta-Llovet', 'Mario González-Rodríguez'];;;;;;;jisrs52z;Sustainability;2023.0;72;['Artificial Intelligence']
5a5e03c3c8bf5052a99f4631e874b1e608e59319;Artificial intelligence in developing countries: The impact of generative artificial intelligence (AI) technologies for development;This paper explores the potential impact of Generative Artificial Intelligence (Generative AI) on developing countries, considering both positive and negative effects across various domains of information, culture, and industry. Generative Artificial Intelligence refers to artificial intelligence (AI) systems that generate content, such as text, audio, or video, aiming to produce novel and creative outputs based on training data. Compared to conversational artificial intelligence, generative artificial intelligence systems have the unique capability of not only providing replies but also generating the content of those responses. Recent advancements in Artificial Intelligence during the Fourth Industrial Revolution, exemplified by tools like ChatGPT, have gained popularity and reshaped content production and creation. However, the benefits of generative artificial intelligence are not equally accessible to all, especially in developing countries, where limited access to cutting-edge technologies and inadequate infrastructure pose challenges. This paper seeks to understand the potential impact of generative AI technologies on developing;['2212887866', '143787727', '2209524983', '2241879633', '2248150677', '151349904', '2241896120', '75067375', '2241902744', '2241896550', '2241892110', '2211498935', '2241896206', '2241878022', '2221218808', '2241889653', '2241896296'];['Nishith Reddy Mannuru', 'Sakib Shahriar', 'Z. A. Teel', 'Ting Wang', 'Brady D. Lund', 'Solomon Tijani', 'Chalermchai Oak Pohboon', 'Daniel A. Agbaji', 'Joy Alhassan', 'JaKLyn Galley', 'Raana Kousari', 'Lydia Ogbadu-Oladapo', 'Shubham Kumar Saurav', 'Aishwarya Srivastava', 'Sai Priya Tummuru', 'Sravya Uppala', 'Praveenkumar Vaidya'];;;;;;;5jvs7ns0;Information Development;2023.0;95;['Artificial Intelligence']
3ddbc58b463156b83c1a6ab792c98898e32aeb7d;Smart farming using artificial intelligence: A review;;['2203839392', '2150473132', '2079704411'];['Yaganteeswarudu Akkem', 'S. K. Biswas', 'Aruna Varanasi'];;;;;;;n5llmznl;Eng. Appl. Artif. Intell.;2023.0;120;['Computer Science', 'Artificial Intelligence']
378236591fc05e79204fd904e9f864efa31cdc74;An Overview of Artificial Intelligence Ethics;Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This article will give a comprehensive overview of this field by summarizing and analyzing the;['15913738', '2118689474', '2105731841', '2115585545'];['Changwu Huang', 'Zeqi Zhang', 'Bifei Mao', 'X. Yao'];;;;;;;5xqt57kp;IEEE Transactions on Artificial Intelligence;2023.0;4;['Computer Science', 'Artificial Intelligence']
b9e9f449da63fbb783ce39db15bf1626a9bb4a44;Artificial intelligence for waste management in smart cities: a review;;['3273326', '2217843411', '48354998', '32474777', '80967597', '50706019', '3488588', '2126610635', '123276858'];['Bingbing Fang', 'Jiacheng Yu', 'Zhonghao Chen', 'A. Osman', 'Mohamed Farghali', 'I. Ihara', 'E. Hamza', 'David W. Rooney', 'P. Yap'];;;;;;;x1wwk3wz;Environmental Chemistry Letters;2023.0;30;['Medicine', 'Artificial Intelligence']
ff97adbdf7ba45c08c6abe277aba04b41e85e5b0;Evaluation of artificial intelligence techniques in disease diagnosis and prediction;;['2198765822', '8307959', '144288618'];['Nafiseh Ghaffar Nia', 'E. Kaplanoğlu', 'A. Nasab'];;;;;;;l1fvnhch;Discover Artificial Intelligence;2023.0;3;['Computer Science', 'Artificial Intelligence']
b313140bde3d9d8ed96f405674fd243e270104fb;Artificial intelligence for digital and computational pathology;;['2253812042', '35685584', '25259989', '16184125', '2187496179', '2253535836', '37122655'];['Andrew H. Song', 'Guillaume Jaume', 'Drew F. K. Williamson', 'Ming Y. Lu', 'Anurag Vaidya', 'Tiffany R. Miller', 'Faisal Mahmood'];;;;;;;o4w49v27;Nature Reviews Bioengineering;2023.0;1;['Artificial Intelligence', 'Computer Science', 'Engineering', 'Biology']
7c1933359a6860fe49d15c6353a241763879e81f;From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where;Nowadays, Industry 4.0 can be considered a reality, a paradigm integrating modern technologies and innovations. Artificial intelligence (AI) can be considered the leading component of the industrial transformation enabling intelligent machines to execute tasks autonomously such as self-monitoring, interpretation, diagnosis, and analysis. AI-based methodologies (especially machine learning and deep learning support manufacturers and industries in predicting their maintenance needs and reducing downtime. Explainable artificial intelligence (XAI) studies and designs approaches, algorithms and tools producing human-understandable explanations of AI-based systems information and decisions. This article presents a comprehensive survey of AI and XAI-based methods adopted in the Industry 4.0 scenario. First, we briefly discuss different technologies enabling Industry 4.0. Then, we present an in-depth investigation of the main methods used in the literature: we also provide the details of what, how, why, and where these methods have been applied for Industry 4.0. Furthermore, we illustrate the opportunities and challenges that elicit;['2151840708', '31444174', '1784067'];['Imran Ahmed', 'Gwanggil Jeon', 'F. Piccialli'];;;;;;;vz47m7cw;IEEE Transactions on Industrial Informatics;2022.0;18;['Computer Science', 'Artificial Intelligence']
b9ede5f604668d0b62a306392cd03f47086e245e;Artificial intelligence in radiology;;['143819435', '40470674', '144101458', '35802562', '143849569'];['A. Hosny', 'C. Parmar', 'John Quackenbush', 'L. Schwartz', 'H. Aerts'];;;;;;;q96ln0qf;Nature Reviews Cancer;2018.0;18;['Computer Science', 'Medicine', 'Artificial Intelligence']
b8f20b0b8a37e7b2e19d416fba80d147b75c887f;Artificial intelligence-based solutions for climate change: a review;;['2145130787', '48354998', '2221641170', '2117421506', '32474777', '80967597', '2221610051', '1403852274', '50706019', '2126610635', '123276858'];['Lin Chen', 'Zhonghao Chen', 'Yubing Zhang', 'Yunfei Liu', 'A. Osman', 'Mohamed Farghali', 'Jianmin Hua', 'A. Al-Fatesh', 'I. Ihara', 'David W. Rooney', 'P. Yap'];;;;;;;v01ck1o8;Environmental Chemistry Letters;2023.0;78;['Artificial Intelligence']
dfd1d219c7e1993bef152f79b81204a828b77d21;Generative artificial intelligence empowers educational reform: current status, issues, and prospects;The emergence of Chat GPT has once again sparked a wave of information revolution in generative artificial intelligence. This article provides a detailed overview of the development and technical support of generative artificial intelligence. It conducts an in-depth analysis of the current application of generative artificial intelligence in the field of education, and identifies problems in four aspects: opacity and unexplainability, data privacy and security, personalization and fairness, and effectiveness and reliability. Corresponding solutions are proposed, such as developing explainable and fair algorithms, upgrading encryption technology, and formulating relevant laws and regulations to protect data, as well as improving the quality and quantity of datasets. The article also looks ahead to the future development trends of generative artificial intelligence in education from four perspectives: personalized education, intelligent teaching, collaborative education, and virtual teaching. The aim of the study is to provide important reference value for research and practice in this;['2110751949', '152699208'];['Haotian Yu', 'Yunyun Guo'];;;;;;;5uygk8u2;Science Bulletin (2023.0);2023.0;8;['Artificial Intelligence']
b67cb8cac83ec0cb683d5378a0ca4d96c8176013;Artificial intelligence in healthcare and education;;['80470531', '144121289'];['M. Dave', 'N. Patel'];;;;;;;c03mawr1;British Dental Journal;2023.0;234;['Medicine', 'Artificial Intelligence']
8ebd4ae177fb1a62298d19891fd6e45e2a5f7685;Artificial Intelligence A Modern Approach 3rd;Artificial IntelligenceArtificial Intelligence: A Modern Approach 2Nd Ed.Introduction to Machine LearningArtificial IntelligenceArtificial Intelligence: A Modern Approach, eBook, Global EditionIntroduction to Artificial IntelligenceModern Approaches in Machine Learning and Cognitive Science: A WalkthroughArtificial Intelligence: Pearson New International EditionArtificial IntelligenceArtificial IntelligenceArtificial IntelligenceArtificial Intelligence a Modern ApproachFundamentals of the New Artificial IntelligenceMultiagent SystemsArtificial IntelligenceArtificial IntelligenceThe Hundred-page Machine Learning BookArtificial IntelligenceArtificial IntelligenceArtificial IntelligenceDistributed Artificial IntelligenceArtificial Intelligence For BeginnersParadigms of Artificial Intelligence ProgrammingHuman CompatibleHuman CompatibleARTIFICIAL INTELLIGENCEArtificial IntelligenceArtificial IntelligenceArtificial Intelligence a Modern ApproachDo the Right ThingArtificial IntelligenceArtificial Intelligence : a Modern ApproachArtificial IntelligenceIntelligent Help Systems for UNIXArtificial IntelligenceArtificial IntelligenceArtificial Intelligence a Modern ApproachArtificial IntelligenceArtificial IntelligenceArtificial Intelligence for Human Computer Interaction: A Modern Approach;['7487197'];['Emily Williams'];;;;;;;mvwhrisr;Science Magazine (2022.0);2022.0;54;['Artificial Intelligence']
635c01476986099adc4ce122bb28ebc6deb46671;Empowering learners for the age of artificial intelligence;;['65953975', '2076137404', '2151396257'];['D. Gašević', 'G. Siemens', 'Shazia Sadiq'];;;;;;;h56e7ta3;Comput. Educ. Artif. Intell.;2023.0;4;['Computer Science', 'Artificial Intelligence']
10f919b1a5161b560504c225cfb2d1b3a4768f80;Artificial intelligence in healthcare: past, present and future;Artificial intelligence (AI) aims to mimic human cognitive functions. It is bringing a paradigm shift to healthcare, powered by increasing availability of healthcare data and rapid progress of analytics techniques. We survey the current status of AI applications in healthcare and discuss its future. AI can be applied to various types of healthcare data (structured and unstructured). Popular AI techniques include machine learning methods for structured data, such as the classical support vector machine and neural network, and the modern deep learning, as well as natural language processing for unstructured data. Major disease areas that use AI tools include cancer, neurology and cardiology. We then review in more details the AI applications in stroke, in the three major areas of early detection and diagnosis, treatment, as well as outcome prediction and prognosis evaluation. We conclude with discussion about pioneer AI systems, such as IBM Watson, and hurdles for real-life deployment;['67092021', '2117937034', '1976425918', '1974599', None, '36156845', '119918227', '47454309', '46829048', '2108094216'];['F. Jiang', 'Yong Jiang', 'Hui Zhi', 'Yi Dong', 'Hao Li', 'Sufeng Ma', 'Yilong Wang', 'Q. Dong', 'Haipeng Shen', 'Yongjun Wang'];;;;;;;tfxl1o9a;Stroke and Vascular Neurology;2017.0;2;['Computer Science', 'Medicine', 'Artificial Intelligence']
e8441a9d8c22f333b4092d3a95d3fbb64a36d428;Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?;The legal and ethical issues that confront society due to Artificial Intelligence (AI) include privacy and surveillance, bias or discrimination, and potentially the philosophical challenge is the role of human judgment. Concerns about newer digital technologies becoming a new source of inaccuracy and data breaches have arisen as a result of its use. Mistakes in the procedure or protocol in the field of healthcare can have devastating consequences for the patient who is the victim of the error. Because patients come into contact with physicians at moments in their lives when they are most vulnerable, it is crucial to remember this. Currently, there are no well-defined regulations in place to address the legal and ethical issues that may arise due to the use of artificial intelligence in healthcare settings. This review attempts to address these pertinent issues highlighting the need for algorithmic transparency, privacy, and protection of all the beneficiaries;['116246793', '82977131', '21766681', '2158670917', '3483295', '2057278194', '2158671047', '66290347', '13966665', '8556033', '50534993', '4769205', '50573337', '4149364'];['Nithesh Naik', 'B. Hameed', 'Dasharathraj K. Shetty', 'Dishant Swain', 'M. Shah', 'R. Paul', 'Kaivalya Aggarwal', 'Sufyan Ibrahim', 'Vathsala Patil', 'Komal Smriti', 'Suyog Shetty', 'Bhavan Prasad Rai', 'P. Chłosta', 'B. Somani'];;;;;;;v133plwu;Frontiers in Surgery;2022.0;9;['Medicine', 'Artificial Intelligence']
2d93d27fb07fc43bb1e430c37f802586bc9aaf00;Trustworthy Artificial Intelligence: A Review;Artificial intelligence (AI) and algorithmic decision making are having a profound impact on our daily lives. These systems are vastly used in different high-stakes applications like healthcare, business, government, education, and justice, moving us toward a more algorithmic society. However, despite so many advantages of these systems, they sometimes directly or indirectly cause harm to the users and society. Therefore, it has become essential to make these systems safe, reliable, and trustworthy. Several requirements, such as fairness, explainability, accountability, reliability, and acceptance, have been proposed in this direction to make these systems trustworthy. This survey analyzes all of these different requirements through the lens of the literature. It provides an overview of different approaches that can help mitigate AI risks and increase trust and acceptance of the systems by utilizing the users and society. It also discusses existing strategies for validating and verifying these systems and the current standardization efforts;['87769689', '29405263', '2123062285', '1719412'];['Davinder Kaur', 'Suleyman Uslu', 'Kaley J. Rittichier', 'A. Durresi'];;;;;;;cx9kl4w7;ACM Computing Surveys (CSUR);2022.0;55;['Computer Science', 'Artificial Intelligence']
ec13995de8797a4e977024942d79fc0d27e20b7b;Ethical principles for artificial intelligence in education;;['145641941', '145117122', '2289857440', '2181844584', '2181845410'];['Andy Nguyen', 'H. Ngo', 'Yvonne Hong', 'Belle Dang', 'Bich-Phuong Thi Nguyen'];;;;;;;wwjab501;Education and Information Technologies;2022.0;28;['Computer Science', 'Medicine', 'Artificial Intelligence']
79d98ae4abec4b13a0447706e44e8d709fe7953c;Artificial intelligence in disease diagnosis: a systematic literature review, synthesizing framework and future research agenda;;['2055911978', '2127070689', '2113234020', '48761825'];['Yogesh Kumar', 'Apeksha Koul', 'Ruchika Singla', 'M. Ijaz'];;;;;;;cw11c8pr;Journal of Ambient Intelligence and Humanized Computing;2022.0;14;['Computer Science', 'Medicine', 'Artificial Intelligence']
df5f3ffe15207eb6ae2f00f3ccc818625b9bfbe7;Artificial Intelligence and Jobs: Evidence from Online Vacancies;We study the impact of artificial intelligence (AI) on labor markets using establishment-level data on the near universe of online vacancies in the United States from 2010 onward. There is rapid growth in AI-related vacancies over 2010–18 that is driven by establishments whose workers engage in tasks compatible with AI’s current capabilities. As these AI-exposed establishments adopt AI, they simultaneously reduce hiring in non-AI positions and change the skill requirements of remaining postings. While visible at the establishment level, the aggregate impacts of AI-labor substitution on employment and wage growth in more exposed occupations and industries is currently too small to be detectable.;['2660799', '145060981', '115470805', '2133941'];['D. Acemoglu', 'David Autor', 'J. Hazell', 'P. Restrepo'];;;;;;;8z5p1fm9;Journal of Labor Economics;2022.0;40;['Artificial Intelligence']
a7a407968c13ced804a063259d72315a43b84f29;Artificial Intelligence in Education: A Review;The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and;['1669767608', '47978704', '144264986'];['Lijia Chen', 'Pingping Chen', 'Zhijian Lin'];;;;;;;rkyy55z6;IEEE Access;2020.0;8;['Computer Science', 'Artificial Intelligence']
ceceaabccaf61edfd1c924d419328f0c2bfe9f81;A Proposal For The Dartmouth Summer Research Project On Artificial Intelligence;We propose that a 2 month, 10 man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans;['2316340027', '103194620', '2263042911', '2316337453', '2316338248', '2316338283', '117507094'];['J. McCarthy', 'Dartmouth College', 'M. Minsky', 'Harvard University', 'N. Rochester', 'I.B.M. Corporation', 'C. E. Shannon'];;;;;;;0dva2941;Science Magazine (2022.0);2022.0;39;['Artificial Intelligence']
d7eef9b5bb65feda6647440e7727bbcdf0edaebc;Dual use of artificial-intelligence-powered drug discovery;;['34577787', '5450685', '2063052193', '1887610'];['Fabio Urbina', 'Filippa Lentzos', 'Cédric Invernizzi', 'S. Ekins'];;;;;;;tfovuw00;Nature Machine Intelligence;2022.0;4;['Computer Science', 'Medicine']
8603193192a64f0c9943989d209e7492689045c1;Artificial Intelligence A Modern Approach 3rd Edition;Artificial IntelligenceArtificial Intelligence: A Modern Approach 2Nd Ed.Introduction to Machine LearningArtificial IntelligenceArtificial Intelligence: A Modern Approach, eBook, Global EditionIntroduction to Artificial IntelligenceModern Approaches in Machine Learning and Cognitive Science: A WalkthroughArtificial Intelligence: Pearson New International EditionArtificial IntelligenceArtificial IntelligenceArtificial IntelligenceArtificial Intelligence a Modern ApproachFundamentals of the New Artificial IntelligenceMultiagent SystemsArtificial IntelligenceArtificial IntelligenceThe Hundred-page Machine Learning BookArtificial IntelligenceArtificial IntelligenceArtificial IntelligenceDistributed Artificial IntelligenceArtificial Intelligence For BeginnersParadigms of Artificial Intelligence ProgrammingHuman CompatibleHuman CompatibleARTIFICIAL INTELLIGENCEArtificial IntelligenceArtificial IntelligenceArtificial Intelligence a Modern ApproachDo the Right ThingArtificial IntelligenceArtificial Intelligence : a Modern ApproachArtificial IntelligenceIntelligent Help Systems for UNIXArtificial IntelligenceArtificial IntelligenceArtificial Intelligence a Modern ApproachArtificial IntelligenceArtificial IntelligenceArtificial Intelligence for Human Computer Interaction: A Modern Approach;['4403506'];['Chris Martinez'];;;;;;;8rq0yt4e;Science Bulletin (2020.0);2020.0;94;['Artificial Intelligence']
ddf4172cad889f178c2db9b1b6302b3c7d5c0147;The potential for artificial intelligence in healthcare;ABSTRACT The complexity and rise of data in healthcare means that artificial intelligence (AI) will increasingly be applied within the field. Several types of AI are already being employed by payers and providers of care, and life sciences companies. The key categories of applications involve diagnosis and treatment recommendations, patient engagement and adherence, and administrative activities. Although there are many instances in which AI can perform healthcare tasks as well or better than humans, implementation factors will prevent large-scale automation of healthcare professional jobs for a considerable period. Ethical issues in the application of AI to healthcare are also discussed.;['145207212', '2235117'];['T. Davenport', 'R. Kalakota'];;;;;;;lx0uvb76;Future Healthcare Journal;2019.0;6;['Medicine', 'Psychology', 'Artificial Intelligence']
e2d3b48b46d34fac164ebcad2eb39661712a1d97;Definition, roles, and potential research issues of the metaverse in education: An artificial intelligence perspective;;['144217709', '1453704586'];['Gwo-jen Hwang', 'Shu-Yun Chien'];;;;;;;m9t01bvw;Comput. Educ. Artif. Intell.;2022.0;3;['Computer Science', 'Artificial Intelligence']
96a35bb48ef7c603ffc6c1e8119bca550fa85dfa;Artificial Intelligence for the Metaverse: A Survey;;['1402997421', '145436642', '39125867', '2156262553', '2155438325', '2144021817'];['Thien Huynh-The', 'Viet Quoc Pham', 'Xuan-Qui Pham', 'Thanh Thi Nguyen', 'Zhu Han', 'Dong-Seong Kim'];;;;;;;t7e6gvpz;Eng. Appl. Artif. Intell.;2022.0;117;['Computer Science', 'Artificial Intelligence']
55b59cf4404f121edb15f69c2493c87eb36a5530;Explainable Artificial Intelligence in education;;['1508543895', '144324892', '1566337182', '1692714', '2065160088', '153176881', '143685506', '1750742', '2092368', '65953975'];['Hassan Khosravi', 'S. B. Shum', 'Guanliang Chen', 'C. Conati', 'Yi-Shan Tsai', 'J.F.L. Kay', 'Simon Knight', 'Roberto Martínez Maldonado', 'S. Sadiq', 'D. Gašević'];;;;;;;ucvki9uw;Comput. Educ. Artif. Intell.;2022.0;3;['Computer Science', 'Artificial Intelligence']
ef0c62ff070a476f216fe478cc190c773f12a1f6;Human Trust in Artificial Intelligence: Review of Empirical Research;Artificial intelligence (AI) characterizes a new generation of technologies capable of interacting with the environment and aiming to simulate human intelligence. The success of integrating AI into...;['101331070', '2696361'];['Ella Glikson', 'A. Woolley'];;;;;;;tz1u54bv;Academy of Management Annals;2020.0;33;['Computer Science', 'Artificial Intelligence']
04de4d9eb0d53025c8ab6c99d1e743f4c1bc1eb6;Systematic review of research on artificial intelligence applications in higher education – where are the educators?;;['1389230375', '11130878', '145768607', '1389230390'];['Olaf Zawacki-Richter', 'Victoria I. Marín', 'Melissa Bond', 'Franziska Gouverneur'];;;;;;;h3w0netw;International Journal of Educational Technology in Higher Education;2019.0;16;['Psychology', 'Artificial Intelligence']
928cd808aba140ec298508df87c5579811ff2f41;Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing;With the breakthroughs in deep learning, the recent years have witnessed a booming of artificial intelligence (AI) applications and services, spanning from personal assistant to recommendation systems to video/audio surveillance. More recently, with the proliferation of mobile computing and Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend, there is an urgent need to push the AI frontiers to the network edge so as to fully unleash the potential of the edge big data. To meet this demand, edge computing, an emerging paradigm that pushes computing tasks and services from the network core to the network edge, has been widely recognized as a promising solution. The resulted new interdiscipline, edge AI or edge intelligence (EI), is beginning to receive a tremendous amount of interest. However, research on EI is still in;['145447664', '1712187180', '2053811799', '123047372', '48181063', '47540395'];['Zhi Zhou', 'Xu Chen', 'En Li', 'Liekang Zeng', 'Ke Luo', 'Junshan Zhang'];;;;;;;hclg5ts0;Proceedings of the IEEE;2019.0;107;['Computer Science', 'Artificial Intelligence']
e5ab21314e9c7b226dfa3c7d6f4d85d8205f878f;Artificial Intelligence in Education: AIEd for Personalised Learning Pathways;Artificial intelligence is the driving force of change focusing on the needs and demands of the student. The research explores Artificial Intelligence in Education (AIEd) for building personalised learning systems for students. The research investigates and proposes a framework for AIEd: social networking sites and chatbots, expert systems for education, intelligent mentors and agents, machine learning, personalised educational systems and virtual educational environments. These technologies help educators to develop and introduce personalised approaches to master new knowledge and develop professional competencies. The research presents a case study of AIEd implementation in education. The scholars conducted the experiment in educational establishments using artificial intelligence in the curriculum. The scholars surveyed 184 second-year students of the Institute of Pedagogy and Psychology at the Abay Kazakh National Pedagogical University and the Kuban State Technological University to collect the data. The scholars considered the collective group discussions regarding the application of artificial intelligence in;['117460583', '114349563', '2188187520'];['Olga Tapalova', 'N. Zhiyenbayeva', 'Dmitry Gura'];;;;;;;ui2lijrb;Electronic Journal of e-Learning;2022.0;67;['Artificial Intelligence']
ccd561625ae82694965d6cbc724086d5f0e00db9;Human activity recognition in artificial intelligence framework: a narrative review;;['2151682130', '2157684312', '2171311970', '49190138', '66904766', '1708097'];['Neha Gupta', 'S. Gupta', 'R. K. Pathak', 'Vanita Jain', 'P. Rashidi', 'J. Suri'];;;;;;;k0xu9ktt;Artificial Intelligence Review;2022.0;55;['Computer Science', 'Medicine', 'Artificial Intelligence']
c4f0566184ebc179c95d6f02daaac94b9802d1df;Artificial intelligence in medical education: a cross-sectional needs assessment;;['2076220979', '5802905', '2083433068', '2190293701', '2190293736'];['M. M. Civaner', 'Y. Uncu', 'Filiz Bulut', 'Esra Giounous Chalil', 'Abdülhamit Tatli'];;;;;;;49zhrvow;BMC Medical Education;2022.0;22;['Medicine', 'Artificial Intelligence']
573e6814c16178186daf537b1e1a5d3c840eef2f;Artificial Intelligence in Service;Artificial intelligence (AI) is increasingly reshaping service by performing various tasks, constituting a major source of innovation, yet threatening human jobs. We develop a theory of AI job replacement to address this double-edged impact. The theory specifies four intelligences required for service tasks—mechanical, analytical, intuitive, and empathetic—and lays out the way firms should decide between humans and machines for accomplishing those tasks. AI is developing in a predictable order, with mechanical mostly preceding analytical, analytical mostly preceding intuitive, and intuitive mostly preceding empathetic intelligence. The theory asserts that AI job replacement occurs fundamentally at the task level, rather than the job level, and for “lower” (easier for AI) intelligence tasks first. AI first replaces some of a service job’s tasks, a transition stage seen as augmentation, and then progresses to replace human labor entirely when it has the ability to take over all of a job’s tasks. The progression of;['50474058', '1813939'];['Ming-Hui Huang', 'R. Rust'];;;;;;;hmfvxa50;Journal of Service Research;2018.0;21;['Computer Science', 'Artificial Intelligence']
e7ed9a61f6b1df3eab50d4f50dc0f7e1ef2b7705;Quo vadis artificial intelligence?;;['7911993', '47057383', '145639696', '2087552576', '1682050'];['Yuchen Jiang', 'Xiang Li', 'Hao Luo', 'Shen Yin', 'O. Kaynak'];;;;;;;dofot9k6;Discover Artificial Intelligence;2022.0;2;['Computer Science', 'Artificial Intelligence']
94e32a898cc8c62c5a25fb9fa01e94c21fd41da5;On scientific understanding with artificial intelligence;;['5906965', '6161242', '47508730', '3372027', '1403855077', '35323511', '40133053', '122433803', '3364349', '133638577', '12977956', '1380248954'];['Mario Krenn', 'R. Pollice', 'S. Guo', 'Matteo Aldeghi', 'Alba Cervera-Lierta', 'Pascal Friederich', 'Gabriel dos Passos Gomes', 'Florian Hase', 'A. Jinich', 'AkshatKumar Nigam', 'Zhenpeng Yao', 'Alán Aspuru-Guzik'];;;;;;;byf3l2qr;Nature Reviews. Physics;2022.0;4;['Computer Science', 'Physics', 'Medicine', 'Artificial Intelligence']
3ce5a172a96008cbdc5ffedf4572b783301fd468;The role of artificial intelligence in achieving the Sustainable Development Goals;;['15687110', '2622491', '39799707', '2599601', '1716665', '6126354', '122252143', '34642801', '2011933', '41019599'];['R. Vinuesa', 'Hossein Azizpour', 'Iolanda Leite', 'Madeline Balaam', 'Virginia Dignum', 'S. Domisch', 'Anna Felländer', 'S. Langhans', 'Max Tegmark', 'F. F. Nerini'];;;;;;;k3vomouf;Nature Communications;2019.0;11;['Computer Science', 'Business', 'Medicine', 'Artificial Intelligence']
d54d6ab14e409e8d2555a1c847800f4506abc7a6;Artificial Intelligence in Medicine;;['2315304608', '2273576504'];['Tahereh Mahmoudi', 'Alireza Mehdizadeh'];;;;;;;h7wlcm2f;Journal of Biomedical Physics & Engineering;2022.0;12;['Medicine', 'Artificial Intelligence']
6fb5ca0ff6821a92b080d0654d245d2407484701;The Roles of Personality Traits, AI Anxiety, and Demographic Factors in Attitudes toward Artificial Intelligence;Abstract The present study adapted the General Attitudes toward Artificial Intelligence Scale (GAAIS) to Turkish and investigated the impact of personality traits, artificial intelligence anxiety, and demographics on attitudes toward artificial intelligence. The sample consisted of 259 female (74%) and 91 male (26%) individuals aged between 18 and 51 (Mean = 24.23). Measures taken were demographics, the Ten-Item Personality Inventory, the Artificial Intelligence Anxiety Scale, and the General Attitudes toward Artificial Intelligence Scale. The Turkish GAAIS had good validity and reliability. Hierarchical Multiple Linear Regression Analyses showed that positive attitudes toward artificial intelligence were significantly predicted by the level of computer use (β = 0.139, p = 0.013), level of knowledge about artificial intelligence (β = 0.119, p = 0.029), and AI learning anxiety (β = −0.172, p = 0.004). Negative attitudes toward artificial intelligence were significantly predicted by agreeableness (β = 0.120, p = 0.019), AI configuration anxiety (β;['2072226241', '34909038', '3074222', '2492734', '2195204506', '2221027869'];['Feridun Kaya', 'F. Aydın', 'A. Schepman', 'P. Rodway', 'Okan Yeti̇şensoy', 'Meva Demir Kaya'];;;;;;;ddhy3xp2;International Journal of Human–Computer Interaction;2022.0;40;['Computer Science', 'Graph', 'Artificial Intelligence']
b4916c497d996ad21433a8fda701b6306b0854cd;Artificial Intelligence and Life in 2030: The One Hundred Year Study on Artificial Intelligence;"In September 2016, Stanford's""One Hundred Year Study on Artificial Intelligence""project (AI100) issued the first report of its planned long-term periodic assessment of artificial intelligence (AI) and its impact on society. It was written by a panel of 17 study authors, each of whom is deeply rooted in AI research, chaired by Peter Stone of the University of Texas at Austin. The report, entitled""Artificial Intelligence and Life in 2030,""examines eight domains of typical urban settings on which AI is likely to have impact over the coming years: transportation, home and service robots, healthcare, education, public safety and security, low-resource communities, employment and workplace, and entertainment. It aims to provide the general public with a scientifically and technologically accurate portrayal of the current state of AI and its potential and to help guide decisions in industry and governments, as well as to inform research and development in the field. The charge for";['144848112', '72419159', '2841157', '3014341', '1741101', '2942743', '144049352', '3027736', '1783184', '1691597', '1388404060', '30907562', '81619738', '98622177', '143873972', '143736701', '2862181'];['P. Stone', 'R. Brooks', 'Erik Brynjolfsson', 'Ryan Calo', 'Oren Etzioni', 'G. Hager', 'Julia Hirschberg', 'Shivaram Kalyanakrishnan', 'Ece Kamar', 'Sarit Kraus', 'Kevin Leyton-Brown', 'D. Parkes', 'W. Press', 'A. Saxenian', 'J. Shah', 'Milind Tambe', 'Astro Teller'];;;;;;;vgft3ot8;ArXiv;2022.0;abs/2211.06318;['Computer Science', 'Artificial Intelligence']
d55e70a42579c7895938b6c43736163dbaf55145;The practical implementation of artificial intelligence technologies in medicine;;['144910737', '5603320', '2145754429', '2205683005', '2148930082', '49481165'];['J. He', 'Sally L. Baxter', 'Jie Xu', 'Jiming Xu', 'Xingtao Zhou', 'Kang Zhang'];;;;;;;ii702bo2;Nature Medicine;2019.0;25;['Computer Science', 'Medicine', 'Artificial Intelligence']
5e2ef6abd77e9d3512e4f9ba694d7c6ad35c8db5;Explainable Artificial Intelligence Applications in Cyber Security: State-of-the-Art in Research;This survey presents a comprehensive review of current literature on Explainable Artificial Intelligence (XAI) methods for cyber security applications. Due to the rapid development of Internet-connected systems and Artificial Intelligence in recent years, Artificial Intelligence including Machine Learning (ML) and Deep Learning (DL) has been widely utilized in the fields of cyber security including intrusion detection, malware detection, and spam filtering. However, although Artificial Intelligence-based approaches for the detection and defense of cyber attacks and threats are more advanced and efficient compared to the conventional signature-based and rule-based cyber security strategies, most ML-based techniques and DL-based techniques are deployed in the “black-box” manner, meaning that security experts and customers are unable to explain how such procedures reach particular conclusions. The deficiencies of transparencies and interpretability of existing Artificial Intelligence techniques would decrease human users’ confidence in the models utilized for the defense against cyber attacks, especially in current situations where;['2180312550', '2738833', '2054656008', '2292768', '2183484005'];['Zhibo Zhang', 'H. A. Hamadi', 'E. Damiani', 'C. Yeun', 'Fatma Taher'];;;;;;;wpfb4vka;IEEE Access;2022.0;10;['Computer Science', 'Artificial Intelligence']
5d5829723fb240543ff15ffeda1f63fff47f628d;Has the Future Started? The Current Growth of Artificial Intelligence, Machine Learning, and Deep Learning;In the modern era, many terms related to artificial intelligence, machine learning, and deep learning are widely used in domains such as business, healthcare, industries, and military. In these fields, the accurate prediction and analysis of data are crucial, regardless of how large the data are. However, using big data is confusing due to the rapid growth and massive development in public life, which requires a tremendous human effort in order to deal with such type of data and extract worthy information from it. Thus, the role of artificial intelligence begins in analyzing big data based on scientific techniques, especially in machine learning, whereby it can identify patterns of decision-making and reduce human intervention. In this regard, the significance role of artificial intelligence, machine learning and deep learning is growing rapidly. In this article, the authors decide to highlight these sciences by discussing how to develop and apply them in;['1394846990'];['Maad M. Mijwil'];;;;;;;thpfgjig;Iraqi Journal for Computer Science and Mathematics;2022.0;38;['Deep Learning', 'Machine Learning', 'Artificial Intelligence']
8e08f45826991850f3077dc09206ae4a4f94d194;Artificial intelligence in cancer target identification and drug discovery;;['1947879835', '145954546', '2115431014', '32421199', '145755245', '2108164991', '7941050', '2108007081'];['Yujie You', 'Xin Lai', 'Ying Pan', 'Huiru Zheng', 'J. Vera', 'Suran Liu', 'Senyi Deng', 'Le Zhang'];;;;;;;1dfygowm;Signal Transduction and Targeted Therapy;2022.0;7;['Medicine', 'Artificial Intelligence']
5e7a7fb69ef7447c2cb8966589e49a5acbee416e;Photonics for artificial intelligence and neuromorphic computing;;['2694890', '2304580', '3400685', '144372362', '1771881', '51032756', '144504492'];['B. Shastri', 'A. Tait', 'T. F. D. Lima', 'W. Pernice', 'H. Bhaskaran', 'C. Wright', 'P. Prucnal'];;;;;;;iyi7uqnz;Nature Photonics;2020.0;15;['Computer Science', 'Physics', 'Artificial Intelligence']
36e2d3fd64ac4b9d1de81efd7db13c394f9dc95d;Artificial Intelligence in Meta-optics;Recent years have witnessed promising artificial intelligence (AI) applications in many disciplines, including optics, engineering, medicine, economics, and education. In particular, the synergy of AI and meta-optics has greatly benefited both fields. Meta-optics are advanced flat optics with novel functions and light-manipulation abilities. The optical properties can be engineered with a unique design to meet various optical demands. This review offers comprehensive coverage of meta-optics and artificial intelligence in synergy. After providing an overview of AI and meta-optics, we categorize and discuss the recent developments integrated by these two topics, namely AI for meta-optics and meta-optics for AI. The former describes how to apply AI to the research of meta-optics for design, simulation, optical information analysis, and application. The latter reports the development of the optical Al system and computation via meta-optics. This review will also provide an in-depth discussion of the challenges of this interdisciplinary field and indicate future;['47110824', '2125533006', '1790053', '145704135'];['M. Chen', 'Xiaoyuan Liu', 'Yanni Sun', 'D. Tsai'];;;;;;;2y6pnt73;Chemical Reviews;2022.0;122;['Medicine', 'Artificial Intelligence']
bfa4ea39e94e38160e4277dfaff5a3c20ba1498a;Principles of Artificial Intelligence;;['144497046'];['N. Nilsson'];;;;;;;ayy9urd4;Computer Science Journal (1980.0);1980.0;58;['Computer Science', 'Artificial Intelligence']
6094988c9ebe2621e6cccc7bc6f52248117e19d0;Frontiers in Artificial Intelligence and Applications;The industrial revolution has been the main cause ever since tremendous technological advancement was observed. The ubiquitous deployment of recent information and communication technologies (ICT), namely Artificial Intelligence (AI), Internet of Things (IoT), and Blockchain technology, is hastening the world’s industrial and technological transformation. This technical aggrandizement enhances the working culture and has a favorable impact on the workplace, as per the progressivist perspective. The breakneck pace of technological advancement, as well as AI, has enabled humans to replace manual labor in various industries. As being a domain of science and technology, AI develops machines and programs for computers that are intelligent and can accomplish tasks that would normally require human intelligence abilities. This paper mainly explores the frontiers of artificial intelligence and its applications in various fields. The AI Frontiers promulgate methodical concepts that are peer-reviewed cutting-edge research on the disruptive technological revolution of Artificial Intelligence. Additionally, some key;['2166510594', '2150905435', '2114155627', '2058601822', '2114358369', '2181846833'];['Jaya Yadav', 'S. Shukla', 'Kanika Sharma', 'Nupur Soni', 'S. Agarwal', 'Prabhash Chandra Pathak'];;;;;;;onshl7ic;2022 3rd International Conference on Computation, Automation and Knowledge Management (ICCAKM);2022.0;64;['Artificial Intelligence']
7e23275f8b809b7a2e95895a31a6cfeb816eddb4;Artificial Intelligence and Chatbots in Psychiatry;;['2007879606', '2156132843', '2054695'];['K. T. Pham', 'Amir Nabizadeh', 'S. Selek'];;;;;;;2p3w6iq7;The Psychiatric Quarterly;2022.0;93;['Medicine', 'Artificial Intelligence']
c4028f56b7eda912ba0d8471cd752eacddeb131f;Future paths for integer programming and links to artificial intelligence;;['145740789'];['F. Glover'];;;;;;;u46pqr5h;Comput. Oper. Res.;1986.0;13;['Computer Science', 'Artificial Intelligence']
3221bd430f90af7ebc033b8a10dab08fc40c8eba;Attitudes and perception of artificial intelligence in healthcare: A cross-sectional survey among patients;Objective The attitudes about the usage of artificial intelligence in healthcare are controversial. Unlike the perception of healthcare professionals, the attitudes of patients and their companions have been of less interest so far. In this study, we aimed to investigate the perception of artificial intelligence in healthcare among this highly relevant group along with the influence of digital affinity and sociodemographic factors. Methods We conducted a cross-sectional study using a paper-based questionnaire with patients and their companions at a German tertiary referral hospital from December 2019 to February 2020. The questionnaire consisted of three sections examining (a) the respondents’ technical affinity, (b) their perception of different aspects of artificial intelligence in healthcare and (c) sociodemographic characteristics. Results From a total of 452 participants, more than 90% already read or heard about artificial intelligence, but only 24% reported good or expert knowledge. Asked on their general perception, 53.18% of the respondents;['50164013', '8374155', '2046108306', '2181097010', '152547573', '1491959023', '32768441', '28974379', '2065806540', '2065214877', '5358528'];['S. Fritsch', 'Andrea Blankenheim', 'Alina Wahl', 'Petra Hetfeld', 'Oliver Maassen', 'Saskia Deffge', 'J. Kunze', 'R. Rossaint', 'Morris Riedel', 'G. Marx', 'J. Bickenbach'];;;;;;;j906izeh;Digital Health;2022.0;8;['Medicine', 'Artificial Intelligence']
83311744b174550032cfe09cb2940703dc9c9245;A Review of Artificial Intelligence (AI) in Education from 2010 to 2020;This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role-playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. However, we also proposed the challenges in education may be caused by AI with regard to inappropriate;['48549659', '2056599771', '3225877', '2692438', '2339850159', '38749421', '2859865', '2118573866', '2152884118'];['Xuesong Zhai', 'Xiaoyan Chu', 'C. Chai', 'M. Jong', 'Andreja Istenic', 'Michael Spector', 'Jia-bao Liu', 'Jing Yuan', 'Yan Li'];8bc59e8b-e251-4201-839a-ec83ae78859d;Complex;conference;10;2021.0;Paris;;;;;['Computer Science', 'Engineering', 'Artificial Intelligence']
0ca9a5ef7695fdaa65325761164c70e56739a902;Explainable artificial intelligence: an analytical review;This paper provides a brief analytical review of the current state‐of‐the‐art in relation to the explainability of artificial intelligence in the context of recent advances in machine learning and deep learning. The paper starts with a brief historical introduction and a taxonomy, and formulates the main challenges in terms of explainability building on the recently formulated National Institute of Standards four principles of explainability. Recently published methods related to the topic are then critically reviewed and analyzed. Finally, future directions for research are suggested.;['1719855', '1380985003', '2121936670', '2123993921', '2124304074'];['P. Angelov', 'E. Soares', 'Richard Jiang', 'Nicholas I. Arnold', 'Peter M. Atkinson'];;;;;;;9vjzt6ml;Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery;2021.0;11;['Computer Science', 'Artificial Intelligence']
be0bbf06977c4dadbf702287733187884a531b8a;Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications;The thriving of artificial intelligence (AI) applications is driving the further evolution of wireless networks. It has been envisioned that 6G will be transformative and will revolutionize the evolution of wireless from “connected things” to “connected intelligence”. However, state-of-the-art deep learning and big data analytics based AI systems require tremendous computation and communication resources, causing significant latency, energy consumption, network congestion, and privacy leakage in both of the training and inference processes. By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks. In this paper, we shall provide our vision for scalable and trustworthy edge AI systems with integrated design of wireless communication strategies and decentralized machine learning models. New design principles of wireless networks, service-driven resource allocation optimization methods,;['145142172', '1754997', '2933300', '1694070'];['K. Letaief', 'Yuanming Shi', 'Jianmin Lu', 'Jianhua Lu'];;;;;;;dwz8enl0;IEEE Journal on Selected Areas in Communications;2021.0;40;['Computer Science', 'Mathematics', 'Engineering', 'Artificial Intelligence']
bd3d0238549555bd07fd25ff61b3d7e01eb02296;Artificial intelligence, robotics, advanced technologies and human resource management: a systematic review;Abstract Although academic production in intelligent automation (e.g. artificial intelligence, robotics) has grown rapidly, we still lack a comprehensive understanding of the impacts of the utilization of these technologies in human resource management (HRM) at an organizational (firms) and individual (employees) level. This study therefore aims to systematize the academic inputs on intelligent automation so far and to clarify what are its main contributions to and challenges for HRM. In a systematic search of 13,136 potentially relevant studies published in the top HRM, international business (IB), general management (GM) and information management (IM) journals, we found 45 articles studying artificial intelligence, robotics and other advanced technologies within HRM settings. Results show that intelligent automation technologies constitute a new approach to managing employees and enhancing firm performance, thus offering several opportunities for HRM but also considerable challenges at a technological and ethical level. The impact of these technologies has been identified;['144031328', '118624908', '50367941', '70668917', '1395358767', '1753048114'];['D. Vrontis', 'M. Christofi', 'V. Pereira', 'S. Tarba', 'Anna Makrides', 'Eleni Trichina'];;;;;;;wefmmmim;The International Journal of Human Resource Management;2021.0;33;['Engineering', 'Artificial Intelligence']
a81434e08ea760cc364c5a9d8aa8cdc09fcbc9f1;The role of artificial intelligence in healthcare: a structured literature review;;['14172485', '144730270', '2054029', '2576041', '15601380'];['Silvana Secinaro', 'D. Calandra', 'A. Secinaro', 'V. Muthurangu', 'P. Biancone'];;;;;;;3fafnuvm;BMC Medical Informatics and Decision Making;2021.0;21;['Computer Science', 'Medicine', 'Artificial Intelligence']
2b6d375d8abea91d46894ebfa7051077253834d5;Artificial intelligence in healthcare: transforming the practice of medicine;ABSTRACT Artificial intelligence (AI) is a powerful and disruptive area of computer science, with the potential to fundamentally transform the practice of medicine and the delivery of healthcare. In this review article, we outline recent breakthroughs in the application of AI in healthcare, describe a roadmap to building effective, reliable and safe AI systems, and discuss the possible future direction of AI augmented healthcare systems.;['2119588844', '1610512742', '2064953709', '2116406786'];['Junaid Bajwa', 'Usman Munir', 'A. Nori', 'Bryan Williams'];;;;;;;1z0tufba;Future Healthcare Journal;2021.0;8;['Medicine', 'Artificial Intelligence']
29409efa04ac99ccf01d2a011d21d5d14e870000;Artificial intelligence to deep learning: machine intelligence approach for drug discovery;;['1409846740', '153610437', '2059118408', '2072850683', '2288195', '38183916'];['Rohan Gupta', 'Devesh Srivastava', 'Mehar Sahu', 'Swati Tiwari', 'R. K. Ambasta', 'Pravir Kumar'];;;;;;;xn1tmoeo;Molecular Diversity;2021.0;25;['Deep Learning', 'Medicine', 'Artificial Intelligence']
a7a65aec0792126674544fdbdca1aff418de3add;Artificial intelligence-enhanced electrocardiography in cardiovascular disease management;;['6908069', '6995238', '6853697', '2002102'];['K. Siontis', 'P. Noseworthy', 'Z. Attia', 'P. Friedman'];;;;;;;gn0q33ap;Nature Reviews. Cardiology;2021.0;18;['Graph', 'Medicine', 'Artificial Intelligence']
d1f0f33c197dc9932c4a2e42eb1a8a60635bb401;Explainable artificial intelligence: a comprehensive review;;['104177601', '2155245925', '2156020692', '2116488047'];['Dang Minh', 'H. X. Wang', 'Y. Li', 'Tan N. Nguyen'];;;;;;;7hule4rn;Artificial Intelligence Review;2021.0;55;['Computer Science', 'Artificial Intelligence']
1b98394ce2be8a7bf575d3b5ef8b569396e60c63;Artificial Intelligence in Agriculture;Abstract: Agriculture Sector plays important role in economic sector. The artificial intelligence is main concern and the emerging subject all across world. And population increasing day by day and with the increasing demand employment and food is also increasing. Our traditional method which was used by the farmer were not sufficient enough to fulfill the requirements. Consequently, synthetic intelligence technique is added. This method supplied meals requirement and employment possibilities to many people. Artificial Intelligence in agriculture has added associate agriculture revolution. This generation has covered the crop yield from different factors like weather adjustments, populace increase, employment problems, and meals protection issues. This era includes crop yields caused by various factors such as climate change, population surge, employment issues, and food security issues. The main difficulty of the document is to verify the many artificial intelligence applications in agriculture, including irrigation, weeding and spraying integrated with sensors and other;['1926074', '2224940232', '2227972532', '2227824879', '2227915651'];['Nikhil Gupta', 'Pooja Gupta', 'Dayam Nadeem', 'Abuzar A', 'Anam Elahi'];;;;;;;vmf4wx7l;International Journal for Research in Applied Science and Engineering Technology;2022.0;53;['Artificial Intelligence']
286a3bf8579deadd9b892bb800614b7c35d5d9a6;Artificial Intelligence and Business Value: a Literature Review;;['2111962291', '2088536305', '2424691', '1716522'];['Ida Merete Enholm', 'Emmanouil Papagiannidis', 'Patrick Mikalef', 'J. Krogstie'];;;;;;;nmat7b1f;Information Systems Frontiers;2021.0;24;['Computer Science', 'Business', 'Artificial Intelligence']
9f3c794596eccef62ee42d595e233ce958678e04;Artificial Intelligence in Dentistry—Narrative Review;Nowadays, artificial intelligence (AI) is becoming more important in medicine and in dentistry. It can be helpful in many fields where the human may be assisted and helped by new technologies. Neural networks are a part of artificial intelligence, and are similar to the human brain in their work and can solve given problems and make fast decisions. This review shows that artificial intelligence and the use of neural networks has developed very rapidly in recent years, and it may be an ordinary tool in modern dentistry in the near future. The advantages of this process are better efficiency, accuracy, and time saving during the diagnosis and treatment planning. More research and improvements are needed in the use of neural networks in dentistry to put them into daily practice and to facilitate the work of the dentist.;['108108559', '49913591', '5003431'];['Agata Ossowska', 'A. Kusiak', 'D. Świetlik'];;;;;;;c3elob78;International Journal of Environmental Research and Public Health;2022.0;19;['Medicine', 'Artificial Intelligence']
38f23fe236b152cd4983c8f30d305a568afd0d3e;A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI;Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide “obviously” interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in;['71352570', '145836900'];['Erico Tjoa', 'Cuntai Guan'];;;;;;;oac51m82;IEEE Transactions on Neural Networks and Learning Systems;2019.0;32;['Computer Science', 'Medicine', 'Artificial Intelligence']
129c66d240883c735dbb08c8f025a6573328827b;The Clinician and Dataset Shift in Artificial Intelligence.;To the Editor: Artificial intelligence (AI) systems are now regularly being used in medical settings,1 although regulatory oversight is inconsistent and undeveloped.2,3 Safe deployment of clinical AI requires informed clinician-users, who are generally responsible for identifying and reporting emerging problems. Clinicians may also serve as administrators in governing the use of clinical AI. A natural question follows: are clinicians adequately prepared to identify circumstances in which AI systems fail to perform their intended function reliably? A major driver of AI system malfunction is known as “dataset shift.”4,5 Most clinical AI systems today use machine learning, algorithms that leverage statistical methods to learn key patterns from clinical data. Dataset shift occurs when a machine-learning system underperforms because of a mismatch between the data set with which it was developed and the data on which it is deployed.4 For example, the University of Michigan Hospital implemented the widely used sepsis-alerting model developed;['50478054', '2928932', '48829479', '2066570629', '2049907921', '46714697', '1740538', '1932128'];['S. G. Finlayson', 'Adarsh Subbaswamy', 'Karandeep Singh', 'John Bowers', 'Annabel Kupke', 'Jonathan Zittrain', 'I. Kohane', 'S. Saria'];;;;;;;mden0xnq;The New England journal of medicine;2021.0;385 3;['Medicine', 'Artificial Intelligence']
4d0b7f66b75cb87ed3da5ffc024ff56b10303dcc;Artificial intelligence–enabled rapid diagnosis of patients with COVID-19;;['2708291', '2570042', '2076814868', '50474061', '38038984', '2107899821', '2132383779', '2146276078', '33887290', '49045041', '46774698', '47560240', '32535758', '12851148', '50342118', '144713402', '2054670268', '1704218299', '1703493970', '121801992', '38164889', '4028845', '5157931', '2642524', '2170730373', '24801515', '1886137', '2152920123'];['X. Mei', 'Hao-Chih Lee', 'Kai-yue Diao', 'Mingqian Huang', 'Bin Lin', 'Chenyu Liu', 'Zongyu Xie', 'Yixuan Ma', 'P. Robson', 'M. Chung', 'Adam Bernheim', 'V. Mani', 'C. Calcagno', 'Kunwei Li', 'Shaolin Li', 'H. Shan', 'Jian Lv', 'Tongtong Zhao', 'Junli Xia', 'Qihua Long', 'Sharon Steinberger', 'A. Jacobi', 'T. Deyer', 'M. Luksza', 'Fang Liu', 'B. Little', 'Z. Fayad', 'Yang Yang'];;;;;;;ra273tw6;Nature Medicine;2020.0;26;['Medicine', 'Artificial Intelligence']
9c145390e6073c96e89cf03d3df3b559f0bb0496;Artificial Intelligence and Management: The Automation–Augmentation Paradox;Taking three recent business books on artificial intelligence (AI) as a starting point, we explore the automation and augmentation concepts in the management domain. Whereas automation implies that...;['2729443', '90481203'];['Sebastian Raisch', 'Sebastian Krakowski'];;;;;;;te4zrudr;Academy of Management Review;2020.0;92;['Computer Science', 'Artificial Intelligence']
cb0cae7f42d0666d9d90b1ca93416abcccef7c44;Predicting cancer outcomes with radiomics and artificial intelligence in radiology;;['46459416', '11014238', '2110094496', '6731233', '1705442'];['K. Bera', 'Nathaniel Braman', 'Amit Gupta', 'V. Velcheti', 'A. Madabhushi'];;;;;;;psqctavw;Nature Reviews Clinical Oncology;2021.0;19;['Medicine', 'Artificial Intelligence']
e49f67fa5c946ad24afcf59699a9cacf1ca53924;Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy;ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.;['1740403'];['B. Shneiderman'];;;;;;;6k3nc6i9;International Journal of Human–Computer Interaction;2020.0;36;['Computer Science', 'Artificial Intelligence']
ccca203382e5dd198c089a0f1d7af7bef0f694e9;TBtools - an integrative toolkit developed for interactive analyses of big biological data.;;['2145774899', '2149052058', '2153911296', '40451574', '143915524', '4098270', '144304984'];['Chengjie Chen', 'Hao Chen', 'Yi Zhang', 'Hannah R Thomas', 'Margaret H. Frank', 'Yehua He', 'Rui Xia'];;;;;;;95hktinh;Molecular plant;2020.0;53;['Medicine', 'Biology']
91b63db746becca15090963a8990dfe2b5103799;Big data: The next frontier for innovation, competition, and productivity;The amount of data in our world has been exploding, and analyzing large data sets—so-called big data— will become a key basis of competition, underpinning new waves of productivity growth, innovation, and consumer surplus, according to research by MGI and McKinsey's Business Technology Office. Leaders in every sector will have to grapple with the implications of big data, not just a few data-oriented managers. The increasing volume and detail of information captured by enterprises, the rise of multimedia, social media, and the Internet of Things will fuel exponential growth in data for the foreseeable future.;['144605904'];['J. Manyika'];;;;;;;e94s4s0r;Business Magazine (2011.0);2011.0;;['Business', 'Big Data']
f117c6f12d067bd66dad40996b3931c069daa2da;Business Intelligence and Analytics: From Big Data to Big Impact;Business intelligence and analytics (BI&A) has emerged as an important area of study for both practitioners and researchers, reflecting the magnitude and impact of data-related problems to be solved in contemporary business organizations. This introduction to the MIS Quarterly Special Issue on Business Intelligence Research first provides a framework that identifies the evolution, applications, and emerging research areas of BI&A. BI&A 1.0, BI&A 2.0, and BI&A 3.0 are defined and described in terms of their key characteristics and capabilities. Current research in BI&A is analyzed and challenges and opportunities associated with BI&A research and education are identified. We also report a bibliometric study of critical BI&A publications, researchers, and research topics based on more than a decade of related academic and industry publications. Finally, the six articles that comprise this special issue are introduced and characterized in terms of the proposed BI&A research framework.;['47666658', '145802082', '1764975'];['Hsinchun Chen', 'R. Chiang', 'V. Storey'];;;;;;;qhmx9jyj;MIS Q.;2012.0;36;['Computer Science', 'Big Data', 'Engineering', 'Analytics']
bf5a42b53d156c0811e88e60d2a49f9fd9367cae;Big data: the management revolution.;Big data, the authors write, is far more powerful than the analytics of the past. Executives can measure and therefore manage more precisely than ever before. They can make better predictions and smarter decisions. They can target more-effective interventions in areas that so far have been dominated by gut and intuition rather than by data and rigor. The differences between big data and analytics are a matter of volume, velocity, and variety: More data now cross the internet every second than were stored in the entire internet 20 years ago. Nearly real-time information makes it possible for a company to be much more agile than its competitors. And that information can come from social networks, images, sensors, the web, or other unstructured sources. The managerial challenges, however, are very real. Senior decision makers have to learn to ask the right questions and embrace evidence-based decision making. Organizations must hire scientists;['3132693', '2841157'];['Andrew P. McAfee', 'Erik Brynjolfsson'];;;;;;;l7u948g8;Harvard business review;2012.0;90 10;['Computer Science', 'Medicine', 'Big Data']
4b06c7e29280b1c6bc05c9df39023b48fef02c93;Escaping the Big Data Paradigm with Compact Transformers;With the rise of Transformers as the standard for language processing, and their advancements in computer vision, there has been a corresponding growth in parameter size and amounts of training data. Many have come to believe that because of this, transformers are not suitable for small sets of data. This trend leads to concerns such as: limited availability of data in certain scientific domains and the exclusion of those with limited resource from research in the field. In this paper, we aim to present an approach for small-scale learning by introducing Compact Transformers. We show for the first time that with the right size, convolutional tokenization, transformers can avoid overfitting and outperform state-of-the-art CNNs on small datasets. Our models are flexible in terms of model size, and can have as little as 0.28M parameters while achieving competitive results. Our best model can reach 98% accuracy when training from scratch on;['2855934', '102471415', '2087066452', '133551208', '2125031571', '48667025'];['Ali Hassani', 'Steven Walton', 'Nikhil Shah', 'Abulikemu Abuduweili', 'Jiachen Li', 'Humphrey Shi'];;;;;;;0khv4b2h;ArXiv;2021.0;abs/2104.05704;['Computer Science', 'Big Data']
85328b4a8132bf4299f8cd7f8e79e850d561c8fc;Big Data Analytics: A Survey;"Internet-based programs and communication techniques have become widely used and respected in the IT industry recently. A persistent source of ""big data,"" or data that is enormous in volume, diverse in type, and has a complicated multidimensional structure, is internet applications and communications. Today, several measures are routinely performed with no assurance that any of them will be helpful in understanding the phenomenon of interest in an era of automatic, large-scale data collection. Online transactions that involve buying, selling, or even investing are all examples of e-commerce. As a result, they generate data that has a complex structure and a high dimension. The usual data storage techniques cannot handle those enormous volumes of data. There is a lot of work being done to find ways to minimize the dimensionality of big data in order to provide analytics reports that are even more accurate and data visualizations that are more interesting.";['2269971203', '2261850659'];['Wasnaa Kadhim Jawad', 'Abbas M. Al-Bakry'];;;;;;;4doiua4a;Iraqi Journal for Computers and Informatics;2022.0;51;['Big Data', 'Analytics']
41d4e093d5f7ed5aae1aaa9eb6c037742e4cf9b1;The use of Big Data Analytics in healthcare;;['2416504', '2079538975'];['Kornelia M. Batko', 'A. Ślęzak'];;;;;;;3d2j0z20;Journal of Big Data;2022.0;9;['Computer Science', 'Medicine', 'Big Data', 'Analytics']
cc017a62c605a0749e35a1264a46d62e78fb68b7;Big Data Analytics;;['46251839', '2237403667', '2283455003'];['Arsalan Zahid Piprani', 'Amjad Ali', 'Adeel Shah'];;;;;;;yibs6u1k;Big Data;2019.0;22;['Computer Science', 'Big Data', 'Analytics']
1bc34cb22131554ba18f6ba9e6ede5beb42939f1;Beyond the hype: Big data concepts, methods, and analytics;;['2348402835', '39060992'];['Amir Gandomi', 'Murtaza Haider'];;;;;;;lptnbdhz;Int. J. Inf. Manag.;2015.0;35;['Computer Science', 'Big Data', 'Analytics']
4e6bba65f7636a655c778a3e54cc58e148468963;CRITICAL QUESTIONS FOR BIG DATA;The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of analyzing genetic sequences, social media interactions, health records, phone logs, government records, and other digital traces left by people. Significant questions emerge. Will large-scale search data help us create better tools, services, and public goods? Or will it usher in a new wave of privacy incursions and invasive marketing? Will data analytics help us understand online communities and political movements? Or will it be used to track protesters and suppress speech? Will it transform how we study human communication and culture, or narrow the palette of research options and alter what ‘research’ means? Given the rise of Big Data as a socio-technical;['38818867', '48024382'];['D. Boyd', 'K. Crawford'];;;;;;;8dq0rlv2;Information, Communication & Society;2012.0;15;['Sociology', 'Big Data']
38f5b53b49be555430f33b8363910191a3df1d14;A Survey on Big Data Analytics: Challenges, Open Research Issues and Tools;Abstract: A huge repository of terabytes of data is generated each day from modern information systems and digital technologies such as Internet of Things and cloud computing. Analysis of these massive data requires a lot of efforts at multiple levels to extract knowledge for decision making. Therefore, big data analysis is a current area of research and development. The basic objective of this paper is to explore the potential impact of big data challenges, open research issues, and various tools associated with it. As a result, this article provides a platform to explore big data at numerous stages. Additionally, it opens a new horizon for researchers to develop the solution, based on the challenges and open research issues.;['2150744', '2285074747'];['D. Acharjya', 'P. KauserAhmed'];;;;;;;c6cg4ej4;International Journal for Research in Applied Science and Engineering Technology;2022.0;65;['Computer Science', 'Big Data', 'Analytics']
1d174f0e3c391368d0f3384a144a6c7487f2a143;Big Data's Disparate Impact;Advocates of algorithmic techniques like data mining argue that these techniques eliminate human biases from the decision-making process. But an algorithm is only as good as the data it works with. Data is frequently imperfect in ways that allow these algorithms to inherit the prejudices of prior decision makers. In other cases, data may simply reflect the widespread biases that persist in society at large. In still others, data mining can discover surprisingly useful regularities that are really just preexisting patterns of exclusion and inequality. Unthinking reliance on data mining can deny historically disadvantaged and vulnerable groups full participation in society. Worse still, because the resulting discrimination is almost always an unintentional emergent property of the algorithm’s use rather than a conscious choice by its programmers, it can be unusually hard to identify the source of the problem or to explain it to a court.This Essay examines these concerns through;['2881033', '46432110'];['Solon Barocas', 'Andrew D. Selbst'];;;;;;;n9q2vmpy;California Law Review;2016.0;104;['Sociology', 'Big Data']
3a74bed911ccf213d9595b2b02a5b1c4ac4dcaf8;Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy;;['120550117'];['T. Doyle'];;;;;;;64qv0ayi;The Information Society;2017.0;33;['Computer Science', 'Big Data']
178571a5cde984c895493e2eb6c5487449d055cf;Data mining in clinical big data: the frequently used databases, steps, and methodological models;;['2139634153', '12013287', '1500673788', '2156059845', '2110812737', '143908701', '80193067'];['Wen-Tao Wu', 'Yuan-jie Li', 'Aozi Feng', 'Li Li', 'Tao Huang', 'A. Xu', 'Jun Lyu'];;;;;;;jxqd0ffe;Military Medical Research;2021.0;8;['Data Mining', 'Medicine', 'Big Data']
bf69c98fca9a9f6c1cde871beddbcdc668b77771;Big Data: A Revolution That Will Transform How We Live, Work, and Think;Since Aristotle, we have fought to understand the causes behind everything. But this ideology is fading. The world of big data can crunch However the indirect implication of a raw material in cdc data processing. He says most common search terms think we'll have lost. At the damnation profoundly surprising conclusions, from make it seems more recently I think. Less as a fascinatingand sometimes profoundly surprising ways not knowing why only one to find knowledge.;['2289710033'];['Kenneth Cukier'];;;;;;;rzycqvg9;Sociology Bulletin (2015.0);2015.0;67;['Sociology', 'Big Data']
92fd5aaeacaa332a725e72647e20baec5c73b73d;Big Data Analytics in Supply Chain Management: A Systematic Literature Review and Research Directions;Big data analytics has been successfully used for various business functions, such as accounting, marketing, supply chain, and operations. Currently, along with the recent development in machine learning and computing infrastructure, big data analytics in the supply chain are surging in importance. In light of the great interest and evolving nature of big data analytics in supply chains, this study conducts a systematic review of existing studies in big data analytics. This study presents a framework of a systematic literature review from interdisciplinary perspectives. From the organizational perspective, this study examines the theoretical foundations and research models that explain the sustainability and performances achieved through the use of big data analytics. Then, from the technical perspective, this study analyzes types of big data analytics, techniques, algorithms, and features developed for enhanced supply chain functions. Finally, this study identifies the research gap and suggests future research directions.;['2152634067', '2468335'];['In Lee', 'George Mangalaraj'];;;;;;;05nywhi6;Big Data Cogn. Comput.;2022.0;6;['Computer Science', 'Big Data', 'Analytics']
b904dcdbd7c7b33938583f2f57d05ca70e121ea9;An Efficient and Secure Big Data Storage in Cloud Environment by Using Triple Data Encryption Standard;In recent decades, big data analysis has become the most important research topic. Hence, big data security offers Cloud application security and monitoring to host highly sensitive data to support Cloud platforms. However, the privacy and security of big data has become an emerging issue that restricts the organization to utilize Cloud services. The existing privacy preserving approaches showed several drawbacks such as a lack of data privacy and accurate data analysis, a lack of efficiency of performance, and completely rely on third party. In order to overcome such an issue, the Triple Data Encryption Standard (TDES) methodology is proposed to provide security for big data in the Cloud environment. The proposed TDES methodology provides a relatively simpler technique by increasing the sizes of keys in Data Encryption Standard (DES) to protect against attacks and defend the privacy of data. The experimental results showed that the proposed TDES method is;['2186480691', '2200758545', '2150706913', '65965701', '2200528122', '2143272549'];['Mohan Naik Ramachandra', 'Madala Srinivasa Rao', 'W. Lai', 'P. Divakarachari', 'Jayachandra Ananda Babu', 'Hemalatha Kivudujogappa Lingappa'];;;;;;;gbb1mzan;Big Data Cogn. Comput.;2022.0;6;['Cloud', 'Computer Science', 'Big Data', 'Encryption']
f12930cd5f58990badc1a7c5d2749cad004cfb0e;Big data analytics for intelligent manufacturing systems: A review;;['46584628', '153250242', '50561597', '2068352939'];['Junliang Wang', 'Chuqiao Xu', 'Jie Zhang', 'Ray Y. Zhong'];;;;;;;u85vmwrz;Journal of Manufacturing Systems;2021.0;;['Computer Science', 'Big Data', 'Analytics']
fe44200fed05f9a7c656f2245deded8fd5f5e1e6;CatBoost for big data: an interdisciplinary review;;['119723024', '1725285'];['John T. Hancock', 'T. Khoshgoftaar'];;;;;;;flapypeg;Journal of Big Data;2020.0;7;['Computer Science', 'Medicine', 'Big Data']
94deb62af3054c49e7d80bd7eb3ed5efe990fc0b;Traffic Flow Prediction With Big Data: A Deep Learning Approach;Accurate and timely traffic flow information is important for the successful deployment of intelligent transportation systems. Over the last few years, traffic data have been exploding, and we have truly entered the era of big data for transportation. Existing traffic flow prediction methods mainly use shallow traffic prediction models and are still unsatisfying for many real-world applications. This situation inspires us to rethink the traffic flow prediction problem based on deep architecture models with big traffic data. In this paper, a novel deep-learning-based traffic flow prediction method is proposed, which considers the spatial and temporal correlations inherently. A stacked autoencoder model is used to learn generic traffic flow features, and it is trained in a greedy layerwise fashion. To the best of our knowledge, this is the first time that a deep architecture model is applied using autoencoders as building blocks to represent traffic flow features for prediction. Moreover, experiments;['34859953', '2241838', '1903243', '2146248481', '143769760'];['Yisheng Lv', 'Y. Duan', 'Wenwen Kang', 'Z. Li', 'Feiyue Wang'];;;;;;;cwfw9iuk;IEEE Transactions on Intelligent Transportation Systems;2015.0;16;['Computer Science', 'Deep Learning', 'Engineering', 'Big Data']
1597449a7f64b6bd24639b4deab96c8a8c184177;Digital twin-driven product design, manufacturing and service with big data;;['50556355', '49776606', '29011153', '47474337', '2153527172', '50470670'];['F. Tao', 'Jiangfeng Cheng', 'Qinglin Qi', 'Meng Zhang', 'He Zhang', 'Fangyuan Sui'];;;;;;;3humgxct;The International Journal of Advanced Manufacturing Technology;2017.0;94;['Engineering', 'Big Data']
b6b7fea1846e85ac1e3c7e3adda6e65b127d0368;IoT, Big Data, and Artificial Intelligence in Agriculture and Food Industry;Internet of Things (IoT) results in a massive amount of streaming data, often referred to as “big data,” which brings new opportunities to monitor agricultural and food processes. Besides sensors, big data from social media is also becoming important for the food industry. In this review, we present an overview of IoT, big data, and artificial intelligence (AI), and their disruptive role in shaping the future of agri-food systems. Following an introduction to the fields of IoT, big data, and AI, we discuss the role of IoT and big data analysis in agriculture (including greenhouse monitoring, intelligent farm machines, and drone-based crop imaging), supply chain modernization, social media (for open innovation and sentiment analysis) in food industry, food quality assessment (using spectral methods and sensor fusion), and finally, food safety (using gene sequencing and blockchain-based digital traceability). A special emphasis is laid on the commercial status of applications and translational;['144984672', '144929055', '1403270550', '35436614', '47232798', '144186679'];['N. Misra', 'Y. Dixit', 'A. Al-Mallahi', 'Manreet Bhullar', 'R. Upadhyay', 'A. Martynenko'];;;;;;;ldg61fkz;IEEE Internet of Things Journal;2020.0;9;['Computer Science', 'Artificial Intelligence', 'Big Data']
a0d18dddaa995b126ad373e33767b9b881d16b2f;An Introductory Review of Deep Learning for Prediction Models With Big Data;Deep learning models stand for a new learning paradigm in artificial intelligence (AI) and machine learning. Recent breakthrough results in image analysis and speech recognition have generated a massive interest in this field because also applications in many other domains providing big data seem possible. On a downside, the mathematical and computational methodology underlying deep learning models is very challenging, especially for interdisciplinary scientists. For this reason, we present in this paper an introductory review of deep learning approaches including Deep Feedforward Neural Networks (D-FFNN), Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs), Autoencoders (AEs), and Long Short-Term Memory (LSTM) networks. These models form the major core architectures of deep learning models currently used and should belong in any data scientist's toolbox. Importantly, those core architectural building blocks can be composed flexibly—in an almost Lego-like manner—to build new application-specific network architectures. Hence, a basic understanding of these network architectures is;['1399003993', '1698784963', '2113276011', '89377594', '1792351'];['F. Emmert-Streib', 'Zhenyi Yang', 'Han Feng', 'S. Tripathi', 'M. Dehmer'];;;;;;;0eduq9zr;Frontiers in Artificial Intelligence;2020.0;3;['Computer Science', 'Deep Learning', 'Medicine', 'Big Data']
456c011594ecacdd24298a161787389ccbe4b88b;Big Data Service Architecture: A Survey;As one of the main development directions in the information field, big data technology can be applied for data mining, data analysis and data sharing in the massive data, and it created huge economic benefits by using the potential value of data. Meanwhile, it can provide decision-making strategies for social and economic development. Big data service architecture is a new service economic model that takes data as a resource, and it loads and extracts the data collected from different data sources. This service architecture provides various customized data processing methods, data analysis and visualization services for service consumers. This paper first briefly introduces the general big data service architecture and the technical processing framework, which covered data collection and storage. Next, we discuss big data processing and analysis according to different service requirements, which can present valuable data for service consumers. Then, we introduce the detailed cloud computing service system;['2143716975', '47795877', '2118913820', '145165793', '2108122564'];['Jin Wang', 'Yaqiong Yang', 'Tian Wang', 'R. Sherratt', 'Jingyu Zhang'];;;;;;;2st8hi5g;Journal of Internet Technology;2020.0;21;['Computer Science', 'Big Data']
8b417c2be7a7707f372049fb1193f0d42f799562;Big Data and AI Revolution in Precision Agriculture: Survey and Challenges;Sustainable agricultural development is a significant solution with fast population development through the use of information and communication (ICT) in precision agriculture, which produced new methods for making cultivation further productive, proficient, well-regulated while preserving the climate. Big data (machine learning, deep learning, etc.) is amongst the vital technologies of ICT employed in precision agriculture for their huge data analytical capabilities to abstract significant information and to assist agricultural practitioners to comprehend well farming practices and take precise decisions. The main goal of this article is to acquire an awareness of the Big Data latest applications in smart agriculture and be acquainted with related social and financial challenges to be concentrated on. This article features data creation methods, accessibility of technology, accessibility of devices, software tools, and data analytic methods, and appropriate applications of big data in precision agriculture. Besides, there are still a few challenges that come across the;['50378979', '144847901'];['S. Bhat', 'N. Huang'];;;;;;;hntqzioj;IEEE Access;2021.0;9;['Computer Science', 'Big Data']
b34fc78de28be598e21118d7cb9d84d63374addc;Analysis of Dimensionality Reduction Techniques on Big Data;Due to digitization, a huge volume of data is being generated across several sectors such as healthcare, production, sales, IoT devices, Web, organizations. Machine learning algorithms are used to uncover patterns among the attributes of this data. Hence, they can be used to make predictions that can be used by medical practitioners and people at managerial level to make executive decisions. Not all the attributes in the datasets generated are important for training the machine learning algorithms. Some attributes might be irrelevant and some might not affect the outcome of the prediction. Ignoring or removing these irrelevant or less important attributes reduces the burden on machine learning algorithms. In this work two of the prominent dimensionality reduction techniques, Linear Discriminant Analysis (LDA) and Principal Component Analysis (PCA) are investigated on four popular Machine Learning (ML) algorithms, Decision Tree Induction, Support Vector Machine (SVM), Naive Bayes Classifier and Random Forest Classifier;['38608914', '49247239', '51017707', '46234199', '32336300', '2176030144', '2287603163', '2176030144'];['G. T. Reddy', 'M. P. K. Reddy', 'Kuruva Lakshmanna', 'Rajesh Kaluri', 'D. Rajput', 'Gautam Srivastava', 'Ieee Thar Baker Senior Member', 'Gautam Srivastava'];;;;;;;c7fo246t;IEEE Access;2020.0;8;['Computer Science', 'Big Data']
02a88547d6f6022bebc9aba6723a310cdf132f3f;Big Data;;['1702878', '2414189', '2080786832', '2092936661', '1712422', '1733290', '2069618919'];['M. Schermann', 'Holmer Hemsen', 'Christoph Buchmüller', 'Till Bitter', 'H. Krcmar', 'V. Markl', 'T. Hoeren'];;;;;;;0l4n1x3x;WIRTSCHAFTSINFORMATIK;2014.0;56;['Computer Science', 'Big Data']
48fc9c42522184c652742255fdf31f7b9ed7ebae;Brief introduction of medical database and data mining technology in big data era;Data mining technology can search for potentially valuable knowledge from a large amount of data, mainly divided into data preparation and data mining, and expression and analysis of results. It is a mature information processing technology and applies database technology. Database technology is a software science that researches manages, and applies databases. The data in the database are processed and analyzed by studying the underlying theory and implementation methods of the structure, storage, design, management, and application of the database. We have introduced several databases and data mining techniques to help a wide range of clinical researchers better understand and apply database technology.;['2144586446', '12013287', '50384351', '2156059845', '1500673788', '2118916449', '120615721', '143908700', '80193067'];['Jin Yang', 'Yuan-jie Li', 'Qingqing Liu', 'Li Li', 'Aozi Feng', 'Tianyi Wang', 'Shuai Zheng', 'Anding Xu', 'Jun Lyu'];;;;;;;ym2oqs5v;Journal of Evidence-Based Medicine;2020.0;13;['Data Mining', 'Medicine', 'Big Data']
cbad0923db89f23febcbd6192ff4149289ff2ad9;A survey on data‐efficient algorithms in big data era;;['9139705'];['Amina Adadi'];;;;;;;9e7ffh87;Journal of Big Data;2021.0;8;['Computer Science', 'Big Data']
752604994a7ca548ff2954114fc61a501d857b1c;Big data analytics and firm performance: Effects of dynamic capabilities;;['2749823', '143809890', '1864298', '121781054', '2051250', '2327630'];['S. Wamba', 'A. Gunasekaran', 'Shahriar Akter', 'S. Ren', 'Rameshwar Dubey', 'S. Childe'];;;;;;;icy25srj;Journal of Business Research;2017.0;70;['Computer Science', 'Big Data', 'Analytics']
391a5f286f814d852dddcab1b2b68e5c1af6c79e;Data mining with big data;Big Data concern large-volume, complex, growing data sets with multiple, autonomous sources. With the fast development of networking, data storage, and the data collection capacity, Big Data are now rapidly expanding in all science and engineering domains, including physical, biological and biomedical sciences. This paper presents a HACE theorem that characterizes the features of the Big Data revolution, and proposes a Big Data processing model, from the data mining perspective. This data-driven model involves demand-driven aggregation of information sources, mining and analysis, user interest modeling, and security and privacy considerations. We analyze the challenging issues in the data-driven model and also in the Big Data revolution.;['2271668292', '2283098327', '2286440807', '2286232238'];['Xindong Wu', 'Xingquan Zhu', 'Gong-Qing Wu', 'Wei Ding'];;;;;;;y0qye9vw;IEEE Transactions on Knowledge and Data Engineering;2016.0;26;['Computer Science', 'Data Mining', 'Big Data']
933baeec555352784848a93284c9dd0e79477759;Big Data in Smart Farming – A review;;['2448041', '47641392', '3059861', '98639980'];['S. Wolfert', 'L. Ge', 'C. Verdouw', 'M. Bogaardt'];;;;;;;ox2o2aj9;Agricultural Systems;2017.0;153;['Economics', 'Big Data']
b473e91cbe80c8b46451b49153cd5f93030480ab;Critical analysis of Big Data challenges and analytical methods;;['2735257', '1772062', '1690610', '1683959'];['U. Sivarajah', 'M. Kamal', 'Z. Irani', 'V. Weerakkody'];;;;;;;mwsej784;Journal of Business Research;2017.0;70;['Psychology', 'Big Data']
56266342b01a4f2ddc28a1e8401dbbad105736a5;Big Data Analytics in Weather Forecasting: A Systematic Review;;['2056343176', '134403952', '2277388', '2719926'];['Marzieh Fathi', 'Mostafa Haghi Kashani', 'S. M. Jameii', 'Ebrahim Mahdipour'];;;;;;;fxwnwhkx;Archives of Computational Methods in Engineering;2021.0;29;['Computer Science', 'Big Data', 'Analytics']
73d4accea441aae2373828a8dc2175aa2759c38f;Big Data in Finance;Big data is revolutionizing the finance industry and has the potential to significantly shape future research in finance. This special issue contains papers following the 2019 NBER-RFS Conference on Big Data. In this introduction to the special issue, we define the “big data” phenomenon as a combination of three features: large size, high dimension, and complex structure. Using the papers in the special issue, we discuss how new research builds on these features to push the frontier on fundamental questions across areas in finance—including corporate finance, market microstructure, and asset pricing. Finally, we offer some thoughts for future research directions.;['2275848903', '102309470', '2240347692'];['Itay Goldstein', 'Chester Spatt', 'Mao Ye'];;;;;;;dt2g91n7;The Review of Financial Studies;2021.0;46;['Economics', 'Big Data']
37b0a7a6c8fb26e32b9206847e78d521a2cd5900;A literature review on one-class classification and its potential applications in big data;;['1809915', '1723353821', '1725285'];['Naeem Seliya', 'Azadeh Abdollah Zadeh', 'T. Khoshgoftaar'];;;;;;;vnirxdyj;Journal of Big Data;2021.0;8;['Computer Science', 'Big Data']
4d1fdd81f033cd58f3723bfc61e7d12079647a7a;Predicting the Future - Big Data, Machine Learning, and Clinical Medicine.;The algorithms of machine learning, which can sift through vast numbers of variables looking for combinations that reliably predict outcomes, will improve prognosis, displace much of the work of radiologists and anatomical pathologists, and improve diagnostic accuracy.;['3797258', '39714312'];['Z. Obermeyer', 'E. Emanuel'];;;;;;;vr9mbzc8;The New England journal of medicine;2016.0;375 13;['Medicine', 'Machine Learning', 'Big Data']
efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea;Big Data and Machine Learning in Health Care.;Nearly all aspects of modern life are in some way being changed by big data and machine learning. Netflix knows what movies people like to watch and Google knows what people want to know based on their search histories. Indeed, Google has recently begun to replace much of its existing non–machine learning technology with machine learning algorithms, and there is great optimism that these techniques can provide similar improvements across many sectors. It isnosurprisethenthatmedicineisawashwithclaims of revolution from the application of machine learning to big health care data. Recent examples have demonstrated that big data and machine learning can create algorithms that perform on par with human physicians.1 Though machine learning and big data may seem mysterious at first, they are in fact deeply related to traditional statistical models that are recognizable to most clinicians. It is our hope that elucidating these connections will demystify these techniques and provide a set;['143649421', '1740538'];['Andrew Beam', 'I. Kohane'];;;;;;;204bsevw;JAMA;2018.0;319 13;['Medicine', 'Machine Learning', 'Big Data']
8f0d7df1e34867682d0816a38ef4a9bf4a74509c;Big data quality framework: a holistic approach to continuous quality management;;['1825498', '2394689', '1949827', '1741232'];['Ikbal Taleb', 'M. Serhani', 'Chafik Bouhaddioui', 'R. Dssouli'];;;;;;;uu284wt6;Journal of Big Data;2021.0;8;['Computer Science', 'Big Data']
9198d6ab8ad1c6f1527a7d4adf06809848bf23c7;Challenges and Future Directions of Big Data and Artificial Intelligence in Education;We discuss the new challenges and directions facing the use of big data and artificial intelligence (AI) in education research, policy-making, and industry. In recent years, applications of big data and AI in education have made significant headways. This highlights a novel trend in leading-edge educational research. The convenience and embeddedness of data collection within educational technologies, paired with computational techniques have made the analyses of big data a reality. We are moving beyond proof-of-concept demonstrations and applications of techniques, and are beginning to see substantial adoption in many areas of education. The key research trends in the domains of big data and AI are associated with assessment, individualized learning, and precision education. Model-driven data analytics approaches will grow quickly to guide the development, interpretation, and validation of the algorithms. However, conclusions from educational analytics should, of course, be applied with caution. At the education policy level, the government should;['48803731', '1804075', '3307051', '145620991', '153909377', '35043342', '1802882', '2055050266', '2158235850', '2250062'];['Hui Luan', 'P. Géczy', 'H. Lai', 'J. Gobert', 'Stephen J. H. Yang', 'H. Ogata', 'J. Baltes', 'R. Guerra', 'Ping Li', 'Chin-Chung Tsai'];;;;;;;uytg0bsu;Frontiers in Psychology;2020.0;11;['Medicine', 'Psychology', 'Artificial Intelligence', 'Big Data']
aca6d5f3866372a4506cf15773ae298f18c3f453;A comprehensive survey of anomaly detection techniques for high dimensional big data;;['2257020336', '1729840', '38152929', '1490967734'];['Srikanth Thudumu', 'P. Branch', 'Jiong Jin', 'Jugdutt Singh'];;;;;;;fzongcu3;Journal of Big Data;2020.0;7;['Computer Science', 'Big Data']
80dd97954ddf3edd22d4cb21f0ac31b7ffed6bbf;Digital Twin and Big Data Towards Smart Manufacturing and Industry 4.0: 360 Degree Comparison;With the advances in new-generation information technologies, especially big data and digital twin, smart manufacturing is becoming the focus of global manufacturing transformation and upgrading. Intelligence comes from data. Integrated analysis for the manufacturing big data is beneficial to all aspects of manufacturing. Besides, the digital twin paves a way for the cyber-physical integration of manufacturing, which is an important bottleneck to achieve smart manufacturing. In this paper, the big data and digital twin in manufacturing are reviewed, including their concept as well as their applications in product design, production planning, manufacturing, and predictive maintenance. On this basis, the similarities and differences between big data and digital twin are compared from the general and data perspectives. Since the big data and digital twin can be complementary, how they can be integrated to promote smart manufacturing are discussed.;['29011153', '50556355'];['Qinglin Qi', 'F. Tao'];;;;;;;rgzs6jrv;IEEE Access;2018.0;6;['Computer Science', 'Big Data']
10d89b13a6309a531c35701d37d3bd76a27a3942;Big Data Storage;;['2277231466', '2288855760'];['Martin Strohbach', 'AS A Commodity'];;;;;;;xrj4hzz3;Computer Science Magazine (2021.0);2021.0;22;['Computer Science', 'Big Data']
bc6dbcaf4d2c76e618ae3f1043fd7276cbdf7f9b;Big data in healthcare: management, analysis and future prospects;;['47212878', '49790135', '145451018', '2066084551'];['Sabyasachi Dash', 'S. Shakyawar', 'Mohit Sharma', 'S. Kaushik'];;;;;;;enfvh4sb;Journal of Big Data;2019.0;6;['Computer Science', 'Big Data']
dac7344737cb824634f757aede2dd46a6eed204b;Big data analytics in healthcare: promise and potential;;['1696238', '2742266'];['W. Raghupathi', 'V. Raghupathi'];;;;;;;stn42wwv;Health Information Science and Systems;2014.0;2;['Computer Science', 'Medicine', 'Big Data', 'Analytics']
78aab73ed574393ab421f25b3a0e3f7343e64748;Big Data and Big Data Analytics;;['8752082', '2606653', '2108409767', '2159706268', '9313397'];['Sam Goundar', 'Akashdeep Bhardwaj', 'Shavindar Singh', 'Mandeep Singh', 'H. Gururaj'];;;;;;;0w5qr1tp;Advances in Big Data Analytics;2022.0;73;['Big Data', 'Analytics']
3b217403302f9cb9d9685404c7646de7bc0db428;Data-intensive applications, challenges, techniques and technologies: A survey on Big Data;;['2265002225', '2264425447'];['Philip Chen', 'Chun-Yang Zhang'];;;;;;;43p0x4ru;Inf. Sci.;2014.0;275;['Computer Science', 'Big Data']
b52db9e41e15f76bdcfbe674abe0314af545c430;The Rise of “Big Data” on Cloud Computing;;['152117542'];['S. Singhal'];;;;;;;q19ximn0;Computer Science Journal (2021.0);2021.0;;['Cloud', 'Computer Science', 'Big Data']
de6cf3534f39748a223b9bb2b59d2e7ffcb6ae03;Using Big Data to Emulate a Target Trial When a Randomized Trial Is Not Available.;Ideally, questions about comparative effectiveness or safety would be answered using an appropriately designed and conducted randomized experiment. When we cannot conduct a randomized experiment, we analyze observational data. Causal inference from large observational databases (big data) can be viewed as an attempt to emulate a randomized experiment-the target experiment or target trial-that would answer the question of interest. When the goal is to guide decisions among several strategies, causal analyses of observational data need to be evaluated with respect to how well they emulate a particular target trial. We outline a framework for comparative effectiveness research using big data that makes the target trial explicit. This framework channels counterfactual theory for comparing the effects of sustained treatment strategies, organizes analytic approaches, provides a structured process for the criticism of observational studies, and helps avoid common methodologic pitfalls.;['40362338', '145607066'];['M. Hernán', 'J. Robins'];;;;;;;1uulcbsz;American journal of epidemiology;2016.0;183 8;['Medicine', 'Big Data']
718b5a40dba91bfa0bdfb9ac9ca4381425d2ff95;Axes of a revolution: challenges and promises of big data in healthcare;;['35641358', '1482559324', '143991343'];['S. Shilo', 'H. Rossman', 'E. Segal'];;;;;;;h8gmj6xb;Nature Medicine;2020.0;26;['Business', 'Medicine', 'Big Data']
78e40584f0d149bf6f98beb5561b7b83cb68e1b1;Assessing the impact of big data on firm innovation performance: Big data is not always better data;;['1752945', '51202981'];['Maryam Ghasemaghaei', 'G. Calic'];;;;;;;f4m0s0sk;Journal of Business Research;2020.0;58;['Business', 'Big Data']
2660dcf5bd16d14862a7bbb241fa4d85ae34327f;"The rise of ""big data"" on cloud computing: Review and open research issues";;['145963904', '3264408', '1940692', '145463228', '143930319', '1740261'];['I. A. T. Hashem', 'Ibrar Yaqoob', 'N. B. Anuar', 'Salimah Mokhtar', 'A. Gani', 'S. Khan'];;;;;;;z8ouf2b0;Inf. Syst.;2015.0;47;['Cloud', 'Computer Science', 'Big Data']
82870bc488b57cdf5ea62877109a7278af2926b3;Big Data and Artificial Intelligence Modeling for Drug Discovery.;Due to the massive data sets available for drug candidates, modern drug discovery has advanced to the big data era. Central to this shift is the development of artificial intelligence approaches to implementing innovative modeling based on the dynamic, heterogeneous, and large nature of drug data sets. As a result, recently developed artificial intelligence approaches such as deep learning and relevant modeling studies provide new solutions to efficacy and safety evaluations of drug candidates based on big data modeling and analysis. The resulting models provided deep insights into the continuum from chemical structure to in vitro, in vivo, and clinical outcomes. The relevant novel data mining, curation, and management techniques provided critical support to recent modeling studies. In summary, the new advancement of artificial intelligence in the big data era has paved the road to future rational drug development and optimization, which will have a significant impact on drug discovery;['145153297'];['Hao Zhu'];;;;;;;507rz2g1;Annual review of pharmacology and toxicology;2020.0;75;['Computer Science', 'Medicine', 'Artificial Intelligence', 'Big Data']
3dfa820702b6181c9964931f0a4d47fd298bf429;Mining Big Data in Education: Affordances and Challenges;The emergence of big data in educational contexts has led to new data-driven approaches to support informed decision making and efforts to improve educational effectiveness. Digital traces of student behavior promise more scalable and finer-grained understanding and support of learning processes, which were previously too costly to obtain with traditional data sources and methodologies. This synthetic review describes the affordances and applications of microlevel (e.g., clickstream data), mesolevel (e.g., text data), and macrolevel (e.g., institutional data) big data. For instance, clickstream data are often used to operationalize and understand knowledge, cognitive strategies, and behavioral processes in order to personalize and enhance instruction and learning. Corpora of student writing are often analyzed with natural language processing techniques to relate linguistic features to cognitive, social, behavioral, and affective processes. Institutional data are often used to improve student and administrational decision making through course guidance systems and early-warning systems. Furthermore, this chapter outlines;['1567584468', '1743903', '144849745', '1580222881', '1630595717', '50846470', '36472283', '145155831', '2996242'];['Christian Fischer', 'Z. Pardos', 'R. Baker', 'J. Williams', 'P. Smyth', 'Renzhe Yu', 'Stefan Slater', 'Rachel B. Baker', 'M. Warschauer'];;;;;;;a0mas71k;Review of Research in Education;2020.0;44;['Psychology', 'Big Data']
3789eb72c32ecf5e33442570358dd786dd67c8a2;Text Mining in Big Data Analytics;"Text mining in big data analytics is emerging as a powerful tool for harnessing the power of unstructured textual data by analyzing it to extract new knowledge and to identify significant patterns and correlations hidden in the data. This study seeks to determine the state of text mining research by examining the developments within published literature over past years and provide valuable insights for practitioners and researchers on the predominant trends, methods, and applications of text mining research. In accordance with this, more than 200 academic journal articles on the subject are included and discussed in this review; the state-of-the-art text mining approaches and techniques used for analyzing transcripts and speeches, meeting transcripts, and academic journal articles, as well as websites, emails, blogs, and social media platforms, across a broad range of application areas are also investigated. Additionally, the benefits and challenges related to text mining are also briefly outlined.";['144152608', '2541805', '1657286983', '1577833677', '71693831'];['Hossein Hassani', 'Christina Beneki', 'Stephane Unger', 'Maedeh Taj Mazinani', 'M. R. Yeganegi'];;;;;;;go6welox;Big Data Cogn. Comput.;2020.0;4;['Computer Science', 'Big Data', 'Analytics']
f11cba099b8cf14815f7b3d85f55ecfddbf9f04d;An Overview of End-to-End Entity Resolution for Big Data;One of the most critical tasks for improving data quality and increasing the reliability of data analytics is Entity Resolution (ER), which aims to identify different descriptions that refer to the same real-world entity. Despite several decades of research, ER remains a challenging problem. In this survey, we highlight the novel aspects of resolving Big Data entities when we should satisfy more than one of the Big Data characteristics simultaneously (i.e., Volume and Velocity with Variety). We present the basic concepts, processing steps, and execution strategies that have been proposed by database, semantic Web, and machine learning communities in order to cope with the loose structuredness, extreme diversity, high speed, and large scale of entity descriptions used by real-world applications. We provide an end-to-end view of ER workflows for Big Data, critically review the pros and cons of existing methods, and conclude with the main open research directions.;['3009404', '3226264', '1725167', '144774666', '12619004'];['V. Christophides', 'Vasilis Efthymiou', 'Themis Palpanas', 'G. Papadakis', 'Kostas Stefanidis'];;;;;;;mvtokkhv;ACM Computing Surveys (CSUR);2020.0;53;['Computer Science', 'Big Data']
e449b9b3fe04fe260731a3c74d2123bf6eaadf5b;A Review of Local Outlier Factor Algorithms for Outlier Detection in Big Data Streams;"Outlier detection is a statistical procedure that aims to find suspicious events or items that are different from the normal form of a dataset. It has drawn considerable interest in the field of data mining and machine learning. Outlier detection is important in many applications, including fraud detection in credit card transactions and network intrusion detection. There are two general types of outlier detection: global and local. Global outliers fall outside the normal range for an entire dataset, whereas local outliers may fall within the normal range for the entire dataset, but outside the normal range for the surrounding data points. This paper addresses local outlier detection. The best-known technique for local outlier detection is the Local Outlier Factor (LOF), a density-based technique. There are many LOF algorithms for a static data environment; however, these algorithms cannot be applied directly to data streams, which are an important type of big";['122358516', '51228069', '1705671', '1920715'];['Omar Alghushairy', 'Raed Alsini', 'T. Soule', 'Xiaogang Ma'];;;;;;;qd5gf616;Big Data Cogn. Comput.;2020.0;5;['Computer Science', 'Big Data']
17fca92ffd527c78c5dc6c7953e96671743807fa;Big Data Analytics Capabilities and Innovation: The Mediating Role of Dynamic Capabilities and Moderating Effect of the Environment;"With big data analytics growing rapidly in popularity, academics and practitioners have been considering the means through which they can incorporate the shifts these technologies bring into their competitive strategies. Drawing on the resource&#8208;based view, the dynamic capabilities view, and on recent literature on big data analytics, this study examines the indirect relationship between a big data analytics capability (BDAC) and two types of innovation capabilities: incremental and radical. The study extends existing research by proposing that BDACs enable firms to generate insight that can help strengthen their dynamic capabilities, which in turn positively impact incremental and radical innovation capabilities. To test their proposed research model, the authors used survey data from 175 chief information officers and IT managers working in Greek firms. By means of partial least squares structural equation modelling, the results confirm the authors&#8217; assumptions regarding the indirect effect that BDACs have on innovation capabilities. Specifically, they";['2424691', '52222865', '3357578', '1716522'];['Patrick Mikalef', 'Maria Boura', 'George Lekakos', 'J. Krogstie'];;;;;;;b73atadz;Change Management Strategy eJournal;2019.0;43;['Computer Science', 'Big Data', 'Analytics']
c48e0bd0f36c25ab83befbc7b7da369b75fd25f5;Big Data-Survey;Big data is the term for any gathering of information sets, so expensive and complex, that it gets to be hard to process for utilizing customary information handling applications. The difficulties incorporate investigation, catch, duration, inquiry, sharing, stockpiling, Exchange, perception, and protection infringement. To reduce spot business patterns, anticipate diseases, conflict etc., we require bigger data sets when compared with the smaller data sets. Enormous information is hard to work with utilizing most social database administration frameworks and desktop measurements and perception bundles, needing rather enormously parallel programming running on tens, hundreds, or even a large number of servers. In this paper there was an observation on Hadoop architecture, different tools used for big data and its security issues.;['2125885487', '152170791'];['P. S. G. Aruna Sri', 'Anusha M'];;;;;;;lcvdbha3;Indonesian Journal of Electrical Engineering and Informatics;2016.0;4;['Computer Science', 'Big Data']
1e4709c0b8fe3bf759cd64dc1ede695d6e5316f0;Deep learning applications and challenges in big data analytics;;['1979817', '2142983', '1725285', '1809915', '145539319', '50076239'];['M. M. Najafabadi', 'Flavio Villanustre', 'T. Khoshgoftaar', 'Naeem Seliya', 'Randall Wald', 'Edin A. Muharemagic'];;;;;;;5i8ant7t;Journal of Big Data;2015.0;2;['Computer Science', 'Deep Learning', 'Big Data', 'Analytics']
247dec05283a1a521f99253a6cca6a5858cac0d2;Big Data and Predictive Analytics and Manufacturing Performance: Integrating Institutional Theory, Resource‐Based View and Big Data Culture;The importance of big data and predictive analytics has been at the forefront of research for operations and manufacturing management. The literature has reported the influence of big data and predictive analytics for improved supply chain and operational performance, but there has been a paucity of literature regarding the role of external institutional pressures on the resources of the organization to build big data capability. To address this gap, this paper draws on the resource‐based view of the firm, institutional theory and organizational culture to develop and test a model that describes the importance of resources for building capabilities, skills and big data culture and subsequently improving cost and operational performance. We test our research hypotheses using 195 surveys, gathered using a pre‐tested questionnaire. Our contribution lies in providing insights regarding the role of external pressures on the selection of resources under the moderating effect of big data culture and;['2051250', '143809890', '2327630', '70039026', '1879141'];['Rameshwar Dubey', 'A. Gunasekaran', 'S. Childe', 'C. Blome', 'T. Papadopoulos'];;;;;;;yhokr1xv;Organizations & Markets: Policies & Processes eJournal;2019.0;22;['Computer Science', 'Predictive Analytics', 'Big Data', 'Analytics']
8894d431a768a35dc7ca4d762ebdba4f407b978c;The ProteomeXchange consortium in 2020: enabling ‘big data’ approaches in proteomics;Abstract The ProteomeXchange (PX) consortium of proteomics resources (http://www.proteomexchange.org) has standardized data submission and dissemination of mass spectrometry proteomics data worldwide since 2012. In this paper, we describe the main developments since the previous update manuscript was published in Nucleic Acids Research in 2017. Since then, in addition to the four PX existing members at the time (PRIDE, PeptideAtlas including the PASSEL resource, MassIVE and jPOST), two new resources have joined PX: iProX (China) and Panorama Public (USA). We first describe the updated submission guidelines, now expanded to include six members. Next, with current data submission statistics, we demonstrate that the proteomics field is now actively embracing public open data policies. At the end of June 2019, more than 14 100 datasets had been submitted to PX resources since 2012, and from those, more than 9 500 in just the last three years. In parallel, an unprecedented increase of data;['1763674', '2865038', '33582313', '1390051934', '31411209', '1605658912', '1402417041', '4007395', '13084208', '39268701', '151067942', '14948487', '46994990', '48576550', '49701119', '1785886', '144252544', '2167765', '2762241', '91596213', '3245770'];['E. Deutsch', 'N. Bandeira', 'Vagisha Sharma', 'Yasset Pérez-Riverol', 'Jeremy J. Carver', 'D. J. Kundu', 'D. García-Seisdedos', 'Andrew F. Jarnuczak', 'Suresh Hewapathirana', 'B. Pullman', 'J. Wertz', 'Zhi Sun', 'S. Kawano', 'Shujiro Okuda', 'Yu Watanabe', 'H. Hermjakob', 'B. MacLean', 'M. MacCoss', 'Yun-ping Zhu', 'Y. Ishihama', 'J. Vizcaíno'];;;;;;;5pdhrelv;Nucleic Acids Research;2019.0;48;['Computer Science', 'Medicine', 'Big Data', 'Biology']
4e13a8e8ba8d33e15ed037bfca7c651047533990;Big data for cyber physical systems in industry 4.0: a survey;ABSTRACT With the technology development in cyber physical systems and big data, there are huge potential to apply them to achieve personalization and improve resource efficiency in Industry 4.0. As Industry 4.0 is the relatively new concept originated from an advanced manufacturing vision supported by the German government in 2011, there are only several existing surveys on either cyber physical systems or big data in Industry 4.0. In addition, there are much less surveys related to the intersection between cyber physical systems and big data in Industry 4.0. However, cyber physical systems are closely related to big data in nature. For example, cyber physical systems will continuously generate a large amount of data which requires the big data techniques to process and help to improve system scalability, security, and efficiency. Therefore, we conduct this survey to bring more attention to this critical intersection and highlight the future research direction to;['39466716', '2055791334'];['Lida Xu', 'Lian Duan'];;;;;;;804wo188;Enterprise Information Systems;2019.0;13;['Computer Science', 'Big Data']
dbabab9bf5955558f73a37644f4bb626106a6d73;Big Data Analytics in Intelligent Transportation Systems: A Survey;Big data is becoming a research focus in intelligent transportation systems (ITS), which can be seen in many projects around the world. Intelligent transportation systems will produce a large amount of data. The produced big data will have profound impacts on the design and application of intelligent transportation systems, which makes ITS safer, more efficient, and profitable. Studying big data analytics in ITS is a flourishing field. This paper first reviews the history and characteristics of big data and intelligent transportation systems. The framework of conducting big data analytics in ITS is discussed next, where the data source and collection methods, data analytics methods and platforms, and big data analytics application categories are summarized. Several case studies of big data analytics applications in intelligent transportation systems, including road traffic accidents analysis, road traffic flow prediction, public transportation service plan, personal travel route plan, rail transportation management and control, and assets;['4096586', '1696615', '51224577', '145550711', '144543527'];['Li Zhu', 'F. Yu', 'Yige Wang', 'B. Ning', 'T. Tang'];;;;;;;6gcte67n;IEEE Transactions on Intelligent Transportation Systems;2019.0;20;['Computer Science', 'Big Data', 'Analytics']
9e3816be8cf4821d74e258de10ee471382936a30;Privacy in the age of medical big data;;['2247069462', '2237824370'];['W. N. Price', 'I. G. Cohen'];;;;;;;st251xt9;Nature Medicine;2019.0;25;['Business', 'Medicine', 'Big Data']
5bc511aa30f72720260d792e57537379fb04c395;Sentiment Analysis in Tourism: Capitalizing on Big Data;Advances in technology have fundamentally changed how information is produced and consumed by all actors involved in tourism. Tourists can now access different sources of information, and they can generate their own content and share their views and experiences. Tourism content shared through social media has become a very influential information source that impacts tourism in terms of both reputation and performance. However, the volume of data on the Internet has reached a level that makes manual processing almost impossible, demanding new analytical approaches. Sentiment analysis is rapidly emerging as an automated process of examining semantic relationships and meaning in reviews. In this article, different sentiment analysis approaches applied in tourism are reviewed and assessed in terms of the datasets used and performances on key evaluation metrics. The article concludes by outlining future research avenues to further advance sentiment analysis in tourism as part of a broader Big Data approach.;['1971318', '22271779', '3281237'];['Alireza Alaei', 'S. Becken', 'Bela Stantic'];;;;;;;v0junpoq;Journal of Travel Research;2019.0;58;['Business', 'Big Data']
0e33833f5e2e2719edfba1d142eb4d27f96e799f;Big data analytics and enterprises: a bibliometric synthesis of the literature;ABSTRACT Understanding the developmental trajectories of big data analytics in the corporate context is highly relevant for information systems research and practice. This study presents a comprehensive bibliometric analysis of applications of big data analytics in enterprises. The sample for this study contained a total of 1727 articles from the Scopus database. The sample was analyzed with techniques such as bibliographic coupling, citation analysis, co-word analysis, and co-authorship analysis. Findings from the co-citation analysis identified four major thematic areas in the extant literature. The evolution of these thematic areas was documented with dynamic co-citation analysis.;['30757622', '1889986', '3062994'];['Sayantan Khanra', 'A. Dhir', 'Matti Mäntymäki'];;;;;;;2wn1bd61;Enterprise Information Systems;2020.0;14;['Computer Science', 'Big Data', 'Analytics']
b080d072cfde697180db3234da08903c092e72c3;Big data analytics capabilities and knowledge management: impact on firm performance;Purpose Big data analytics (BDA) guarantees that data may be analysed and categorised into useful information for businesses and transformed into big data related-knowledge and efficient decision-making processes, thereby improving performance. However, the management of the knowledge generated from the BDA as well as its integration and combination with firm knowledge have scarcely been investigated, despite an emergent need of a structured and integrated approach. The paper aims to discuss these issues. Design/methodology/approach Through an empirical analysis based on structural equation modelling with data collected from 88 Italian SMEs, the authors tested if BDA capabilities have a positive impact on firm performances, as well as the mediator effect of knowledge management (KM) on this relationship. Findings The findings of this paper show that firms that developed more BDA capabilities than others, both technological and managerial, increased their performances and that KM orientation plays a significant role in amplifying the effect;['35207612', '40119435', '2160518', '48704195'];['Alberto Ferraris', 'A. Mazzoleni', 'A. Devalle', 'Jerome Couturier'];;;;;;;8693oimm;Management Decision;2019.0;85;['Computer Science', 'Big Data', 'Analytics']
d2ae65522ac50b7b68462f43e5774ff323c52421;Uncertainty in big data analytics: survey, opportunities, and challenges;;['145373888', '1891097', '40647665'];['Reihaneh H. Hariri', 'Erik M. Fredericks', 'Kate M. Bowers'];;;;;;;hu63hvt4;Journal of Big Data;2019.0;6;['Computer Science', 'Big Data', 'Analytics']
c24d47ff95cd4bda073c75ec24ececaa3b10c995;A survey of data partitioning and sampling methods to support big data analysis;Computer clusters with the shared-nothing architecture are the major computing platforms for big data processing and analysis. In cluster computing, data partitioning and sampling are two fundamental strategies to speed up the computation of big data and increase scalability. In this paper, we present a comprehensive survey of the methods and techniques of data partitioning and sampling with respect to big data processing and analysis. We start with an overview of the mainstream big data frameworks on Hadoop clusters. The basic methods of data partitioning are then discussed including three classical horizontal partitioning schemes: range, hash, and random partitioning. Data partitioning on Hadoop clusters is also discussed with a summary of new strategies for big data partitioning, including the new Random Sample Partition (RSP) distributed model. The classical methods of data sampling are then investigated, including simple random sampling, stratified sampling, and reservoir sampling. Two common methods of big data;['46933871', '152292148', '2128523', '2894178', '1680649161'];['M.S. Mahmud', 'J. Huang', 'Salman Salloum', 'Tamer Z. Emara', 'Kuanishbay Sadatdiynov'];;;;;;;2vecxidk;Big Data Min. Anal.;2020.0;3;['Computer Science', 'Big Data']
e8b7a9be9f2d0578a95319ed5841978e10429967;Big data management in the mining industry;;['120783473'];['Chong-chong Qi'];;;;;;;abs0er9n;International Journal of Minerals, Metallurgy and Materials;2020.0;27;['Business', 'Big Data']
75c364909914f17791837ec88090262aa6656d3e;Big data in IBD: big progress for clinical practice;IBD is a complex multifactorial inflammatory disease of the gut driven by extrinsic and intrinsic factors, including host genetics, the immune system, environmental factors and the gut microbiome. Technological advancements such as next-generation sequencing, high-throughput omics data generation and molecular networks have catalysed IBD research. The advent of artificial intelligence, in particular, machine learning, and systems biology has opened the avenue for the efficient integration and interpretation of big datasets for discovering clinically translatable knowledge. In this narrative review, we discuss how big data integration and machine learning have been applied to translational IBD research. Approaches such as machine learning may enable patient stratification, prediction of disease progression and therapy responses for fine-tuning treatment options with positive impacts on cost, health and safety. We also outline the challenges and opportunities presented by machine learning and big data in clinical IBD research.;['11918365', '89037982', '47798382', '6050881', '2961601', '3615640'];['N. S. Seyed Tabib', 'M. Madgwick', 'P. Sudhakar', 'B. Verstockt', 'T. Korcsmáros', 'S. Vermeire'];;;;;;;fnk7ogj4;Gut;2020.0;69;['Computer Science', 'Medicine', 'Big Data']
18d87bff073687c025f9bd23ab2dfb20d5f72a66;BIM Big Data Storage in WebVRGIS;In the context of big data and the Internet of Things, with the advancement of geospatial data acquisition and retrieval, the volume of available geospatial data is increasing every minute. Thus, new data-management architecture is needed. We proposed a building information model (BIM) big data-storage-management solution with hybrid storage architecture based on web virtual reality geographical information system (WebVRGIS). BIM is associated with the integration of spatial and semantic information on the various stages of urban building. In this paper, based on the spatial distribution characteristics of BIM geospatial big data, a data storage and management model is proposed for BIM geospatial big data management. The architecture primarily includes Not only Structured Query Language (NoSQL) database and distributed peer-to-peer storage. The evaluation of the proposed storage method is conducted on the same software platform as our previous research about WebVR. The experimental results show that the hybrid storage architecture proposed;['145772858', '2116431916', '38929912', '9138305'];['Zhihan Lv', 'Xiaoming Li', 'Haibin Lv', 'Wenqun Xiu'];;;;;;;zxbhywz0;IEEE Transactions on Industrial Informatics;2020.0;16;['Computer Science', 'Big Data']
a60a4e5f7f872b9825ddff5d379857c2091ca52b;Current landscape and influence of big data on finance;;['103731383', '51218701', '144078473'];['M. Hasan', 'J. Popp', 'J. Oláh'];;;;;;;g5jv1f3z;Journal of Big Data;2020.0;7;['Computer Science', 'Big Data']
ba9b6f805feb62c978d384211f910790643a023e;Big data monetization throughout Big Data Value Chain: a comprehensive review;;['1481047992', '1394504819', '2360190', '40360441'];['Abou Zakaria Faroukhi', 'Imane El Alaoui', 'Youssef Gahi', 'A. Amine'];;;;;;;uiqo1l0j;Journal of Big Data;2020.0;7;['Computer Science', 'Big Data']
e7c8fcbc24c73a576339e5f34f9f23f5ea732b3b;Creating Strategic Business Value from Big Data Analytics: A Research Framework;Abstract Despite the publicity regarding big data and analytics (BDA), the success rate of these projects and strategic value created from them are unclear. Most literature on BDA focuses on how it can be used to enhance tactical organizational capabilities, but very few studies examine its impact on organizational value. Further, we see limited framing of how BDA can create strategic value for the organization. After all, the ultimate success of any BDA project lies in realizing strategic business value, which gives firms a competitive advantage. In this study, we describe the value proposition of BDA by delineating its components. We offer a framing of BDA value by extending existing frameworks of information technology value, then illustrate the framework through BDA applications in practice. The framework is then discussed in terms of its ability to study constructs and relationships that focus on BDA value creation and realization. We also present;['144894714', '145802082', '38804760', '33006924'];['V. Grover', 'R. Chiang', 'Ting-Peng Liang', 'Dongsong Zhang'];;;;;;;7heyktiu;Journal of Management Information Systems;2018.0;35;['Computer Science', 'Business', 'Big Data', 'Analytics']
99f06e88e76f1af51d08d7adfb26d758ebc6acab;Advanced data analytics for enhancing building performances: From data-driven to big data-driven approaches;;['1751969372', '143902767', '2057532745', '2112329722', '2610610', '2072531339'];['C. Fan', 'D. Yan', 'F. Xiao', 'Ao Li', 'Jingjing An', 'Xuyuan Kang'];;;;;;;zu6lgex6;Building Simulation;2020.0;14;['Computer Science', 'Big Data', 'Analytics']
8adb47deeef943c2c1bae41f9498a382fb818a16;Big data in education: a state of the art, limitations, and future research directions;;['145096938', '89333756', '46723193'];['Mariam Baig', 'Liyana Shuib', 'E. Yadegaridehkordi'];;;;;;;63eid1jq;International Journal of Educational Technology in Higher Education;2020.0;17;['Sociology', 'Big Data']
9810bcaf5ac1792e6a2738a86f85ce270d448040;Flexible and durable wood-based triboelectric nanogenerators for self-powered sensing in athletic big data analytics;;['145194157', '2140053420', '2112246116', '9870307', '145916712', '153189200', '80938908', '2141377585', '92015504', '9933376', '1390879413'];['Jianjun Luo', 'Ziming Wang', 'Liang Xu', 'A. Wang', 'K. Han', 'Tao Jiang', 'Qingsong Lai', 'Yu Bai', 'Wei-Yao Tang', 'F. Fan', 'Zhong Lin Wang'];;;;;;;emtejtrq;Nature Communications;2019.0;10;['Computer Science', 'Medicine', 'Big Data', 'Analytics']
cc1e82125f7f8636b25ccdcdb63e8f812add7f87;A Big Data Enabled Channel Model for 5G Wireless Communication Systems;The standardization process of the fifth generation (5G) wireless communications has recently been accelerated and the first commercial 5G services would be provided as early as in 2018. The increasing of enormous smartphones, new complex scenarios, large frequency bands, massive antenna elements, and dense small cells will generate big datasets and bring 5G communications to the era of big data. This paper investigates various applications of big data analytics, especially machine learning algorithms in wireless communications and channel modeling. We propose a big data and machine learning enabled wireless channel model framework. The proposed channel model is based on artificial neural networks (ANNs), including feed-forward neural network (FNN) and radial basis function neural network (RBF-NN). The input parameters are transmitter (Tx) and receiver (Rx) coordinates, Tx–Rx distance, and carrier frequency, while the output parameters are channel statistical properties, including the received power, root mean square (RMS) delay spread (DS), and;['2144794493', '2302556600', '2075396941', None, '2152916916', '2149869431', '1735048', '2236529'];['Jie Huang', 'Cheng-Xiang Wang', 'L. Bai', 'Jian Sun', 'Yang Yang', 'Jie Li', 'O. Tirkkonen', 'Ming-Tuo Zhou'];;;;;;;ybwu6wis;IEEE Transactions on Big Data;2020.0;6;['Computer Science', 'Engineering', 'Big Data']
8d2142cf2b9ffdbdaf13473c39a6b1bd737d12ba;Deep learning and big data technologies for IoT security;;['150202182', '96997078', '2215941', '143930319', '145993580', '1504149495', '1504080542', '2113544439'];['Mohamed Ahzam Amanullah', 'R. Habeeb', 'F. Nasaruddin', 'A. Gani', 'E. Ahmed', 'Abdul Salam Mohamed Nainar', 'Nazihah Md. Akim', 'Muhammad Imran'];;;;;;;qdft0l31;Comput. Commun.;2020.0;151;['Computer Science', 'Deep Learning', 'Big Data']
16575f23ff879e6353a55bbfbbcc54e27606bfc5;Big data analytics: Understanding its capabilities and potential benefits for healthcare organizations;;['49415495', '8991498', '1826467'];['Yichuan Wang', 'LeeAnn Kung', 'T. Byrd'];;;;;;;nw6e5su4;Technological Forecasting and Social Change;2018.0;126;['Computer Science', 'Big Data', 'Analytics']
b0ee814c7a3eed260c9913861329c9f73e880d00;DEA under big data: data enabled analytics and network data envelopment analysis;;['2717738'];['Joe Zhu'];;;;;;;8e5agnlv;Annals of Operations Research;2020.0;309;['Computer Science', 'Big Data', 'Analytics']
0026ea8a0fd31bdc959a4b9ed4d449f3015be8d1;Big Data and Its Applications in Smart Real Estate and the Disaster Management Life Cycle: A Systematic Analysis;Big data is the concept of enormous amounts of data being generated daily in different fields due to the increased use of technology and internet sources. Despite the various advancements and the hopes of better understanding, big data management and analysis remain a challenge, calling for more rigorous and detailed research, as well as the identifications of methods and ways in which big data could be tackled and put to good use. The existing research lacks in discussing and evaluating the pertinent tools and technologies to analyze big data in an efficient manner which calls for a comprehensive and holistic analysis of the published articles to summarize the concept of big data and see field-specific applications. To address this gap and keep a recent focus, research articles published in last decade, belonging to top-tier and high-impact journals, were retrieved using the search engines of Google Scholar, Scopus, and Web of;['71940750', '1657644010', '48633912', '90426770'];['Hafiz Suliman Munawar', 'S. Qayyum', 'Fahim Ullah', 'S. Sepasgozar'];;;;;;;cepxmn3a;Big Data Cogn. Comput.;2020.0;4;['Computer Science', 'Big Data']
971c35bcab25fbf4fd4bb6e128cf2586f0ab1d67;Manufacturing big data ecosystem: A systematic literature review;;['98495275', '143894735', '115609123'];['Yesheng Cui', 'S. Kara', 'Ka-Ching Chan'];;;;;;;u1m4l7d3;Robotics Comput. Integr. Manuf.;2020.0;62;['Computer Science', 'Big Data']
7f5cd5b1340ac06ea38bd05373c30136a6f4c1ca;The value of Big Data in government: The case of ‘smart cities’;The emergence of Big Data has added a new aspect to conceptualizing the use of digital technologies in the delivery of public services and for realizing digital governance. This article explores, via the ‘value-chain’ approach, the evolution of digital governance research, and aligns it with current developments associated with data analytics, often referred to as ‘Big Data’. In many ways, the current discourse around Big Data reiterates and repeats established commentaries within the eGovernment research community. This body of knowledge provides an opportunity to reflect on the ‘promise’ of Big Data, both in relation to service delivery and policy formulation. This includes, issues associated with the quality and reliability of data, from mixing public and private sector data, issues associated with the ownership of raw and manipulated data, and ethical issues concerning surveillance and privacy. These insights and the issues raised help assess the value of Big Data in government;['2235459675', '2296802333'];['Karl L€ ofgren', 'William R Webster'];;;;;;;oangvv2l;Big Data & Society;2020.0;7;['Computer Science', 'Business', 'Big Data']
521e5c337be51b8f8fdb858580bb46a0545ab1f9;When Gaussian Process Meets Big Data: A Review of Scalable GPs;The vast quantity of information brought by big data as well as the evolving computer hardware encourages success stories in the machine learning community. In the meanwhile, it poses challenges for the Gaussian process regression (GPR), a well-known nonparametric, and interpretable Bayesian model, which suffers from cubic complexity to data size. To improve the scalability while retaining desirable prediction quality, a variety of scalable GPs have been presented. However, they have not yet been comprehensively reviewed and analyzed to be well understood by both academia and industry. The review of scalable GPs in the GP community is timely and important due to the explosion of data size. To this end, this article is devoted to reviewing state-of-the-art scalable GPs involving two main categories: global approximations that distillate the entire data and local approximations that divide the data for subspace learning. Particularly, for global approximations, we mainly focus on sparse approximations;['2115552258', '144848119', '2685045', '1688642'];['Haitao Liu', 'Y. Ong', 'Xiaobo Shen', 'Jianfei Cai'];;;;;;;dr19bvr9;IEEE Transactions on Neural Networks and Learning Systems;2018.0;31;['Computer Science', 'Medicine', 'Mathematics', 'Big Data']
1f8a23697562b001082b147779b5eaefd3513d0a;Human migration: the big data perspective;;['39496312', '50663909', '1780833', '144386157', '2288804757', '1685102', '1704327', '30912359', '65925190', '144263850', '3145906', '1739490', '1693341', '28956425', '33769943', '2111337069'];['A. Sîrbu', 'G. Andrienko', 'N. Andrienko', 'C. Boldrini', 'M. Conti', 'F. Giannotti', 'Riccardo Guidotti', 'Simone Bertoli', 'Jisu Kim', 'Cristina Ioana Muntean', 'Luca Pappalardo', 'A. Passarella', 'D. Pedreschi', 'Laura Pollacci', 'Francesca Pratesi', 'Rajesh Sharma'];;;;;;;tktpxmi6;International Journal of Data Science and Analytics;2020.0;11;['Computer Science', 'Big Data']
ed9e7821b3e51c7e59183300d6c8cf90c8de0f26;COVID-19 is spatial: Ensuring that mobile Big Data is used for social good;The mobility restrictions related to COVID-19 pandemic have resulted in the biggest disruption to individual mobilities in modern times. The crisis is clearly spatial in nature, and examining the geographical aspect is important in understanding the broad implications of the pandemic. The avalanche of mobile Big Data makes it possible to study the spatial effects of the crisis with spatiotemporal detail at the national and global scales. However, the current crisis also highlights serious limitations in the readiness to take the advantage of mobile Big Data for social good, both within and beyond the interests of health sector. We propose two strategical pathways for the future use of mobile Big Data for societal impact assessment, addressing access to both raw mobile Big Data as well as aggregated data products. Both pathways require careful considerations of privacy issues, harmonized and transparent methodologies, and attention to the representativeness, reliability and continuity of;['101768561', '4902441', '32343498', '4478199'];['A. Poom', 'O. Järv', 'Matthew Zook', 'T. Toivonen'];;;;;;;2ao77m68;Big Data & Society;2020.0;7;['Geography', 'Big Data']
d63b884d5ebc739f6e1bdf861fa9276260781404;Deep Learning for IoT Big Data and Streaming Analytics: A Survey;In the era of the Internet of Things (IoT), an enormous amount of sensing devices collect and/or generate various sensory data over time for a wide range of fields and applications. Based on the nature of the application, these devices will result in big or fast/real-time data streams. Applying analytics over such data streams to discover new information, predict future insights, and make control decisions is a crucial process that makes IoT a worthy paradigm for businesses and a quality-of-life improving technology. In this paper, we provide a thorough overview on using a class of advanced machine learning techniques, namely deep learning (DL), to facilitate the analytics and learning in the IoT domain. We start by articulating IoT data characteristics and identifying two major treatments for IoT data from a machine learning perspective, namely IoT big data analytics and IoT streaming data analytics. We also discuss why DL is a;['4488990', '1404786833', '1683936', '145837053'];['M. Mohammadi', 'Ala I. Al-Fuqaha', 'Sameh Sorour', 'M. Guizani'];;;;;;;k7l28lxx;IEEE Communications Surveys & Tutorials;2017.0;20;['Computer Science', 'Deep Learning', 'Big Data', 'Analytics']
6a261e1e38506b0e4c113ba29a2d5e5d0709ed26;Big data analytics and firm performance: Findings from a mixed-method approach;;['2424691', '52222865', '3357578', '1716522'];['Patrick Mikalef', 'Maria Boura', 'George Lekakos', 'J. Krogstie'];;;;;;;z45lygii;Journal of Business Research;2019.0;9;['Computer Science', 'Big Data', 'Analytics']
243d553f1fc5b7ee8cfb6f49629f3a0a32b2c5c5;Big Data Analytics in Operations Management;Big data analytics is critical in modern operations management (OM). In this study, we first explore the existing big data‐related analytics techniques, and identify their strengths, weaknesses as well as major functionalities. We then discuss various big data analytics strategies to overcome the respective computational and data challenges. After that, we examine the literature and reveal how different types of big data methods (techniques, strategies, and architectures) can be applied to different OM topical areas, namely forecasting, inventory management, revenue management and marketing, transportation management, supply chain management, and risk analysis. We also investigate via case studies the real‐world applications of big data analytics in top branded enterprises. Finally, we conclude the study with a discussion of future research.;['144728286', '1694705', '71219359'];['T. Choi', 'S. Wallace', 'Yulan Wang'];;;;;;;6qe9uikz;Production and Operations Management;2018.0;27;['Computer Science', 'Big Data', 'Analytics']
d99e88d3c1821857ca6945470698351925f9737f;A survey on addressing high-class imbalance in big data;;['51925440', '1725285', '8566633', '1809915'];['Joffrey L. Leevy', 'T. Khoshgoftaar', 'Richard A. Bauder', 'Naeem Seliya'];;;;;;;jvg9rven;Journal of Big Data;2018.0;5;['Computer Science', 'Big Data']
d65d64c3f6ea322d9e85138fe5c8e85acbf661e3;A Bibliometric Analysis and Visualization of Medical Big Data Research;With the rapid development of “Internet plus”, medical care has entered the era of big data. However, there is little research on medical big data (MBD) from the perspectives of bibliometrics and visualization. The substantive research on the basic aspects of MBD itself is also rare. This study aims to explore the current status of medical big data through visualization analysis on the journal papers related to MBD. We analyze a total of 988 references which were downloaded from the Science Citation Index Expanded and the Social Science Citation Index databases from Web of Science and the time span was defined as “all years”. The GraphPad Prism 5, VOSviewer and CiteSpace softwares are used for analysis. Many results concerning the annual trends, the top players in terms of journal and institute levels, the citations and H-index in terms of country level, the keywords distribution, the highly cited papers, the co-authorship;['2314246', '2087083011', '8043060', '49673304', '1682727', '145681778'];['Huchang Liao', 'Ming Tang', 'L. Luo', 'Chunyang Li', 'F. Chiclana', 'Xiao-Jun Zeng'];;;;;;;nvuri8sk;Sustainability;2018.0;10;['Economics', 'Big Data']
6eefbb79f98e902e9d2efa057bfea174843bf3dc;Analysis of healthcare big data;;['1792647', '2065509293'];['Zhihan Lv', 'Liang Qiao'];;;;;;;m0f8jhi4;Future Gener. Comput. Syst.;2020.0;109;['Computer Science', 'Big Data']
91fc647899f801c9d351349ce73779918f90a713;Big data and machine learning algorithms for health-care delivery.;;['7452993', '114139456'];['K. Ngiam', 'Ing Wei Khor'];;;;;;;myiiwrr6;The Lancet. Oncology;2019.0;20 5;['Medicine', 'Machine Learning', 'Big Data']
8e6d0ed32aaa5e3d7c598d5a2ace76eab8485801;On big data, artificial intelligence and smart cities;;['107864595', '121660594'];['Z. Allam', 'Zaynah A. Dhunny'];;;;;;;3wqnlqzj;Cities;2019.0;41;['Business', 'Artificial Intelligence', 'Big Data']
ca0e479ba2327f71e842d033b6b48b082962cc6a;Big data and analytics: a data management perspective in public administration;In recent years, data analytics has enabled the policy makers to improve the accuracy levels of results while framing policies and strategies. This research field still has great potential waiting to be tapped, which would help to mitigate the challenges of public administration system. The present article introduces the concept of big data and provides a comprehensive overview to readers about the 'big data application framework' in public administration via data driven e-governance (DDeG). The conceptual framework here identifies the inherent possibilities of big data from the perspective of individual citizen as well as the administration. The overall finding of the study has broadened the scope of e-governance by exploring the technological aspects like network of internet (IoT), and artificial intelligence (AI). The author has concluded by pointing, the role of big data processes and its corresponding improved characteristics in public administration.;['30387454'];['Prabhat Mittal'];;;;;;;y68hn9xr;International Journal of Big Data Management;2020.0;64;['Computer Science', 'Big Data', 'Analytics']
ecef432e7f6c9f431d5b34706a8de1fdebec46f9;From Big Data to Precision Medicine;For over a decade the term “Big data” has been used to describe the rapid increase in volume, variety and velocity of information available, not just in medical research but in almost every aspect of our lives. As scientists, we now have the capacity to rapidly generate, store and analyse data that, only a few years ago, would have taken many years to compile. However, “Big data” no longer means what it once did. The term has expanded and now refers not to just large data volume, but to our increasing ability to analyse and interpret those data. Tautologies such as “data analytics” and “data science” have emerged to describe approaches to the volume of available information as it grows ever larger. New methods dedicated to improving data collection, storage, cleaning, processing and interpretation continue to be developed, although not always by, or for, medical researchers. Exploiting new tools to;['2193799', '34734228', '143920977', '5190887', '143833453', '73773486', '1836456', '2044599', '15210212'];['Tim Hulsen', 'S. Jamuar', 'A. Moody', 'J. Karnes', 'O. Varga', 'Stine Hedensted', 'R. Spreafico', 'D. Hafler', 'E. McKinney'];;;;;;;4kcoipkr;Frontiers in Medicine;2019.0;6;['Computer Science', 'Medicine', 'Big Data']
3527f43e8156d1bf5a0998405047c98036d172f0;Internet of vehicles in big data era;As the rapid development of automotive telematics, modern vehicles are expected to be connected through heterogeneous radio access technologies and are able to exchange massive information with their surrounding environment. By significantly expanding the network scale and conducting both real time and long term information processing, the traditional Vehicular Ad- Hoc Networks U+0028 VANETs U+0029 are evolving to the Internet of Vehicles U+0028 IoV U+0029, which promises efficient and intelligent prospect for the future transportation system. On the other hand, vehicles are not only consuming but also generating a huge amount and enormous types of data, which are referred to as Big Data. In this article, we first investigate the relationship between IoV and big data in vehicular environment, mainly on how IoV supports the transmission, storage, computing of the big data, and in return how IoV benefits from big data in terms of IoV characterization, performance evaluation and big;['1794590', '2265001', '36689599', '15806418', '48321874', '50762194', '145947929'];['Wenchao Xu', 'Haibo Zhou', 'Nan Cheng', 'Feng Lyu', 'Weisen Shi', 'Jiayin Chen', 'X. Shen'];;;;;;;2lppc06c;IEEE/CAA Journal of Automatica Sinica;2018.0;5;['Computer Science', 'Big Data']
80f5ee8578ee76e2c17824f211762ffec7e029d4;VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection;Accurate detection of objects in 3D point clouds is a central problem in many applications, such as autonomous navigation, housekeeping robots, and augmented/virtual reality. To interface a highly sparse LiDAR point cloud with a region proposal network (RPN), most existing efforts have focused on hand-crafted feature representations, for example, a bird's eye view projection. In this work, we remove the need of manual feature engineering for 3D point clouds and propose VoxelNet, a generic 3D detection network that unifies feature extraction and bounding box prediction into a single stage, end-to-end trainable deep network. Specifically, VoxelNet divides a point cloud into equally spaced 3D voxels and transforms a group of points within each voxel into a unified feature representation through the newly introduced voxel feature encoding (VFE) layer. In this way, the point cloud is encoded as a descriptive volumetric representation, which is then connected to a RPN to generate detections.;['2118860832', '2577513'];['Yin Zhou', 'Oncel Tuzel'];;;;;;;pm27ecdw;2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition;2017.0;69;['Cloud', 'Computer Science']
487b787e6ca2368aff7941c86e39941db83c5087;The NIST Definition of Cloud Computing;Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model promotes availability and is composed of five essential characteristics, three service models, and four deployment models.;['152956203', '46190295'];['P. Mell', 'T. Grance'];;;;;;;q5itgz6n;Business Bulletin (2011.0);2011.0;23;['Cloud', 'Business']
7ce6eca495909de2ffa0b6d9c16993757208764e;PointRCNN: 3D Object Proposal Generation and Detection From Point Cloud;In this paper, we propose PointRCNN for 3D object detection from raw point cloud. The whole framework is composed of two stages: stage-1 for the bottom-up 3D proposal generation and stage-2 for refining proposals in the canonical coordinates to obtain the final detection results. Instead of generating proposals from RGB image or projecting point cloud to bird's view or voxels as previous methods do, our stage-1 sub-network directly generates a small number of high-quality 3D proposals from point cloud in a bottom-up manner via segmenting the point cloud of the whole scene into foreground points and background. The stage-2 sub-network transforms the pooled points of each proposal to canonical coordinates to learn better local spatial features, which is combined with global semantic features of each point learned in stage-1 for accurate box refinement and confidence prediction. Extensive experiments on the 3D detection benchmark of KITTI dataset show that our proposed;['2072683588', '93768810', '47893312'];['Shaoshuai Shi', 'Xiaogang Wang', 'Hongsheng Li'];768b87bb-8a18-4d9c-a161-4d483c776bcf;Computer Vision and Pattern Recognition;conference;17;2018.0;Los Angeles;;;;;['Cloud', 'Computer Science']
5deef74e922df23a636a3fd4e33c119247de8d30;A view of cloud computing;Clearing the clouds away from the true potential and obstacles posed by this computing capability.;['144482217', '143608596', '50331526', '1687701', '38793222', '2371549', '4113761', '1701130', '35264592', '2326149473', '143834867'];['Michael Armbrust', 'A. Fox', 'Rean Griffith', 'A. Joseph', 'R. Katz', 'A. Konwinski', 'Gunho Lee', 'D. Patterson', 'Ariel S. Rabkin', 'Ion Stoica', 'M. Zaharia'];;;;;;;iuxstyma;Commun. ACM;2010.0;53;['Cloud', 'Computer Science']
1f7190fc294246f83f1f331cc51e3264851d0d36;Above the Clouds: A Berkeley View of Cloud Computing;Cloud Computing, the long-held dream of computing as a utility, has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. Developers with innovative ideas for new Internet services no longer require the large capital outlays in hardware to deploy their service or the human expense to operate it. They need not be concerned about overprovisioning for a service whose popularity does not meet their predictions, thus wasting costly resources, or underprovisioning for one that becomes wildly popular, thus missing potential customers and revenue. Moreover, companies with large batch-oriented tasks can get results as quickly as their programs can scale, since using 1000 servers for one hour costs no more than using one server for 1000 hours. This elasticity of resources, without paying a premium for large scale, is unprecedented in;['144482217', '143608596', '50331526', '1687701', '38793222', '2371549', '4113761', '1701130', '35264592', '2326149473', '143834867'];['Michael Armbrust', 'A. Fox', 'Rean Griffith', 'A. Joseph', 'R. Katz', 'A. Konwinski', 'Gunho Lee', 'D. Patterson', 'Ariel S. Rabkin', 'Ion Stoica', 'M. Zaharia'];;;;;;;pmx4sd6x;Science;2009.0;53;['Cloud', 'Computer Science']
30a82a63a339c1e69aac36b23900544fe9ec97bb;CloudSim: a toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms;Cloud computing is a recent advancement wherein IT infrastructure and applications are provided as ‘services’ to end‐users under a usage‐based payment model. It can leverage virtualized services even on the fly based on requirements (workload patterns and QoS) varying with time. The application services hosted under Cloud computing model have complex provisioning, composition, configuration, and deployment requirements. Evaluating the performance of Cloud provisioning policies, application workload models, and resources performance models in a repeatable manner under varying system and user configurations and requirements is difficult to achieve. To overcome this challenge, we propose CloudSim: an extensible simulation toolkit that enables modeling and simulation of Cloud computing systems and application provisioning environments. The CloudSim toolkit supports both system and behavior modeling of Cloud system components such as data centers, virtual machines (VMs) and resource provisioning policies. It implements generic application provisioning techniques that can be extended with ease and limited effort.;['145034579', '144928956', '2441288', '144717050', '1709598'];['R. Calheiros', 'R. Ranjan', 'A. Beloglazov', 'C. Rose', 'R. Buyya'];;;;;;;i8ee67ef;Software: Practice and Experience;2011.0;41;['Cloud', 'Computer Science']
fcc0eb6ff52827a121673280ea34f870d0c93b54;3D is here: Point Cloud Library (PCL);With the advent of new, low-cost 3D sensing hardware such as the Kinect, and continued efforts in advanced point cloud processing, 3D perception gains more and more importance in robotics, as well as other fields. In this paper we present one of our most recent initiatives in the areas of point cloud perception: PCL (Point Cloud Library - http://pointclouds.org). PCL presents an advanced and extensive approach to the subject of 3D perception, and it's meant to provide support for all the common 3D building blocks that applications need. The library contains state-of-the art algorithms for: filtering, feature estimation, surface reconstruction, registration, model fitting and segmentation. PCL is supported by an international community of robotics and perception researchers. We provide a brief walkthrough of PCL including its algorithmic capabilities and implementation strategies.;['2689311', '2070002084'];['R. Rusu', 'S. Cousins'];3f2626a8-9d78-42ca-9e0d-4b853b59cdcc;IEEE International Conference on Robotics and Automation;conference;6;2011.0;Beijing;;;;;['Cloud', 'Computer Science', 'Engineering']
c69859fd9ee74e5287c5dbf22ee7e82663fe8bdd;Benchmarking cloud serving systems with YCSB;"While the use of MapReduce systems (such as Hadoop) for large scale data analysis has been widely recognized and studied, we have recently seen an explosion in the number of systems developed for cloud data serving. These newer systems address ""cloud OLTP"" applications, though they typically do not support ACID transactions. Examples of systems proposed for cloud serving use include BigTable, PNUTS, Cassandra, HBase, Azure, CouchDB, SimpleDB, Voldemort, and many others. Further, they are being applied to a diverse range of applications that differ considerably from traditional (e.g., TPC-C like) serving workloads. The number of emerging cloud serving systems and the wide range of proposed applications, coupled with a lack of apples-to-apples performance comparisons, makes it difficult to understand the tradeoffs between systems and the workloads for which they are suited. We present the ""Yahoo! Cloud Serving Benchmark"" (YCSB) framework, with the goal of facilitating performance comparisons of the new";['2780009', '2305624', '39023402', '1709145', '145879573'];['Brian F. Cooper', 'Adam Silberstein', 'Erwin Tam', 'R. Ramakrishnan', 'Russell Sears'];d13e941e-4cac-4f1d-bdca-77d927e31f1b;ACM Symposium on Cloud Computing;conference;17;2010.0;Houston;;;;;['Cloud', 'Computer Science']
ff50b46b4e1cc0fd9beb832fc3468785b635a824;PCT: Point cloud transformer;;['2088775481', '67011150', '79305819', '31471368', '2404014', '145140922'];['Meng-Hao Guo', 'Junxiong Cai', 'Zheng-Ning Liu', 'Tai-Jiang Mu', 'Ralph Robert Martin', 'Shimin Hu'];;;;;;;oxbtjn1r;Computational Visual Media;2020.0;7;['Cloud', 'Computer Science']
7ef08f1fa127af817cdfd9d3bd00bdf60e32143b;Cloud computing: state-of-the-art and research challenges;;['2145906351', '2110453601', '1715494'];['Qi Zhang', 'Lu Cheng', 'R. Boutaba'];;;;;;;voo99s4l;Journal of Internet Services and Applications;2010.0;1;['Cloud', 'Computer Science']
c50a7f1850d1770fe728b8e42200e463ca669896;Cloud Computing and Grid Computing 360-Degree Compared;"Cloud computing has become another buzzword after Web 2.0. However, there are dozens of different definitions for cloud computing and there seems to be no consensus on what a cloud is. On the other hand, cloud computing is not a completely new concept; it has intricate connection to the relatively new but thirteen-year established grid computing paradigm, and other relevant technologies such as utility computing, cluster computing, and distributed systems in general. This paper strives to compare and contrast cloud computing with grid computing from various angles and give insights into the essential characteristics of both.";['1698701', '40560637', '1747651', '1700537'];['Ian T Foster', 'Yong Zhao', 'I. Raicu', 'Shiyong Lu'];e4e999b7-2be0-4bd0-ad3b-7afd3fe50a4d;Grid Computing Environments;conference;3;2008.0;Barcelona;;;;;['Cloud', 'Computer Science']
3b98a87a3d4c6935b29380c4070a6c637306df64;Bulk Parameterization of the Snow Field in a Cloud Model;Abstract A two-dimensional, time-dependent cloud model has been used to simulate a moderate intensity thunderstorm for the High Plains region. Six forms of water substance (water vapor, cloud water, cloud ice, rain, snow and hail, i.e., graupel) are simulated. The model utilizes the “bulk water” microphysical parameterization technique to represent the precipitation fields which are all assumed to follow exponential size distribution functions. Autoconversion concepts are used to parameterize the collision-coalescence and collision-aggregation processes. Accretion processes involving the various forms of liquid and solid hydrometeors are simulated in this model. The transformation of cloud ice to snow through autoconversion (aggregation) and Bergeron process and subsequent accretional growth or aggregation to form hail are simulated. Hail is also produced by various contact mechanisms and via probabilistic freezing of raindrops. Evaporation (sublimation) is considered for all precipitation particles outsi...;['2116262554', '33985174', '92560500'];['Yuh-Lang Lin', 'R. Farley', 'H. D. Orville'];;;;;;;5j8lhtiq;Journal of Applied Meteorology;1983.0;22;['Cloud', 'Environmental Science']
7545dd6921d1c4f59b2cabe2994726506fa527e1;Aerosols, Cloud Microphysics, and Fractional Cloudiness;Increases in aerosol concentrations over the oceans may increase the amount of low-level cloudiness through a reduction in drizzle—a process that regulates the liquid-water content and the energetics of shallow marine clouds. The resulting increase in the global albedo would be in addition to the increase due to enhancement in reflectivity associated with a decrease in droplet size and would contribute to a cooling of the earth's surface.;['98507616'];['B. Albrecht'];;;;;;;njjzup3f;Science;1989.0;245;['Cloud', 'Medicine', 'Environmental Science']
dd2819016c6bf244c39b3e6707b60389bbdbcd21;Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point Modeling;We present Point-BERT, a new paradigm for learning Transformers to generalize the concept of BERT [8] to 3D point cloud. Inspired by BERT, we devise a Masked Point Modeling (MPM) task to pre-train point cloud Transformers. Specifically, we first divide a point cloud into several local point patches, and a point cloud Tokenizer with a discrete Variational AutoEncoder (dVAE) is designed to generate discrete point tokens containing meaningful local information. Then, we randomly mask out some patches of input point clouds and feed them into the backbone Transformers. The pre-training objective is to recover the original point tokens at the masked locations under the supervision of point tokens obtained by the Tokenizer. Extensive experiments demonstrate that the proposed BERT-style pre-training strategy significantly improves the performance of standard point cloud Transformers. Equipped with our pre-training strategy, we show that a pure Transformer architecture attains 93.8% accuracy on ModelNet40 and 83.1% accuracy;['2116329737', '145016965', '2052552620', '34097174', '48128428', '1697700'];['Xumin Yu', 'Lulu Tang', 'Yongming Rao', 'Tiejun Huang', 'Jie Zhou', 'Jiwen Lu'];768b87bb-8a18-4d9c-a161-4d483c776bcf;Computer Vision and Pattern Recognition;conference;10;2021.0;Beijing;;;;;['Cloud', 'Computer Science']
c32fd8ea1b3f2df410410fb18d569dede102c53a;Diffusion Probabilistic Models for 3D Point Cloud Generation;We present a probabilistic model for point cloud generation, which is fundamental for various 3D vision tasks such as shape completion, upsampling, synthesis and data augmentation. Inspired by the diffusion process in non-equilibrium thermodynamics, we view points in point clouds as particles in a thermodynamic system in contact with a heat bath, which diffuse from the original distribution to a noise distribution. Point cloud generation thus amounts to learning the reverse diffusion process that transforms the noise distribution to the distribution of a desired shape. Specifically, we propose to model the reverse diffusion process for point clouds as a Markov chain conditioned on certain shape latent. We derive the variational bound in closed form for training and provide implementations of the model. Experimental results demonstrate that our model achieves competitive performance in point cloud generation and auto-encoding. The code is available at https://github.com/luost26/diffusion-point-cloud.;['35518638', '1486300471'];['Shitong Luo', 'Wei Hu'];768b87bb-8a18-4d9c-a161-4d483c776bcf;Computer Vision and Pattern Recognition;conference;9;2021.0;Barcelona;;;;;['Cloud', 'Computer Science']
59e258b91748c8b44dac3572ac75845ee52cb649;Oceanic phytoplankton, atmospheric sulphur, cloud albedo and climate;;['3867095', '3505908', '5561755', '31778876'];['R. Charlson', 'J. Lovelock', 'M. Andreae', 'S. Warren'];;;;;;;6pdrin30;Nature;1987.0;326;['Cloud', 'Environmental Science']
80da612e1831b8c11539180871843cff6dfaac90;PoinTr: Diverse Point Cloud Completion with Geometry-Aware Transformers;Point clouds captured in real-world applications are of-ten incomplete due to the limited sensor resolution, single viewpoint, and occlusion. Therefore, recovering the complete point clouds from partial ones becomes an indispensable task in many practical applications. In this paper, we present a new method that reformulates point cloud completion as a set-to-set translation problem and design a new model, called PoinTr that adopts a transformer encoder-decoder architecture for point cloud completion. By rep-resenting the point cloud as a set of unordered groups of points with position embeddings, we convert the point cloud to a sequence of point proxies and employ the transformers for point cloud generation. To facilitate transformers to better leverage the inductive bias about 3D geometric structures of point clouds, we further devise a geometry-aware block that models the local geometric relationships explicitly. The migration of transformers enables our model to better learn structural knowledge and preserve detailed;['2116330410', '39358728', '2142663191', '2124814824', '1697700', '2108485135'];['Xumin Yu', 'Yongming Rao', 'Ziyi Wang', 'Zuyan Liu', 'Jiwen Lu', 'Jie Zhou'];7654260e-79f9-45c5-9663-d72027cf88f3;IEEE International Conference on Computer Vision;conference;11;2021.0;Abuja;;;;;['Cloud', 'Computer Science']
2b9b4a646c5b86b0fbf0e18cd3bd0f52e06fa980;A break in the clouds: towards a cloud definition;This paper discusses the concept of Cloud Computing to achieve a complete definition of what a Cloud is, using the main characteristics typically associated with this paradigm in the literature. More than 20 definitions have been studied allowing for the extraction of a consensus definition as well as a minimum definition containing the essential characteristics. This paper pays much attention to the Grid paradigm, as it is often confused with Cloud technologies. We also describe the relationships and distinctions between the Grid and Cloud approaches.;['50736271', '1401187222', '145941543', '37267894'];['L. González', 'Luis Rodero-Merino', 'J. Cáceres', 'Maik A. Lindner'];;;;;;;a8nwju38;Comput. Commun. Rev.;2008.0;39;['Cloud', 'Computer Science']
0d88252e3a8777618d680fbb7fe64f8c1bdd1483;Efficient Multi-User Computation Offloading for Mobile-Edge Cloud Computing;Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper, we first study the multi-user computation offloading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution, and hence adopt a game theoretic approach for achieving efficient computation offloading in a distributed manner. We formulate the distributed computation offloading decision making problem among mobile device users as a multi-user computation offloading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the finite improvement property. We then design a distributed computation offloading algorithm that can achieve a Nash equilibrium, derive the upper bound of the convergence time, and quantify its efficiency ratio over the centralized optimal solutions in;['2144230079', '40657800', '1715356', '1799074'];['Xu Chen', 'Lei Jiao', 'Wenzhong Li', 'Xiaoming Fu'];;;;;;;cu3bopdg;IEEE/ACM Transactions on Networking;2015.0;24;['Cloud', 'Computer Science']
b2b0c31d036941cb557be4afb7101dc1b72f17cb;Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data;Deep learning techniques for point cloud data have demonstrated great potentials in solving classical problems in 3D computer vision such as 3D object classification and segmentation. Several recent 3D object classification methods have reported state-of-the-art performance on CAD model datasets such as ModelNet40 with high accuracy (~92\%). Despite such impressive results, in this paper, we argue that object classification is still a challenging task when objects are framed with real-world settings. To prove this, we introduce ScanObjectNN, a new real-world point cloud object dataset based on scanned indoor scene data. From our comprehensive benchmark, we show that our dataset poses great challenges to existing point cloud classification techniques as objects from real-world scans are often cluttered with background and/or are partial due to occlusions. We identify three key open problems for point cloud object classification, and propose new point cloud classification neural networks that achieve state-of-the-art performance on classifying objects;['41022658', '39701719', '143807806', '1779016', '123914790'];['M. Uy', 'Quang-Hieu Pham', 'Binh-Son Hua', 'D. Nguyen', 'Sai-Kit Yeung'];7654260e-79f9-45c5-9663-d72027cf88f3;IEEE International Conference on Computer Vision;conference;17;2019.0;Houston;;;;;['Cloud', 'Computer Science']
1bb466a643ef08434fbb6527cfc3d891d2932f8f;Cloud Computing - The Business Perspective;If cloud computing (CC) is to achieve its potential, there needs to be a clear understanding of the various issues involved, both from the perspectives of the providers and the consumers of the technology. There is an equally urgent need for understanding the business-related issues surrounding CC. We interviewed several industry executives who are either involved as developers or are evaluating CC as an enterprise user. We identify the strengths, weaknesses, opportunities and threats for the industry. We also identify the various issues that will affect the different stakeholders of CC. We issue a set of recommendations for the practitioners who will provide and manage this technology. For IS researchers, we outline the different areas of research that need attention so that we are in a position to advise the industry in the years to come. Finally, we outline some of the key issues facing governmental agencies who will be;['145195700', '2145250465', '3323424', '2813613'];['Sean Marston', 'Zhi Li', 'Subhajyoti Bandyopadhyay', 'Anand Ghalsasi'];d8ec66ab-0083-4a4d-bf44-ce85d2daad69;Hawaii International Conference on System Sciences;conference;2;2011.0;Berlin;;;;;['Cloud', 'Computer Science', 'Business']
49b0b43e57dc8efe3a92f06ddcb5a7f39da4790d;SO-Net: Self-Organizing Network for Point Cloud Analysis;This paper presents SO-Net, a permutation invariant architecture for deep learning with orderless point clouds. The SO-Net models the spatial distribution of point cloud by building a Self-Organizing Map (SOM). Based on the SOM, SO-Net performs hierarchical feature extraction on individual points and SOM nodes, and ultimately represents the input point cloud by a single feature vector. The receptive field of the network can be systematically adjusted by conducting point-to-node k nearest neighbor search. In recognition tasks such as point cloud reconstruction, classification, object part segmentation and shape retrieval, our proposed network demonstrates performance that is similar with or better than state-of-the-art approaches. In addition, the training speed is significantly faster than existing point cloud recognition networks because of the parallelizability and simplicity of the proposed architecture. Our code is available at the project website.1;['2109003378', '2108381415', '35181410'];['Jiaxin Li', 'Ben M. Chen', 'Gim Hee Lee'];;;;;;;7kffr1jy;2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition;2018.0;80;['Cloud', 'Computer Science']
572a5aa00f0569887469ffb7554699c21156ba0b;FoldingNet: Point Cloud Auto-Encoder via Deep Grid Deformation;Recent deep networks that directly handle points in a point set, e.g., PointNet, have been state-of-the-art for supervised learning tasks on point clouds such as classification and segmentation. In this work, a novel end-to-end deep auto-encoder is proposed to address unsupervised learning challenges on point clouds. On the encoder side, a graph-based enhancement is enforced to promote local structures on top of PointNet. Then, a novel folding-based decoder deforms a canonical 2D grid onto the underlying 3D object surface of a point cloud, achieving low reconstruction errors even for objects with delicate structures. The proposed decoder only uses about 7% parameters of a decoder with fully-connected neural networks, yet leads to a more discriminative representation that achieves higher linear SVM classification accuracy than the benchmark. In addition, the proposed decoder structure is shown, in theory, to be a generic architecture that is able to reconstruct an arbitrary point cloud from;['49576470', '144066717', '2577784', '144309297'];['Yaoqing Yang', 'Chen Feng', 'Yiru Shen', 'Dong Tian'];;;;;;;ntjkgo32;2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition;2017.0;61;['Cloud', 'Computer Science']
6da3d71dc601fd9cd6b4e84bc947de5474c5873b;A survey of mobile cloud computing: architecture, applications, and approaches;Together with an explosive growth of the mobile applications and emerging of cloud computing concept, mobile cloud computing (MCC) has been introduced to be a potential technology for mobile services. MCC integrates the cloud computing into the mobile environment and overcomes obstacles related to the performance (e.g., battery life, storage, and bandwidth), environment (e.g., heterogeneity, scalability, and availability), and security (e.g., reliability and privacy) discussed in mobile computing. This paper gives a survey of MCC, which helps general readers have an overview of the MCC including the definition, architecture, and applications. The issues, existing solutions, and approaches are presented. In addition, the future research directions of MCC are discussed. Copyright © 2011 John Wiley & Sons, Ltd.;['2233724', '2414439', '1713586', '144442055'];['D. Hoang', 'Chonho Lee', 'D. Niyato', 'Ping Wang'];;;;;;;dhai6a03;Wirel. Commun. Mob. Comput.;2013.0;13;['Cloud', 'Computer Science']
b2fdee22aa02477292b858fbafcb418932732bce;Cloud computing;As with any new trend in the IT world, enterprises must figure out the benefits and risks of cloud computing and the best way to use this technology. The buzz around cloud computing has reached a fever pitch. Some believe it is a disruptive trend representing the next stage in the evolution of the internet. Others believe it is hype, as it uses long established computing technologies. One thing is clear: The industry needs an objective, straightforward conversation about how this new computing paradigm will impact organizations, how it can be used with existing technologies, and the potential pitfalls of proprietary technologies that can lead to lock-in and limited choice. This document is intended to initiate a conversation that will bring together the emerging cloud computing community (both cloud users and cloud vendors) around a core set of principles. We believe that these core principles are rooted in the belief;['1890685', '2145808495', '2109038571'];['P. Pandey', 'Sandeep Singh', 'Suraj Singh'];e448ade4-5d3c-4040-b6a5-edfc5fd3e0e5;International Conference & Workshop on Emerging Trends in Technology;conference;11;2010.0;London;;;;;['Cloud', 'Computer Science']
22cc76c6d9b25facb2874bbcbbbfe781a4d85bcd;Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud;In this paper, we propose a graph neural network to detect objects from a LiDAR point cloud. Towards this end, we encode the point cloud efficiently in a fixed radius near-neighbors graph. We design a graph neural network, named Point-GNN, to predict the category and shape of the object that each vertex in the graph belongs to. In Point-GNN, we propose an auto-registration mechanism to reduce translation variance, and also design a box merging and scoring operation to combine detections from multiple vertices accurately. Our experiments on the KITTI benchmark show the proposed approach achieves leading accuracy using the point cloud alone and can even surpass fusion-based algorithms. Our results demonstrate the potential of using the graph neural network as a new approach for 3D object detection. The code is available at https://github.com/WeijingShi/Point-GNN.;['2506296', '143862425'];['Weijing Shi', 'R. Rajkumar'];768b87bb-8a18-4d9c-a161-4d483c776bcf;Computer Vision and Pattern Recognition;conference;14;2020.0;Barcelona;;;;;['Cloud', 'Computer Science', 'Graph']
be78a87bbfc30a540b477087089d106ce2b394f1;Integration of Cloud computing and Internet of Things: A survey;;['6600296', '9394208', '2283135', '30487203'];['A. Botta', 'Walter de Donato', 'V. Persico', 'A. Pescapé'];;;;;;;f2grsrlt;Future Gener. Comput. Syst.;2016.0;56;['Cloud', 'Computer Science']
e69fa2ec8a83fd256f7e5843dc31c125d90360dd;PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition;"Unlike its image based counterpart, point cloud based retrieval for place recognition has remained as an unexplored and unsolved problem. This is largely due to the difficulty in extracting local feature descriptors from a point cloud that can subsequently be encoded into a global descriptor for the retrieval task. In this paper, we propose the PointNetVLAD where we leverage on the recent success of deep networks to solve point cloud based retrieval for place recognition. Specifically, our PointNetVLAD is a combination/modification of the existing PointNet and NetVLAD, which allows end-to-end training and inference to extract the global descriptor from a given 3D point cloud. Furthermore, we propose the ""lazy triplet and quadruplet"" loss functions that can achieve more discriminative and generalizable global descriptors to tackle the retrieval task. We create benchmark datasets for point cloud based retrieval for place recognition, and the experimental results on these datasets show the feasibility";['41022658', '35181410'];['M. Uy', 'Gim Hee Lee'];;;;;;;av12ix5v;2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition;2018.0;14;['Cloud', 'Computer Science']
afb1acd9cb0caa50b9b9170e3cd63fa4a6f65478;Client-Edge-Cloud Hierarchical Federated Learning;Federated Learning is a collaborative machine learning framework to train a deep learning model without accessing clients’ private data. Previous works assume one central parameter server either at the cloud or at the edge. The cloud server can access more data but with excessive communication overhead and long latency, while the edge server enjoys more efficient communications with the clients. To combine their advantages, we propose a client-edge-cloud hierarchical Federated Learning system, supported with a HierFAVG algorithm that allows multiple edge servers to perform partial model aggregation. In this way, the model can be trained faster and better communication-computation trade-offs can be achieved. Convergence analysis is provided for HierFAVG and the effects of key parameters are also investigated, which lead to qualitative design guidelines. Empirical experiments verify the analysis and demonstrate the benefits of this hierarchical architecture in different data distribution scenarios. Particularly, it is shown that by introducing the;['2118467847', None, '2107567409', '145142172'];['Lumin Liu', 'Jun Zhang', 'S. H. Song', 'K. Letaief'];;;;;;;9t09vg5e;ICC 2020 - 2020 IEEE International Conference on Communications (ICC);2019.0;59;['Cloud', 'Computer Science']
0b9476177e70d281d4a52aa60809b6a15d2a7523;PF-Net: Point Fractal Network for 3D Point Cloud Completion;In this paper, we propose a Point Fractal Network (PF-Net), a novel learning-based approach for precise and high-fidelity point cloud completion. Unlike existing point cloud completion networks, which generate the overall shape of the point cloud from the incomplete point cloud and always change existing points and encounter noise and geometrical loss, PF-Net preserves the spatial arrangements of the incomplete point cloud and can figure out the detailed geometrical structure of the missing region(s) in the prediction. To succeed at this task, PF-Net estimates the missing point cloud hierarchically by utilizing a feature-points-based multi-scale generating network. Further, we add up multi-stage completion loss and adversarial loss to generate more realistic missing region(s). The adversarial loss can better tackle multiple modes in the prediction. Our experiments demonstrate the effectiveness of our method for several challenging point cloud completion tasks.;['2109595473', '1390337950', '2305230695', '2060411257', '2052967041'];['Zitian Huang', 'Yikuan Yu', 'Jiawen Xu', 'Feng Ni', 'Xinyi Le'];768b87bb-8a18-4d9c-a161-4d483c776bcf;Computer Vision and Pattern Recognition;conference;4;2020.0;Abuja;;;;;['Cloud', 'Computer Science']
a022334521d88eb0181e76f01b53ce42e7dcc302;An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud & Edge Systems;Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds or thousands of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and cloud utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present DeathStarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail;['145428778', '49890070', '41019405', '65725576', '93731098', '93042929', '46248474', '2380805', '46182825', '50108803', '94420614', '41019343', '2119288014', '94097459', '92971187', '93416728', '32607852', '2143243420', '93822326', '46221635', '2068165756', '2145283314', '93757860', '3234334'];['Yu Gan', 'Yanqi Zhang', 'Dailun Cheng', 'A. Shetty', 'Priyal Rathi', 'Nayan Katarki', 'Ariana Bruno', 'Justin Hu', 'Brian Ritchken', 'Brendon Jackson', 'Kelvin Hu', 'Meghna Pancholi', 'Yuan He', 'B. Clancy', 'C. Colen', 'Fukang Wen', 'Catherine Leung', 'Siyuan Wang', 'Leon Zaruvinsky', 'Mateo Espinosa Zarlenga', 'Rick Lin', 'Zhongling Liu', 'Jake Padilla', 'Christina Delimitrou'];d4610af5-85e0-480b-8773-5c71d92a7b99;International Conference on Architectural Support for Programming Languages and Operating Systems;conference;3;2019.0;Los Angeles;;;;;['Cloud', 'Computer Science']
51871d01c26acb651c81adaf073c32c3d9ec0f0b;Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge;The computation for today's intelligent personal assistants such as Apple Siri, Google Now, and Microsoft Cortana, is performed in the cloud. This cloud-only approach requires significant amounts of data to be sent to the cloud over the wireless network and puts significant computational pressure on the datacenter. However, as the computational resources in mobile devices become more powerful and energy efficient, questions arise as to whether this cloud-only processing is desirable moving forward, and what are the implications of pushing some or all of this compute to the mobile devices on the edge. In this paper, we examine the status quo approach of cloud-only processing and investigate computation partitioning strategies that effectively leverage both the cycles in the cloud and on the mobile device to achieve low latency, low energy consumption, and high datacenter throughput for this class of intelligent applications. Our study uses 8 intelligent applications spanning computer vision,;['2085723', '2546385', '2443277', '1860422', '1751516', '144603405', '2235128'];['Yiping Kang', 'Johann Hauswald', 'Cao Gao', 'A. Rovinski', 'T. Mudge', 'Jason Mars', 'Lingjia Tang'];d4610af5-85e0-480b-8773-5c71d92a7b99;International Conference on Architectural Support for Programming Languages and Operating Systems;conference;18;2017.0;São Paulo;;;;;['Cloud', 'Computer Science']
05a2f1fe94ac485d9adf9a5bce131b66c56b47c4;Cloud Programming Simplified: A Berkeley View on Serverless Computing;Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.;['145426489', '1389954462', '7905466', '2104538', '2712026', '2699039', '34961417', '144601996', '48778049', '2397000', '2119114305', '144963510', '2316152822', '2091409722'];['Eric Jonas', 'Johann Schleier-Smith', 'Vikram Sreekanti', 'Chia-che Tsai', 'Anurag Khandelwal', 'Qifan Pu', 'Vaishaal Shankar', 'J. Carreira', 'K. Krauth', 'N. Yadwadkar', 'Joseph Gonzalez', 'Raluca A. Popa', 'Ion Stoica', 'D. Patterson'];;;;;;;iainffps;ArXiv;2019.0;abs/1902.03383;['Cloud', 'Computer Science']
3d7df210adf70f30f952739553201994b92e5630;PointWeb: Enhancing Local Neighborhood Features for Point Cloud Processing;This paper presents PointWeb, a new approach to extract contextual features from local neighborhood in a point cloud. Unlike previous work, we densely connect each point with every other in a local neighborhood, aiming to specify feature of each point based on the local region characteristics for better representing the region. A novel module, namely Adaptive Feature Adjustment (AFA) module, is presented to find the interaction between points. For each local region, an impact map carrying element-wise impact between point pairs is applied to the feature difference map. Each feature is then pulled or pushed by other features in the same region according to the adaptively learned impact indicators. The adjusted features are well encoded with region information, and thus benefit the point cloud recognition tasks, such as point cloud segmentation and classification. Experimental results show that our model outperforms the state-of-the-arts on both semantic segmentation and shape classification datasets.;['3459894', '2108810714', '144856288', '1729056'];['Hengshuang Zhao', 'Li Jiang', 'Chi-Wing Fu', 'Jiaya Jia'];768b87bb-8a18-4d9c-a161-4d483c776bcf;Computer Vision and Pattern Recognition;conference;5;2019.0;Houston;;;;;['Cloud', 'Computer Science']
8fc928bb430d3f72ac876ca156042ad1860acacd;Article in Press Future Generation Computer Systems ( ) – Future Generation Computer Systems Cloud Computing and Emerging It Platforms: Vision, Hype, and Reality for Delivering Computing as the 5th Utility;With the significant advances in Information and Communications Technology (ICT) over the last half century, there is an increasingly perceived vision that computing will one day be the 5th utility (after water, electricity, gas, and telephony). This computing utility, like all other four existing utilities, will provide the basic level of computing service that is considered essential to meet the everyday needs of the general community. To deliver this vision, a number of computing paradigms have been proposed, of which the latest one is known as Cloud computing. Hence, in this paper, we define Cloud computing and provide the architecture for creating Clouds with market-oriented resource allocation by leveraging technologies such as Virtual Machines (VMs). We also provide insights on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain Service Level Agreement (SLA)-oriented resource allocation. In addition, we reveal our early thoughts on;['1709598', '2273004787', '2271114095', '2291598', '2544814', '1783686'];['R. Buyya', 'Shin Chee', 'Yeo', 'S. Venugopal', 'J. Broberg', 'I. Brandić'];;;;;;;14uxjc29;Science Review (nan);;65;['Cloud']
7a2e527b6d51071a54aac7a8bdb56ca735a1f78b;Large-Scale Point Cloud Semantic Segmentation with Superpoint Graphs;We propose a novel deep learning-based framework to tackle the challenge of semantic segmentation of large-scale point clouds of millions of points. We argue that the organization of 3D point clouds can be efficiently captured by a structure called superpoint graph (SPG), derived from a partition of the scanned scene into geometrically homogeneous elements. SPGs offer a compact yet rich representation of contextual relationships between object parts, which is then exploited by a graph convolutional network. Our framework sets a new state of the art for segmenting outdoor LiDAR scans (+11.9 and +8.8 mIoU points for both Semantic3D test sets), as well as indoor scans (+12.4 mIoU points for the S3DIS dataset).;['115987954', '3451689'];['Loic Landrieu', 'M. Simonovsky'];;;;;;;tt0x6lyp;2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition;2017.0;65;['Cloud', 'Computer Science', 'Graph']
0d46406058396f66fca4a248b897956159dfabcb;PointFlow: 3D Point Cloud Generation With Continuous Normalizing Flows;As 3D point clouds become the representation of choice for multiple vision and graphics applications, the ability to synthesize or reconstruct high-resolution, high-fidelity point clouds becomes crucial. Despite the recent success of deep learning models in discriminative tasks of point clouds, generating point clouds remains challenging. This paper proposes a principled probabilistic framework to generate 3D point clouds by modeling them as a distribution of distributions. Specifically, we learn a two-level hierarchy of distributions where the first level is the distribution of shapes and the second level is the distribution of points given a shape. This formulation allows us to both sample shapes and sample an arbitrary number of points from a shape. Our generative model, named PointFlow, learns each level of the distribution with a continuous normalizing flow. The invertibility of normalizing flows enables the computation of the likelihood during training and allows us to train our model in;['29983981', '144247007', '19235216', '39793900', '50172592', '1790580'];['Guandao Yang', 'Xun Huang', 'Zekun Hao', 'Ming-Yu Liu', 'Serge J. Belongie', 'Bharath Hariharan'];7654260e-79f9-45c5-9663-d72027cf88f3;IEEE International Conference on Computer Vision;conference;19;2019.0;Berlin;;;;;['Cloud', 'Computer Science']
731304583d2e40bf6ee030e3cd81f767713f999a;CloneCloud: elastic execution between mobile device and cloud;Mobile applications are becoming increasingly ubiquitous and provide ever richer functionality on mobile devices. At the same time, such devices often enjoy strong connectivity with more powerful machines ranging from laptops and desktops to commercial clouds. This paper presents the design and implementation of CloneCloud, a system that automatically transforms mobile applications to benefit from the cloud. The system is a flexible application partitioner and execution runtime that enables unmodified mobile applications running in an application-level virtual machine to seamlessly off-load part of their execution from mobile devices onto device clones operating in a computational cloud. CloneCloud uses a combination of static analysis and dynamic profiling to partition applications automatically at a fine granularity while optimizing execution time and energy use for a target computation and communication environment. At runtime, the application partitioning is effected by migrating a thread from the mobile device at a chosen point to the clone;['1704157', '2937896', '2286904', '145835621', '1994583'];['Byung-Gon Chun', 'Sunghwan Ihm', 'Petros Maniatis', 'M. Naik', 'A. Patti'];e4f51561-5050-4b9c-87c2-c49957677fbf;European Conference on Computer Systems;conference;15;2011.0;Abuja;;;;;['Cloud', 'Computer Science']
e50db41ef56a0c33832ac35b269e4b1139903dcb;Cloud RAN for Mobile Networks—A Technology Overview;Cloud Radio Access Network (C-RAN) is a novel mobile network architecture which can address a number of challenges the operators face while trying to support growing end-user's needs. The main idea behind C-RAN is to pool the Baseband Units (BBUs) from multiple base stations into centralized BBU Pool for statistical multiplexing gain, while shifting the burden to the high-speed wireline transmission of In-phase and Quadrature (IQ) data. C-RAN enables energy efficient network operation and possible cost savings on baseband resources. Furthermore, it improves network capacity by performing load balancing and cooperative processing of signals originating from several base stations. This paper surveys the state-of-the-art literature on C-RAN. It can serve as a starting point for anyone willing to understand C-RAN architecture and advance the research on C-RAN.;['2250972', '40554619', '145191813', '2645391', '2130255', '34544152', '2994335'];['Aleksandra Checko', 'H. Christiansen', 'Ying Yan', 'L. Scolari', 'Georgios Kardaras', 'M. Berger', 'L. Dittmann'];;;;;;;jfda7v98;IEEE Communications Surveys & Tutorials;2015.0;17;['Cloud', 'Computer Science']
20f846fc514c4b2ef83a2e0764dce29f4ea8a925;IoT and Cloud Computing Issues, Challenges and Opportunities: A Review;With the exponential growth of the Industrial Internet of Things (IIoT), multiple outlets are constantly producing a vast volume of data. It is unwise to locally store all the raw data in the IIoT devices since the energy and storage spaces of the end devices are strictly constrained. self-organization and short-range Internet of Things (IoT) networking also support outsourced data and cloud computing, independent of the distinctive resource constraint properties. For the remainder of the findings, there is a sequence of unfamiliar safeguards for IoT and cloud integration problems. The delivery of cloud computing is highly efficient, storage is becoming more and more current, and some groups are now altering their data from in house records Cloud Computing Vendors' hubs. Intensive IoT applications for workloads and data are subject to challenges while utilizing cloud computing tools. In this report, we research IoT and cloud computing and address cloud-compatible problems and;['100960057', '2087524773', '52132700', '2087848062', '2057022712', '52132506'];['M. Sadeeq', 'N. M. Abdulkareem', 'Subhi R. M. Zeebaree', 'D. M. Ahmed', 'A. Sami', 'R. Zebari'];;;;;;;7t0j20tu;Qubahan Academic Journal;2021.0;94;['Cloud', 'Computer Science']
477a1de90ba8f22e4f4068ff8d6233afe74db936;GRNet: Gridding Residual Network for Dense Point Cloud Completion;;['3451627', '1720100', '7523259', '87581594', '1761159', '8397576'];['Haozhe Xie', 'H. Yao', 'Shangchen Zhou', 'Jiageng Mao', 'Shengping Zhang', 'Wenxiu Sun'];167fa0ca-e88a-4ef7-a16f-bc66c457c806;European Conference on Computer Vision;conference;11;2020.0;Abuja;;;;;['Cloud', 'Computer Science', 'Geology', 'Engineering']
adeb6bf8919b9b6b458486499b936f649ae31c2b;IoT-Cloud-Based Smart Healthcare Monitoring System for Heart Disease Prediction via Deep Learning;The Internet of Things confers seamless connectivity between people and objects, and its confluence with the Cloud improves our lives. Predictive analytics in the medical domain can help turn a reactive healthcare strategy into a proactive one, with advanced artificial intelligence and machine learning approaches permeating the healthcare industry. As the subfield of ML, deep learning possesses the transformative potential for accurately analysing vast data at exceptional speeds, eliciting intelligent insights, and efficiently solving intricate issues. The accurate and timely prediction of diseases is crucial in ensuring preventive care alongside early intervention for people at risk. With the widespread adoption of electronic clinical records, creating prediction models with enhanced accuracy is key to harnessing recurrent neural network variants of deep learning possessing the ability to manage sequential time-series data. The proposed system acquires data from IoT devices, and the electronic clinical data stored on the cloud pertaining to patient history;['2286710502', '2286456235', '2286729598', '2286706072', '2286706374', '2286706058', '2286706312', '2178882650', '2178872255', '2286607174', '2286448139'];['P.M.D. Raj Vincent', 'K. Srinivasan', 'Gutierrez Reina', 'D. IoT-Cloud-Based', 'Francisco Luna-Perej ó n', 'Lourdes Mir ó Amarante', 'Francisco G ó mez-Rodr í guez', 'A. Nancy', 'Dakshanamoorthy Ravindran', 'P. M. Durai', 'Daniel Gutierrez'];;;;;;;vmavdibz;Electronics;2022.0;18;['Cloud', 'Deep Learning']
f0db5b28dae48d4e56a2238297f987a38d54036e;A survey on security challenges in cloud computing: issues, threats, and solutions;;['115399836', '147511642'];['Hamed Tabrizchi', 'Marjan Kuchaki Rafsanjani'];;;;;;;51qxd64h;The Journal of Supercomputing;2020.0;76;['Cloud', 'Computer Science']
b6cf10713451191de8f0d30211f85a1080249a74;TopNet: Structural Point Cloud Decoder;3D point cloud generation is of great use for 3D scene modeling and understanding. Real-world 3D object point clouds can be properly described by a collection of low-level and high-level structures such as surfaces, geometric primitives, semantic parts,etc. In fact, there exist many different representations of a 3D object point cloud as a set of point groups. Existing frameworks for point cloud genera-ion either do not consider structure in their proposed solutions, or assume and enforce a specific structure/topology,e.g. a collection of manifolds or surfaces, for the generated point cloud of a 3D object. In this work, we pro-pose a novel decoder that generates a structured point cloud without assuming any specific structure or topology on the underlying point set. Our decoder is softly constrained to generate a point cloud following a hierarchical rooted tree structure. We show that given enough capacity and allowing for redundancies, the proposed decoder is;['26917145', '13622184', '1387977754', '145950884', '1702137'];['Lyne P. Tchapmi', 'Vineet Kosaraju', 'Hamid Rezatofighi', 'I. Reid', 'S. Savarese'];768b87bb-8a18-4d9c-a161-4d483c776bcf;Computer Vision and Pattern Recognition;conference;6;2019.0;New York;;;;;['Cloud', 'Computer Science']
4f940cfbfa70c67ecb026478a8607fa7ec376220;Computation Offloading and Resource Allocation For Cloud Assisted Mobile Edge Computing in Vehicular Networks;Computation offloading services provide required computing resources for vehicles with computation-intensive tasks. Past computation offloading research mainly focused on mobile edge computing (MEC) or cloud computing, separately. This paper presents a collaborative approach based on MEC and cloud computing that offloads services to automobiles in vehicular networks. A cloud-MEC collaborative computation offloading problem is formulated through jointly optimizing computation offloading decision and computation resource allocation. Since the problem is non-convex and NP-hard, we propose a collaborative computation offloading and resource allocation optimization (CCORAO) scheme, and design a distributed computation offloading and resource allocation algorithm for CCORAO scheme that achieves the optimal solution. The simulation results show that the proposed algorithm can effectively improve the system utility and computation time, especially for the scenario where the MEC servers fail to meet demands due to insufficient computation resources.;['2685496', '2108273385', '143929757', '49481130'];['Junhui Zhao', 'Qiuping Li', 'Yi Gong', 'Ke Zhang'];;;;;;;jdcnjpxv;IEEE Transactions on Vehicular Technology;2019.0;68;['Cloud', 'Computer Science']
af2ad9cad35e99a9076b37176b92398a487e057d;Collaborative Cloud and Edge Computing for Latency Minimization;By performing data processing at the network edge, mobile edge computing can effectively overcome the deficiencies of network congestion and long latency in cloud computing systems. To improve edge cloud efficiency with limited communication and computation capacities, we investigate the collaboration between cloud computing and edge computing, where the tasks of mobile devices can be partially processed at the edge node and at the cloud server. First, a joint communication and computation resource allocation problem is formulated to minimize the weighted-sum latency of all mobile devices. Then, the closed-form optimal task splitting strategy is derived as a function of the normalized backhaul communication capacity and the normalized cloud computation capacity. Some interesting and useful insights for the optimal task splitting strategy are also highlighted by analyzing four special scenarios. Based on this, we further transform the original joint communication and computation resource allocation problem into an equivalent convex optimization problem;['10770281', '1703118', '51178155', '1410112765'];['Jinke Ren', 'Guanding Yu', 'Yinghui He', 'Geoffrey Y. Li'];;;;;;;6aao6arx;IEEE Transactions on Vehicular Technology;2019.0;68;['Cloud', 'Computer Science']
f48d322244c906b45792b28206df7cfb23495004;Escape from Cells: Deep Kd-Networks for the Recognition of 3D Point Cloud Models;We present a new deep learning architecture (called Kdnetwork) that is designed for 3D model recognition tasks and works with unstructured point clouds. The new architecture performs multiplicative transformations and shares parameters of these transformations according to the subdivisions of the point clouds imposed onto them by kdtrees. Unlike the currently dominant convolutional architectures that usually require rasterization on uniform twodimensional or three-dimensional grids, Kd-networks do not rely on such grids in any way and therefore avoid poor scaling behavior. In a series of experiments with popular shape recognition benchmarks, Kd-networks demonstrate competitive performance in a number of shape recognition tasks such as shape classification, shape retrieval and shape part segmentation.;['10714572', '1740145'];['Roman Klokov', 'V. Lempitsky'];7654260e-79f9-45c5-9663-d72027cf88f3;IEEE International Conference on Computer Vision;conference;11;2017.0;Tokyo;;;;;['Cloud', 'Computer Science']
805f2ab1c5c6035744d647744af58a1359df12c1;What Is Cloud Computing?;Cloud computing is a distributed environment for multiple organizations to use remotely and get high scalability, reliability on anytime, anywhere, and pay-as-you-go concepts. An organization has to create data centres to store, manage, and process the information to achieve benefits from data and make decisions. Cloud gives organizations a successful approach that leads to profit without maintaining the cost of data centres and technical staff to manage the services. Cloud has different types of architectures, types of clouds, and cost packages for using the cloud. These services can be scaled up or down when required by an organization. Cloud has unbeatable future because IT world is acquiring it and giving a boost to their businesses. Many cloud providers are using it and the remaining are moving to cloud. Cloud computing also gives birth to edge computing, fog computing, and many more zero downtime solutions.;['19182651'];['Ekaba Bisong'];;;;;;;66mjkmtp;Cloud Technologies;2019.0;91;['Cloud', 'Computer Science']
1a620e05f545f9e729e4e30adb035452af40e0dc;A Survey on End-Edge-Cloud Orchestrated Network Computing Paradigms;Sending data to the cloud for analysis was a prominent trend during the past decades, driving cloud computing as a dominant computing paradigm. However, the dramatically increasing number of devices and data traffic in the Internet-of-Things (IoT) era are posing significant burdens on the capacity-limited Internet and uncontrollable service delay. It becomes difficult to meet the delay-sensitive and context-aware service requirements of IoT applications by using cloud computing alone. Facing these challenges, computing paradigms are shifting from the centralized cloud computing to distributed edge computing. Several new computing paradigms, including Transparent Computing, Mobile Edge Computing, Fog Computing, and Cloudlet, have emerged to leverage the distributed resources at network edge to provide timely and context-aware services. By integrating end devices, edge servers, and cloud, they form a hierarchical IoT architecture, i.e., End-Edge-Cloud orchestrated architecture to improve the performance of IoT systems. This article presents a comprehensive survey of these emerging computing;['145847892', '2078272', '50824125', '46867829', '2149200369'];['Ju Ren', 'Deyu Zhang', 'Shiwen He', 'Yaoxue Zhang', 'Tao Li'];;;;;;;829bqzjo;ACM Computing Surveys (CSUR);2019.0;52;['Cloud', 'Computer Science']
c078bf5f00a1bfb8df6bda9bc7fee6bfea6f5cbb;Blockchain: A Panacea for Healthcare Cloud-Based Data Security and Privacy?;One particular trend observed in healthcare is the progressive shift of data and services to the cloud, partly due to convenience (e.g. availability of complete patient medical history in real-time) and savings (e.g. economics of healthcare data management). There are, however, limitations to using conventional cryptographic primitives and access control models to address security and privacy concerns in an increasingly cloud-based environment. In this paper, we study the potential to use the Blockchain technology to protect healthcare data hosted within the cloud. We also describe the practical challenges of such a proposition and further research that is required.;['39850767', '1722848', '1695827', '47960476', '2840539'];['C. Esposito', 'A. D. Santis', 'G. Tortora', 'Henry Chang', 'Kim-Kwang Raymond Choo'];;;;;;;4dqjp4gt;IEEE Cloud Computing;2018.0;5;['Cloud', 'Computer Science']
49403326211c20b3c1ac7f6b6ac2471a11af8f07;A Survey on Internet of Things and Cloud Computing for Healthcare;The fast development of the Internet of Things (IoT) technology in recent years has supported connections of numerous smart things along with sensors and established seamless data exchange between them, so it leads to a stringy requirement for data analysis and data storage platform such as cloud computing and fog computing. Healthcare is one of the application domains in IoT that draws enormous interest from industry, the research community, and the public sector. The development of IoT and cloud computing is improving patient safety, staff satisfaction, and operational efficiency in the medical industry. This survey is conducted to analyze the latest IoT components, applications, and market trends of IoT in healthcare, as well as study current development in IoT and cloud computing-based healthcare applications since 2015. We also consider how promising technologies such as cloud computing, ambient assisted living, big data, and wearables are being applied in the healthcare industry;['40547902', '27648067', '4460268', '114915097', '40638847'];['L. Dang', 'Md. Jalil Piran', 'Dongil Han', 'Kyungbok Min', 'Hyeonjoon Moon'];;;;;;;ha00inb4;Electronics;2019.0;3;['Cloud', 'Computer Science']
c5ec766a89b308979eadcbe5d71c3faaa1794c8e;Secure integration of IoT and Cloud Computing;;['144717855', '2668299', '2151899447', '144901889'];['C. Stergiou', 'K. Psannis', 'Byung-Gyu Kim', 'B. Gupta'];;;;;;;xyzirgne;Future Gener. Comput. Syst.;2018.0;78;['Cloud', 'Computer Science']
e62ab6416643e49245f997b203f97e072e053016;Hey, you, get off of my cloud: exploring information leakage in third-party compute clouds;Third-party cloud computing represents the promise of outsourcing as applied to computation. Services, such as Microsoft's Azure and Amazon's EC2, allow users to instantiate virtual machines (VMs) on demand and thus purchase precisely the capacity they require when they require it. In turn, the use of virtualization allows third-party cloud providers to maximize the utilization of their sunk capital costs by multiplexing many customer VMs across a shared physical infrastructure. However, in this paper, we show that this approach can also introduce new vulnerabilities. Using the Amazon EC2 service as a case study, we show that it is possible to map the internal cloud infrastructure, identify where a particular target VM is likely to reside, and then instantiate new VMs until one is placed co-resident with the target. We explore how such placement can then be used to mount cross-VM side-channel attacks to extract information from a target VM on;['1707461', '2337345', '1786752', '1727599'];['Thomas Ristenpart', 'Eran Tromer', 'H. Shacham', 'S. Savage'];73f7fe95-b68b-468f-b7ba-3013ca879e50;Conference on Computer and Communications Security;conference;18;2009.0;Paris;;;;;['Cloud', 'Computer Science']
5d9b36e296e6f61177c2f1739a6ca8c553303c09;Semantic3D.net: A new Large-scale Point Cloud Classification Benchmark;This paper presents a new 3D point cloud classification benchmark data set with over four billion manually labelled points, meant as input for data-hungry (deep) learning methods. We also discuss first submissions to the benchmark that use deep convolutional neural networks (CNNs) as a work horse, which already show remarkable performance improvements over state-of-the-art. CNNs have become the de-facto standard for many tasks in computer vision and machine learning like semantic segmentation or object detection in images, but have no yet led to a true breakthrough for 3D point cloud labelling tasks due to lack of training data. With the massive data set presented in this paper, we aim at closing this data gap to help unleash the full potential of deep learning methods for 3D labelling tasks. Our this http URL data set consists of dense point clouds acquired with static terrestrial laser scanners. It contains 8 semantic classes;['47099966', '2417003', '1728641', '1753678', '144810819', '1742208'];['Timo Hackel', 'Nikolay Savinov', 'Lubor Ladicky', 'J. D. Wegner', 'K. Schindler', 'M. Pollefeys'];;;;;;;0vtacdyk;ArXiv;2017.0;abs/1704.03847;['Cloud', 'Computer Science']
6c4fc0ca14a74dd75ba78d7d783b67c4c7c2b15b;Efficient RANSAC for Point‐Cloud Shape Detection;In this paper we present an automatic algorithm to detect basic shapes in unorganized point clouds. The algorithm decomposes the point cloud into a concise, hybrid structure of inherent shapes and a set of remaining points. Each detected shape serves as a proxy for a set of corresponding points. Our method is based on random sampling and detects planes, spheres, cylinders, cones and tori. For models with surfaces composed of these basic shapes only, for example, CAD models, we automatically obtain a representation solely consisting of shape proxies. We demonstrate that the algorithm is robust even in the presence of many outliers and a high degree of noise. The proposed method scales well with respect to the size of the input point cloud and the number and size of the shapes within the data. Even point sets with several millions of samples are robustly decomposed within less than a minute.;['39596695', '20824819', '1698206'];['Ruwen Schnabel', 'Roland Wahl', 'R. Klein'];;;;;;;mkvuvn02;Computer Graphics Forum;2007.0;26;['Cloud', 'Computer Science', 'Mathematics']
a9d11c8371a3608aab9996c742e7c12bd3562b25;The Eucalyptus Open-Source Cloud-Computing System;"Cloud computing systems fundamentally provide access to large pools of data and computational resources through a variety of interfaces similar in spirit to existing grid and HPC resource management and programming systems. These types of systems offer a new programming target for scalable application developers and have gained popularity over the past few years. However, most cloud computing systems in operation today are proprietary, rely upon infrastructure that is invisible to the research community, or are not explicitly designed to be instrumented and modified by systems researchers. In this work, we present Eucalyptus -- an open-source software framework for cloud computing that implements what is commonly referred to as Infrastructure as a Service (IaaS); systems that give users the ability to run and control entire virtual machine instances deployed across a variety physical resources. We outline the basic principles of the Eucalyptus design, detail important operational aspects of the system,";['1798987', '1682591', '2037463', '2348876', '39549770', '3237080', '2677581'];['Daniel Nurmi', 'R. Wolski', 'Chris Grzegorczyk', 'Graziano Obertelli', 'Sunil Soman', 'Lamia Youseff', 'Dmitrii Zagorodnov'];;;;;;;wxdxbe7g;2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid;2009.0;74;['Cloud', 'Computer Science']
da773af7e4f1248f47e6057eabcb595b3997eac9;Distributed Deep Neural Networks Over the Cloud, the Edge and End Devices;We propose distributed deep neural networks (DDNNs) over distributed computing hierarchies, consisting of the cloud, the edge (fog) and end devices. While being able to accommodate inference of a deep neural network (DNN) in the cloud, a DDNN also allows fast and localized inference using shallow portions of the neural network at the edge and end devices. When supported by a scalable distributed computing hierarchy, a DDNN can scale up in neural network size and scale out in geographical span. Due to its distributed nature, DDNNs enhance sensor fusion, system fault tolerance and data privacy for DNN applications. In implementing a DDNN, we map sections of a DNN onto a distributed computing hierarchy. By jointly training these sections, we minimize communication and resource usage for devices and maximize usefulness of extracted features which are utilized in the cloud. The resulting system has built-in support for automatic sensor fusion and fault;['3242151', '1841852', '144153718'];['Surat Teerapittayanon', 'Bradley McDanel', 'H. T. Kung'];ffe5bb5c-04ed-488e-985d-d3a7b39542cf;IEEE International Conference on Distributed Computing Systems;conference;2;2017.0;Houston;;;;;['Neural Networks', 'Computer Science', 'Cloud']
0a1ea5f5481aa5959f4a93fef9c2fc19f20d5093;The MODIS Cloud Optical and Microphysical Products: Collection 6 Updates and Examples From Terra and Aqua;"The Moderate-Resolution Imaging Spectroradiometer (MODIS) level-2 (L2) cloud product (earth science data set names MOD06 and MYD06 for Terra and Aqua MODIS, respectively) provides pixel-level retrievals of cloud top properties (day and night pressure, temperature, and height) and cloud optical properties (optical thickness, effective particle radius, and water path for both liquid water and ice cloud thermodynamic phases-daytime only). Collection 6 (C6) reprocessing of the product was completed in May 2014 and March 2015 for MODIS Aqua and Terra, respectively. Here we provide an overview of major C6 optical property algorithm changes relative to the previous Collection 5 (C5) product. Notable C6 optical and microphysical algorithm changes include: 1) new ice cloud optical property models and a more extensive cloud radiative transfer code lookup table (LUT) approach; 2) improvement in the skill of the shortwave-derived cloud thermodynamic phase; 3) separate cloud effective radius retrieval data sets for each spectral combination";['2599057', '39039438', '32170594', '98796966', '49231627', '145106263', '144445059', '143782446', '3327999', '34832246', '2327836169', '49550912', '2503153'];['S. Platnick', 'K. Meyer', 'M. King', 'G. Wind', 'N. Amarasinghe', 'B. Marchant', 'G. Arnold', 'Zhibo Zhang', 'P. Hubanks', 'R. Holz', 'Ping Yang', 'W. L. Ridgway', 'J. Riedi'];;;;;;;y2ttpvdz;IEEE Transactions on Geoscience and Remote Sensing;2017.0;55;['Cloud', 'Computer Science', 'Medicine', 'Environmental Science']
fb6cdfc1e3e3c9e552efdd5cbad340cbf77a2bdd;Oruta: Privacy- Preserving Public Auditing for Shared Data in the Cloud;We believe that sharing data among multiple users is perhaps one of the most engaging features that motivates cloud storage. A unique problem introduced during the process of public auditing for shared data in the cloud is how to preserve identity privacy from the TPA, because the identities of signers on shared data may indicate that a particular user in the group or a special block in shared data is a higher valuable target than others. Abstract—With cloud storage services, it is common place for data to be not only stored in the cloud, but also shared across multiple users. However, public auditing for such shared data — while preserving identity privacy— remains to be an open challenge. In this paper, we propose the first privacy-preserving mechanism that allows public auditing on shared data stored in the cloud. In particular, we exploit ring signatures to compute the verification information needed;['108526100', '143908346', '37709477'];['.M Supraja', 'T. Sudha', 'N. Padmaja'];;;;;;;dwqlylxv;International journal of engineering research and technology;2018.0;3;['Cloud', 'Computer Science']
7f844ddd70bba6338be6d06ff079aedf84b5953b;Improvement and expansion of the Fmask algorithm: cloud, cloud shadow, and snow detection for Landsats 4–7, 8, and Sentinel 2 images;;['145250899', '2283199988', '16252651'];['Zhe Zhu', 'Shixiong Wang', 'C. Woodcock'];;;;;;;030nia2d;Remote Sensing of Environment;2015.0;159;['Cloud', 'Environmental Science']
33e77edcd42960bc1ed931ada45b9aa8d0e60e16;Addressing cloud computing security issues;;['2081312', '2734992'];['Dimitrios Zissis', 'D. Lekkas'];;;;;;;vekxlas1;Future Gener. Comput. Syst.;2012.0;28;['Cloud', 'Computer Science']
8d67bac352dcd43c9c08f917ba8c4bebb444b55d;A cloud-scale acceleration architecture;Hyperscale datacenter providers have struggled to balance the growing need for specialized hardware (efficiency) with the economic benefits of homogeneity (manageability). In this paper we propose a new cloud architecture that uses reconfigurable logic to accelerate both network plane functions and applications. This Configurable Cloud architecture places a layer of reconfigurable logic (FPGAs) between the network switches and the servers, enabling network flows to be programmably transformed at line rate, enabling acceleration of local applications running on the server, and enabling the FPGAs to communicate directly, at datacenter scale, to harvest remote FPGAs unused by their local servers. We deployed this design over a production server bed, and show how it can be used for both service acceleration (Web search ranking) and network acceleration (encryption of data in transit at high-speeds). This architecture is much more scalable than prior work which used secondary rack-scale networks for inter-FPGA communication. By coupling;['2986818', '49842903', '3651513', '2818237', '1684785', '2589995', '14744223', '47780664', '2065904471', '2145425761', '7380875', '1882691', '1682478', '1691992', '2065407153', '39577517', '2000338', '144859824'];['Adrian M. Caulfield', 'Eric S. Chung', 'Andrew Putnam', 'Hari Angepat', 'J. Fowers', 'M. Haselman', 'Stephen Heil', 'Matt Humphrey', 'P. Kaur', 'Joo-Young Kim', 'Daniel Lo', 'Todd Massengill', 'Kalin Ovtcharov', 'Michael Papamichael', 'Lisa Woods', 'S. Lanka', 'Derek Chiou', 'D. Burger'];0942fb86-c16f-4084-9902-10ddcfe18180;Micro;conference;3;2016.0;São Paulo;;;;;['Cloud', 'Computer Science']
6fbbb3b44ffde1a65371eceefbeb40194e3afc91;Optimal Workload Allocation in Fog-Cloud Computing Toward Balanced Delay and Power Consumption;Mobile users typically have high demand on localized and location-based information services. To always retrieve the localized data from the remote cloud, however, tends to be inefficient, which motivates fog computing. The fog computing, also known as edge computing, extends cloud computing by deploying localized computing facilities at the premise of users, which prestores cloud data and distributes to mobile users with fast-rate local connections. As such, fog computing introduces an intermediate fog layer between mobile users and cloud, and complements cloud computing toward low-latency high-rate services to mobile users. In this fundamental framework, it is important to study the interplay and cooperation between the edge (fog) and the core (cloud). In this paper, the tradeoff between power consumption and transmission delay in the fog-cloud computing system is investigated. We formulate a workload allocation problem which suggests the optimal workload allocations between fog and cloud toward the minimal power consumption;['9351870', '144988716', '2343110', '9533837', '50855146'];['Ruilong Deng', 'R. Lu', 'Chengzhe Lai', 'T. Luan', 'Hao Liang'];;;;;;;j529iquu;IEEE Internet of Things Journal;2016.0;3;['Cloud', 'Computer Science']
f0ff1e0739494fcbaeefc3e30038457ed606b1c4;Morphing and Sampling Network for Dense Point Cloud Completion;3D point cloud completion, the task of inferring the complete geometric shape from a partial point cloud, has been attracting attention in the community. For acquiring high-fidelity dense point clouds and avoiding uneven distribution, blurred details, or structural loss of existing methods' results, we propose a novel approach to complete the partial point cloud in two stages. Specifically, in the first stage, the approach predicts a complete but coarse-grained point cloud with a collection of parametric surface elements. Then, in the second stage, it merges the coarse-grained prediction with the input point cloud by a novel sampling algorithm. Our method utilizes a joint loss function to guide the distribution of the points. Extensive experiments verify the effectiveness of our method and demonstrate that it outperforms the existing methods in both the Earth Mover's Distance (EMD) and the Chamfer Distance (CD).;['47842126', '2053947248', '2119317986', '1388486428', '145140922'];['Minghua Liu', 'Lu Sheng', 'Sheng Yang', 'Jing Shao', 'Shimin Hu'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;1;2019.0;London;;;;;['Cloud', 'Computer Science']
84eae1234a6a9d64b6be73756ef9abafd31a83bf;ProvChain: A Blockchain-Based Data Provenance Architecture in Cloud Environment with Enhanced Privacy and Availability;Cloud data provenance is metadata that records the history of the creation and operations performed on a cloud data object. Secure data provenance is crucial for data accountability, forensics and privacy. In this paper, we propose a decentralized and trusted cloud data provenance architecture using blockchain technology. Blockchain-based data provenance can provide tamper-proof records, enable the transparency of data accountability in the cloud, and help to enhance the privacy and availability of the provenance data. We make use of the cloud storage scenario and choose the cloud file as a data unit to detect user operations for collecting provenance data. We design and implement ProvChain, an architecture to collect and verify cloud data provenance, by embedding the provenance data into blockchain transactions. ProvChain operates mainly in three phases: (1) provenance data collection, (2) provenance data storage, and (3) provenance data validation. Results from performance evaluation demonstrate that ProvChain provides security;['5868759', '1719516', '2314055', '145231705', '1723424', '144678875'];['Xueping Liang', 'S. Shetty', 'Deepak K. Tosh', 'Charles A. Kamhoua', 'K. Kwiat', 'Laurent L. Njilla'];57f970eb-366a-4bfa-aa06-2ff70d834806;IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing;conference;19;2017.0;Los Angeles;;;;;['Cloud', 'Computer Science']
919209c7c3a8dd7547c05cc8cf22ad5b53aa11a7;Achieving Secure, Scalable, and Fine-grained Data Access Control in Cloud Computing;Cloud computing is an emerging computing paradigm in which resources of the computing infrastructure are provided as services over the Internet. As promising as it is, this paradigm also brings forth many new challenges for data security and access control when users outsource sensitive data for sharing on cloud servers, which are not within the same trusted domain as data owners. To keep sensitive user data confidential against untrusted servers, existing solutions usually apply cryptographic methods by disclosing data decryption keys only to authorized users. However, in doing so, these solutions inevitably introduce a heavy computation overhead on the data owner for key distribution and data management when fine-grained data access control is desired, and thus do not scale well. The problem of simultaneously achieving fine-grainedness, scalability, and data confidentiality of access control actually still remains unresolved. This paper addresses this challenging open issue by, on one hand, defining and;['34744447', None, '144222395', '145612191'];['Shucheng Yu', 'Cong Wang', 'K. Ren', 'Wenjing Lou'];;;;;;;6fg5v0iy;2010 Proceedings IEEE INFOCOM;2010.0;85;['Cloud', 'Computer Science']
116927fbe4c9732fd1e392035a100c33b14e9d59;Big Data and cloud computing: innovation opportunities and challenges;"ABSTRACT Big Data has emerged in the past few years as a new paradigm providing abundant data and opportunities to improve and/or enable research and decision-support applications with unprecedented value for digital earth applications including business, sciences and engineering. At the same time, Big Data presents challenges for digital earth to store, transport, process, mine and serve the data. Cloud computing provides fundamental support to address the challenges with shared computing resources including computing, storage, networking and analytical software; the application of these resources has fostered impressive Big Data advancements. This paper surveys the two frontiers – Big Data and cloud computing – and reviews the advantages and consequences of utilizing cloud computing to tackling Big Data in the digital earth and relevant science domains. From the aspects of a general introduction, sources, challenges, technology status and research opportunities, the following observations are offered: (i) cloud computing and Big Data";['31823352', '32780423', '2574686', '2146385158', '46183721'];['C. Yang', 'Qunying Huang', 'Zhenlong Li', 'Kai Liu', 'F. Hu'];;;;;;;jkt5atb6;International Journal of Digital Earth;2017.0;10;['Cloud', 'Computer Science', 'Big Data']
861fca2a8708aa5c82b6447e6883c0f66fb6cad5;Dust Grain-Size Distributions and Extinction in the Milky Way, Large Magellanic Cloud, and Small Magellanic Cloud;We construct size distributions for carbonaceous and silicate grain populations in different regions of the Milky Way, LMC, and SMC. The size distributions include sufficient very small carbonaceous grains (including polycyclic aromatic hydrocarbon molecules) to account for the observed infrared and microwave emission from the diffuse interstellar medium. Our distributions reproduce the observed extinction of starlight, which varies depending on the interstellar environment through which the light travels. As shown by Cardelli, Clayton, and Mathis in 1989, these variations can be roughly parameterized by the ratio of visual extinction to reddening, RV. We adopt a fairly simple functional form for the size distribution, characterized by several parameters. We tabulate these parameters for various combinations of values for RV and bC, the C abundance in very small grains. We also find size distributions for the line of sight to HD 210121 and for sight lines in the LMC and SMC. For;['101113879', '3684240'];['J. Weingartner', 'B. Draine'];;;;;;;7bj60s4v;The Astrophysical Journal;2001.0;548;['Cloud', 'Physics']
a17141d9184ff8e05d90a8073ee9f0bef48bce71;Occupy the cloud: distributed computing for the 99%;Distributed computing remains inaccessible to a large number of users, in spite of many open source platforms and extensive commercial offerings. While distributed computation frameworks have moved beyond a simple map-reduce model, many users are still left to struggle with complex cluster management and configuration tools, even for running simple embarrassingly parallel jobs. We argue that stateless functions represent a viable platform for these users, eliminating cluster management overhead, fulfilling the promise of elasticity. Furthermore, using our prototype implementation, PyWren, we show that this model is general enough to implement a number of distributed computing models, such as BSP, efficiently. Extrapolating from recent trends in network bandwidth and the advent of disaggregated storage, we suggest that stateless functions are a natural fit for data processing in future computing environments.;['145426489', '2699039', '2697906', '2316152888', '9229182'];['Eric Jonas', 'Qifan Pu', 'S. Venkataraman', 'Ion Stoica', 'B. Recht'];d13e941e-4cac-4f1d-bdca-77d927e31f1b;ACM Symposium on Cloud Computing;conference;4;2017.0;London;;;;;['Cloud', 'Computer Science']
b3d6e545cf259c63b81526624e2a0a47844818aa;Enabling Public Verifiability and Data Dynamics for Storage Security in Cloud Computing;;['40102806', None, '144222395', '145612191', '2141513593'];['Qian Wang', 'Cong Wang', 'K. Ren', 'Wenjing Lou', 'Jin Li'];0bddd5d7-2897-495a-a961-465abe6e04de;European Symposium on Research in Computer Security;conference;20;2009.0;Barcelona;;;;;['Cloud', 'Computer Science']
21431fefe9ab4613c9e606c50d5f9fa8ff8923bd;Software-Defined Networking (SDN) and Distributed Denial of Service (DDoS) Attacks in Cloud Computing Environments: A Survey, Some Research Issues, and Challenges;Distributed Denial of Service (DDoS) attacks in cloud computing environments are growing due to the essential characteristics of cloud computing. With recent advances in software-defined networking (SDN), SDN-based cloud brings us new chances to defeat DDoS attacks in cloud computing environments. Nevertheless, there is a contradictory relationship between SDN and DDoS attacks. On one hand, the capabilities of SDN, including software-based traffic analysis, centralized control, global view of the network, dynamic updating of forwarding rules, make it easier to detect and react to DDoS attacks. On the other hand, the security of SDN itself remains to be addressed, and potential DDoS vulnerabilities exist across SDN platforms. In this paper, we discuss the new trends and characteristics of DDoS attacks in cloud computing, and provide a comprehensive survey of defense mechanisms against DDoS attacks using SDN. In addition, we review the studies about launching DDoS attacks on SDN, as well as;['144523271', '29953431', '3478880', '2108981225'];['Qiao Yan', 'F. Yu', 'Q. Gong', 'Jian-qiang Li'];;;;;;;f9gia24y;IEEE Communications Surveys & Tutorials;2016.0;18;['Cloud', 'Computer Science']
1870ebd563fcc8cd2b4b0c66ceb17c80a852dbcc;Blockchain Meets Cloud Computing: A Survey;"Blockchain technology has been deemed to be an ideal choice for strengthening existing computing systems in varied manners. As one of the network-enabled technologies, cloud computing has been broadly adopted in the industry through numerous cloud service models. Fusing blockchain technology with existing cloud systems has a great potential in both functionality/performance enhancement and security/privacy improvement. The question remains on how blockchain technology inserts into current deployed cloud solutions and enables the reengineering of cloud datacenter. This survey addresses this issue and investigates recent efforts in the technical fusion of blockchain and clouds. Three technical dimensions roughly are covered in this work. First, we concern the service model and review an emerging cloud-relevant blockchain service model, Blockchain-as-a-Service (BaaS); second, security is considered a key technical dimension in this work and both access control and searchable encryption schemes are assessed; finally, we examine the performance of cloud datacenter with supports/participance of";['2529746', '52172068', '1692039', '144958145'];['Keke Gai', 'Jinnan Guo', 'Liehuang Zhu', 'Shui Yu'];;;;;;;ccqngc9h;IEEE Communications Surveys & Tutorials;2020.0;22;['Cloud', 'Computer Science']
30242c19b45a126ca3c2ca80bd5b0a27e4cbc856;Improving our fundamental understanding of the role of aerosol−cloud interactions in the climate system;The effect of an increase in atmospheric aerosol concentrations on the distribution and radiative properties of Earth’s clouds is the most uncertain component of the overall global radiative forcing from preindustrial time. General circulation models (GCMs) are the tool for predicting future climate, but the treatment of aerosols, clouds, and aerosol−cloud radiative effects carries large uncertainties that directly affect GCM predictions, such as climate sensitivity. Predictions are hampered by the large range of scales of interaction between various components that need to be captured. Observation systems (remote sensing, in situ) are increasingly being used to constrain predictions, but significant challenges exist, to some extent because of the large range of scales and the fact that the various measuring systems tend to address different scales. Fine-scale models represent clouds, aerosols, and aerosol−cloud interactions with high fidelity but do not include interactions with the larger scale and are therefore limited from a;['2530017', '67038210', '145731477', '95824587', '5949435', '4424831', '145498827', '3060995', '41207379', '50487745', '8971717', '8950739', '145228715', '6115779', '3902161', '2264883', '145574955', '145520420', '46798441', '145483922', '26480577', '26805422', '2237523756'];['J. Seinfeld', 'C. Bretherton', 'K. Carslaw', 'H. Coe', 'P. DeMott', 'E. Dunlea', 'G. Feingold', 'S. Ghan', 'A. Guenther', 'R. Kahn', 'I. Kraucunas', 'S. Kreidenweis', 'M. Molina', 'A. Nenes', 'J. Penner', 'K. Prather', 'V. Ramanathan', 'V. Ramaswamy', 'P. Rasch', 'A. Ravishankara', 'D. Rosenfeld', 'G. Stephens', 'R. Wood'];;;;;;;8qxlxc06;Proceedings of the National Academy of Sciences;2016.0;113;['Cloud', 'Medicine', 'Geography']
fe8a742318315587bca05f41bee2e502c51cbbba;Cloud Container Technologies: A State-of-the-Art Review;Containers as a lightweight technology to virtualise applications have recently been successful, particularly to manage applications in the cloud. Often, the management of clusters of containers becomes essential and the orchestration of the construction and deployment becomes a central problem. This emerging topic has been taken up by researchers, but there is currently no secondary study to consolidate this research. We aim to identify, taxonomically classify and systematically compare the existing research body on containers and their orchestration and specifically the application of this technology in the cloud. We have conducted a systematic mapping study of 46 selected studies. We classified and compared the selected studies based on a characterisation framework. This results in a discussion of agreed and emerging concerns in the container orchestration space, positioning it within the cloud context, but also moving it closer to current concerns in cloud platforms, microservices and continuous development.;['8516149', '1787701', '2265546', '31948108'];['C. Pahl', 'Antonio Brogi', 'J. Soldani', 'Pooyan Jamshidi'];;;;;;;dwkfxqhl;IEEE Transactions on Cloud Computing;2019.0;7;['Cloud', 'Computer Science']
8d0efc6da17d5bf01446ce48ed9e9ac7e32d6565;A Survey of Communication Protocols for Internet of Things and Related Challenges of Fog and Cloud Computing Integration;The fast increment in the number of IoT (Internet of Things) devices is accelerating the research on new solutions to make cloud services scalable. In this context, the novel concept of fog computing as well as the combined fog-to-cloud computing paradigm is becoming essential to decentralize the cloud, while bringing the services closer to the end-system. This article surveys e application layer communication protocols to fulfill the IoT communication requirements, and their potential for implementation in fog- and cloud-based IoT systems. To this end, the article first briefly presents potential protocol candidates, including request-reply and publish-subscribe protocols. After that, the article surveys these protocols based on their main characteristics, as well as the main performance issues, including latency, energy consumption, and network throughput. These findings are thereafter used to place the protocols in each segment of the system (IoT, fog, cloud), and thus opens up the discussion on their choice,;['30611682', '46552388', '1708705', '1397682775'];['Jasenka Dizdarevic', 'Francisco Carpio', 'A. Jukan', 'X. Masip-Bruin'];;;;;;;ipema7iv;ACM Computing Surveys (CSUR);2018.0;51;['Cloud', 'Computer Science']
ac049658546137e7e0dcb4588d39e4d27c846e8a;Scheduling in cloud manufacturing: state-of-the-art and research challenges;For the past eight years, cloud manufacturing as a new manufacturing paradigm has attracted a large amount of research interest worldwide. The aim of cloud manufacturing is to deliver on-demand manufacturing services to consumers over the Internet. Scheduling is one of the critical means for achieving the aim of cloud manufacturing. Thus far, about 158 articles have been published on scheduling in cloud manufacturing. However, research on scheduling in cloud manufacturing faces numerous challenges. Thus, there is an urgent need to ascertain the current status and identify issues and challenges to be addressed in the future. Covering articles published on the subject over the past eight years, this article aims to provide a state-of-the-art literature survey on scheduling issues in cloud manufacturing. A detailed statistical analysis of the literature is provided based on the data gathered from the Elsevier’s Scopus abstract and citation database. Typical characteristics of scheduling issues in;['47908702', '95266142', '2108249118', '1390531672', '50081734'];['Yongkui Liu', 'Lihui Wang', 'X. Wang', 'X. Xu', 'Lin Zhang'];;;;;;;vqw518v5;International Journal of Production Research;2019.0;57;['Cloud', 'Computer Science']
7cf026a27f60fdce71e1bed0ce3808e5c149e319;Understanding determinants of cloud computing adoption using an integrated TAM-TOE model;– The purpose of this paper is to integrate TAM model and TOE framework for cloud computing adoption at organizational level. , – A conceptual framework was developed using technological and organizational variables of TOE framework as external variables of TAM model while environmental variables were proposed to have direct impact on cloud computing adoption. A questionnaire was used to collect the data from 280 companies in IT, manufacturing and finance sectors in India. The data were analyzed using exploratory and confirmatory factor analyses. Further, structural equation modeling was used to test the proposed model. , – The study identified relative advantage, compatibility, complexity, organizational readiness, top management commitment, and training and education as important variables for affecting cloud computing adoption using perceived ease of use (PEOU) and perceived usefulness (PU) as mediating variables. Also, competitive pressure and trading partner support were found directly affecting cloud computing adoption intentions. The;['2940611', '2362916', '32746789'];['H. Gangwar', 'Hema Date', 'R. Ramaswamy'];;;;;;;8aib1p3n;J. Enterp. Inf. Manag.;2015.0;28;['Cloud', 'Computer Science', 'Engineering']
3971c7213dd5221de0cd9fb5e899f527f951dddf;Object-based cloud and cloud shadow detection in Landsat imagery;;['145250899', '16252651'];['Zhe Zhu', 'C. Woodcock'];;;;;;;l9kzh8hz;Remote Sensing of Environment;2012.0;118;['Cloud', 'Computer Science']
ec13c3e7119191802e6f5783d297fe7a5a05293e;Mobile cloud computing: A survey;;['2131391', '1704577', '145492472'];['Niroshinie Fernando', 'S. Loke', 'W. Rahayu'];;;;;;;byjrnq8k;Future Gener. Comput. Syst.;2013.0;29;['Cloud', 'Computer Science']
04ecc68f27f8adcd986cf86b89861d0766c3feb1;RGCNN: Regularized Graph CNN for Point Cloud Segmentation;Point cloud, an efficient 3D object representation, has become popular with the development of depth sensing and 3D laser scanning techniques. It has attracted attention in various applications such as 3D tele-presence, navigation for unmanned vehicles and heritage reconstruction. The understanding of point clouds, such as point cloud segmentation, is crucial in exploiting the informative value of point clouds for such applications. Due to the irregularity of the data format, previous deep learning works often convert point clouds to regular 3D voxel grids or collections of images before feeding them into neural networks, which leads to voluminous data and quantization artifacts. In this paper, we instead propose a regularized graph convolutional neural network (RGCNN) that directly consumes point clouds. Leveraging on spectral graph theory, we treat features of points in a point cloud as signals on graph, and define the convolution over graph by Chebyshev polynomial approximation. In particular, we;['93104384', '1486300471', '35310979', '2060163708'];['Gusi Te', 'Wei Hu', 'Zongming Guo', 'Amin Zheng'];f2c85de5-7cfa-4b92-8714-a0fbdcf0274e;ACM Multimedia;conference;8;2018.0;Sydney;;;;;['Cloud', 'Computer Science', 'Graph']
0bb320c5c0219d2cbf43d03916d555046091a398;The MODIS cloud products: algorithms and examples from Terra;The Moderate Resolution Imaging Spectroradiometer (MODIS) is one of five instruments aboard the Terra Earth Observing System (EOS) platform launched in December 1999. After achieving final orbit, MODIS began Earth observations in late February 2000 and has been acquiring data since that time. The instrument is also being flown on the Aqua spacecraft, launched in May 2002. A comprehensive set of remote sensing algorithms for cloud detection and the retrieval of cloud physical and optical properties have been developed by members of the MODIS atmosphere science team. The archived products from these algorithms have applications in climate change studies, climate modeling, numerical weather prediction, as well as fundamental atmospheric research. In addition to an extensive cloud mask, products include cloud-top properties (temperature, pressure, effective emissivity), cloud thermodynamic phase, cloud optical and microphysical parameters (optical thickness, effective particle radius, water path), as well as derived statistics. We will describe the various;['2599057', '32170594', '26495389', '145162843', '35540947', '2503153', '31805336'];['S. Platnick', 'M. King', 'S. Ackerman', 'W. Menzel', 'B. Baum', 'J. Riedi', 'R. Frey'];;;;;;;0kp8jz2s;IEEE Trans. Geosci. Remote. Sens.;2003.0;41;['Cloud', 'Computer Science', 'Environmental Science']
7f415e318928fdad206b2984994a5a5ed58a2b35;Privacy-Preserving Public Auditing for Data Storage Security in Cloud Computing;Cloud Computing is the long dreamed vision of computing as a utility, where users can remotely store their data into the cloud so as to enjoy the on-demand high quality applications and services from a shared pool of configurable computing resources. By data outsourcing, users can be relieved from the burden of local data storage and maintenance. However, the fact that users no longer have physical possession of the possibly large size of outsourced data makes the data integrity protection in Cloud Computing a very challenging and potentially formidable task, especially for users with constrained computing resources and capabilities. Thus, enabling public auditability for cloud data storage security is of critical importance so that users can resort to an external audit party to check the integrity of outsourced data when needed. To securely introduce an effective third party auditor (TPA), the following two fundamental requirements have to be met: 1);[None, '40102806', '144222395', '145612191'];['Cong Wang', 'Qian Wang', 'K. Ren', 'Wenjing Lou'];;;;;;;yw4cu9b7;2010 Proceedings IEEE INFOCOM;2010.0;55;['Cloud', 'Computer Science', 'Business']
8d3a115131f741ffa7a0815f9fa47707673ec3a2;Follow-Me Cloud: When Cloud Services Follow Mobile Users;The trend towards the cloudification of the 3GPP LTE mobile network architecture and the emergence of federated cloud infrastructures call for alternative service delivery strategies for improved user experience and efficient resource utilization. We propose Follow-Me Cloud (FMC), a design tailored to this environment, but with a broader applicability, which allows mobile users to always be connected via the optimal data anchor and mobility gateways, while cloud-based services follow them and are delivered via the optimal service point inside the cloud infrastructure. Follow-Me Cloud applies a Markov-decision-process-based algorithm for cost-effective performance-optimized service migration decisions, while two alternative schemes to ensure service continuity and disruption-free operation are proposed, based on either software defined networking technologies or the locator/identifier separation protocol. Numerical results from our analytic model for follow-me cloud, as well as testbed experiments with the two alternative follow-me cloud implementations we have developed, demonstrate quantitatively and qualitatively the advantages it;['1682312', '143816652', '1977724'];['T. Taleb', 'A. Ksentini', 'P. Frangoudis'];;;;;;;m5y6y79b;IEEE Transactions on Cloud Computing;2019.0;7;['Cloud', 'Computer Science']
78da12073562af63b2f0e5f22f2503583e485702;From cloud computing to cloud manufacturing;;['1390531672'];['X. Xu'];;;;;;;0dgmmgo8;Robotics and Computer-integrated Manufacturing;2012.0;28;['Cloud', 'Computer Science']
4ac15bbdedd3f826d68587942768eeac280b666d;Review of Aerosol–Cloud Interactions: Mechanisms, Significance, and Challenges;AbstractOver the past decade, the number of studies that investigate aerosol–cloud interactions has increased considerably. Although tremendous progress has been made to improve the understanding of basic physical mechanisms of aerosol–cloud interactions and reduce their uncertainties in climate forcing, there is still poor understanding of 1) some of the mechanisms that interact with each other over multiple spatial and temporal scales, 2) the feedbacks between microphysical and dynamical processes and between local-scale processes and large-scale circulations, and 3) the significance of cloud–aerosol interactions on weather systems as well as regional and global climate. This review focuses on recent theoretical studies and important mechanisms on aerosol–cloud interactions and discusses the significances of aerosol impacts on radiative forcing and precipitation extremes associated with different cloud systems. The authors summarize the main obstacles preventing the science from making a leap—for exampl...;['2272176540', '47906285', '26480577', '49543901'];['Jiwen Fan', 'Y. Wang', 'D. Rosenfeld', 'Xiaohong Liu'];;;;;;;l25tis5o;Journal of the Atmospheric Sciences;2016.0;73;['Cloud', 'Environmental Science']
3b645732e5d5b92636fbe9ca7e3363a4164a569f;The cost of a cloud: research problems in data center networks;The data centers used to create cloud services represent a significant investment in capital outlay and ongoing costs. Accordingly, we first examine the costs of cloud service data centers today. The cost breakdown reveals the importance of optimizing work completed per dollar invested. Unfortunately, the resources inside the data centers often operate at low utilization due to resource stranding and fragmentation. To attack this first problem, we propose (1) increasing network agility, and (2) providing appropriate incentives to shape resource consumption. Second, we note that cloud service providers are building out geo-distributed networks of data centers. Geo-diversity lowers latency to users and increases reliability in the presence of an outage taking out an entire site. However, without appropriate design and management, these geo-diverse data center networks can raise the cost of providing service. Moreover, leveraging geo-diversity requires services be designed to benefit from it. To attack this problem, we propose;['34820574', '2065116446', '6103581', '40413635'];['A. Greenberg', 'James R. Hamilton', 'D. Maltz', 'Parveen Patel'];;;;;;;kq56suts;Comput. Commun. Rev.;2008.0;39;['Cloud', 'Computer Science']
325f4787a40c14518529a64332b801e6f53b22d7;Market-Oriented Cloud Computing: Vision, Hype, and Reality for Delivering IT Services as Computing Utilities;"This keynote paper: presents a 21st century vision of computing; identifies various computing paradigms promising to deliver the vision of computing utilities; defines Cloud computing and provides the architecture for creating market-oriented Clouds by leveraging technologies such as VMs; provides thoughts on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain SLA-oriented resource allocation; presents some representative Cloud platforms especially those developed in industries along with our current work towards realising market-oriented resource allocation of Clouds by leveraging the 3rd generation Aneka enterprise Grid technology; reveals our early thoughts on interconnecting Clouds for dynamically creating an atmospheric computing environment along with pointers to future community research; and concludes with the need for convergence of competing IT paradigms for delivering our 21st century vision.";['1709598', '2353888', '2291598'];['R. Buyya', 'Chee Shin Yeo', 'S. Venugopal'];c57e0966-f80c-4bbb-aadb-b6a0842e1390;IEEE International Conference on High Performance Computing and Communications;conference;17;2008.0;Beijing;;;;;['Cloud', 'Computer Science']
a3821587594ebe95ad80d6db237f66cd88ff8758;Enhancing the security of cloud data using hybrid encryption algorithm;;['9192059', '9312242', '19222303'];['K. R. Sajay', 'S. Babu', 'Y. Vijayalakshmi'];;;;;;;bha7ch07;Journal of Ambient Intelligence and Humanized Computing;2019.0;82;['Cloud', 'Computer Science', 'Encryption']
93a96e0f68038fbbe70f80952632e8f0770af56e;Cloud Computing for Mobile Users: Can Offloading Computation Save Energy?;The cloud heralds a new era of computing where application services are provided through the Internet. Cloud computing can enhance the computing capability of mobile systems, but is it the ultimate solution for extending such systems' battery lifetimes?;['2110685283', '1781255'];['Karthik Kumar', 'Yung-Hsiang Lu'];;;;;;;3rx4brck;Computer;2010.0;43;['Cloud', 'Computer Science']
2a59411d40995fdfcd88b5c0ddd59161ac6eccad;Colored Point Cloud Registration Revisited;We present an algorithm for aligning two colored point clouds. The key idea is to optimize a joint photometric and geometric objective that locks the alignment along both the normal direction and the tangent plane. We extend a photometric objective for aligning RGB-D images to point clouds, by locally parameterizing the point cloud with a virtual camera. Experiments demonstrate that our algorithm is more accurate and more robust than prior point cloud registration algorithms, including those that utilize color information. We use the presented algorithms to enhance a state-of-the-art scene reconstruction system. The precision of the resulting system is demonstrated on real-world scenes with accurate ground-truth models.;['2870153', '7451623', '145231047'];['Jaesik Park', 'Qian-Yi Zhou', 'V. Koltun'];7654260e-79f9-45c5-9663-d72027cf88f3;IEEE International Conference on Computer Vision;conference;10;2017.0;Houston;;;;;['Cloud', 'Computer Science']
89a45f283144013ab824afd50b154a1e0ce4577f;Dynamic Data Operations with Deduplication in Privacy-Preserving Public Auditing for Secure Cloud Storage;Cloud storage service has been increasing in popularity as cloud computing plays an important role in the IT domain. Users can be relieved of the burden of storage and computation, by outsourcing the large data files to the cloud servers. However, from the cloud service providers' point of view, it is wise to utilize the data deduplication techniques to reduce the costs of running large storage system and energy consumption on cloud servers. Based on the dynamic nature of data in the cloud storage system, we not only need to assure the data integrity with an auditing protocol supporting dynamic data operations for users, but also consider resorting to data deduplication techniques in the dynamic data operations for cloud service providers to achieve the goal of reducing costs. Thus, in this paper, we propose a mechanism that combines data deduplication with dynamic data operations in the privacy preserving public auditing;[None, '145876490', '40102806', '144222395', '145612191'];['Cong Wang', 'Sherman S. M. Chow', 'Qian Wang', 'K. Ren', 'Wenjing Lou'];;;;;;;j70ws93v;22017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC);2017.0;01;['Cloud', 'Computer Science']
f286ff4d80e330e27b858cc4ec32a0c3bef0e125;Geometric distortion metrics for point cloud compression;It is challenging to measure the geometry distortion of point cloud introduced by point cloud compression. Conventionally, the errors between point clouds are measured in terms of point-to-point or point-to-surface distances, that either ignores the surface structures or heavily tends to rely on specific surface reconstructions. To overcome these drawbacks, we propose using point-to-plane distances as a measure of geometric distortions on point cloud compression. The intrinsic resolution of the point clouds is proposed as a normalizer to convert the mean square errors to PSNR numbers. In addition, the perceived local planes are investigated at different scales of the point cloud. Finally, the proposed metric is independent of the size of the point cloud and rather reveals the geometric fidelity of the point cloud. From experiments, we demonstrate that our method could better track the perceived quality than the point-to-point approach while requires limited computations.;['144309297', '9169832', '144066717', '39680709', '1690385'];['Dong Tian', 'H. Ochimizu', 'Chen Feng', 'R. Cohen', 'A. Vetro'];b6369c33-5d70-463c-8e82-95a54efa3cc8;International Conference on Information Photonics;conference;1;2017.0;Paris;;;;;['Cloud', 'Computer Science']
6d7d48fdde91604d8047e8574b11d05465d9e0be;3D fully convolutional network for vehicle detection in point cloud;2D fully convolutional network has been recently successfully applied to the object detection problem on images. In this paper, we extend the fully convolutional network based detection techniques to 3D and apply it to point cloud data. The proposed approach is verified on the task of vehicle detection from lidar point cloud for autonomous driving. Experiments on the KITTI dataset shows significant performance improvement over the previous point cloud based detection approaches.;['38406638'];['Bo Li'];37275deb-3fcf-4d16-ae77-95db9899b1f3;IEEE/RJS International Conference on Intelligent RObots and Systems;conference;14;2016.0;Los Angeles;;;;;['Cloud', 'Computer Science']
6da97b0e5a973242567612788b2c0982c4529789;A hierarchical edge cloud architecture for mobile computing;The performance of mobile computing would be significantly improved by leveraging cloud computing and migrating mobile workloads for remote execution at the cloud. In this paper, to efficiently handle the peak load and satisfy the requirements of remote program execution, we propose to deploy cloud servers at the network edge and design the edge cloud as a tree hierarchy of geo-distributed servers, so as to efficiently utilize the cloud resources to serve the peak loads from mobile users. The hierarchical architecture of edge cloud enables aggregation of the peak loads across different tiers of cloud servers to maximize the amount of mobile workloads being served. To ensure efficient utilization of cloud resources, we further propose a workload placement algorithm that decides which edge cloud servers mobile programs are placed on and how much computational capacity is provisioned to execute each program. The performance of our proposed hierarchical edge cloud architecture;['2069441004', '2154405247', '145816343'];['Liang Tong', 'Yong Li', 'Wei Gao'];;;;;;;zfk5mp6e;IEEE INFOCOM 2016 - The 35th Annual IEEE International Conference on Computer Communications;2016.0;23;['Cloud', 'Computer Science']
32a11508fcbbb64a9b427b57403dc1ad54b6d718;A Cost-Effective Deadline-Constrained Dynamic Scheduling Algorithm for Scientific Workflows in a Cloud Environment;Cloud computing, a distributed computing paradigm, enables delivery of IT resources over the Internet and follows the pay-as-you-go billing model. Workflow scheduling is one of the most challenging problems in cloud computing. Although, workflow scheduling on distributed systems like grids and clusters have been extensively studied, however, these solutions are not viable for a cloud environment. It is because, a cloud environment differs from other distributed environment in two major ways: on-demand resource provisioning and pay-as-you-go pricing model. Thus, to achieve the true benefits of workflow orchestration onto cloud resources novel approaches that can capitalize the advantages and address the challenges specific to a cloud environment needs to be developed. This work proposes a dynamic cost-effective deadline-constrained heuristic algorithm for scheduling a scientific workflow in a public cloud. The proposed technique aims to exploit the advantages offered by cloud computing while taking into account the virtual machine (VM) performance variability;['48938947', '3211750'];['Jyoti Sahni', 'D. P. Vidyarthi'];;;;;;;sydv9aze;IEEE Transactions on Cloud Computing;2018.0;6;['Cloud', 'Computer Science']
1eb363ef8d56f8b229166216ba69a70184368535;An Analysis of the Cloud Computing Security Problem;Cloud computing is a new computational paradigm that offers an innovative business model for organizations to adopt IT without upfront investment. Despite the potential gains achieved from the cloud computing, the model security is still questionable which impacts the cloud model adoption. The security problem becomes more complicated under the cloud model as new dimensions have entered into the problem scope related to the model architecture, multi-tenancy, elasticity, and layers dependency stack. In this paper we introduce a detailed analysis of the cloud security problem. We investigated the problem from the cloud architecture perspective, the cloud offered characteristics perspective, the cloud stakeholders' perspective, and the cloud service delivery models perspective. Based on this analysis we derive a detailed specification of the cloud security problem and key features that should be covered by any proposed security solution.;['3166473', '1687239', None];['Mohamed Almorsy', 'J. Grundy', 'Ingo Müller'];8bcdbd50-f829-4fb4-ab17-bf6bffa1c5a5;Asia-Pacific Software Engineering Conference;conference;20;2016.0;Beijing;;;;;['Cloud', 'Computer Science']
7a1eec7fc53fa2e4de69bab6aed1b68e949331f1;A Taxonomy and Survey of Cloud Computing Systems;The computational world is becoming very large and complex. Cloud Computing has emerged as a popular computing model to support processing large volumetric data using clusters of commodity computers. According to J.Dean and S. Ghemawat [1], Google currently processes over 20 terabytes of raw web data. It's some fascinating, large-scale processing of data that makes your head spin and appreciate the years of distributed computing fine-tuning applied to today's large problems. The evolution of cloud computing can handle such massive data as per on demand service. Nowadays the computational world is opting for pay-for-use models and Hype and discussion aside, there remains no concrete definition of cloud computing. In this paper, we first develop a comprehensive taxonomy for describing cloud computing architecture. Then we use this taxonomy to survey several existing cloud computing services developed by various projects world-wide such as Google, force.com, Amazon. We use the taxonomy and survey;['3407759', '143691244', '1822292'];['B. Rimal', 'Eunmi Choi', 'I. Lumb'];;;;;;;31dr46h6;2009 Fifth International Joint Conference on INC, IMS and IDC;2009.0;18;['Cloud', 'Computer Science']
f125b540d7453eb58d38f933588f4b80c80959f2;Containers and Cloud: From LXC to Docker to Kubernetes;"This issue's ""Cloud Tidbit"" focuses on container technology and how it's emerging as an important part of the cloud computing infrastructure. It looks at Docker, an open source project that automates the faster deployment of Linux applications, and Kubernetes, an open source cluster manager for Docker containers.";['2058099341'];['D. Bernstein'];;;;;;;oqsxpm2h;IEEE Cloud Computing;2014.0;1;['Cloud', 'Computer Science']
17f19d9ec093ef82a10f1276fc53c10d4667836d;Shielding Applications from an Untrusted Cloud with Haven;Today’s cloud computing infrastructure requires substantial trust. Cloud users rely on both the provider’s staff and its globally distributed software/hardware platform not to expose any of their private data. We introduce the notion of shielded execution, which protects the confidentiality and integrity of a program and its data from the platform on which it runs (i.e., the cloud operator’s OS, VM, and firmware). Our prototype, Haven, is the first system to achieve shielded execution of unmodified legacy applications, including SQL Server and Apache, on a commodity OS (Windows) and commodity hardware. Haven leverages the hardware protection of Intel SGX to defend against privileged code and physical attacks such as memory probes, and also addresses the dual challenges of executing unmodified legacy binaries and protecting them from a malicious host. This work motivated recent changes in the SGX specification.;['1919355', '143697538', '1880051'];['Andrew Baumann', 'Marcus Peinado', 'G. Hunt'];86c43745-31d9-4c1a-b33f-ce3aa0042dbb;USENIX Symposium on Operating Systems Design and Implementation;conference;2;2014.0;Beijing;;;;;['Cloud', 'Computer Science']
713fbe049deb2bdd01ac07f25ccf4e015b16c98e;A Survey on Resource Scheduling in Cloud Computing: Issues and Challenges;;['48039508', '1920204'];['Sukhpal Singh', 'Inderveer Chana'];;;;;;;3t3vrncc;Journal of Grid Computing;2016.0;14;['Cloud', 'Computer Science']
317ad53bea6fb603c20f692bb2f1a01e2dc86161;From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy;Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI;['11690554', '1845852582', '2140578267', '2185323688', '1741545369'];['Maanak Gupta', 'Charankumar Akiri', 'Kshitiz Aryal', 'Elisabeth Parker', 'Lopamudra Praharaj'];;;;;;;6xdtilqz;IEEE Access;2023.0;11;['Computer Science', 'Cybersecurity']
193f54879601e76884d6562a5e5e01117fed3ded;Cybersecurity compliance in financial institutions: A comparative analysis of global standards and regulations;Cybersecurity is a critical concern for financial institutions worldwide, given the increasing frequency and sophistication of cyberattacks. This paper conducts a comparative analysis of global standards and regulations governing cybersecurity compliance in financial institutions. By examining the regulatory frameworks of key jurisdictions, including the United States, the European Union, and Asia-Pacific countries, this study aims to identify common trends, differences, and best practices in cybersecurity compliance. The analysis begins by outlining the regulatory landscape for cybersecurity in financial institutions, highlighting the key objectives and principles underlying these regulations. It then compares the regulatory frameworks of different regions, focusing on areas such as data protection, incident response, and risk management. By examining the specific requirements and guidelines set forth by each jurisdiction, this study identifies the strengths and weaknesses of current cybersecurity regulations and offers recommendations for enhancing compliance and resilience. One of the key findings of this study is the;['2301238634', '2301240930', '2301241444'];['Ngozi Samuel Uzougbo', 'Chinonso Gladys Ikegwu', 'Adefolake Olachi Adewusi'];;;;;;;gc525wxr;International Journal of Science and Research Archive;2024.0;80;['Cybersecurity']
c81aa1a53904bd359aa014d6576fbb54809bd779;The integration of artificial intelligence in cybersecurity measures for sustainable finance platforms: An analysis;This study delves into the integration of Artificial Intelligence (AI) in cybersecurity measures within smart cities, aiming to uncover both the challenges and opportunities this fusion presents. With the burgeoning reliance on interconnected digital infrastructures and the vast data ecosystems within urban environments, smart cities are increasingly susceptible to sophisticated cyber threats. Through a systematic literature review and content analysis, this research identifies the unique cybersecurity vulnerabilities faced by smart cities and evaluates how AI technologies can fortify urban cybersecurity frameworks. The methodology encompasses a comprehensive review of recent scholarly articles, industry reports, and case studies to assess the role of AI in enhancing threat detection, response, and prevention mechanisms. Key findings reveal that AI-driven cybersecurity solutions significantly enhance the resilience of smart cities against cyber threats by providing advanced analytical capabilities and real-time threat intelligence. However, the study also highlights the critical need for robust ethical and privacy considerations;['2303877043', '2302616639', '2302616898', '2303881270'];['Ezekiel Onyekachukwu Udeh', 'Prisca Amajuoyi', 'Kudirat Bukola Adeusi', 'Anwulika Ogechukwu Scott'];;;;;;;wrdtmean;"Computer Science &amp; IT Research Journal";2024.0;51;['Cybersecurity', 'Artificial Intelligence']
a5747b67b3213c7eccba6183b9bffb4828e8a299;CYBERSECURITY IN BANKING: A GLOBAL PERSPECTIVE WITH A FOCUS ON NIGERIAN PRACTICES;The paper review cybersecurity practices in banking, with a specific focus on Nigerian banks. Cybersecurity has become a paramount concern in the banking industry worldwide, given the escalating frequency and sophistication of cyber threats. This study provides an overview of the global landscape of cybersecurity in banking, with a specific focus on practices observed in Nigeria. The global banking sector is witnessing a surge in digital transformation, marked by the adoption of advanced technologies and online financial services. However, this digitization brings with it unprecedented cybersecurity challenges, ranging from data breaches and ransomware attacks to sophisticated financial fraud. Financial institutions globally are compelled to fortify their cybersecurity frameworks to protect sensitive customer information, ensure the integrity of financial transactions, and maintain trust in the digital financial ecosystem. Nigeria, as a key player in the African banking landscape, faces unique cybersecurity challenges and has developed distinct strategies to safeguard its financial;['2268349678', '2276083334', '2280216174', '2277966027', '2268534121', '2276088894'];['Azeez Olanipekun Hassan', 'Sarah Kuzankah Ewuga', 'Adekunle Abiola Abdul', 'Temitayo Oluwaseun Abrahams', 'Monisola Oladeinde', 'Samuel Onimisi Dawodu'];;;;;;;bp5kf1he;"Computer Science &amp; IT Research Journal";2024.0;64;['Cybersecurity']
9ed1c306e77ddcc195b2beffa09049399a07a470;Artificial intelligence for cybersecurity: Literature review and future research directions;;['47570595', '1687279', '1700676'];['Ramanpreet Kaur', 'D. Gabrijelcic', 'T. Klobučar'];;;;;;;4sw55ox9;Inf. Fusion;2023.0;97;['Computer Science', 'Cybersecurity', 'Artificial Intelligence']
b1c09857fea0540334b7dd9e1f7b5d2b1247d86c;DATA CONFIDENTIALITY AND INTEGRITY: A REVIEW OF ACCOUNTING AND CYBERSECURITY CONTROLS IN SUPERANNUATION ORGANIZATIONS;In an era dominated by digital transformation, superannuation organizations face unprecedented challenges in safeguarding the confidentiality and integrity of sensitive financial data. This review explores the intricate relationship between accounting practices and cybersecurity controls within the context of superannuation entities. By examining the existing literature, regulatory frameworks, and industry best practices, this paper synthesizes the key considerations essential for ensuring robust data protection. The study delves into the critical role of accounting systems in managing financial information and the subsequent implications for data confidentiality. It investigates how evolving accounting standards and practices intersect with cybersecurity protocols to fortify the integrity of financial records within superannuation organizations. The dynamic nature of cyber threats necessitates a comprehensive analysis of technological safeguards, risk management frameworks, and compliance measures to uphold data confidentiality. Furthermore, the review underscores the imperative for a multidimensional approach to cybersecurity in the superannuation sector. It discusses the integration of;['2276098916', '2282621013', '2290736541', '2276088455', '2282620980'];['Anthony Anyanwu', 'Temidayo Olorunsogo', 'Temitayo Oluwaseun Abrahams', 'Odunayo Josephine Akindote', 'Oluwatosin Reis'];;;;;;;asqlznqd;"Computer Science &amp; IT Research Journal";2024.0;6;['Cybersecurity']
f169931858410fe06af98967fc131669a8c81ac4;LSTM Recurrent Neural Networks for Cybersecurity Named Entity Recognition;The automated and timely conversion of cybersecurity information from unstructured online sources, such as blogs and articles to more formal representations has become a necessity for many applications in the domain nowadays. Named Entity Recognition (NER) is one of the early phases towards this goal. It involves the detection of the relevant domain entities, such as product, version, attack name, etc. in technical documents. Although generally considered a simple task in the information extraction field, it is quite challenging in some domains like cybersecurity because of the complex structure of its entities. The state of the art methods require time-consuming and labor intensive feature engineering that describes the properties of the entities, their context, domain knowledge, and linguistic characteristics. The model demonstrated in this paper is domain independent and does not rely on any features specific to the entities in the cybersecurity domain, hence does not require expert knowledge to;['50678943', '145235056'];['Houssem Gasmi', 'Abdelaziz Bouras'];;;;;;;h9s2jeva;ArXiv;2024.0;abs/2409.10521;['Neural Networks', 'Computer Science', 'Cybersecurity']
be8940fd490e058cb851a21bd455ffb9b01d025a;CYBERSECURITY DYNAMICS IN NIGERIAN BANKING: TRENDS AND STRATEGIES REVIEW;This paper provides an in-depth review of the cybersecurity dynamics within the Nigerian banking sector, emphasizing recent trends and strategic approaches to address emerging challenges. As a review paper, it synthesizes existing literature, reports, and case studies to offer a comprehensive understanding of the current cybersecurity landscape in Nigerian banks. The focus is on identifying the predominant cyber threats, analyzing the sector's response strategies, and evaluating the effectiveness of these measures in the context of Nigeria's unique socio-economic and regulatory environment. Our analysis reveals a notable escalation in cyber threats, particularly phishing, ransomware, and insider attacks, which have been intensified by the rapid digital transformation in banking services. The review identifies key factors contributing to these challenges, such as the increasing sophistication of cybercriminals, the digital literacy gap among customers, and the evolving nature of cyber threats. It also examines the strategic responses of Nigerian banks, including the adoption of;['2327738876', '2289253438', '2281872028', '2281665409'];['Oluwatosin Reis', 'Johnson Sunday Oliha', 'Femi Osasona', 'Ogugua Chimezie Obi'];;;;;;;csd5bp67;"Computer Science &amp; IT Research Journal";2024.0;26;['Cybersecurity']
5ccd0970fbdb1e4a321434223ee3e13399ad0851;CYBERSECURITY CHALLENGES IN THE AGE OF AI: THEORETICAL APPROACHES AND PRACTICAL SOLUTIONS;In the ever-evolving landscape of cybersecurity, the proliferation of artificial intelligence (AI) technologies introduces both promising advancements and daunting challenges. This paper explores the theoretical underpinnings and practical implications of addressing cybersecurity challenges in the age of AI. With the integration of AI into various facets of digital infrastructure, including threat detection, authentication, and response mechanisms, cyber threats have become increasingly sophisticated and difficult to mitigate. Theoretical approaches delve into understanding the intricate interplay between AI algorithms, human behavior, and adversarial tactics, elucidating the underlying mechanisms of cyber attacks and defense strategies. However, this complexity also engenders novel vulnerabilities, as AI-driven attacks leverage machine learning algorithms to evade traditional security measures, posing formidable challenges to organizations across sectors. As such, practical solutions necessitate a multifaceted approach, encompassing robust threat intelligence, adaptive defense mechanisms, and ethical considerations to safeguard against AI-driven cyber threats effectively. Leveraging AI for cybersecurity defense holds promise;['2297230392'];['Babajide Tolulope Familoni'];;;;;;;ptn3n7t3;"Computer Science &amp; IT Research Journal";2024.0;29;['Cybersecurity']
49771cf58fc601e7592fec0cc0de71e0364c3ff2;The Role of AI in Cybersecurity: Addressing Threats in the Digital Age;In the contemporary digital landscape, cybersecurity stands as a paramount concern due to the increasing sophistication and frequency of cyber threats. Artificial Intelligence (AI) has emerged as a potent tool in fortifying defenses against these evolving threats. This paper examines the multifaceted role of AI in cybersecurity, elucidating its applications in threat detection, vulnerability assessment, incident response, and predictive analysis. By leveraging machine learning algorithms, AI systems can swiftly analyze vast troves of data to identify anomalous patterns indicative of potential security breaches. Moreover, AI-driven technologies enable proactive defense mechanisms, empowering organizations to preemptively mitigate risks and safeguard sensitive information. However, the deployment of AI in cybersecurity also raises pertinent ethical and privacy considerations, necessitating a balanced approach towards its implementation. Through a comprehensive analysis, this paper underscores the imperative of integrating AI into cybersecurity frameworks to effectively mitigate threats in the digital age.;['2289698409'];['Nicolas Guzman Camacho'];;;;;;;hxpl8jb7;Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023;2024.0;80;['Cybersecurity']
e1ba19c3a819a79b5979cd57289011ba905bad70;Machine learning in cybersecurity: A review of threat detection and defense mechanisms;The cybersecurity concerns get increasingly intricate as the digital world progresses. In light of the increasing complexity of cyber threats, it is imperative to develop and implement advanced and flexible security strategies. Machine Learning (ML) has become a potent tool in strengthening cybersecurity, providing the capacity to scrutinise extensive information, recognise trends, and improve threat detection and defence methods. This paper examines the significance of ML in the field of cybersecurity, with a special emphasis on the identification of threats and the implementation of protective measures. By incorporating ML algorithms into cybersecurity frameworks, organisations may automate decision-making processes, facilitating prompt responses to ever-changing threats. The initial segment explores the terrain of cyber threats, highlighting the necessity for dynamic and aggressive security methods. Conventional solutions that rely on signatures are frequently inadequate when it comes to handling sophisticated, shape-shifting attacks. ML algorithms, in contrast, have exceptional proficiency in identifying nuanced patterns;['2282311375', '4820479', '2290099374', '2290202317'];['Temitayo Oluwaseun Abrahams', 'U. Okoli', 'Ogugua Chimezie Obi', 'Adebunmi Okechukwu Adewusi'];;;;;;;fxyk7gqe;World Journal of Advanced Research and Reviews;2024.0;55;['Threat Detection', 'Cybersecurity', 'Machine Learning']
a88d5fb82358d19d0daed7d35d49f03ea6796b57;Large Language Models in Cybersecurity: State-of-the-Art;The rise of Large Language Models (LLMs) has revolutionized our comprehension of intelligence bringing us closer to Artificial Intelligence. Since their introduction, researchers have actively explored the applications of LLMs across diverse fields, significantly elevating capabilities. Cybersecurity, traditionally resistant to data-driven solutions and slow to embrace machine learning, stands out as a domain. This study examines the existing literature, providing a thorough characterization of both defensive and adversarial applications of LLMs within the realm of cybersecurity. Our review not only surveys and categorizes the current landscape but also identifies critical research gaps. By evaluating both offensive and defensive applications, we aim to provide a holistic understanding of the potential risks and opportunities associated with LLM-driven cybersecurity.;['9553167', '47104154', '1854677692', '41048869', '2282472128', '2255611957'];['Farzad Nourmohammadzadeh Motlagh', 'Mehrdad Hajizadeh', 'Mehryar Majd', 'Pejman Najafi', 'Feng Cheng', 'Christoph Meinel'];;;;;;;qh0y9kiq;ArXiv;2024.0;abs/2402.00891;['Computer Science', 'Cybersecurity']
754f3d75adbf243cda601bb815784a2d73bbb711;MASTERING COMPLIANCE: A COMPREHENSIVE REVIEW OF REGULATORY FRAMEWORKS IN ACCOUNTING AND CYBERSECURITY;In the rapidly evolving landscape of business and technology, the intersection of accounting and cybersecurity has become a focal point for organizations striving to maintain integrity, security, and regulatory adherence. This paper presents a meticulous examination of regulatory frameworks governing both accounting and cybersecurity domains. The study aims to provide a comprehensive understanding of the intricate compliance landscape, offering valuable insights for practitioners, policymakers, and scholars. The investigation unfolds through a dual lens, meticulously dissecting the regulatory intricacies surrounding financial reporting in accounting and the safeguarding of digital assets in cybersecurity. A critical analysis of prominent global regulatory bodies, such as the Financial Accounting Standards Board (FASB), the International Financial Reporting Standards (IFRS), and cybersecurity standards like ISO 27001 and NIST Cybersecurity Framework, forms the cornerstone of this research. The paper delves into the historical evolution of accounting and cybersecurity regulations, identifying key milestones and paradigm shifts that have shaped;['2277966027', '2276083334', '2279235013', '2279245631', '2268349678', '2276088894'];['Temitayo Oluwaseun Abrahams', 'Sarah Kuzankah Ewuga', 'Simon Kaggwa', 'Prisca Ugomma Uwaoma', 'Azeez Olanipekun Hassan', 'Samuel Onimisi Dawodu'];;;;;;;qv8x7sd5;"Computer Science &amp; IT Research Journal";2024.0;8;['Cybersecurity']
1098d3743083c4c6a39a124efb725c10d2b7423c;COMPREHENSIVE REVIEW ON CYBERSECURITY: MODERN THREATS AND ADVANCED DEFENSE STRATEGIES;In the rapidly evolving landscape of cyberspace, the prevalence of sophisticated cyber threats has escalated, posing formidable challenges to individuals, organizations, and nations. This comprehensive review explores the contemporary panorama of cybersecurity, focusing on the latest threats and the advanced defense strategies employed to mitigate them. The analysis encompasses a wide spectrum of cyber threats, including malware, ransomware, phishing attacks, and advanced persistent threats (APTs), shedding light on their evolving tactics, techniques, and procedures. The review delves into the intricate world of cybercrime, emphasizing the motives behind attacks and the diverse range of threat actors involved, from individual hackers to state-sponsored entities. By examining recent case studies and real-world incidents, the review provides valuable insights into the dynamic nature of cyber threats, emphasizing the need for proactive and adaptive cybersecurity measures. Furthermore, the review critically evaluates cutting-edge defense mechanisms and strategies deployed to counteract these threats. It explores advancements in;['2281665409', '2281880960', '2281864440', '2282737838', '2281872934', '2282737947'];['Ogugua Chimezie Obi', 'Onyinyechi Vivian Akagha', 'Samuel Onimisi Dawodu', 'Anthony Chigozie Anyanwu', 'Shedrack Onwusinkwue', 'Islam Ahmad Ibrahim Ahmad'];;;;;;;rxn7ej21;"Computer Science &amp; IT Research Journal";2024.0;38;['Cybersecurity']
e30a06e161d7ef4612ae56e5e91f7c8c15fe6951;CYBERSECURITY IN THE FINANCIAL SECTOR: A COMPARATIVE ANALYSIS OF THE USA AND NIGERIA;This paper provides a comprehensive review and comparative analysis of cybersecurity challenges and strategies within the financial sectors of the United States of America (USA) and Nigeria. It aims to elucidate the complexities and variances in cybersecurity practices, focusing on the different approaches taken by these nations to safeguard their financial data against increasing cyber threats. Through a detailed examination of existing literature, including academic journals, industry reports, and cybersecurity incident databases, this study identifies the unique and common cybersecurity vulnerabilities, regulatory environments, and defense mechanisms employed by the financial sectors in both countries. The review reveals that the USA's financial sector benefits from advanced cybersecurity technologies and a strong regulatory framework, yet faces challenges related to sophisticated cyber-attacks and the management of insider threats. Conversely, Nigeria's financial sector grapples with issues such as limited cybersecurity awareness, technological constraints, and evolving regulatory frameworks. Despite these disparities, both countries share the;['2294039735', '2297241946'];['Babajide Tolulope Familoni', 'Philip Olaseni Shoetan'];;;;;;;i9ayn1hr;"Computer Science &amp; IT Research Journal";2024.0;95;['Cybersecurity']
767e710dd7036a4b01a9a2156b006b66bc4b2250;AI-Driven Cybersecurity: Balancing Advancements and Safeguards;As Artificial Intelligence (AI) continues its rapid evolution, its profound influence on cybersecurity becomes increasingly evident. This study delves into the pivotal role of AI in fortifying cybersecurity measures, emphasizing its capacity for enhanced threat detection, automated response mechanisms, and the development of resilient security frameworks. However, alongside its promise, recognition of AI's susceptibility to exploitation in sophisticated cyber-attacks exists, underscoring the imperative for continual advancements in AI-driven security solutions. This research offers a nuanced perspective on AI's impact on cybersecurity, advocating for the proactive integration of AI strategies, sustained research efforts, and formulating ethical guidelines. Adopting supervised machine learning (ML) algorithms like decision trees, support vector machines, and neural networks aims to harness AI's potential to bolster cybersecurity while concurrently addressing associated risks, paving the way for a secure digital landscape. Regarding accuracy, the neural network outperforms other models by 98%.;['2300937514', '2300512526', '2300937511', '2300506407', '2300519129', '2331885636', '2300934876'];['Atia Shahana', 'Rakibul Hasan', 'Sayeda Farjana Farabi', 'Jahanara Akter', 'Md Abdullah Al Mahmud', 'F. Johora', 'Gurkan Suzer'];;;;;;;d3asq1kw;Journal of Computer Science and Technology Studies;2024.0;67;['Cybersecurity']
bf0e9446eca16e8ac1e759dce6a7b3f22d2111de;When LLMs Meet Cybersecurity: A Systematic Literature Review;The rapid development of large language models (LLMs) has opened new avenues across various fields, including cybersecurity, which faces an evolving threat landscape and demand for innovative technologies. Despite initial explorations into the application of LLMs in cybersecurity, there is a lack of a comprehensive overview of this research area. This paper addresses this gap by providing a systematic literature review, covering the analysis of over 300 works, encompassing 25 LLMs and more than 10 downstream scenarios. Our comprehensive overview addresses three key research questions: the construction of cybersecurity-oriented LLMs, the application of LLMs to various cybersecurity tasks, the challenges and further research in this area. This study aims to shed light on the extensive potential of LLMs in enhancing cybersecurity practices and serve as a valuable resource for applying LLMs in this field. We also maintain and regularly update a list of practical guides on LLMs for cybersecurity at;['2300373722', '2300091500', '2300083605', '2300163790', '2300196563', '2300134286'];['Jie Zhang', 'Haoyu Bu', 'Hui Wen', 'Yu Chen', 'Lun Li', 'Hongsong Zhu'];;;;;;;sjy5ifmw;Cybersecur.;2024.0;8;['Computer Science', 'Cybersecurity']
2c2accf9d8a80d996ee79049af202385b87bfd3f;Best practices in cybersecurity for green building management systems: Protecting sustainable infrastructure from cyber threats;This study explores the critical intersection of cybersecurity and sustainable infrastructure, with a focus on Green Building Management Systems (GBMS). Recognizing the increasing sophistication of cyber threats and the integration of digital technologies in sustainable buildings, this research aims to understand the challenges and prospects of cybersecurity within this context. Employing a systematic literature review and content analysis, the study examines peer-reviewed articles, conference proceedings, and industry reports from 2010 to 2024. The methodology facilitates a comprehensive understanding of the evolution, current practices, and future directions of cybersecurity measures in sustainable infrastructure. Key findings reveal that robust cybersecurity measures are foundational to protecting the digital and physical assets underpinning sustainable infrastructure. The study identifies core principles of cybersecurity, such as resilience and the integration of cybersecurity with sustainability efforts, as crucial for enhancing the security posture of GBMS. Looking ahead, the research anticipates a future where cybersecurity measures are seamlessly;['2309564812', '2309568937', '2309565012'];['Adebimpe Bolatito Ige', 'Eseoghene Kupa', 'Oluwatosin Ilori'];;;;;;;m5nkffun;International Journal of Science and Research Archive;2024.0;28;['Cybersecurity']
1d028098b8301aa66e6a575e2e92573c9da1e92a;Cybersecurity risks in online banking: A detailed review and preventive strategies applicatio;In an era where the digital transformation of the banking sector intersects with the escalating complexity of cyber threats, this paper endeavors to dissect the multifaceted realm of cybersecurity within the banking industry. With a backdrop of increasing online banking adoption and the concomitant rise in cybercrime, the study aims to illuminate the current cybersecurity landscape, evaluate the efficacy of existing frameworks and propose strategic enhancements to fortify digital defenses. Employing a methodological amalgam of literature review and analysis of recent cybersecurity incidents, this investigation delves into the intricacies of cyber threats, the financial repercussions of breaches and the robustness of current cybersecurity measures in banking. The scope of this paper encompasses a comprehensive examination of recent cyber incidents, an assessment of the financial impact of cyber-attacks, an evaluation of the effectiveness of existing cybersecurity frameworks and the formulation of strategic recommendations for bolstering cybersecurity measures. Through this scholarly inquiry,;['2222807739', '2215422586', '2287952712', '2291412219'];['A. Oyewole', 'Chinwe Chinazo Okoye', 'Onyeka Chrisanctus Ofodile', 'Chinonye Esther Ugochukwu'];;;;;;;3alz00m3;World Journal of Advanced Research and Reviews;2024.0;88;['Cybersecurity']
3139e0c7002df948519a66b5a57a43fab9e013b9;Artificial intelligence in cybersecurity: Protecting national infrastructure: A USA review;Artificial Intelligence (AI) has emerged as a transformative force in the field of cybersecurity, playing a pivotal role in safeguarding national infrastructure. This review focuses on the application of AI technologies within the context of the United States, examining their efficacy in fortifying critical systems against evolving cyber threats. The paper delves into various AI-driven cybersecurity strategies, ranging from anomaly detection and predictive analysis to threat intelligence and automated response mechanisms. The integration of AI in cybersecurity not only enhances the speed and accuracy of threat detection but also addresses the dynamic nature of cyber threats. The specific AI technologies employed in the United States, including machine learning, natural language processing, and neural networks, highlighting their contributions to bolstering the resilience of national infrastructure are also examined. Furthermore, the challenges and ethical considerations associated with the widespread adoption of AI in cybersecurity are assessed. It discusses the need for robust;['2254582983', '2290202317', '4820479', '2282309771', '2290203185', '2290099374'];['Donald Obinna Daraojimba', 'Adebunmi Okechukwu Adewusi', 'U. Okoli', 'Temidayo Olorunsogo', 'E. Adaga', 'Ogugua Chimezie Obi'];;;;;;;ex3f0q2h;World Journal of Advanced Research and Reviews;2024.0;97;['Cybersecurity', 'Artificial Intelligence']
aa1b6eb2563523b72d01d2570f71a81930a83320;Artificial intelligence (AI) cybersecurity dimensions: a comprehensive framework for understanding adversarial and offensive AI;;['144878627', '2284228092'];['Masike Malatji', 'Alaa Tolah'];;;;;;;wcp8stov;AI and Ethics;2024.0;;['Cybersecurity', 'Artificial Intelligence']
983968c21137edc191dd6d8b1578858f98ca5a93;A REVIEW OF CYBERSECURITY STRATEGIES IN MODERN ORGANIZATIONS: EXAMINING THE EVOLUTION AND EFFECTIVENESS OF CYBERSECURITY MEASURES FOR DATA PROTECTION;In an era where digital threats are increasingly pervasive, understanding the evolution and efficacy of cybersecurity strategies in modern organizations is paramount. This study provides a comprehensive analysis of the dynamic landscape of cybersecurity, exploring its progression from traditional methods to innovative, technology-driven approaches. The digital age has ushered in complex cyber threats, necessitating robust cybersecurity measures. This study examines cybersecurity strategies' historical development, current trends, and future directions across different organizational contexts and industries. The primary aim is to assess the evolution and effectiveness of cybersecurity measures, identify existing gaps, and understand the interplay between human behavior, technology, and policy in cybersecurity. The paper encompasses a comprehensive methodological framework for cybersecurity analysis, exploring the effectiveness of traditional versus modern approaches, the role of AI and ML, and the impact of international policies. It also presents case studies to illustrate successes and failures in cybersecurity implementation. Key findings reveal a;['2277966027', '2276083334', '2276088894', '2276075268', '2268349678'];['Temitayo Oluwaseun Abrahams', 'Sarah Kuzankah Ewuga', 'Samuel Onimisi Dawodu', 'Abimbola Oluwatoyin Adegbite', 'Azeez Olanipekun Hassan'];;;;;;;z7adt62q;"Computer Science &amp; IT Research Journal";2024.0;8;['Cybersecurity']
208c0148b8e4bad8a557be72e424a01092389dc9;Aligning sustainable development goals with cybersecurity strategies: Ensuring a secure and sustainable future;This study explores the critical intersection between cybersecurity and sustainable development, aiming to understand how cybersecurity measures can support the achievement of the Sustainable Development Goals (SDGs). Employing a systematic literature review and content analysis, the research scrutinizes peer-reviewed articles, conference proceedings, and reports from international organizations, focusing on literature published from 2010 to 2024. The inclusion criteria targeted works that directly address the role of cybersecurity in sustainable development, particularly those discussing emerging technologies and their potential to enhance digital security in support of the SDGs. The exclusion criteria filtered out non-peer-reviewed articles, opinion pieces, and studies not explicitly linking cybersecurity with sustainable development efforts. Key findings highlight the indispensable role of cybersecurity in safeguarding digital infrastructure essential for achieving SDGs, emphasizing the transformative potential of innovations such as blockchain technology and artificial intelligence in enhancing cybersecurity measures. The study identifies significant challenges at the intersection of cybersecurity and;['2317088286', '2309270838', '2309269959', '2306656791'];['Adebimpe Bolatito', 'Adebimpe Bolatito Ige', 'Eseoghene Kupa', 'Oluwatosin Ilori'];;;;;;;opf6j3y6;GSC Advanced Research and Reviews;2024.0;99;['Cybersecurity']
0b2e4715c70c5f79eeaffad6a9774cb0392babd0;A Critical Cybersecurity Analysis and Future Research Directions for the Internet of Things: A Comprehensive Review;The emergence of the Internet of Things (IoT) technology has brought about tremendous possibilities, but at the same time, it has opened up new vulnerabilities and attack vectors that could compromise the confidentiality, integrity, and availability of connected systems. Developing a secure IoT ecosystem is a daunting challenge that requires a systematic and holistic approach to identify and mitigate potential security threats. Cybersecurity research considerations play a critical role in this regard, as they provide the foundation for designing and implementing security measures that can address emerging risks. To achieve a secure IoT ecosystem, scientists and engineers must first define rigorous security specifications that serve as the foundation for developing secure devices, chipsets, and networks. Developing such specifications requires an interdisciplinary approach that involves multiple stakeholders, including cybersecurity experts, network architects, system designers, and domain experts. The primary challenge in IoT security is ensuring the system can defend against both;['2139215419', '49944037', '47311590', '3045674'];['Usman Tariq', 'Irfan Uddin Ahmed', 'A. Bashir', 'K. Shaukat'];3dbf084c-ef47-4b74-9919-047b40704538;Italian National Conference on Sensors;conference;7;2023.0;Abuja;;;;;['Computer Science', 'Cybersecurity', 'Medicine']
ef8f8dc9eff937d65a312ee619c16cf06eb3e456;Recent Advances on Federated Learning for Cybersecurity and Cybersecurity for Federated Learning for Internet of Things;Decentralized paradigm in the field of cybersecurity and machine learning (ML) for the emerging Internet of Things (IoT) has gained a lot of attention from the government, academia, and industries in recent years. Federated cybersecurity (FC) is regarded as a revolutionary concept to make the IoT safer and more efficient in the future. This emerging concept has the potential of detecting security threats, taking countermeasures, and limiting the spreading of threats over the IoT network system efficiently. An objective of cybersecurity is achieved by forming the federation of the learned and shared model on top of various participants. Federated learning (FL), which is regarded as a privacy-aware ML model, is particularly useful to secure the vulnerable IoT environment. In this article, we start with background and comparison of centralized learning, distributed on-site learning, and FL, which is then followed by a survey of the application of FL to cybersecurity for;['1380982173', '1729159'];['Bimal Ghimire', 'D. Rawat'];;;;;;;75urftoe;IEEE Internet of Things Journal;2022.0;9;['Computer Science', 'Cybersecurity']
c6874a0d173de76c1e79df43324c4d58d30a30bc;Cybersecurity of Smart Inverters in the Smart Grid: A Survey;The penetration of distributed energy resources (DERs) in smart grids significantly increases the number of field devices owned and controlled by consumers, aggregators, third parties, and utilities. As the interface between DER and power grids, DER inverters are becoming smarter with various grid-support functions and communication capabilities. Meanwhile, the cybersecurity risks of smart inverters are also on the rise due to the extensive utilization of information and communication technologies. The potential negative impacts of cyberattacks on smart inverters have attracted significant attention from scholars and organizations. To advance the research on smart inverter cybersecurity and provide insights into its technical achievements, barriers, and future directions, this article will give a comprehensive review of critical attacks and defense strategies for smart inverters and inverter-based systems like microgrids. We start this survey with an overview of the smart inverter introduction, including device- and grid-level architectures, grid-support functions, and communication protocols. We then;['2110480595', '1654081623'];['Yuanliang Li', 'Jun Yan'];;;;;;;mabuledw;IEEE Transactions on Power Electronics;2023.0;38;['Cybersecurity']
e9d573b0a7f72883c76a8457c6fc62cec69769d1;Digital Transformation and Cybersecurity Challenges for Businesses Resilience: Issues and Recommendations;This systematic literature review explores the digital transformation (DT) and cybersecurity implications for achieving business resilience. DT involves transitioning organizational processes to IT solutions, which can result in significant changes across various aspects of an organization. However, emerging technologies such as artificial intelligence, big data and analytics, blockchain, and cloud computing drive digital transformation worldwide while increasing cybersecurity risks for businesses undergoing this process. This literature survey article highlights the importance of comprehensive knowledge of cybersecurity threats during DT implementation to prevent interruptions due to malicious activities or unauthorized access by attackers aiming at sensitive information alteration, destruction, or extortion from users. Cybersecurity is essential to DT as it protects digital assets from cyber threats. We conducted a systematic literature review using the PRISMA methodology in this research. Our literature review found that DT has increased efficiency and productivity but poses new challenges related to cybersecurity risks, such as data;['2057626576', '2225326294', '2225362268', '2225324818', '2044984212'];['Saqib Saeed', 'Salha A. Altamimi', 'Norah A. Alkayyal', 'Ebtisam Alshehri', 'Dina A. Alabbad'];3dbf084c-ef47-4b74-9919-047b40704538;Italian National Conference on Sensors;conference;2;2023.0;São Paulo;;;;;['Computer Science', 'Cybersecurity', 'Medicine']
81e8396f2257952819dabd425fd6ac7c48d16fb8;Towards Artificial Intelligence-Based Cybersecurity: The Practices and ChatGPT Generated Ways to Combat Cybercrime;Today, cybersecurity is considered one of the most noteworthy topics that are circulated frequently among companies in order to protect their data from hacking operations. The emergence of cyberspace contributed to the growth of electronic systems. It is a virtual digital space through which interconnection is established between computers and smartphones connected within the Internet of Things environment. This space is critical in building a safe digital environment free of threats and cybercrime. It is only possible to make a digital environment with the presence of cyberspace, which contains modern technologies that make this environment safe and far from unauthorized individuals. Cybersecurity has a wide range of challenges and obstacles in performance, and it is difficult for companies to face them. In this report, the most significant practices, sound, and good strategies will be studied to stop cybercrime and make a digital environment that guarantees data transfers between electronic devices;['1394846990', '2345455453', '1447250772', None];['Maad M. Mijwil', 'Maad M. Mijwil', 'Mohammad Aljanabi', 'ChatGPT'];;;;;;;tk6f1zr9;Iraqi Journal for Computer Science and Mathematics;2023.0;54;['Cybersecurity', 'Artificial Intelligence']
a2fe496b4db6c3baf093463f2af7c5c3bdf9c0c5;The Significance of Machine Learning and Deep Learning Techniques in Cybersecurity: A Comprehensive Review;People in the modern era spend most of their lives in virtual environments that offer a range of public and private services and social platforms. Therefore, these environments need to be protected from cyber attackers that can steal data or disrupt systems. Cybersecurity refers to a collection of technical, organizational, and executive means for preventing the unauthorized use or misuse of electronic information and communication systems to ensure the continuity of their work, guarantee the confidentiality and privacy of personal data, and protect consumers from threats and intrusions. Accordingly, this article explores the cybersecurity practices that protect computer systems from attacks, hacking, and data thefts and investigates the role of artificial intelligence in this domain. This article also summarizes the most significant literature that explore the roles and effects of machine learning and deep learning techniques in cybersecurity. Results show that machine learning and deep learning techniques play significant roles;['1394846990'];['Maad M. Mijwil'];;;;;;;rklskykg;Iraqi Journal for Computer Science and Mathematics;2023.0;49;['Deep Learning', 'Cybersecurity', 'Machine Learning']
b2319ad4828be04bc873a55762cee49583740fb3;Counterattacking Cyber Threats: A Framework for the Future of Cybersecurity;Amidst the rapid advancements in the digital landscape, the convergence of digitization and cyber threats presents new challenges for organizational security. This article presents a comprehensive framework that aims to shape the future of cyber security. This framework responds to the complexities of modern cyber threats and provides guidance to organizations to enhance their resilience. The primary focus lies in the integration of capabilities with resilience. By combining these elements into cyber security practices, organizations can improve their ability to predict, mitigate, respond to, and recover from cyber disasters. This article emphasizes the importance of organizational leadership, accountability, and innovation in achieving cyber resilience. As cyber threat challenges continue to evolve, this framework offers strategic guidance to address the intricate dynamics between digitization and cyber security, moving towards a safer and more robust digital environment in the future.;['2231538602', '144432618', '9093870'];['Muhammad Fakhrul Safitra', 'M. Lubis', 'Hanif Fakhrurroja'];;;;;;;6zrnvpuv;Sustainability;2023.0;90;['Cybersecurity']
807110054f8137a10ed5bb05a33e93bf596f897a;ChatGPT: Exploring the Role of Cybersecurity in the Protection of Medical Information;ChatGPT is a large language model developed by OpenAI. It is trained on a dataset of conversational text and can be used to generate human-like responses to prompts in a variety of languages and formats. It can be used for tasks such as chatbots, language translation, and text completion. The role of ChatGPT is to generate human-like text based on a given prompt or context. It can be used in a variety of applications such as chatbots, language translation, text completion, and question answering. Additionally, it can be fine-tuned for specific tasks such as generating product descriptions or summarizing articles. It can also be used to generate creative writing such as poetry and stories. It can be integrated into a wide range of industries from customer service to entertainment, to research.;['1394846990', '1447250772', '145907529'];['Maad M. Mijwil', 'Mohammad Aljanabi', 'Ahmed Ali'];;;;;;;rbztffs4;Mesopotamian Journal of Cyber Security;2023.0;62;['Cybersecurity']
b2084a383f69fbcc3ab779f4b1aa425c5224229e;Deep Learning Based Attack Detection for Cyber-Physical System Cybersecurity: A Survey;With the booming of cyber attacks and cyber criminals against cyber-physical systems (CPSs), detecting these attacks remains challenging. It might be the worst of times, but it might be the best of times because of opportunities brought by machine learning (ML), in particular deep learning (DL). In general, DL delivers superior performance to ML because of its layered setting and its effective algorithm for extract useful information from training data. DL models are adopted quickly to cyber attacks against CPS systems. In this survey, a holistic view of recently proposed DL solutions is provided to cyber attack detection in the CPS context. A six-step DL driven methodology is provided to summarize and analyze the surveyed literature for applying DL methods to detect cyber attacks against CPS systems. The methodology includes CPS scenario analysis, cyber attack identification, ML problem formulation, DL model customization, data acquisition for training, and performance evaluation. The;['37269546', '2114094874', '2067611028', '2145763295', '145018147', '70402545'];['Jun Zhang', 'Lei Pan', 'Qing-Long Han', 'Chao Chen', 'Sheng Wen', 'Yang Xiang'];;;;;;;qolynaab;IEEE/CAA Journal of Automatica Sinica;2022.0;9;['Computer Science', 'Deep Learning', 'Cybersecurity']
66fc6467aec08ebb6047a3429a5c9ff6a8cceb90;Current trends in AI and ML for cybersecurity: A state-of-the-art survey;Abstract This paper provides a comprehensive survey of the state-of-the-art use of Artificial Intelligence (AI) and Machine Learning (ML) in the field of cybersecurity. The paper illuminates key applications of AI and ML in cybersecurity, while also addressing existing challenges and posing unresolved questions for future research. The paper also emphasizes the ethical and legal implications associated with their implementation. The researchers conducted a thorough survey by reviewing numerous papers and articles from respected sources such as IEEE, ACM, and Springer. Their focus centered on the latest AI and ML breakthroughs in cybersecurity, while also exploring current challenges and open research questions. The results indicate that integrating AI and ML into cybersecurity systems shows great potential for future research and development. Intrusion detection and response, malware detection, and network security are among the most promising applications identified. According to the survey, 45% of organizations have already implemented AI and ML;['52152819'];['Nachaat Mohamed'];;;;;;;m4q3n7ze;Cogent Engineering;2023.0;10;['Cybersecurity']
1e8ccc3909baf44b45161f8ee10bd25a49fc01a1;A comprehensive study on cybersecurity challenges and opportunities in the IoT world;It has become possible to link anything and everything to the Internet in recent decades due to the expanding Internet of Things (IoT). As a result, our usage of technology has changed a lot, causing digital disruption in the real world. IoT allows drones, sensors, digital set‐top boxes, surveillance cameras, wearable technology, and medical equipment to be connected to the internet. Healthcare, manufacturing, utilities, transportation, and housing are among the various sectors that has become intelligent. Recently, we have seen a surge in cybersecurity challenges and opportunities for the improvement of various IoT applications. Although cybersecurity and the IoT are extensively researched, there is a dearth of studies that exclusively focus on the evolution of cybersecurity challenges in the area of AI and machine learning, blockchain and zero trust, lightweight security, integration of IoT with 5G networks, and many more in the IoT world. The availability of environment‐capturing sensors and;['2215203347', '70292225', '120635369'];['Aejaz Nazir Lone', 'Suhel Mustajab', 'M.Aftab Alam'];;;;;;;f1inpd26;Security and Privacy;2023.0;6;['Computer Science', 'Cybersecurity']
154862cd1839ebeae9c0ed79e9d4eadefad5843b;Cybersecurity for Sustainable Smart Healthcare: State of the Art, Taxonomy, Mechanisms, and Essential Roles;Cutting-edge technologies have been widely employed in healthcare delivery, resulting in transformative advances and promising enhanced patient care, operational efficiency, and resource usage. However, the proliferation of networked devices and data-driven systems has created new cybersecurity threats that jeopardize the integrity, confidentiality, and availability of critical healthcare data. This review paper offers a comprehensive evaluation of the current state of cybersecurity in the context of smart healthcare, presenting a structured taxonomy of its existing cyber threats, mechanisms and essential roles. This study explored cybersecurity and smart healthcare systems (SHSs). It identified and discussed the most pressing cyber threats and attacks that SHSs face, including fake base stations, medjacking, and Sybil attacks. This study examined the security measures deployed to combat cyber threats and attacks in SHSs. These measures include cryptographic-based techniques, digital watermarking, digital steganography, and many others. Patient data protection, the prevention of data breaches, and the maintenance of;['2280536174', '1394846990'];['Guma Ali', 'Maad M. Mijwil'];;;;;;;pdbxfepu;Mesopotamian Journal of CyberSecurity;2024.0;83;['Cybersecurity']
b652b2ce62479f8524a4917126da760dae7a048c;Cybersecurity Challenges for Manufacturing Systems 4.0: Assessment of the Business Impact Level;An ever-growing number of companies are moving toward the Industry 4.0 paradigm, adopting a range of advanced technologies (e.g., smart sensors, big data analytics, and cloud computing) and networking their manufacturing systems. This improves the efficiency and effectiveness of operations but also introduces new cybersecurity challenges. In this article, the impact assessment methodology is applied in the context of manufacturing systems 4.0 (also known as smart manufacturing systems, cyber manufacturing systems, or digital manufacturing systems), thus identifying the critical assets to be protected against cyber-attacks and assessing the business impacts in the case of subtractive and additive technologies. The research design of the single case study with multiple units of analysis is applied. In particular, a large company, a leader in the manufacturing of aeronautical components, is considered a representative case study, and its two main types of manufacturing cells that is, those based on networked computer numerical control machines;['48139416', '1715946', '79513578', '1797751'];['A. Corallo', 'M. Lazoi', 'M. Lezzi', 'P. Pontrandolfo'];;;;;;;489by0ah;IEEE Transactions on Engineering Management;2023.0;70;['Computer Science', 'Business', 'Cybersecurity']
cc1697038a9fcca37977b3b0e1bd9d434d3d9a3e;AI-Driven Cybersecurity: An Overview, Security Intelligence Modeling and Research Directions;;['3456687', '12752964', '2005430834'];['Iqbal H. Sarker', 'Md. Hasan Furhad', 'Raza Nowrozy'];;;;;;;4v363cfh;SN Computer Science;2021.0;2;['Computer Science', 'Cybersecurity']
8895cfd205a7f3d4ba99caea175dc4f7d0db3b7b;Chatgpt for cybersecurity: practical applications, challenges, and future directions;;['2292256970', '2338309657', '2160291212'];['Muna Al-Hawawreh', 'Ahamed Aljuhani', 'Yaser Jararweh'];;;;;;;czfsrfln;Cluster Computing;2023.0;26;['Computer Science', 'Cybersecurity']
4f71d51b8e296c7b7350a79d668adf6416144a0c;Cyberattacks in Smart Grids: Challenges and Solving the Multi-Criteria Decision-Making for Cybersecurity Options, Including Ones That Incorporate Artificial Intelligence, Using an Analytical Hierarchy Process;Smart grids have emerged as a transformative technology in the power sector, enabling efficient energy management. However, the increased reliance on digital technologies also exposes smart grids to various cybersecurity threats and attacks. This article provides a comprehensive exploration of cyberattacks and cybersecurity in smart grids, focusing on critical components and applications. It examines various cyberattack types and their implications on smart grids, backed by real-world case studies and quantitative models. To select optimal cybersecurity options, the study proposes a multi-criteria decision-making (MCDM) approach using the analytical hierarchy process (AHP). Additionally, the integration of artificial intelligence (AI) techniques in smart-grid security is examined, highlighting the potential benefits and challenges. Overall, the findings suggest that “security effectiveness” holds the highest importance, followed by “cost-effectiveness”, “scalability”, and “Integration and compatibility”, while other criteria (i.e., “performance impact”, “manageability and usability”, “compliance and regulatory requirements”, “resilience and redundancy”, “vendor support and collaboration”, and “future;['2003442121'];['Ayat-allah Bouramdane'];;;;;;;wutw78ql;J. Cybersecur. Priv.;2023.0;3;['Computer Science', 'Cybersecurity', 'Artificial Intelligence']
f70158eddb1b09b48672a08e074f68dd7d26d327;Exploring the Top Five Evolving Threats in Cybersecurity: An In-Depth Overview;The term cybersecurity refers to an environment capable of protecting digital devices, networks and information from unauthorized access and preventing data theft or alteration. It is composed of a collection of carefully crafted techniques, processes, and practices to protect sensitive information and deterring cyber-attacks. In the recent period, the domain of cybersecurity has undergone rapid growth in response to the increasing cyber threats. Cybersecurity includes important tactics that help protect the digital environment, which are firewalls, encryption, secure passwords, and threat detection and response systems. Employees must be trained on these tactics. This article will discuss the five most pressing challenges facing the cybersecurity industry today that must be taken into account by businesses, organizations, and individuals in order to secure their confidential data from cybercrime. The conclusion of the article highlighted the significance of growing awareness about cybersecurity risks in order to effectively handle digital environments and protect them;['1394846990', '2210937523', '21366673', '48385425', '2156915219'];['Maad M. Mijwil', 'Omega John Unogwu', 'Y. Filali', 'I. Bala', 'Humam Al-Shahwani'];;;;;;;dmyfpwr1;Mesopotamian Journal of Cyber Security;2023.0;22;['Cybersecurity']
427a38f01ee3ea20a7c850550e444190ec98852d;Machine Learning in Cybersecurity: Techniques and Challenges;In the computer world, data science is the force behind the recent dramatic changes in cybersecurity's operations and technologies. The secret to making a security system automated and intelligent is to extract patterns or insights related to security incidents from cybersecurity data and construct appropriate data-driven models. Data science, also known as diverse scientific approaches, machine learning techniques, processes, and systems, is the study of actual occurrences via the use of data. Due to its distinctive qualities, such as flexibility, scalability, and the capability to quickly adapt to new and unknowable obstacles, machine learning techniques have been used in many scientific fields. Due to notable advancements in social networks, cloud and web technologies, online banking, mobile environments, smart grids, etc., cyber security is a rapidly expanding sector that requires a lot of attention. Such a broad range of computer security issues have been effectively addressed by various machine learning techniques.;['2214559159'];['J. Bharadiya'];;;;;;;oj6f93sn;European Journal of Technology;2023.0;28;['Cybersecurity', 'Machine Learning']
07ac8f33e82eec20dc3733eb825deae5d6404967;Review of strategic alignment: Accounting and cybersecurity for data confidentiality and financial security;In the contemporary landscape of rapidly evolving technological advancements and the increasing prevalence of cyber threats, organizations face a critical imperative to align their accounting practices with robust cybersecurity measures. This review explores the symbiotic relationship between accounting and cybersecurity in safeguarding data confidentiality and ensuring financial security. Focusing on the intersection of these two domains, we examine the strategic alignment required to fortify organizations against the escalating challenges posed by cyber threats to sensitive financial information. The review begins by delving into the intricate connection between accounting processes and the protection of financial data, emphasizing the pivotal role of accurate financial reporting and transparent disclosure in maintaining stakeholder trust. Subsequently, it scrutinizes the evolving threat landscape, identifying cyber risks that specifically target financial systems and data. The analysis underscores the need for a comprehensive strategic approach that integrates accounting practices with cybersecurity protocols to effectively mitigate these risks. Furthermore,;['2290201278', '2282311375', '2295263109', '2279235013', '2279242513', '2290363027'];['Samuel Onimisi Dawodu', 'Temitayo Oluwaseun Abrahams', 'Sarah Kuzankah Ewuga', 'Simon Kaggwa', 'Prisca Ugomma Uwaoma', 'Azeez Olanipekun Hassan'];;;;;;;trhfrh9w;World Journal of Advanced Research and Reviews;2023.0;13;['Cybersecurity']
ad98eed098edbc93040f9eb3054a1cd7f4b95795;The elephant in the room: cybersecurity in healthcare;;['2215222522'];['Anthony James Cartwright'];;;;;;;zns73let;Journal of Clinical Monitoring and Computing;2023.0;74;['Cybersecurity', 'Medicine']
4d39e473e298765ef0f11dcccd204ac0c2ee8ad5;Cybersecurity Risk Analysis of Electric Vehicles Charging Stations;The increasing availability of Electric Vehicles (EVs) is driving a shift away from traditional gasoline-powered vehicles. Subsequently, the demand for Electric Vehicle Charging Systems (EVCS) is rising, leading to the significant growth of EVCS as public and private charging infrastructure. The cybersecurity-related risks in EVCS have significantly increased due to the growing network of EVCS. In this context, this paper presents a cybersecurity risk analysis of the network of EVCS. Firstly, the recent advancements in the EVCS network, recent EV adaptation trends, and charging use cases are described as a background of the research area. Secondly, cybersecurity aspects in EVCS have been presented considering infrastructure and protocol-centric vulnerabilities with possible cyber-attack scenarios. Thirdly, threats in EVCS have been validated with real-time data-centric analysis of EV charging sessions. The paper also highlights potential open research issues in EV cyber research as new knowledge for domain researchers and practitioners.;['2225807670', '3025665', '51019763', '2225801568', '2112823504', '2143685121', '2152343987', '2153500078', '2153772709'];['Safa Hamdare', 'Omprakash Kaiwartya', 'Mohammad Aljaidi', 'Manish Jugran', 'Yue Cao', 'Sushil Kumar', 'M. Mahmud', 'David J. Brown', 'Jaime Lloret'];3dbf084c-ef47-4b74-9919-047b40704538;Italian National Conference on Sensors;conference;3;2023.0;São Paulo;;;;;['Computer Science', 'Cybersecurity', 'Medicine']
eebc1abfd4d5615b1562686b182488a0e9914c9c;Evaluating the adoption of cybersecurity and its influence on organizational performance;;['11052299', '2215518058', '2011284', '2412276', '2923630'];['Tahereh Hasani', 'Norman O’Reilly', 'A. Dehghantanha', 'Davar Rezania', 'Nadège Levallet'];;;;;;;8fg6xke8;Sn Business & Economics;2023.0;3;['Cybersecurity', 'Medicine']
6f5b87e38cfb4a47e3ac7988cca5612ccf0a2946;Detecting Cybersecurity Attacks in Internet of Things Using Artificial Intelligence Methods: A Systematic Literature Review;In recent years, technology has advanced to the fourth industrial revolution (Industry 4.0), where the Internet of things (IoTs), fog computing, computer security, and cyberattacks have evolved exponentially on a large scale. The rapid development of IoT devices and networks in various forms generate enormous amounts of data which in turn demand careful authentication and security. Artificial intelligence (AI) is considered one of the most promising methods for addressing cybersecurity threats and providing security. In this study, we present a systematic literature review (SLR) that categorize, map and survey the existing literature on AI methods used to detect cybersecurity attacks in the IoT environment. The scope of this SLR includes an in-depth investigation on most AI trending techniques in cybersecurity and state-of-art solutions. A systematic search was performed on various electronic databases (SCOPUS, Science Direct, IEEE Xplore, Web of Science, ACM, and MDPI). Out of the identified records, 80 studies;['2149590607', '9315276', '2800915', '1874566', '2019908712', '1739277', '2577908'];['Mujaheed Abdullahi', 'Yahia Baashar', 'H. Alhussian', 'A. Alwadain', 'Norshakirah Aziz', 'Luiz Fernando Capretz', 'S. J. Abdulkadir'];;;;;;;7nvss89a;Electronics;2022.0;26;['Cybersecurity', 'Artificial Intelligence']
ede0a8039a561905f40777ec2ae66c2010e3f2bc;Cybersecurity data science: an overview from machine learning perspective;;['3456687', '3456687', '144366819', '49696663', '2315003324', '1682100', '46201673'];['Iqbal H. Sarker', 'Iqbal H. Sarker', 'A. Kayes', 'S. Badsha', 'Hamed Alqahtani', 'P. Watters', 'Alex Ng'];;;;;;;kxpnwmnq;Journal of Big Data;2020.0;7;['Computer Science', 'Cybersecurity', 'Machine Learning']
4737e7b19041092055203adc0cb8a2570381766e;Federated Learning for Cybersecurity: Concepts, Challenges, and Future Directions;Federated learning (FL) is a recent development in artificial intelligence, which is typically based on the concept of decentralized data. As cyberattacks are frequently happening in the various applications deployed in real time, most industrialists are hesitating to move forward in adopting the technology of the Internet of Everything. This article aims to provide an extensive study on how FL could be utilized for providing better cybersecurity and prevent various cyberattacks in real time. We present an extensive survey of the various FL models currently developed by researchers for providing authentication, privacy, trust management, and attack detection. We also discuss few real-time use cases that have been deployed recently and how FL is adopted in them for preserving privacy of data and improving the performance of the system. Based on the study, we conclude this article with some prominent challenges and future directions on which the researchers can focus for;['2474250', '117002369', '2136624605', '29919430', '11041265', '145436642'];['M. Alazab', 'S. Rm', 'P. M', 'Praveen Kumar Reddy Maddikunta', 'T. Gadekallu', 'Viet Quoc Pham'];;;;;;;604p8kjy;IEEE Transactions on Industrial Informatics;2022.0;18;['Computer Science', 'Cybersecurity']
8e08ba2cdb657f6b2986b92457dd09845094fab9;Cyber risk and cybersecurity: a systematic review of data availability;;['2155014658', '2077016707', '92622093', '153102410', '47086166', '47527467', '1972613'];['Frank Cremer', 'Barry Sheehan', 'Michel Fortmann', 'ArashNegahdari Kia', 'Martin Mullins', 'Finbarr Murphy', 'S. Materne'];;;;;;;8oyjqb9w;The Geneva Papers on Risk and Insurance. Issues and Practice;2022.0;47;['Cybersecurity', 'Medicine']
76a6b3a8e9900675a829a981d89540454acbcf1b;Cybersecurity for Blockchain-Based IoT Systems: A Review;The Internet of Things (IoT) has become a pervasive technology with various applications ranging from smart homes and cities to industrial automation and healthcare. However, the increasing adoption of IoT devices has also raised significant concerns about cybersecurity and privacy. Blockchain, as a distributed and immutable ledger technology, has been proposed as a potential solution to enhance the security and privacy of IoT systems. Blockchain-based IoT systems offer several benefits, such as decentralization, transparency, and data integrity. However, they also pose unique cybersecurity challenges that need to be addressed for their secure and reliable deployment. In this paper, we review the existing literature and highlight the key challenges in cybersecurity for blockchain-based IoT systems. We categorize these challenges into three main areas: (i) IoT device security, (ii) blockchain security, and (iii) integration of IoT devices with blockchain (network security). Through an in-depth analysis, we present the current state of research;['2180280043', '2212611521', '2210586703'];['Razan Alajlan', 'Norah Alhumam', 'Mounir Frikha'];;;;;;;rwt93xo0;Applied Sciences;2023.0;52;['Cybersecurity']
4cb2924d5f4a076724942d791076438679b384be;Cybersecurity knowledge graphs;;['3210745'];['L. Sikos'];;;;;;;3vvjuhwd;Knowledge and Information Systems;2023.0;65;['Computer Science', 'Graph', 'Cybersecurity']
7dd8bfd43b690c7311c1e1ae7274c6c642258d0e;More than malware: unmasking the hidden risk of cybersecurity regulations;;['68977580', '2282598159'];['Mazaher Kianpour', 'Shahid Raza'];;;;;;;v6crj2bv;International Cybersecurity Law Review;2024.0;5;['Cybersecurity', 'Malware']
631c9955109d6ced0c1daa0b6aa46523a833856f;Exploring the Frontiers of Cybersecurity Behavior: A Systematic Review of Studies and Theories;Cybersecurity procedures and policies are prevalent countermeasures for protecting organizations from cybercrimes and security incidents. Without considering human behaviors, implementing these countermeasures will remain useless. Cybersecurity behavior has gained much attention in recent years. However, a systematic review that provides extensive insights into cybersecurity behavior through different technologies and services and covers various directions in large-scale research remains lacking. Therefore, this study retrieved and analyzed 2210 articles published on cybersecurity behavior. The retrieved articles were then thoroughly examined to meet the inclusion and exclusion criteria, in which 39 studies published between 2012 and 2021 were ultimately picked for further in-depth analysis. The main findings showed that the protection motivation theory (PMT) dominated the list of theories and models examining cybersecurity behavior. Cybersecurity behavior and intention behavior counted for the highest purpose for most studies, with fewer studies focusing on cybersecurity awareness and compliance behavior. Most examined studies were conducted in;['2003363232', '1399262006', '40241708'];['Afrah Almansoori', 'M. Al-Emran', 'Khaled Shaalan'];;;;;;;58gp8g8c;Applied Sciences;2023.0;20;['Cybersecurity']
d87d4e0c38c07259036b540cc6e0976469c704f5;Exploring Cybersecurity Education and Training Techniques: A Comprehensive Review of Traditional, Virtual Reality, and Augmented Reality Approaches;Considering the alarming increase in cyberattacks and their potential financial implications, the importance of cybersecurity education and training cannot be overstated. This paper presents a systematic literature review that examines different cybersecurity education and training techniques with a focus on symmetry. It primarily focuses on traditional cybersecurity education techniques and emerging technologies, such as virtual reality (VR) and augmented reality (AR), through the lens of symmetry. The main objective of this study is to explore the existing cybersecurity training techniques, identify the challenges involved, and assess the effectiveness of cybersecurity training based on VR and AR while emphasizing the concept of symmetry. Through careful selection criteria, 66 primary studies were selected from a total of 150 pertinent research studies. This article offers valuable insights into the pros and cons of conventional training approaches, explores the use of VR and AR in cybersecurity education concerning symmetry, and thoroughly discusses the challenges;['3447881', '145827751', '2110034622', '2084851517', '2266478523'];['Abdullah M. Alnajim', 'Shabana Habib', 'Muhammad Islam', 'Hazim Saleh Al-Rawashdeh', 'Muhammad Wasim'];;;;;;;amcam0oz;Symmetry;2023.0;15;['Computer Science', 'Cybersecurity']
fc3a36ccb3ab7ecd365592d52089d57a870b36bc;Regulatory cybersecurity governance in the making: the formation of ENISA and its struggle for epistemic authority;ABSTRACT Over the last decades, cybersecurity has become a top priority for the European Union (EU). As a contribution to scholarship on the ‘regulatory security state’, we analyze how the European Union Agency for Cybersecurity (ENISA), emerged and stabilized as the EU's key agency for cybersecurity. We use data from policy documents, secondary sources, and semi-structured interviews to show how ENISA struggled to become a relevant actor by carving out a specific role for itself. In particular, we show how challenging it was for the agency to acquire epistemic authority. Although the trajectory of ENISA supports attempts to govern through regulation, it also shows that its role was never a given, only functions as part of a larger whole, and continues to be subject to change. Our article indicates that the study of security governance must remain ontologically flexible to capture hybrid forms and political struggles.;['147454724', '46954272'];['Myriam Dunn Cavelty', 'M. Smeets'];;;;;;;xyj0m2nb;Journal of European Public Policy;2023.0;30;['Cybersecurity']
17859c19e41a29b657aa3323ed396f733086c47d;Prevention of Phishing Attacks Using AI-Based Cybersecurity Awareness Training;Machine learning has been described as an effective measure in avoiding most cyberattacks. The development of AI has therefore promoted increased security for most computer attacks. Phishing attacks are risky and can be prevented through AI-based solutions. This factor suggests the need for increased awareness of cybersecurity through AI. Developing awareness for most people will prevent these types of attacks. The research paper describes how the awareness of AI-based cybersecurity could ensure a reduction of phishing attacks. The paper, therefore, showcases the effectiveness of AI-based cybersecurity awareness training and how it may influence cyber-attacks.;['33220564', '2128204211', '2064326216'];['Md Meraj Ansari', 'Pawan Kumar Sharma', 'Bibhu Dash'];;;;;;;z3pk1kj8;International Journal of Smart Sensor and Adhoc Network.;2022.0;62;['Cybersecurity', 'Phishing']
ff3270fa5eefd970f11d95d53b98a69abb706b25;Internet of Things (IoT) Cybersecurity Research: A Review of Current Research Topics;As an emerging technology, the Internet of Things (IoT) revolutionized the global network comprising of people, smart devices, intelligent objects, data, and information. The development of IoT is still in its infancy and many related issues need to be solved. IoT is a unified concept of embedding everything. IoT has a great chance to make the world a higher level of accessibility, integrity, availability, scalability, confidentiality, and interoperability. However, how to protect IoT is a challenging task. System security is the foundation for the development of IoT. This article systematically reviews IoT cybersecurity. The key considerations are the protection and integration of heterogeneous smart devices and information communication technologies (ICT). This review provides useful information and insights to researchers and practitioners who are interested in cybersecurity of IoT, including the current research of IoT cybersecurity, IoT cybersecurity architecture and taxonomy, key enabling countermeasures and strategies, major applications in industries, research;[None, '144557929'];['Yang Lu', 'Li D. Xu'];;;;;;;pqn99n9v;IEEE Internet of Things Journal;2019.0;6;['Computer Science', 'Cybersecurity']
bd2c8ab62b3713e22552b97bdc16bb454556eae3;A Dynamic and Adaptive Cybersecurity Governance Framework;"Cybersecurity protects cyberspace from a wide range of cyber threats to reduce overall business risk, ensure business continuity, and maximize business opportunities and return on investments. Cybersecurity is well achieved by using appropriate sets of security governance frameworks. To this end, various Information Technology (IT) and cybersecurity governance frameworks have been reviewed along with their benefits and limitations. The major limitations of the reviewed frameworks are; they are complex and have complicated structures to implement, they are expensive and require high skill IT and security professionals. Moreover, the frameworks require many requirement checklists for implementation and auditing purposes and a lot of time and resources. To fill the limitations mentioned above, a simple, dynamic, and adaptive cybersecurity governance framework is proposed that provides security related strategic direction, ensures that security risks are managed appropriately, and ensures that organizations’ resources are utilized optimally. The framework incorporated different components not considered in";['2432324'];['H. M. Melaku'];;;;;;;9nhsvl27;J. Cybersecur. Priv.;2023.0;3;['Computer Science', 'Cybersecurity']
9e2865b761d06f43a05d3fc9fbad5a17c09937cb;Cybersecurity and Confidentiality in Smart Grid for Enhancing Sustainability and Reliability;Ensuring cybersecurity and confidentiality in smart grids is crucial for enhancing sustainability and reliability in today's technology-driven world. With the increasing reliance on smart grid technologies, it is imperative to address the potential cybersecurity risks and protect the confidentiality of sensitive data. This research focuses on exploring the challenges and strategies associated with cybersecurity and confidentiality in smart grids. It examines the importance of safeguarding smart grid infrastructure from cyber threats to maintain sustainable and reliable energy delivery systems. The study investigates various techniques and technologies, including encryption, authentication, intrusion detection, and secure communication protocols, that can be employed to enhance the cybersecurity and confidentiality of smart grids. By highlighting the significance of a robust cybersecurity framework and the integration of privacy-preserving measures, this research aims to contribute to the development of secure and resilient smart grid systems. The findings and recommendations presented in this work provide valuable insights for;['2225746839'];['Rahul Kumar Jha'];;;;;;;0arbcv6i;December 2023;2023.0;84;['Cybersecurity']
de6ccb50f96501fc9ae113d52654f4e0f93cfc49;The Influence of Artificial Intelligence on E-Governance and Cybersecurity in Smart Cities: A Stakeholder’s Perspective;"Artificial intelligence (AI) has been identified as a critical technology of Fourth Industrial Revolution (Industry 4.0) for protecting computer network systems against cyber-attacks, malware, phishing, damage, or illicit access. AI has potential in strengthening the cyber capabilities and safety of nation-states, local governments, and non-state entities through e-Governance. Existing research provides a mixed association between AI, e-Governance, and cybersecurity; however, this relationship is believed to be context-specific. AI, e-Governance, and cybersecurity influence and are affected by various stakeholders possessing a variety of knowledge and expertise in respective areas. To fill this context specific gap, this study investigates the direct relationship between AI, e-Governance, and cybersecurity. Furthermore, this study examines the mediating role of e-Governance between AI and cybersecurity and moderating effect of stakeholders involvement on the relationship between AI, e-Governance, and cybersecurity. The results of PLS-SEM path modeling analysis revealed a partial mediating impact of e-Governance between AI and cybersecurity.";['2159768691', '69963250'];['S. A. A. Bokhari', 'Seunghwan Myeong'];;;;;;;u48da3er;IEEE Access;2023.0;11;['Computer Science', 'Cybersecurity', 'Artificial Intelligence']
0802e689e8bc7791fea45311ec6203642c32fb7e;Cybercompetitions: A survey of competitions, tools, and systems to support cybersecurity education;;['2123350411', '3243454'];['Tyler Balon', 'I. Baggili'];;;;;;;9vl40xz6;Education and Information Technologies;2023.0;39;['Cybersecurity', 'Medicine']
1814944434626fa98d79e17b4732c2a5d5bb1151;The Role of Machine Learning in Cybersecurity;Machine Learning (ML) represents a pivotal technology for current and future information systems, and many domains already leverage the capabilities of ML. However, deployment of ML in cybersecurity is still at an early stage, revealing a significant discrepancy between research and practice. Such a discrepancy has its root cause in the current state of the art, which does not allow us to identify the role of ML in cybersecurity. The full potential of ML will never be unleashed unless its pros and cons are understood by a broad audience. This article is the first attempt to provide a holistic understanding of the role of ML in the entire cybersecurity domain—to any potential reader with an interest in this topic. We highlight the advantages of ML with respect to human-driven detection methods, as well as the additional tasks that can be addressed by ML in cybersecurity. Moreover, we elucidate various intrinsic;['119764154', '1754215', '133909699', '2975210', '2212862276', '2123504437', '2075681394'];['Giovanni Apruzzese', 'P. Laskov', 'Edgardo Montes de Oca', 'Wissam Mallouli', 'Luis Brdalo Rapa', 'A. Grammatopoulos', 'Fabio Di Franco'];;;;;;;g8l0b5um;Digital Threats: Research and Practice;2022.0;4;['Computer Science', 'Cybersecurity', 'Machine Learning']
9196214e8f81b4a6efda6c8891a6365bccf865df;Explainable Artificial Intelligence in CyberSecurity: A Survey;Nowadays, Artificial Intelligence (AI) is widely applied in every area of human being’s daily life. Despite the AI benefits, its application suffers from the opacity of complex internal mechanisms and doesn’t satisfy by design the principles of Explainable Artificial Intelligence (XAI). The lack of transparency further exacerbates the problem in the field of CyberSecurity because entrusting crucial decisions to a system that cannot explain itself presents obvious dangers. There are several methods in the literature capable of providing explainability of AI results. Anyway, the application of XAI in CyberSecurity can be a double-edged sword. It substantially improves the CyberSecurity practices but simultaneously leaves the system vulnerable to adversary attacks. Therefore, there is a need to analyze the state-of-the-art of XAI methods in CyberSecurity to provide a clear vision for future research. This study presents an in-depth examination of the application of XAI in CyberSecurity. It considers more than 300 papers;['2067064455', '2721973', '2061104792', '2121344176'];['N. Capuano', 'G. Fenza', 'V. Loia', 'Claudio Stanzione'];;;;;;;liaszoom;IEEE Access;2022.0;10;['Computer Science', 'Cybersecurity', 'Artificial Intelligence']
a8bffeee237f0106a9377a0eb9643f6f9d2be50a;Cybersecurity awareness in the context of the Industrial Internet of Things: A systematic literature review;;['48139416', '1715946', '79513578', '2151410382'];['A. Corallo', 'M. Lazoi', 'M. Lezzi', 'A. Luperto'];;;;;;;xnhfj89i;Comput. Ind.;2022.0;137;['Cybersecurity', 'Medicine']
7a0392ef4c607392de92ee1f7c84e68780e7976b;Cybersecurity, Data Privacy and Blockchain: A Review;;['1742178619', '1742254031', '2055082996', '2149798897', '1705901', '2584973', '2006534498', '1505722696', '2149799007'];['Vinden Wylde', 'Nisha Rawindaran', 'J. Lawrence', 'Rushil Balasubramanian', 'E. Prakash', 'Ambikesh Jayal', 'Imtiaz A. Khan', 'C. Hewage', 'Jon Platts'];;;;;;;ujnw5t3g;Sn Computer Science;2022.0;3;['Computer Science', 'Cybersecurity', 'Medicine']
032832f71799eba6565e2444778dcffccbd76280;Microsoft CloudMine: Data Mining for the Executive Order on Improving the Nation's Cybersecurity;As any other US software maker, Microsoft is bound by the “Executive Order on Improving the Nation's Cybersecurity” [2] which dictates a clear mandate to “enhance the software supply chain security” and to generally improve the cyber security practices. However, this is much easier written down than enforced. The executive order imposes new rules and requirements that will impact engineering practices and evidence collection for most projects and engineering teams in a relatively short period of time. Part of the response is the requirement to build up comprehensive inventories of software artifacts contributing to US government systems, which is a massive task when done manually would be tedious and fragile as software eco-systems change rapidly. Required is a system that will constantly monitor and update the inventory of software artifacts and contributors so that at any given point of time, the scope and involved teams for any software security incident;['39496137', '2172223304', '2172223566', '39855161', '2172228380', '2172224059', '2172209671', '2172209669', '1979660', '1906848', '2172209406'];['Kim Herzig', 'Luke Ghostling', 'Maximilian Grothusmann', 'Sascha Just', 'Nora Huang', 'Alan Klimowski', 'Yashasvini Ramkumar', 'Myles McLeroy', 'Kivanç Muslu', 'Hitesh Sajnani', 'Varsha Vadaga'];d7907408-25bc-4816-a81d-4e0f2f6482c8;IEEE Working Conference on Mining Software Repositories;conference;12;2022.0;São Paulo;;;;;['Cloud', 'Computer Science', 'Cybersecurity', 'Data Mining']
8220aa9254d478dd77a6e1efb8aa5ad3e177858d;Machine Learning for Intelligent Data Analysis and Automation in Cybersecurity: Current and Future Prospects;;['3456687'];['Iqbal H. Sarker'];;;;;;;08inuvrg;Annals of Data Science;2022.0;10;['Cybersecurity', 'Machine Learning']
39361b3507c9f8b0a97780568b645f80a208d78a;Machine Learning and Deep Learning Methods for Cybersecurity;With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.;['2067672128', '2069277364', '2118357790', '49069825', '121704135', '96519515', '49594896', '2149274', '2201459853'];['Yang Xin', 'Lingshuang Kong', 'Zhi Liu', 'Yuling Chen', 'Yanmiao Li', 'Hongliang Zhu', 'Mingcheng Gao', 'Haixia Hou', 'Chunhua Wang'];;;;;;;hdwmew1s;IEEE Access;2018.0;6;['Computer Science', 'Deep Learning', 'Cybersecurity', 'Machine Learning']
20c27659690854435c020b8b5ba8dee0683920cd;A Survey on Explainable Artificial Intelligence for Cybersecurity;The “black-box” nature of artificial intelligence (AI) models has been the source of many concerns in their use for critical applications. Explainable Artificial Intelligence (XAI) is a rapidly growing research field that aims to create machine learning models that can provide clear and interpretable explanations for their decisions and actions. In the field of cybersecurity, XAI has the potential to revolutionize the way we approach network and system security by enabling us to better understand the behavior of cyber threats and to design more effective defenses. In this survey, we review the state of the art in XAI for cybersecurity and explore the various approaches that have been proposed to address this important problem. The review follows a systematic classification of cybersecurity threats and issues in networks and digital systems. We discuss the challenges and limitations of current XAI methods in the context of cybersecurity and outline promising directions for;['29807997', '1812107', '66399627', '1722280', '2212527193', '2212340032', '1718596', '144378341'];['Gaith Rjoub', 'J. Bentahar', 'Omar Abdel Wahab', 'R. Mizouni', 'Alyssa Song', 'Robin Cohen', 'Hadi Otrok', 'A. Mourad'];;;;;;;em2qxoat;IEEE Transactions on Network and Service Management;2023.0;20;['Computer Science', 'Cybersecurity', 'Artificial Intelligence']
e29c43b6991de6dfd5aec41c4a10e02260c26cef;Cybersecurity for autonomous vehicles: Review of attacks and defense;;['1947512956', '2109319019', '2109695231', '2157836035', '1802174'];['Kyounggon Kim', 'Jun Seok Kim', 'S. Jeong', 'Jo-Hee Park', 'H. Kim'];;;;;;;ay30iarh;Comput. Secur.;2021.0;103;['Computer Science', 'Cybersecurity']
8e78efdb8b92dfd12e7a78a15abcc475e168c2aa;Cybersecurity Threats and Their Mitigation Approaches Using Machine Learning - A Review;Machine learning is of rising importance in cybersecurity. The primary objective of applying machine learning in cybersecurity is to make the process of malware detection more actionable, scalable and effective than traditional approaches, which require human intervention. The cybersecurity domain involves machine learning challenges that require efficient methodical and theoretical handling. Several machine learning and statistical methods, such as deep learning, support vector machines and Bayesian classification, among others, have proven effective in mitigating cyber-attacks. The detection of hidden trends and insights from network data and building of a corresponding data-driven machine learning model to prevent these attacks is vital to design intelligent security systems. In this survey, the focus is on the machine learning techniques that have been implemented on cybersecurity data to make these systems secure. Existing cybersecurity threats and how machine learning techniques have been used to mitigate these threats have been discussed. The shortcomings of these;['40297013', '2077395617', '40499273', '26549692', '2175377495', '2175918341'];['Mostofa Ahsan', 'Kendall E. Nygard', 'Rahul Gomes', 'M. Chowdhury', 'Nafiz Rifat', 'Jayden F Connolly'];;;;;;;ikbn9ybj;J. Cybersecur. Priv.;2022.0;2;['Computer Science', 'Cybersecurity', 'Machine Learning']
5cc34b7a11f3d1a062d7cfaab02414f4869d93cb;Framework for Improving Critical Infrastructure Cybersecurity, Version 1.1 ;<jats:p />;['46904580'];['M. Barrett'];;;;;;;smisbr2o;Computer Science Magazine (2018.0);2018.0;;['Computer Science', 'Cybersecurity']
fa56abe6d66692aa0eb65ca50f0edf45b18bc008;Addressing Cybersecurity Challenges in Education;This study aimed to address the challenges of cybersecurity in education. As kindergarten through twelfth-grade education shifts to online and remote learning, educators and governments are increasingly vulnerable to the risks of cyberattacks and cybercrimes. This study focused on the strategies that institutions can employ to increase their students’ cybersecurity awareness and simultaneously motivate them to pursue cybersecurity as a career. To achieve the research objectives, a systematic review of ten studies was performed, and the results showed that game-based strategies were effective in increasing students’ awareness about cybersecurity and their interest in pursuing cybersecurity as a career. The study’s implications suggest that game designers and developers may want to develop advanced games that gauge students’ cybersecurity skills and ability to respond to aggressive forms of cyberattacks in addition to enhancing their knowledge of cybersecurity.;['2178677046'];['William J. Triplett'];;;;;;;n8ji4i0u;International Journal of STEM Education for Sustainability;2023.0;81;['Cybersecurity']
edbe03bb332961060e20f4a01be5a87941886c55;Organizational Learning from Cybersecurity Performance: Effects on Cybersecurity Investment Decisions;;['52217899', '1796920'];['F. A. Shaikh', 'M. Siponen'];;;;;;;yseeqqg1;Inf. Syst. Frontiers;2023.0;26;['Computer Science', 'Cybersecurity']
456a70485aafc12dfed4fb7354668d72aae9b658;SecureBERT: A Domain-Specific Language Model for Cybersecurity;;['40927786', '2188652812', '3489126', '1399221705'];['Ehsan Aghaei', 'Xi Niu', 'W. Shadid', 'E. Al-Shaer'];3c96db8c-8ea9-4c77-8a78-f8207dcc8453;Security and Privacy in Communication Networks;conference;15;2022.0;Barcelona;;;;;['Computer Science', 'Cybersecurity']
d7fbe4c6de245a182875133947538f7b1d9c59fe;Governing autonomous vehicles: emerging responses for safety, liability, privacy, cybersecurity, and industry risks;"ABSTRACT The benefits of autonomous vehicles (AVs) are widely acknowledged, but there are concerns about the extent of these benefits and AV risks and unintended consequences. In this article, we first examine AVs and different categories of the technological risks associated with them. We then explore strategies that can be adopted to address these risks, and explore emerging responses by governments for addressing AV risks. Our analyses reveal that, thus far, governments have in most instances avoided stringent measures in order to promote AV developments and the majority of responses are non-binding and focus on creating councils or working groups to better explore AV implications. The US has been active in introducing legislations to address issues related to privacy and cybersecurity. The UK and Germany, in particular, have enacted laws to address liability issues; other countries mostly acknowledge these issues, but have yet to implement specific strategies. To address privacy";['3299973', '41018764'];['Araz Taeihagh', 'H. S. M. Lim'];;;;;;;hikfvx5k;Transport Reviews;2018.0;39;['Computer Science', 'Business', 'Cybersecurity']
41c34865767056f4f45d5c0b1eb73e957b8b675b;Cybersecurity Education in the Age of AI: Integrating AI Learning into Cybersecurity High School Curricula;"Artificial Intelligence (AI) and cybersecurity are becoming increasingly intertwined, with AI and Machine Learning (AI/ML) being leveraged for cybersecurity, and cybersecurity helping address issues caused by AI. The goal in our exploratory curricular initiative is to dovetail the need to teach these two critical, emerging topics in highschool, and create a suite of novel activities, 'AI & Cybersecurity for Teens' (ACT) that introduces AI/ML in the context of cybersecurity and prepares high school teachers to integrate them in their cybersecurity curricula. Additionally, ACT activities are designed such that teachers (and students) build a deeper understanding of how ML works and how the machine actually ""learns"". Such understanding will aid more meaningful interrogation of critical issues such as AI ethics and bias. ACT introduces core ML topics contextualized in cybersecurity topics through a range of programming activities and pre-programmed games in NetsBlox, an easy-to-use block-based programming environment. We conducted 2 pilot";['37245087', '2750745', '2081598594'];['Shuchi Grover', 'B. Broll', 'Derek Babb'];2c9ecac6-f875-4a9b-acc2-10bd9f6782df;Technical Symposium on Computer Science Education;conference;5;2023.0;São Paulo;;;;;['Computer Science', 'Cybersecurity']
b75f22eb43531974ca7e843d17ce47e1a4445f50;Attacks to Automatous Vehicles: A Deep Learning Algorithm for Cybersecurity;Rapid technological development has changed drastically the automotive industry. Network communication has improved, helping the vehicles transition from completely machine- to software-controlled technologies. The autonomous vehicle network is controlled by the controller area network (CAN) bus protocol. Nevertheless, the autonomous vehicle network still has issues and weaknesses concerning cybersecurity due to the complexity of data and traffic behaviors that benefit the unauthorized intrusion to a CAN bus and several types of attacks. Therefore, developing systems to rapidly detect message attacks in CAN is one of the biggest challenges. This study presents a high-performance system with an artificial intelligence approach that protects the vehicle network from cyber threats. The system secures the autonomous vehicle from intrusions by using deep learning approaches. The proposed security system was verified by using a real automatic vehicle network dataset, including spoofing, flood, replaying attacks, and benign packets. Preprocessing was applied to convert the categorical data;['9092628', '73109651'];['Theyazn H. H. Aldhyani', 'Hasan Alkahtani'];3dbf084c-ef47-4b74-9919-047b40704538;Italian National Conference on Sensors;conference;3;2022.0;New York;;;;;['Cybersecurity', 'Computer Science', 'Deep Learning', 'Medicine']
1ceec32de34b70a816d19b71cdf0cd590c490ae7;The Impact and Limitations of Artificial Intelligence in Cybersecurity: A Literature Review;;['33220564', '2064326216', '2107387291', '2164530819'];['Md Meraj Ansari', 'Bibhu Dash', 'P. Sharma', 'Nikhitha Yathiraju'];;;;;;;ufye1yj3;IJARCCE;2022.0;57;['Cybersecurity', 'Artificial Intelligence']
98a71b310ce8a9e796d15f295a447cce3bb29e11;Review of Electric Vehicle Charger Cybersecurity Vulnerabilities, Potential Impacts, and Defenses;Worldwide growth in electric vehicle use is prompting new installations of private and public electric vehicle supply equipment (EVSE). EVSE devices support the electrification of the transportation industry but also represent a linchpin for power systems and transportation infrastructures. Cybersecurity researchers have recently identified several vulnerabilities that exist in EVSE devices, communications to electric vehicles (EVs), and upstream services, such as EVSE vendor cloud services, third party systems, and grid operators. The potential impact of attacks on these systems stretches from localized, relatively minor effects to long-term national disruptions. Fortunately, there is a strong and expanding collection of information technology (IT) and operational technology (OT) cybersecurity best practices that may be applied to the EVSE environment to secure this equipment. In this paper, we survey publicly disclosed EVSE vulnerabilities, the impact of EV charger cyberattacks, and proposed security protections for EV charging technologies.;['2115732116', '2006696237', '2142422067', '1576017824'];['Jay Johnson', 'Timothy Berg', 'Benjamin Anderson', 'Brian Wright'];;;;;;;42j7y2vm;Energies;2022.0;52;['Cybersecurity']
4eb1170ef1d5f7707ad6042b7f418816a0b85cd3;Understanding Cybersecurity Frameworks and Information Security Standards—A Review and Comprehensive Overview;Businesses are reliant on data to survive in the competitive market, and data is constantly in danger of loss or theft. Loss of valuable data leads to negative consequences for both individuals and organizations. Cybersecurity is the process of protecting sensitive data from damage or theft. To successfully achieve the objectives of implementing cybersecurity at different levels, a range of procedures and standards should be followed. Cybersecurity standards determine the requirements that an organization should follow to achieve cybersecurity objectives and facilitate against cybercrimes. Cybersecurity standards demonstrate whether an information system can meet security requirements through a range of best practices and procedures. A range of standards has been established by various organizations to be employed in information systems of different sizes and types. However, it is challenging for businesses to adopt the standard that is the most appropriate based on their cybersecurity demands. Reviewing the experiences of other businesses;['2636344'];['Hamed Taherdoost'];;;;;;;eg0r2uj1;Electronics;2022.0;34;['Cybersecurity']
f2345a08c082d163c2df2d227352ae7f2dbbf5e6;Cybersecurity Challenges in the Maritime Sector;Cyberattacks have been rapidly increasing over the years, resulting to big financial losses to businesses for recovery, regulatory sanctions, as well as collateral damages, such as reputation and trust. In this respect, the maritime sector, which until now was considered safe due to the lack of Internet connectivity and the isolated nature of ships in the sea, is showing a 900% increase in cybersecurity breaches on operational technology as it enters the digital era. Although some research is being conducted in this area, maritime cybersecurity has not been deeply investigated. Hence, this paper provides a close investigation of the landscape of cybersecurity in the maritime sector with the aim of highlighting security problems and challenges. First, it explores the systems available on ships that could be targeted by attackers, their possible vulnerabilities that an attacker could exploit, the consequences if the system is accessed, and actual incidents. Then, it describes;['2158420447', '1727344570', '24889005', '101057486', '2253819'];['F. Akpan', 'G. Bendiab', 'S. Shiaeles', 'S. Karamperidis', 'Michalis Michaloliakos'];;;;;;;cvrrk3eb;Network;2022.0;2;['Computer Science', 'Cybersecurity']
710441167e62b550304efcadb0a8888cca1986e2;A survey on deep learning for cybersecurity: Progress, challenges, and opportunities;;['1381890552', '49762743', '144705186'];['Mayra Alexandra Macas Carrasco', 'Chunming Wu', 'Walter Fuertes'];;;;;;;dk9k7vg1;Comput. Networks;2022.0;212;['Computer Science', 'Deep Learning', 'Cybersecurity']
41f442ac80c2e816277278f89e5e0170782c632b;Impact of cybersecurity on operations and supply chain management: Emerging trends and future research directions;The new age economy is primarily driven by Industry 4.0 and Industry 5.0, which facilitate smartification of organizations by helping them integrate and automate decision making. Recent advances in information and communication technologies, such as the cloud, big data, Internet of things, and artificial intelligence and nanotechnology, have accelerated the adoption of Industry 4.0 and Industry 5.0. Because of these advancements, organizations are now facing new challenges in the form of cybersecurity risks that are partly caused by these technologies. In recent years, there has been a spike in the number of cyberattacks, and organizations are taking steps to minimize the impacts of these attacks. To address this critical issue, in this article, we discuss possible future research directions that production and operations management (POM) researchers can undertake to help organizations, supply chains, and governments develop robust strategies for reducing the number of attacks and their repercussions. In particular, we;['1739153328', '145875798'];['Subodha Kumar', 'Rakesh R. Mallipeddi'];;;;;;;vxval5og;Production and Operations Management;2022.0;31;['Cybersecurity']
6cf4e1a24aeccf041c57e0c6d3862c2789dbb972;Explainable artificial intelligence for cybersecurity: a literature survey;;['2093993', '3385931', '2189102819', '37287857', '2182450447', '3246730', '153086550', '2117088205', '47295112'];['F. Charmet', 'Harry Chandra Tanuwidjaja', 'Solayman Ayoubi', 'Pierre-François Gimenez', 'Yufei Han', 'Houda Jmila', 'Grégory Blanc', 'Takeshi Takahashi', 'Zonghua Zhang'];;;;;;;8w90s5hg;Annals of Telecommunications;2022.0;77;['Computer Science', 'Cybersecurity', 'Artificial Intelligence']
8d2a1fd8845ef471fa05fa5f277e7694f623b22c;XAI for Cybersecurity: State of the Art, Challenges, Open Issues and Future Directions;In the past few years, artificial intelligence (AI) techniques have been implemented in almost all verticals of human life. However, the results generated from the AI models often lag explainability. AI models often appear as a blackbox wherein developers are unable to explain or trace back the reasoning behind a specific decision. Explainable AI (XAI) is a rapid growing field of research which helps to extract information and also visualize the results generated with an optimum transparency. The present study provides and extensive review of the use of XAI in cybersecurity. Cybersecurity enables protection of systems, networks and programs from different types of attacks. The use of XAI has immense potential in predicting such attacks. The paper provides a brief overview on cybersecurity and the various forms of attack. Then the use of traditional AI techniques and its associated challenges are discussed which opens its doors towards use of XAI;['2154336483', '3314907', '2286538930', '47706103', '2168889073', '29919430', '151453737', '34917705', '2474250', '11041265'];['Gautam Srivastava', 'R. Jhaveri', 'S. Bhattacharya', 'Sharnil Pandya', 'Rajeswari', 'Praveen Kumar Reddy Maddikunta', 'Gokul Yenduri', 'Jon G. Hall', 'M. Alazab', 'T. Gadekallu'];;;;;;;4vm7uc0t;ArXiv;2022.0;abs/2206.03585;['Computer Science', 'Cybersecurity']
5ac7c1bda99faa74a9b78c23c3d7818af1ed4e39;Cybersecurity in the AI-Based Metaverse: A Survey;The Metaverse is a multi-user virtual world that combines physical reality with digital virtual reality. The three basic technologies for building the Metaverse are immersive technologies, artificial intelligence, and blockchain. Companies are subsequently making significant investments into creating an artificially intelligent Metaverse, with the consequence that cybersecurity has become more crucial. As cybercrime increases exponentially, it is evident that a comprehensive study of Metaverse security based on artificial intelligence is lacking. A growing number of distributed denial-of-service attacks and theft of user identification information makes it necessary to conduct comprehensive and inclusive research in this field in order to identify the Metaverse’s vulnerabilities and weaknesses. This article provides a summary of existing research on AI-based Metaverse cybersecurity and discusses relevant security challenges. Based on the results, the issue of user identification plays a very important role in the presented works, for which biometric methods are the most commonly used. While;['2141365313', '2159540338', '2965408'];['Mitra Pooyandeh', 'K. Han', 'I. Sohn'];;;;;;;mkablmd1;Applied Sciences;2022.0;4;['Cybersecurity']
b8a2fb97fb72725210ffd8af52446a88c88f072d;Deep Cybersecurity: A Comprehensive Overview from Neural Network and Deep Learning Perspective;;['3456687'];['Iqbal H. Sarker'];;;;;;;hf1dw2po;SN Computer Science;2021.0;2;['Computer Science', 'Deep Learning', 'Cybersecurity']
234b4d0309e06ea41b7b90bffebb5437ed4093d8;Machine Learning and Deep Learning Approaches for CyberSecurity: A Review;The rapid evolution and growth of the internet through the last decades led to more concern about cyber-attacks that are continuously increasing and changing. As a result, an effective intrusion detection system was required to protect data, and the discovery of artificial intelligence’s sub-fields, machine learning, and deep learning, was one of the most successful ways to address this problem. This paper reviewed intrusion detection systems and discussed what types of learning algorithms machine learning and deep learning are using to protect data from malicious behavior. It discusses recent machine learning and deep learning work with various network implementations, applications, algorithms, learning approaches, and datasets to develop an operational intrusion detection system.;['74917972', '1768107', '144722450', '2154335443', '1901634', '144396569'];['A. Halbouni', 'T. Gunawan', 'M. Habaebi', 'Murad Halbouni', 'M. Kartiwi', 'R. Ahmad'];;;;;;;dt3t5xyz;IEEE Access;2022.0;10;['Computer Science', 'Deep Learning', 'Cybersecurity', 'Machine Learning']
ee5ae247cc7de464dbe4e68fcc797b0b4ad9afe1;Digital sovereignty and taking back control: from regulatory capitalism to regulatory mercantilism in EU cybersecurity;ABSTRACT In recent years, we have been able to observe the emergence and mainstreaming of an EU discourse on digital sovereignty, which highlights the importance of gaining back control of EU digital infrastructure and technological production, based on the EU's perceived loss of economic competitiveness, limited capacity to innovate, high degree of dependence on foreign digital infrastructures and service providers and, related to all these factors, difficulty in providing EU citizens with a high level of cybersecurity. Bearing in mind that a considerable percentage of these infrastructures and service providers are under private sector control, the present article asks how this sovereignty discourse conceptualises the role of the private sector in EU cybersecurity. Drawing from a Regulatory Capitalism theoretical model, this article proposes that the EU has instead entered a Regulatory Mercantilist phase where it seeks to reassert its control over cyberspace, impose digital borders, accumulate data wealth and reduce;['98881621', '97478095'];['B. Farrand', 'Helena Carrapico'];;;;;;;uqu9gyc4;European Security;2022.0;31;['Cybersecurity']
4db664cd2d36bca5e6fe2bccf428d83edd57a4e6;Wireless Communications for Data Security: Efficiency Assessment of Cybersecurity Industry—A Promising Application for UAVs;The design of cooperative applications combining several unmanned aerial and aquatic vehicles is now possible thanks to the considerable advancements in wireless communication technology and the low production costs for small, unmanned vehicles. For example, the information delivered over the air instead of inside an optical fiber causes it to be far simpler for an eavesdropper to intercept and improperly change the information. This article thoroughly analyzes the cybersecurity industry’s efficiency in addressing the rapidly expanding requirement to incorporate compelling security features into wireless communication systems. In this research, we used a combination of DEA window analysis with the Malmquist index approach to assess the efficiency of the cybersecurity industry. We used input and output factors utilizing financial data from 2017–2020 sources from a US market. It was found that U1—Synopsys and U9—Fortinet exhibited the best performances when relating Malmquist and DEA window analysis. By evaluating ten big companies in;['2116632260', '2143952458', '2179791171', '2075326999'];['C. Wang', 'Fugian Yang', 'Nhut T. M. Vo', 'V. Nguyen'];;;;;;;3hnrqn2y;Drones;2022.0;88;['Cybersecurity']
0295272e0fc6e906c12cd22f8895eff8bbf4b52c;Role of Artificial Intelligence in the Internet of Things (IoT) cybersecurity;;['2293639627', '2120761444', '34672156'];['M. Kuzlu', 'Corinne Fair', 'Ozgur Guler'];;;;;;;oa2ae362;Discover Internet of Things;2021.0;1;['Computer Science', 'Cybersecurity', 'Artificial Intelligence']
f883e7399e49d08bacdd82a34b36802959a53887;Distributed Energy Resources Cybersecurity Outlook: Vulnerabilities, Attacks, Impacts, and Mitigations;"The digitization and decentralization of the electric power grid are key thrusts for an economically and environmentally sustainable future. Toward this goal, distributed energy resources (DER), including rooftop solar panels, battery storage, electric vehicles, etc., are becoming ubiquitous in power systems. Power utilities benefit from DERs as they minimize operational costs; at the same time, DERs grant users and aggregators control over the power they produce and consume. DERs are interconnected, interoperable, and support remotely controllable features; thus, their cybersecurity is of cardinal importance. DER communication dependencies and the diversity of DER architectures widen the threat surface and aggravate the cybersecurity posture of power systems. In this work, we focus on security oversights that reside in the cyber and physical layers of DERs and can jeopardize grid operations. The existing works have underlined the impact of cyberattacks targeting DER assets; however, they either focus on specific system components (e.g., communication";['1814068574', '32469781', '2953860'];['Ioannis Zografopoulos', 'N. Hatziargyriou', 'Charalambos Konstantinou'];;;;;;;2iwfxupp;IEEE Systems Journal;2022.0;17;['Computer Science', 'Cybersecurity', 'Engineering']
127ee97763be6e26a80fbb3fa191d414fcc0256a;Blockchain for Cybersecurity in Smart Grid: A Comprehensive Survey;Blockchain is an immutable type of distributed ledger that is capable of storing data without relying on a third party. Blockchain technology has attracted significant interest in research areas, including its application in the smart grid for cybersecurity. Although significant efforts have been devoted to utilizing blockchain in the smart grid for cybersecurity, there is a lack of comprehensive survey on blockchain in the smart grid for cybersecurity in both application and technological perspectives. To fill this gap, we conducted a comprehensive survey on blockchain for smart gird cybersecurity. This conducted survey presents the latest insights of ideas, architectures, and techniques of implementation that are relevant to blockchain's application in the smart grid for cybersecurity. This article aims at providing helpful guidance and reference for future research efforts specific to blockchain for cybersecurity in the smart grid.;['2113954022', '1753386484', '50855146'];['Zhu Peng', 'Talha Zamir', 'Hao Liang'];;;;;;;e08qqg60;IEEE Transactions on Industrial Informatics;2021.0;17;['Computer Science', 'Cybersecurity']
ecf8ffdbaf064d6c0dc225f1d9b42bbb094a767b;Enhancing Cybersecurity Policies with Blockchain Technology: A Survey;Cybersecurity is a major challenge in today’s era despite being equipped with multiple technologies, the world is lacking behind due to security issues. The domains like industries, manufacturing plants, healthcare organizations, educational institutes, etc are at the edge of shifting entirely to digitalization. This gives us immense improvement in existing processes but on the other hand, digitalized information is prone to hackers. Blockchain Technology is widely used for creating cryptocurrency as well as the research community is also utilizing this concept for numerous other applications. Supply chain, industry 4.0, defense services, agriculture industry, and many other fields exploit blockchain technology’s benefits. In this research paper, the recent work in the direction of boosting cybersecurity in different fields with blockchain technology is discussed, and also the future directions are outlined by depicting the research gap in that specific research area. Blockchain Technology is the master coin to provide reliable, transparent, and;['2144870032', '153494643'];['Atul Kumar', 'Ishu Sharma'];0dc0e794-53db-401d-bd8f-8da9165b2865;International Conferences on Contemporary Computing and Informatics;conference;14;2022.0;Los Angeles;;;;;['Computer Science', 'Cybersecurity']
11f1b7693c6ff1544f099b7f7bdb06ab6e8c6531;Deep Reinforcement Learning in the Advanced Cybersecurity Threat Detection and Protection;;['2138408476', '1806129', '36882468'];['Mohit Sewak', 'S. K. Sahay', 'Hemant Rathore'];;;;;;;9jndh9fv;Information Systems Frontiers;2022.0;25;['Computer Science', 'Cybersecurity', 'Threat Detection']
3f00a50f9515f28b5469ee0fee394e4187ce0f7b;Stress, Burnout, and Security Fatigue in Cybersecurity: A Human Factors Problem;"Abstract Stress, burnout, and security fatigue continue as slight destroyers of strong cybersecurity and significant human factors concerns. The persistence of these human performance issues is concerning given the lack of mitigation and integration of human factors practitioners to mitigate these adverse risk circumstances. Security fatigue is not a new phenomenon but the evolving nature of cybersecurity results in various sub-categories of security fatigue; thus, making it a difficult problem to solve. Stress and burnout are major causes of short tenures in senior roles for security executives. Business decision-makers lack the expertise to explore the negative influences of stress, burnout, and security fatigue on cybersecurity. Technology-led cycles are organizations’ primary course of action to mitigate cybersecurity threats, resulting in complexity debt and making businesses more vulnerable to attacks. Human factors professionals can identify high-friction areas that degrade human performance and implement initiatives to reduce the risk. Human performance degradation in";['152376142'];['C. Nobles'];;;;;;;hrd6a2fg;HOLISTICA – Journal of Business and Public Administration;2022.0;13;['Cybersecurity']
93e64e090c5d51ae70df240b918401c13642aeb0;Functionality-Preserving Adversarial Machine Learning for Robust Classification in Cybersecurity and Intrusion Detection Domains: A Survey;Machine learning has become widely adopted as a strategy for dealing with a variety of cybersecurity issues, ranging from insider threat detection to intrusion and malware detection. However, by their very nature, machine learning systems can introduce vulnerabilities to a security defence whereby a learnt model is unaware of so-called adversarial examples that may intentionally result in mis-classification and therefore bypass a system. Adversarial machine learning has been a research topic for over a decade and is now an accepted but open problem. Much of the early research on adversarial examples has addressed issues related to computer vision, yet as machine learning continues to be adopted in other domains, then likewise it is important to assess the potential vulnerabilities that may occur. A key part of transferring to new domains relates to functionality-preservation, such that any crafted attack can still execute the original intended functionality when inspected by a human;['2059622328', '2155386', '1749393', '32735793'];['Andrew McCarthy', 'Essam Ghadafi', 'Panagiotis Andriotis', 'Phil Legg'];;;;;;;s6otankd;J. Cybersecur. Priv.;2022.0;2;['Computer Science', 'Cybersecurity', 'Machine Learning']
d00403ad22de33fd0bb59074ab0de5d7d7176d8f;Cybersecurity Enterprises Policies: A Comparative Study;Cybersecurity is a critical issue that must be prioritized not just by enterprises of all kinds, but also by national security. To safeguard an organization’s cyberenvironments, information, and communication technologies, many enterprises are investing substantially in cybersecurity these days. One part of the cyberdefense mechanism is building an enterprises’ security policies library, for consistent implementation of security controls. Significant and common cybersecurity policies of various enterprises are compared and explored in this study to provide robust and comprehensive cybersecurity knowledge that can be used in various enterprises. Several significant common security policies were identified and discussed in this comprehensive study. This study identified 10 common cybersecurity policy aspects in five enterprises: healthcare, finance, education, aviation, and e-commerce. We aimed to build a strong infrastructure in each business, and investigate the security laws and policies that apply to all businesses in each sector. Furthermore, the findings of this study reveal that;['144204979', '2902959', '143742258', '70124169'];['A. Mishra', 'Y. Alzoubi', 'A. Gill', 'M. Anwar'];3dbf084c-ef47-4b74-9919-047b40704538;Italian National Conference on Sensors;conference;1;2022.0;London;;;;;['Computer Science', 'Cybersecurity', 'Medicine']
26127c75e87cf8786ce2d9c8da32a5ea3d1c3693;Problem- Based Cybersecurity Lab with Knowledge Graph as Guidance;Lecture-based teaching paired with laboratory-based exercises is most commonly used in cybersecurity instruction. However, it focuses more on theories and models but fails to provide learners with practical problem-solving skills and opportunities to explore real-world cybersecurity challenges. Problem-based Learning (PBL) has been identified as an efficient pedagogy for many disciplines, especially engineering education. It provides learners with real-world complex problem scenarios, which encourages learners to collaborate with classmates, ask questions and develop a deeper understanding of the concepts while solving real-world cybersecurity problems. This paper describes the application of the PBL methodology to enhance professional training-based cybersecurity education. The authors developed an online laboratory environment to apply PBL with Knowledge-Graph (KG) based guidance for hands-on labs in cybersecurity training.Learners are provided access to a virtual lab environment with knowledge graph guidance to simulated real-life cybersecurity scenarios. Thus, they are forced to think independently and apply their knowledge to create cyber-attacks;['2310475', '48000683', '2154394108', '34577327'];['Yuli Deng', 'Zhengping Zeng', 'Kritshekhar Jha', 'Dijiang Huang'];;;;;;;e5iotzvi;Journal of Artificial Intelligence and Technology;2022.0;56;['Graph', 'Cybersecurity']
6d2ed9bf1d83c8db1f9cbf92ea2f57ea90ef6839;How Powerful are Graph Neural Networks?;Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically;['3360632', '48594758', '1702139', '2594093'];['Keyulu Xu', 'Weihua Hu', 'J. Leskovec', 'S. Jegelka'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;2;2018.0;Sydney;;;;;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
189b79cda928d58f695cf8323b9ce2196fc22409;Graph-based genome alignment and genotyping with HISAT2 and HISAT-genotype;;['47181672', '39011068', '2115224068', '104377747', '1744109'];['Daehwan Kim', 'Joseph M. Paggi', 'Chanhee Park', 'C. Bennett', 'S. Salzberg'];;;;;;;xxiqi6c4;Nature Biotechnology;2019.0;37;['Computer Science', 'Graph', 'Medicine']
33998aff64ce51df8dee45989cdca4b6b1329ec4;Graph Attention Networks;We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).;['3444569', '7153363', '8742492', '144290131', '144269589', '1751762'];['Petar Velickovic', 'Guillem Cucurull', 'Arantxa Casanova', 'Adriana Romero', 'P. Lio’', 'Yoshua Bengio'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;7;2017.0;Chicago;;;;;['Computer Science', 'Graph', 'Mathematics']
cd8a9914d50b0ac63315872530274d158d6aff09;Modeling Relational Data with Graph Convolutional Networks;;['8804828', '41016725', '2789097', '9965217', '144889265', '1678311'];['M. Schlichtkrull', 'Thomas Kipf', 'Peter Bloem', 'Rianne van den Berg', 'Ivan Titov', 'M. Welling'];c7bde2ee-6ad5-49c7-9498-a01e46c162eb;Extended Semantic Web Conference;conference;11;2017.0;Sydney;;;;;['Computer Science', 'Graph', 'Mathematics']
81a4fd3004df0eb05d6c1cef96ad33d5407820df;A Comprehensive Survey on Graph Neural Networks;Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes,;['2109557884', '2585415', '31370754', '2062835', '48934799', '144019071'];['Zonghan Wu', 'Shirui Pan', 'Fengwen Chen', 'Guodong Long', 'Chengqi Zhang', 'Philip S. Yu'];;;;;;;egc9eizk;IEEE Transactions on Neural Networks and Learning Systems;2019.0;32;['Computer Science', 'Mathematics', 'Medicine', 'Neural Networks', 'Graph']
63a513832f56addb67be81a2fa399b233f3030fc;Fast Graph Representation Learning with PyTorch Geometric;We introduce PyTorch Geometric, a library for deep learning on irregularly structured input data such as graphs, point clouds and manifolds, built upon PyTorch. In addition to general graph data structures and processing methods, it contains a variety of recently published methods from the domains of relational learning and 3D data processing. PyTorch Geometric achieves high data throughput by leveraging sparse GPU acceleration, by providing dedicated CUDA kernels and by introducing efficient mini-batch handling for input examples of different size. In this work, we present the library in detail and perform a comprehensive comparative study of the implemented methods in homogeneous evaluation scenarios.;['3410500', '9572099'];['Matthias Fey', 'J. E. Lenssen'];;;;;;;p9tieqxv;ArXiv;2019.0;abs/1903.02428;['Computer Science', 'Graph', 'Mathematics']
36eff562f65125511b5dfab68ce7f7a943c27478;Semi-Supervised Classification with Graph Convolutional Networks;We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.;['41016725', '1678311'];['Thomas Kipf', 'M. Welling'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;17;2016.0;Houston;;;;;['Computer Science', 'Graph', 'Mathematics']
1ee0abcb8f0afd74d602255d529d7c2a036a8f02;Graph Theory;;['2761897'];['Frank de Zeeuw'];;;;;;;vzlb49ba;Science Magazine (2016.0);2016.0;66;['Graph']
e1799aaf23c12af6932dc0ef3dfb1638f01413d1;Dynamic Graph CNN for Learning on Point Clouds;"Point clouds provide a flexible geometric representation suitable for countless applications in computer graphics; they also comprise the raw output of most 3D data acquisition devices. While hand-designed features on point clouds have long been proposed in graphics and vision, however, the recent overwhelming success of convolutional neural networks (CNNs) for image analysis suggests the value of adapting insight from CNN to the point cloud world. Point clouds inherently lack topological information, so designing a model to recover topology can enrich the representation power of point clouds. To this end, we propose a new neural network module dubbed EdgeConv suitable for CNN-based high-level tasks on point clouds, including classification and segmentation. EdgeConv acts on graphs dynamically computed in each layer of the network. It is differentiable and can be plugged into existing architectures. Compared to existing modules operating in extrinsic space or treating each point independently, EdgeConv has several appealing";['2118462083', '1409692637', '2117940996', '1934849', '1732570', '1932072'];['Yue Wang', 'Yongbin Sun', 'Ziwei Liu', 'S. Sarma', 'M. Bronstein', 'J. Solomon'];;;;;;;twgr4g2s;ACM Transactions on Graphics (TOG);2018.0;38;['Cloud', 'Computer Science', 'Graph']
3024f58826a5bce3378af94f677e8fb90cbb49e0;LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation;Graph Convolution Network (GCN) has become new state-of-the-art for collaborative filtering. Nevertheless, the reasons of its effectiveness for recommendation are not well understood. Existing work that adapts GCN to recommendation lacks thorough ablation analyses on GCN, which is originally designed for graph classification tasks and equipped with many neural network operations. However, we empirically find that the two most common designs in GCNs -- feature transformation and nonlinear activation -- contribute little to the performance of collaborative filtering. Even worse, including them adds to the difficulty of training and degrades recommendation performance. In this work, we aim to simplify the design of GCN to make it more concise and appropriate for recommendation. We propose a new model named LightGCN, including only the most essential component in GCN -- neighborhood aggregation -- for collaborative filtering. Specifically, LightGCN learns user and item embeddings by linearly propagating them on the user-item interaction graph,;['7792071', '2068923630', '2144796537', '2694924', '1699819', '2146059323'];['Xiangnan He', 'Kuan Deng', 'Xiang Wang', 'Yan Li', 'Yongdong Zhang', 'Meng Wang'];8dce23a9-44e0-4381-a39e-2acc1edff700;Annual International ACM SIGIR Conference on Research and Development in Information Retrieval;conference;13;2020.0;Houston;;;;;['Computer Science', 'Graph']
ea5dd6a3d8f210d05e53a7b6fa5e16f1b115f693;Graph Neural Networks: A Review of Methods and Applications;;['48128428', '52297757', '2621696', '3443627', '49293587', '1753344'];['Jie Zhou', 'Ganqu Cui', 'Zhengyan Zhang', 'Cheng Yang', 'Zhiyuan Liu', 'Maosong Sun'];;;;;;;h9ys7nhk;ArXiv;2018.0;abs/1812.08434;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
72edcb3788f9c141a3ed28e6d36f75ca4977d27e;Spatio-temporal Graph Convolutional Neural Network: A Deep Learning Framework for Traffic Forecasting;Timely accurate traffic forecast is crucial for urban traffic control and guidance. Due to the high nonlinearity and complexity of traffic flow, traditional methods cannot satisfy the requirements of mid-and-long term prediction tasks and often neglect spatial and temporal dependencies. In this paper, we propose a novel deep learning framework, Spatio-Temporal Graph Convolutional Networks (STGCN), to tackle the time series prediction problem in traffic domain. Instead of applying regular convolutional and recurrent units, we formulate the problem on graphs and build the model with complete convolutional structures, which enable much faster training speed with fewer parameters. Experiments show that our model STGCN effectively captures comprehensive spatio-temporal correlations through modeling multi-scale traffic networks and consistently outperforms state-of-the-art baselines on various real-world traffic datasets.;['46806278', '26379330', '1703952'];['Ting Yu', 'Haoteng Yin', 'Zhanxing Zhu'];67f7f831-711a-43c8-8785-1e09005359b5;International Joint Conference on Artificial Intelligence;conference;1;2017.0;São Paulo;;;;;['Computer Science', 'Graph', 'Deep Learning', 'Mathematics']
597bd2e45427563cdf025e53a3239006aa364cfc;Open Graph Benchmark: Datasets for Machine Learning on Graphs;We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale (up to 100+ million nodes and 1+ billion edges), encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup,;['48594758', '3410500', '2095762', '2047998', '40046694', '2156641189', '1754926', '1702139'];['Weihua Hu', 'Matthias Fey', 'M. Zitnik', 'Yuxiao Dong', 'Hongyu Ren', 'Bowen Liu', 'Michele Catasta', 'J. Leskovec'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;9;2020.0;Abuja;;;;;['Computer Science', 'Graph', 'Mathematics', 'Machine Learning']
54906484f42e871f7c47bbfe784a358b1448231f;Variational Graph Auto-Encoders;We introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.;['41016725', '1678311'];['Thomas Kipf', 'M. Welling'];;;;;;;90t1utk8;ArXiv;2016.0;abs/1611.07308;['Computer Science', 'Graph', 'Mathematics']
c5f5f179d80a3bf9b4f29750283a87eaca42e91b;Neural Graph Collaborative Filtering;Learning vector representations (aka. embeddings) of users and items lies at the core of modern recommender systems. Ranging from early matrix factorization to recently emerged deep learning based methods, existing efforts typically obtain a user's (or an item's) embedding by mapping from pre-existing features that describe the user (or the item), such as ID and attributes. We argue that an inherent drawback of such methods is that, the collaborative signal, which is latent in user-item interactions, is not encoded in the embedding process. As such, the resultant embeddings may not be sufficient to capture the collaborative filtering effect. In this work, we propose to integrate the user-item interactions - more specifically the bipartite graph structure - into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. This leads to the expressive modeling of high-order;['98285513', '7792071', '2146058320', '2163400298', '144078686'];['Xiang Wang', 'Xiangnan He', 'Meng Wang', 'Fuli Feng', 'Tat-Seng Chua'];8dce23a9-44e0-4381-a39e-2acc1edff700;Annual International ACM SIGIR Conference on Research and Development in Information Retrieval;conference;5;2019.0;Paris;;;;;['Computer Science', 'Graph']
7e71eedb078181873a56f2adcfef9dddaeb95602;Simplifying Graph Convolutional Networks;Graph Convolutional Networks (GCNs) and their variants have experienced significant attention and have become the de facto methods for learning graph representations. GCNs derive inspiration primarily from recent deep learning approaches, and as a result, may inherit unnecessary complexity and redundant computation. In this paper, we reduce this excess complexity through successively removing nonlinearities and collapsing weight matrices between consecutive layers. We theoretically analyze the resulting linear model and show that it corresponds to a fixed low-pass filter followed by a linear classifier. Notably, our experimental evaluation demonstrates that these simplifications do not negatively impact accuracy in many downstream applications. Moreover, the resulting model scales to larger datasets, is naturally interpretable, and yields up to two orders of magnitude speedup over FastGCN.;['24277779', '123437034', '3383481', '2258547281', None, '7446832'];['Felix Wu', 'Tianyi Zhang', 'A. Souza', 'Christopher Fifty', 'Tao Yu', 'Kilian Q. Weinberger'];fc0a208c-acb7-47dc-a0d4-af8190e21d29;International Conference on Machine Learning;conference;9;2019.0;London;;;;;['Computer Science', 'Graph', 'Mathematics']
6c96c2d4a3fbd572fef2d59cb856521ee1746789;Graph Convolutional Neural Networks for Web-Scale Recommender Systems;Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains an unsolved challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. Overall,;['83539859', '2933399', '2118439896', '50988143', '49437682', '1702139'];['Rex Ying', 'Ruining He', 'Kaifeng Chen', 'Pong Eksombatchai', 'William L. Hamilton', 'J. Leskovec'];a0edb93b-1e95-4128-a295-6b1659149cef;Knowledge Discovery and Data Mining;conference;10;2018.0;Tokyo;;;;;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
00b7efbf14a54cced4b9f19e663b70ffbd01324b;Heterogeneous Graph Attention Network;Graph neural network, as a powerful graph representation technique based on deep learning, has shown superior performance and attracted considerable research interest. However, it has not been fully considered in graph neural network for heterogeneous graph which contains different types of nodes and links. The heterogeneity and rich semantic information bring great challenges for designing a graph neural network for heterogeneous graph. Recently, one of the most exciting advancements in deep learning is the attention mechanism, whose great potential has been well demonstrated in various areas. In this paper, we first propose a novel heterogeneous graph neural network based on the hierarchical attention, including node-level and semantic-level attentions. Specifically, the node-level attention aims to learn the importance between a node and its meta-path based neighbors, while the semantic-level attention is able to learn the importance of different meta-paths. With the learned importance from both node-level and semantic-level attention, the importance;['2118449003', '51111816', '144123161', '1735282', '143738684', '152297693', '7873409'];['Xiao Wang', 'Houye Ji', 'C. Shi', 'Bai Wang', 'Peng Cui', 'Philip S. Yu', 'Yanfang Ye'];e07422f9-c065-40c3-a37b-75e98dce79fe;The Web Conference;conference;4;2019.0;Houston;;;;;['Computer Science', 'Graph']
69906b74ee369cd25522ec432ecbc601a77c9d87;Spectral graph theory;Spectral graph theory is a vast and expanding area of combinatorics. We start these notes by introducing and motivating classical matrices associated with a graph, and then show how to derive combinatorial properties of a graph from the eigenvalues of these matrices. We then examine more modern results such as polynomial interlacing and high dimensional expanders;['2285529840'];['Amol Sahebrao Hinge'];;;;;;;l2lw2zub;"Zeta and 𝐿-functions in Number Theory and
                    Combinatorics";2019.0;30;['Graph', 'Mathematics']
36652428740cd30d245d55889f01a7fb04a91c93;Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning;Many interesting problems in machine learning are being revisited with new deep learning tools. For graph-based semi-supervised learning, a recent important development is graph convolutional networks (GCNs), which nicely integrate local vertex features and graph topology in the convolutional layers. Although the GCN model compares favorably with other state-of-the-art methods, its mechanisms are not clear and it still requires considerable amount of labeled data for validation and model selection. In this paper, we develop deeper insights into the GCN model and address its fundamental limits. First, we show that the graph convolution of the GCN model is actually a special form of Laplacian smoothing, which is the key reason why GCNs work, but it also brings potential concerns of over-smoothing with many convolutional layers. Second, to overcome the limits of the GCN model with shallow architectures, we propose both co-training and self-training approaches to train GCNs. Our approaches significantly improve;['35692225', '40592359', '19195265'];['Qimai Li', 'Zhichao Han', 'Xiao-Ming Wu'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;9;2018.0;Paris;;;;;['Computer Science', 'Graph', 'Mathematics']
d08a0eb7024dff5c4fabd58144a38031633d4e1a;Benchmarking Graph Neural Networks;Graph neural networks (GNNs) have become the standard toolkit for analyzing and learning from data on graphs. As the field grows, it becomes critical to identify key architectures and validate new ideas that generalize to larger, more complex datasets. Unfortunately, it has been increasingly difficult to gauge the effectiveness of new models in the absence of a standardized benchmark with consistent experimental settings. In this paper, we introduce a reproducible GNN benchmarking framework, with the facility for researchers to add new models conveniently for arbitrary datasets. We demonstrate the usefulness of our framework by presenting a principled investigation into the recent Weisfeiler-Lehman GNNs (WL-GNNs) compared to message passing-based graph convolutional networks (GCNs) for a variety of graph tasks, i.e. graph regression/classification and node/link prediction, with medium-scale datasets.;['51235219', '38009979', '81634721', '1751762', '2549032'];['Vijay Prakash Dwivedi', 'Chaitanya K. Joshi', 'T. Laurent', 'Yoshua Bengio', 'X. Bresson'];;;;;;;u2i3ea4y;ArXiv;2023.0;abs/2003.00982;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
59cdf849049627e4c30f3bd866e3a7e03e893251;Complex brain networks: graph theoretical analysis of structural and functional systems;;['34217324', '1694232'];['E. Bullmore', 'O. Sporns'];;;;;;;hqo2wyhg;Nature Reviews Neuroscience;2009.0;10;['Medicine', 'Graph', 'Psychology']
967a21a111757d6af7f7a25ca7ea2bdf6d505098;Deep Graph Infomax;We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs---both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. In contrast to most prior approaches to unsupervised learning with GCNs, DGI does not rely on random walk objectives, and is readily applicable to both transductive and inductive learning setups. We demonstrate competitive performance on a variety of node classification benchmarks, which at times even exceeds the performance of supervised learning.;['3444569', '26958176', '49437682', '144269589', '1751762', '40482726'];['Petar Velickovic', 'W. Fedus', 'William L. Hamilton', 'P. Lio’', 'Yoshua Bengio', 'R. Devon Hjelm'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;7;2018.0;London;;;;;['Computer Science', 'Graph', 'Mathematics']
3a58efcc4558727cc5c131c44923635da4524f33;Relational inductive biases, deep learning, and graph networks;"Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between ""hand-engineering"" and ""end-to-end"" learning, and instead advocate for an approach which benefits from their complementary strengths.";['2019153', '2158860', '2603033', '1398105826', '3133079', '145478807', '2844530', '143724694', '35030998', None, '1854385', '2107148568', '5055381', '2058362', '35188630', '40348417', '145254624', '36942233', '2066201331', '1745899', '2801204', '1688276', '143967473', '46378362', '1689108', '47002813', '1996134'];['P. Battaglia', 'Jessica B. Hamrick', 'V. Bapst', 'Alvaro Sanchez-Gonzalez', 'V. Zambaldi', 'Mateusz Malinowski', 'Andrea Tacchetti', 'David Raposo', 'Adam Santoro', 'Ryan Faulkner', 'Çaglar Gülçehre', 'H. F. Song', 'A. J. Ballard', 'J. Gilmer', 'George E. Dahl', 'Ashish Vaswani', 'Kelsey R. Allen', 'C. Nash', 'Victoria Langston', 'Chris Dyer', 'N. Heess', 'D. Wierstra', 'Pushmeet Kohli', 'M. Botvinick', 'O. Vinyals', 'Yujia Li', 'Razvan Pascanu'];;;;;;;cv6p29u8;ArXiv;2018.0;abs/1806.01261;['Computer Science', 'Graph', 'Deep Learning', 'Mathematics']
b07c157e7d40e06a4f2d486b16d5180d8b24acb9;Algebraic Graph Theory;;['2238617836', '1688178'];['Christopher D. Godsil', 'G. Royle'];;;;;;;d18a7x7k;Mathematics Magazine (2001.0);2001.0;36;['Computer Science', 'Graph', 'Mathematics']
26aa6fe2028b5eefbaa40ab54ef725bbbe7d9810;ConceptNet 5.5: An Open Multilingual Graph of General Knowledge;Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings. ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert-created resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use. When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this;['145696762', '2060230787', '2232845'];['R. Speer', 'Joshua Chin', 'Catherine Havasi'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;13;2016.0;Paris;;;;;['Computer Science', 'Graph']
994afdf0db0cb0456f4f76468380822c2f532726;Learning Entity and Relation Embeddings for Knowledge Graph Completion;Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant;['2427350', '49293587', '1753344', '2152797839', '144809121'];['Yankai Lin', 'Zhiyuan Liu', 'Maosong Sun', 'Yang Liu', 'Xuan Zhu'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;17;2015.0;Beijing;;;;;['Computer Science', 'Graph']
3120324069ec20eed853d3f9bbbceb32e4173b93;Fast approximate energy minimization via graph cuts;In this paper we address the problem of minimizing a large class of energy functions that occur in early vision. The major restriction is that the energy function's smoothness term must only involve pairs of pixels. We propose two algorithms that use graph cuts to compute a local minimum even when very large moves are allowed. The first move we consider is an /spl alpha/-/spl beta/-swap: for a pair of labels /spl alpha/,/spl beta/, this move exchanges the labels between an arbitrary set of pixels labeled a and another arbitrary set labeled /spl beta/. Our first algorithm generates a labeling such that there is no swap move that decreases the energy. The second move we consider is an /spl alpha/-expansion: for a label a, this move assigns an arbitrary set of pixels the label /spl alpha/. Our second algorithm, which requires the smoothness term to be a metric, generates a;['1692688', '1922280', '2984143'];['Yuri Boykov', 'Olga Veksler', 'R. Zabih'];;;;;;;eaj8gubx;Proceedings of the Seventh IEEE International Conference on Computer Vision;2001.0;1;['Computer Science', 'Graph', 'Mathematics']
2d867297dfe0d3ce2ed5b1d0f2dff88cac46ee94;Pregel: a system for large-scale graph processing;Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs - in some cases billions of vertices, trillions of edges - poses challenges to their efficient processing. In this paper we present a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertex-centric approach is flexible enough to express a broad set of algorithms. The model has been designed for efficient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier. Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs;['1766747', '2268793', '144211012', '2381974', '40607909', '1858799', '2911719'];['G. Malewicz', 'Matthew H. Austern', 'Aart J. C. Bik', 'James C. Dehnert', 'I. Horn', 'Naty Leiser', 'G. Czajkowski'];;;;;;;3cskq21x;Proceedings of the 2010 ACM SIGMOD International Conference on Management of data;2010.0;32;['Computer Science', 'Graph']
2a9fbca9dc6badbeedc591ad829c5c6e0f950fd6;Graph Contrastive Learning with Augmentations;Generalizable, transferrable, and robust representation learning on graph-structured data remains a challenge for current graph neural networks (GNNs). Unlike what has been developed for convolutional neural networks (CNNs) for image data, self-supervised learning and pre-training are less explored for GNNs. In this paper, we propose a graph contrastive learning (GraphCL) framework for learning unsupervised representations of graph data. We first design four types of graph augmentations to incorporate various priors. We then systematically study the impact of various combinations of graph augmentations on multiple datasets, in four different settings: semi-supervised, unsupervised, and transfer learning as well as adversarial attacks. The results show that, even without tuning augmentation extents nor using sophisticated GNN architectures, our GraphCL framework can produce graph representations of similar or better generalizability, transferrability, and robustness compared to state-of-the-art methods. We also investigate the impact of parameterized graph augmentation extents and patterns, and observe further performance gains in;['89197162', '2648459', '2003767516', '145358498', '2969311', '1705610299'];['Yuning You', 'Tianlong Chen', 'Yongduo Sui', 'Ting Chen', 'Zhangyang Wang', 'Yang Shen'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;9;2020.0;New York;;;;;['Computer Science', 'Graph']
8f096071a09701012c9c279aee2a88143a295935;RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space;We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.;['48064856', '123580511', '143619007', '152226504'];['Zhiqing Sun', 'Zhihong Deng', 'Jian-Yun Nie', 'Jian Tang'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;1;2018.0;Houston;;;;;['Computer Science', 'Graph', 'Mathematics']
3efd851140aa28e95221b55fcc5659eea97b172d;The Graph Neural Network Model;Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.;['47260481', '145467467', '1733691', '1784450', '3073217'];['F. Scarselli', 'M. Gori', 'A. Tsoi', 'M. Hagenbuchner', 'G. Monfardini'];;;;;;;vi05inju;IEEE Transactions on Neural Networks;2009.0;20;['Computer Science', 'Graph', 'Medicine']
1976c9eeccc7115d18a04f1e7fb5145db6b96002;Freebase: a collaboratively created graph database for structuring human knowledge;Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.;['1742448', '2065123479', '2990264', '1399112633', '2110748390'];['K. Bollacker', 'Colin Evans', 'Praveen K. Paritosh', 'Tim Sturge', 'Jamie Taylor'];;;;;;;cowgd5w2;Computer Science Bulletin (2008.0);2008.0;43;['Computer Science', 'Graph', 'Graph Database']
aeeffe327e6c93e9010c7b1e401caa9113723851;Efficient Graph-Based Image Segmentation;;['1685089', '1713089'];['Pedro F. Felzenszwalb', 'D. Huttenlocher'];;;;;;;2ii71tnh;International Journal of Computer Vision;2004.0;59;['Computer Science', 'Graph', 'Mathematics']
b8d9b10cf54629364523ec065e6307ab87f7d4f0;iRun: Horizontal and Vertical Shape of a Region-Based Graph Compression;Graph data are pervasive worldwide, e.g., social networks, citation networks, and web graphs. A real-world graph can be huge and requires heavy computational and storage resources for processing. Various graph compression techniques have been presented to accelerate the processing time and utilize memory efficiently. SOTA approaches decompose a graph into fixed-size submatrices and compress it by applying the existing graph compression algorithm. This approach is promising if the input graph is dense. Otherwise, an optimal graph compression ratio cannot be achieved. Graphs such as those used by social networks exhibit a power-law distribution. Thus, applying compression to the fixed-size block of a matrix could lead to the empty cell processing of that matrix. In this paper, we solve the problem of ordered matrix compression on a deep level, dividing the block into sub-blocks to achieve the best compression ratio. We observe that the ordered matrix compression ratio could be improved;['2198082533', '2145419030'];['Muhammad Umair', 'Young-Koo Lee'];3dbf084c-ef47-4b74-9919-047b40704538;Italian National Conference on Sensors;conference;10;2022.0;Houston;;;;;['Computer Science', 'Graph', 'Medicine']
1d81e7f428fea2b2e15ee3a96fe843ca603acc4c;Simple and Deep Graph Convolutional Networks;Graph convolutional networks (GCNs) are a powerful deep learning approach for graph-structured data. Recently, GCNs and subsequent variants have shown superior performance in various application areas on real-world datasets. Despite their success, most of the current GCN models are shallow, due to the {\em over-smoothing} problem. In this paper, we study the problem of designing and analyzing deep graph convolutional networks. We propose the GCNII, an extension of the vanilla GCN model with two simple yet effective techniques: {\em Initial residual} and {\em Identity mapping}. We provide theoretical and empirical evidence that the two techniques effectively relieves the problem of over-smoothing. Our experiments show that the deep GCNII model outperforms the state-of-the-art methods on various semi- and full-supervised tasks. Code is available at this https URL .;['2108633355', '12457830', '3251920', '1696332', '2110479359'];['Ming Chen', 'Zhewei Wei', 'Zengfeng Huang', 'Bolin Ding', 'Yaliang Li'];fc0a208c-acb7-47dc-a0d4-af8190e21d29;International Conference on Machine Learning;conference;13;2020.0;Beijing;;;;;['Computer Science', 'Graph', 'Mathematics']
2a3f862199883ceff5e3c74126f0c80770653e05;Knowledge Graph Embedding by Translating on Hyperplanes;We deal with embedding a large scale knowledge graph composed of entities and relations into a continuous vector space. TransE is a promising method proposed recently, which is very efficient while achieving state-of-the-art predictive performance. We discuss some mapping properties of relations which should be considered in embedding, such as reflexive, one-to-many, many-to-one, and many-to-many. We note that TransE does not do well in dealing with these properties. Some complex models are capable of preserving these mapping properties but sacrifice efficiency in the process. To make a good trade-off between model capacity and efficiency, in this paper we propose TransH which models a relation as a hyperplane together with a translation operation on it. In this way, we can well preserve the above mapping properties of relations with almost the same model complexity of TransE. Additionally, as a practical knowledge graph is often far from completed, how to construct negative;['2118452539', '2108090984', '2592554', '35773227'];['Zhen Wang', 'Jianwen Zhang', 'Jianlin Feng', 'Zheng Chen'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;16;2014.0;Paris;;;;;['Computer Science', 'Graph']
d18b48f77eb5c517a6d2c1fa434d2952a1b0a825;Hierarchical Graph Representation Learning with Differentiable Pooling;Recently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs---a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DiffPool, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DiffPool learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DiffPool yields an average improvement of;['83539859', '145829303', '143622465', '145201124', '49437682', '1702139'];['Rex Ying', 'Jiaxuan You', 'Christopher Morris', 'Xiang Ren', 'William L. Hamilton', 'J. Leskovec'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;4;2018.0;Beijing;;;;;['Computer Science', 'Graph', 'Mathematics']
6bc77c4dc6075ee81c05f0f5f43e44b2a34a5876;Graph Theory with Applications;"When I first entered the world of Mathematics, I became aware of a strange and little-regarded sect of ""Graph Theorists"", inhabiting a shadowy borderland known to the rest of the community as the ""slums of Topology"". What changes there have been in a few short years! That shadowy borderland has become a thriving metropolis. International conferences on Graph Theory occur with almost embarrassing frequency. Journals on Graph Theory abound: I once counted the Editorial Offices of three of them in one of the mathematical departments of one of the Universities of one of the smaller cities of Canada. Any connection with Topology is likely to be firmly repudiated as soon as noted. I became aware of the burgeoning of Graph Theory when I studied the 1940 paper of Brooks, Smith, Stone and Tutte in the Duke Mathematical Journal, ostensibly on squared rectangles. They wrote of trees and Kirchhoffs Laws, of";['48611572'];['E. S. Buffa'];;;;;;;7jm62ufd;Journal of the Operational Research Society;1977.0;;['Computer Science', 'Graph']
415224a9aff759f6972189df8b7761dfd6a81154;Introduction to graph theory;In graph theory, the term graph refers to a set of vertices and a set of edges. A vertex can be used to represent any object. Graphs may contain undirected or directed edges. An undirected edge is a set of two vertices. A directed edge is an ordered pair of two vertices where the edge goes from the first vertex to the second vertex. Graphs that contain directed edges are called directed graphs or digraphs.;['1774907'];['K. Fraughnaugh'];;;;;;;p6ouar5t;The Mathematical Gazette;1973.0;57;['Computer Science', 'Graph']
9697d32ed0a16da167f2bdba05ef96d0da066eb5;Convolutional 2D Knowledge Graph Embeddings;Link prediction for knowledge graphs is the task of predicting missing relationships between entities. Previous work on link prediction has focused on shallow, fast models which can scale to large knowledge graphs. However, these models learn less expressive features than deep, multi-layer models — which potentially limits performance. In this work we introduce ConvE, a multi-layer convolutional network model for link prediction, and report state-of-the-art results for several established datasets. We also show that the model is highly parameter efficient, yielding the same performance as DistMult and R-GCN with 8x and 17x fewer parameters. Analysis of our model suggests that it is particularly effective at modelling nodes with high indegree — which are common in highly-connected, complex knowledge graphs such as Freebase and YAGO3. In addition, it has been noted that the WN18 and FB15k datasets suffer from test set leakage, due to inverse relations from the training set being;['3239480', '3051815', '1918552', '48662861'];['Tim Dettmers', 'Pasquale Minervini', 'Pontus Stenetorp', 'Sebastian Riedel'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;9;2017.0;Barcelona;;;;;['Computer Science', 'Graph', 'Mathematics']
385742fffcf113656f0d3cf6c06ef95cb8439dc6;Depth-First Search and Linear Graph Algorithms;The value of depth-first search or “backtracking” as a technique for solving problems is illustrated by two examples. An improved version of an algorithm for finding the strongly connected components of a directed graph and at algorithm for finding the biconnected components of an undirect graph are presented. The space and time requirements of both algorithms are bounded by $k_1 V + k_2 E + k_3 $ for some constants $k_1 ,k_2 $, and $k_3 $, where V is the number of vertices and E is the number of edges of the graph being examined.;['1721050'];['R. Tarjan'];;;;;;;3a1v09fo;SIAM J. Comput.;1972.0;1;['Computer Science', 'Graph', 'Mathematics']
f412bb31ec9ef8bbef70eefc7ffd04420c1365d9;Graph-Based Visual Saliency;A new bottom-up visual saliency model, Graph-Based Visual Saliency (GBVS), is proposed. It consists of two steps: first forming activation maps on certain feature channels, and then normalizing them in a way which highlights conspicuity and admits combination with other maps. The model is simple, and biologically plausible insofar as it is naturally parallelized. This model powerfully predicts human fixations on 749 variations of 108 natural images, achieving 98% of the ROC area of a human-based control, whereas the classical algorithms of Itti & Koch ([2], [3], [4]) achieve only 84%.;['39810944', '145624227', '1690922'];['Jonathan Harel', 'C. Koch', 'P. Perona'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;2;2006.0;São Paulo;;;;;['Computer Science', 'Graph']
fae129338c0899576524506008427f64477d3967;Graph WaveNet for Deep Spatial-Temporal Graph Modeling;Spatial-temporal graph modeling is an important task to analyze the spatial relations and temporal trends of components in a system. Existing approaches mostly capture the spatial dependency on a fixed graph structure, assuming that the underlying relation between entities is pre-determined. However, the explicit graph structure (relation) does not necessarily reflect the true dependency and genuine relation may be missing due to the incomplete connections in the data. Furthermore, existing methods are ineffective to capture the temporal trends as the RNNs or CNNs employed in these methods cannot capture long-range temporal sequences. To overcome these limitations, we propose in this paper a novel graph neural network architecture, {Graph WaveNet}, for spatial-temporal graph modeling. By developing a novel adaptive dependency matrix and learn it through node embedding, our model can precisely capture the hidden spatial dependency in the data. With a stacked dilated 1D convolution component whose receptive field grows exponentially;['2109557884', '2585415', '2062835', '1746594', '48934799'];['Zonghan Wu', 'Shirui Pan', 'Guodong Long', 'Jing Jiang', 'Chengqi Zhang'];67f7f831-711a-43c8-8785-1e09005359b5;International Joint Conference on Artificial Intelligence;conference;5;2019.0;Beijing;;;;;['Computer Science', 'Graph', 'Mathematics']
30321b036607a7936221235ea8ec7cf7c1627100;Knowledge Graph Embedding: A Survey of Approaches and Applications;Knowledge graph (KG) embedding is to embed components of a KG including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the KG. It can benefit a variety of downstream tasks such as KG completion and relation extraction, and hence has quickly gained massive attention. In this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. Particularly, we make the review based on the type of information used in the embedding task. Techniques that conduct embedding using only facts observed in the KG are first introduced. We describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. After that, we discuss techniques that further incorporate additional information besides facts. We focus specifically on the use of entity types, relation paths,;['143906199', '1855978', '37722675', '48358041'];['Quan Wang', 'Zhendong Mao', 'Bin Wang', 'Li Guo'];;;;;;;rjiclzwe;IEEE Transactions on Knowledge and Data Engineering;2017.0;29;['Computer Science', 'Graph']
de02ec03f6a71246e505862a7195894601fbab99;KGAT: Knowledge Graph Attention Network for Recommendation;To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method;['98285513', '7792071', '2112867078', '2152972434', '144078686'];['Xiang Wang', 'Xiangnan He', 'Yixin Cao', 'Meng Liu', 'Tat-Seng Chua'];a0edb93b-1e95-4128-a295-6b1659149cef;Knowledge Discovery and Data Mining;conference;16;2019.0;Sydney;;;;;['Computer Science', 'Graph', 'Mathematics']
492f57ee9ceb61fb5a47ad7aebfec1121887a175;Gated Graph Sequence Neural Networks;Abstract: Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures.;['47002813', '1725299', '2107692', '1804104'];['Yujia Li', 'Daniel Tarlow', 'Marc Brockschmidt', 'R. Zemel'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;10;2015.0;Chicago;;;;;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
789a7069d1a2d02d784e4821685b216cc63e6ec8;Strategies for Pre-training Graph Neural Networks;Many applications of machine learning require a model to make accurate pre-dictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that naive strategies, which;['48594758', '2156641189', '145986494', '2095762', '145419642', '1806271', '1702139'];['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'M. Zitnik', 'Percy Liang', 'V. Pande', 'J. Leskovec'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;11;2019.0;Abuja;;;;;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
8ea9cb53779a8c1bb0e53764f88669bd7edf38f0;E(n) Equivariant Graph Neural Networks;This paper introduces a new model to learn graph neural networks equivariant to rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. In addition, whereas existing methods are limited to equivariance on 3 dimensional spaces, our model is easily scaled to higher-dimensional spaces. We demonstrate the effectiveness of our method on dynamical systems modelling, representation learning in graph autoencoders and predicting molecular properties.;['73240341', '65928943', '1678311'];['Victor Garcia Satorras', 'Emiel Hoogeboom', 'M. Welling'];fc0a208c-acb7-47dc-a0d4-af8190e21d29;International Conference on Machine Learning;conference;2;2021.0;Chicago;;;;;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
38efda194ce8ca7166119ae403e43aef57f62f7c;Graph-based Algorithm for Boolean Function Manipulation;;['34673652'];['R. Bryant'];;;;;;;y2pl6xqk;IEEE Transactions on Computers;1989.0;;['Computer Science', 'Graph']
ab30672c8c5e4787f6a5985f26a8f281f0db2fb8;How Attentive are Graph Attention Networks?;Graph Attention Networks (GATs) are one of the most popular GNN architectures and are considered as the state-of-the-art architecture for representation learning with graphs. In GAT, every node attends to its neighbors given its own representation as the query. However, in this paper we show that GAT computes a very limited kind of attention: the ranking of the attention scores is unconditioned on the query node. We formally define this restricted kind of attention as static attention and distinguish it from a strictly more expressive dynamic attention. Because GATs use a static attention mechanism, there are simple graph problems that GAT cannot express: in a controlled problem, we show that static attention hinders GAT from even fitting the training data. To remove this limitation, we introduce a simple fix by modifying the order of operations and propose GATv2: a dynamic graph attention variant that is strictly more expressive than GAT.;['1720739223', '47051926', '1743232'];['Shaked Brody', 'Uri Alon', 'Eran Yahav'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;17;2021.0;Paris;;;;;['Computer Science', 'Graph']
30c15f9be29524e72b9744f8dc14faf2a122d65f;What energy functions can be minimized via graph cuts?;;['144653004', '2984143'];['V. Kolmogorov', 'R. Zabih'];;;;;;;otcbl0af;IEEE Transactions on Pattern Analysis and Machine Intelligence;2002.0;26;['Computer Science', 'Graph', 'Medicine']
b161c4aaddd2983a9d4d5a240bd5ffa84b36c4e7;GraphMAE: Self-Supervised Masked Graph Autoencoders;Self-supervised learning (SSL) has been extensively explored in recent years. Particularly, generative SSL has seen emerging success in natural language processing and other fields, such as the wide adoption of BERT and GPT. Despite this, contrastive learning---which heavily relies on structural data augmentation and complicated training strategies---has been the dominant approach in graph SSL, while the progress of generative SSL on graphs, especially graph autoencoders (GAEs), has thus far not reached the potential as promised in other fields. In this paper, we identify and examine the issues that negatively impact the development of GAEs, including their reconstruction objective, training robustness, and error metric. We present a masked graph autoencoder GraphMAE (code is publicly available at https://github.com/THUDM/GraphMAE) that mitigates these issues for generative self-supervised graph learning. Instead of reconstructing structures, we propose to focus on feature reconstruction with both a masking strategy and scaled cosine error that benefit the robust training;['2068251467', '2111312892', '83546711', '2047998', '38385080', '47074042', '2148911956'];['Zhenyu Hou', 'Xiao Liu', 'Yukuo Cen', 'Yuxiao Dong', 'Hongxia Yang', 'C. Wang', 'Jie Tang'];a0edb93b-1e95-4128-a295-6b1659149cef;Knowledge Discovery and Data Mining;conference;20;2022.0;Berlin;;;;;['Computer Science', 'Graph']
75d82765de0900fed1a7a073415d8f7c625f79e8;Spectral Graph Theory;Eigenvalues and the Laplacian of a graph Isoperimetric problems Diameters and eigenvalues Paths, flows, and routing Eigenvalues and quasi-randomness Expanders and explicit constructions Eigenvalues of symmetrical graphs Eigenvalues of subgraphs with boundary conditions Harnack inequalities Heat kernels Sobolev inequalities Advanced techniques for random walks on graphs Bibliography Index.;['4231116'];['F. Chung'];;;;;;;yjfcdjgf;Computer Science Review (1996.0);1996.0;;['Computer Science', 'Graph']
6017e81c5ede6c38b306a3df9738aeb04baa7619;Graph Convolutional Networks for Text Classification;Text classification is an important and classical problem in natural language processing. There have been a number of studies that applied convolutional neural networks (convolution on regular grid, e.g., sequence) to classification. However, only a limited number of studies have explored the more flexible graph convolutional neural networks (convolution on non-grid, e.g., arbitrary graph) for the task. In this work, we propose to use graph convolutional networks for text classification. We build a single text graph for a corpus based on word co-occurrence and document word relations, then learn a Text Graph Convolutional Network (Text GCN) for the corpus. Our Text GCN is initialized with one-hot representation for word and document, it then jointly learns the embeddings for both words and documents, as supervised by the known class labels for documents. Our experimental results on multiple benchmark datasets demonstrate that a vanilla Text GCN without any external word embeddings or;['100680875', '145449667', '1683396'];['Liang Yao', 'Chengsheng Mao', 'Yuan Luo'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;12;2018.0;London;;;;;['Computer Science', 'Graph']
6ea57a2aea08ce0628c93f77bdc24c2f3e9cc6da;Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks;In recent years, graph neural networks (GNNs) have emerged as a powerful neural architecture to learn vector representations of nodes and graphs in a supervised, end-to-end fashion. Up to now, GNNs have only been evaluated empirically—showing promising results. The following work investigates GNNs from a theoretical point of view and relates them to the 1-dimensional Weisfeiler-Leman graph isomorphism heuristic (1-WL). We show that GNNs have the same expressiveness as the 1-WL in terms of distinguishing non-isomorphic (sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on this, we propose a generalization of GNNs, so-called k-dimensional GNNs (k-GNNs), which can take higher-order graph structures at multiple scales into account. These higher-order structures play an essential role in the characterization of social networks and molecule graphs. Our experimental evaluation confirms our theoretical findings as well as confirms that higher-order information is useful in the task of graph classification and regression.;['143622465', '8787552', '3410500', '49437682', '9572099', '3329062', '1744396'];['Christopher Morris', 'Martin Ritzert', 'Matthias Fey', 'William L. Hamilton', 'J. E. Lenssen', 'Gaurav Rattan', 'Martin Grohe'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;20;2018.0;London;;;;;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
75e924bd79d27a23f3f93d9b1ab62a779505c8d2;Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks;Modeling multivariate time series has long been a subject that has attracted researchers from a diverse range of fields including economics, finance, and traffic. A basic assumption behind multivariate time series forecasting is that its variables depend on one another but, upon looking closely, it is fair to say that existing methods fail to fully exploit latent spatial dependencies between pairs of variables. In recent years, meanwhile, graph neural networks (GNNs) have shown high capability in handling relational dependencies. GNNs require well-defined graph structures for information propagation which means they cannot be applied directly for multivariate time series where the dependencies are not known in advance. In this paper, we propose a general graph neural network framework designed specifically for multivariate time series data. Our approach automatically extracts the uni-directed relations among variables through a graph learning module, into which external knowledge like variable attributes can be easily integrated. A;['2109557884', '2585415', '2062835', '1746594', '144950946', '48934799'];['Zonghan Wu', 'Shirui Pan', 'Guodong Long', 'Jing Jiang', 'Xiaojun Chang', 'Chengqi Zhang'];a0edb93b-1e95-4128-a295-6b1659149cef;Knowledge Discovery and Data Mining;conference;18;2020.0;Los Angeles;;;;;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
d81fc968196e06ccafd7ea4c008b13e1cad1be64;An End-to-End Deep Learning Architecture for Graph Classification;Neural networks are typically designed to deal with data in tensor forms. In this paper, we propose a novel neural network architecture accepting graphs of arbitrary structure. Given a dataset containing graphs in the form of (G,y) where G is a graph and y is its class, we aim to develop neural networks that read the graphs directly and learn a classification function. There are two main challenges: 1) how to extract useful features characterizing the rich information encoded in a graph for classification purpose, and 2) how to sequentially read a graph in a meaningful and consistent order. To address the first challenge, we design a localized graph convolution model and show its connection with two graph kernels. To address the second challenge, we design a novel SortPooling layer which sorts graph vertices in a consistent order so that traditional neural networks can be trained on the graphs. Experiments;['3098251', '7217944', '40059761', '9527255'];['Muhan Zhang', 'Zhicheng Cui', 'Marion Neumann', 'Yixin Chen'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;5;2018.0;Paris;;;;;['Computer Science', 'Graph', 'Deep Learning']
5c27487c3e0894b65e976a287e6f8c9aa40f089c;Face recognition by elastic bunch graph matching;We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transform. Image graphs of new faces are extracted by an elastic graph matching process and can be compared by a simple similarity function. The system differs from Lades et al. (1993) in three respects. Phase information is used for accurate node positioning. Object-adapted graphs are used to handle large rotations in depth. Image graph extraction is based on a novel data structure, the bunch graph, which is constructed from a small set of sample image graphs.;['1736245', '145893752', '1721722', '1704573'];['Laurenz Wiskott', 'J. Fellous', 'N. Krüger', 'C. Malsburg'];;;;;;;7gyxp0ni;Proceedings of International Conference on Image Processing;1997.0;1;['Computer Science', 'Graph', 'Mathematics']
eea094ba215c5a6b1b178fd3190f4e10b5d5ca98;Graph drawing by force‐directed placement;We present a modification of the spring‐embedder model of Eades [Congressus Numerantium, 42, 149–160, (1984)] for drawing undirected graphs with straight edges. Our heuristic strives for uniform edge lengths, and we develop it in analogy to forces in natural systems, for a simple, elegant, conceptually‐intuitive, and efficient algorithm.;['38255588', '1743464'];['Thomas M. J. Fruchterman', 'E. Reingold'];;;;;;;3fr2bs2p;Software: Practice and Experience;1991.0;21;['Computer Science', 'Graph']
3d846cb01f6a975554035d2210b578ca61344b22;Revisiting Semi-Supervised Learning with Graph Embeddings;We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.;['2109512754', '50056360', '145124475'];['Zhilin Yang', 'William W. Cohen', 'R. Salakhutdinov'];fc0a208c-acb7-47dc-a0d4-af8190e21d29;International Conference on Machine Learning;conference;7;2016.0;Tokyo;;;;;['Computer Science', 'Graph', 'Mathematics']
e48f36aacb72adb74cef077c87d2351121124137;Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition;In skeleton-based action recognition, graph convolutional networks (GCNs), which model the human body skeletons as spatiotemporal graphs, have achieved remarkable performance. However, in existing GCN-based methods, the topology of the graph is set manually, and it is fixed over all layers and input samples. This may not be optimal for the hierarchical GCN and diverse samples in action recognition tasks. In addition, the second-order information (the lengths and directions of bones) of the skeleton data, which is naturally more informative and discriminative for action recognition, is rarely investigated in existing methods. In this work, we propose a novel two-stream adaptive graph convolutional network (2s-AGCN) for skeleton-based action recognition. The topology of the graph in our model can be either uniformly or individually learned by the BP algorithm in an end-to-end manner. This data-driven method increases the flexibility of the model for graph construction and brings more generality to adapt to;['19284184', '40382978', '143949499', '1694235'];['Lei Shi', 'Yifan Zhang', 'Jian Cheng', 'Hanqing Lu'];768b87bb-8a18-4d9c-a161-4d483c776bcf;Computer Vision and Pattern Recognition;conference;18;2018.0;Houston;;;;;['Computer Science', 'Graph']
3aca80d2a6ec2014342c4abe6611d498c789f7fa;Graph Theory;Abstract;['2271959477'];['José M. Rodríguez'];;;;;;;84i0yyx9;Symmetry;2018.0;10;['Computer Science', 'Graph']
bea139a35ffe458d7aec576b5e651cd8ac80e4d2;Introduction to Graph Theory;1. Fundamental Concepts. What Is a Graph? Paths, Cycles, and Trails. Vertex Degrees and Counting. Directed Graphs. 2. Trees and Distance. Basic Properties. Spanning Trees and Enumeration. Optimization and Trees. 3. Matchings and Factors. Matchings and Covers. Algorithms and Applications. Matchings in General Graphs. 4. Connectivity and Paths. Cuts and Connectivity. k-connected Graphs. Network Flow Problems. 5. Coloring of Graphs. Vertex Colorings and Upper Bounds. Structure of k-chromatic Graphs. Enumerative Aspects. 6. Planar Graphs. Embeddings and Euler's Formula. Characterization of Planar Graphs. Parameters of Planarity. 7. Edges and Cycles. Line Graphs and Edge-Coloring. Hamiltonian Cycles. Planarity, Coloring, and Cycles. 8. Additional Topics (Optional). Perfect Graphs. Matroids. Ramsey Theory. More Extremal Problems. Random Graphs. Eigenvalues of Graphs. Appendix A: Mathematical Background. Appendix B: Optimization and Complexity. Appendix C: Hints for Selected Exercises. Appendix D: Glossary of Terms. Appendix E: Supplemental Reading. Appendix F: References. Indices.;['1709358'];['D. West'];;;;;;;ip659svm;Mathematics Review (1995.0);1995.0;;['Graph', 'Mathematics']
00358a3f17821476d93461192b9229fe7d92bb3f;GNNExplainer: Generating Explanations for Graph Neural Networks;Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models and explaining predictions made by GNNs remains unsolved. Here we propose GnnExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GnnExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GnnExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GnnExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify;['83539859', '40974349', '145829303', '2095762', '1702139'];['Rex Ying', 'Dylan Bourgeois', 'Jiaxuan You', 'M. Zitnik', 'J. Leskovec'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;10;2019.0;Barcelona;;;;;['Computer Science', 'Medicine', 'Mathematics', 'Neural Networks', 'Graph']
0ca7d8c3250d43d14fdde46bf6fc299654d861ef;Heterogeneous Graph Transformer;Recent years have witnessed the emerging success of graph neural networks (GNNs) for modeling structured data. However, most GNNs are designed for homogeneous graphs, in which all nodes and edges belong to the same types, making it infeasible to represent heterogeneous structures. In this paper, we present the Heterogeneous Graph Transformer (HGT) architecture for modeling Web-scale heterogeneous graphs. To model heterogeneity, we design node- and edge-type dependent parameters to characterize the heterogeneous attention over each edge, empowering HGT to maintain dedicated representations for different types of nodes and edges. To handle Web-scale graph data, we design the heterogeneous mini-batch graph sampling algorithm—HGSampling—for efficient and scalable training. Extensive experiments on the Open Academic Graph of 179 million nodes and 2 billion edges show that the proposed HGT model consistently outperforms all the state-of-the-art GNN baselines by 9–21 on various downstream tasks. The dataset and source code of HGT are publicly available;['3407296', '2047998', '1748169', '2109461904'];['Ziniu Hu', 'Yuxiao Dong', 'Kuansan Wang', 'Yizhou Sun'];e07422f9-c065-40c3-a37b-75e98dce79fe;The Web Conference;conference;16;2020.0;Tokyo;;;;;['Computer Science', 'Graph', 'Mathematics']
acf87283fa8ae426f1a4987b345b401bf2913f61;Do Transformers Really Perform Badly for Graph Representation?;The Transformer architecture has become a dominant choice in many domains, such as natural language processing and computer vision. Yet, it has not achieved competitive performance on popular leaderboards of graph-level prediction compared to mainstream GNN variants. Therefore, it remains a mystery how Transformers could perform well for graph representation learning. In this paper, we solve this mystery by presenting Graphormer, which is built upon the standard Transformer architecture, and could attain excellent results on a broad range of graph representation learning tasks, especially on the recent OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the graph is the necessity of effectively encoding the structural information of a graph into the model. To this end, we propose several simple yet effective structural encoding methods to help Graphormer better model graph-structured data. Besides, we mathematically characterize the expressive power of Graphormer and exhibit that with our ways of encoding;['2051552141', '123970124', '2108801920', '150311931', '35286545', '2266036459', '2266126249', '2266182896'];['Chengxuan Ying', 'Tianle Cai', 'Shengjie Luo', 'Shuxin Zheng', 'Guolin Ke', 'Di He', 'Yanming Shen', 'Tie-Yan Liu'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;20;2021.0;Sydney;;;;;['Computer Science', 'Graph']
05c4eb154ad9512a69569c18d68bc4428ee8bb83;Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks;"Graph convolutional network (GCN) has been successfully applied to many graph-based applications; however, training a large-scale GCN remains challenging. Current SGD-based algorithms suffer from either a high computational cost that exponentially grows with number of GCN layers, or a large space requirement for keeping the entire graph and the embedding of each node in memory. In this paper, we propose Cluster-GCN, a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure. Cluster-GCN works as the following: at each step, it samples a block of nodes that associate with a dense subgraph identified by a graph clustering algorithm, and restricts the neighborhood search within this subgraph. This simple but effective strategy leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with previous algorithms. To test the scalability of our algorithm, we create a new Amazon2M data with 2";['2537924', '23979212', '3422911', '1678662', '1751569', '1793529'];['Wei-Lin Chiang', 'Xuanqing Liu', 'Si Si', 'Yang Li', 'Samy Bengio', 'Cho-Jui Hsieh'];a0edb93b-1e95-4128-a295-6b1659149cef;Knowledge Discovery and Data Mining;conference;8;2019.0;Beijing;;;;;['Computer Science', 'Graph', 'Mathematics']
b5b717bd65678b9b980ae3f2aaea0396e87ab0e2;Channel-wise Topology Refinement Graph Convolution for Skeleton-Based Action Recognition;Graph convolutional networks (GCNs) have been widely used and achieved remarkable results in skeleton-based action recognition. In GCNs, graph topology dominates feature aggregation and therefore is the key to extracting representative features. In this work, we propose a novel Channel-wise Topology Refinement Graph Convolution (CTR-GC) to dynamically learn different topologies and effectively aggregate joint features in different channels for skeleton-based action recognition. The proposed CTR-GC models channel-wise topologies through learning a shared topology as a generic prior for all channels and refining it with channel-specific correlations for each channel. Our refinement method introduces few extra parameters and significantly reduces the difficulty of modeling channel-wise topologies. Furthermore, via reformulating graph convolutions into a unified form, we find that CTR-GC relaxes strict constraints of graph convolutions, leading to stronger representation capability. Combining CTR-GC with temporal modeling modules, we develop a powerful graph convolutional network named CTR-GCN which notably outperforms state-of-the-art methods on;['2137389378', '2144370824', '50199457', '2152691925', '2115656688', '40506509'];['Yuxin Chen', 'Ziqi Zhang', 'Chunfen Yuan', 'Bing Li', 'Ying Deng', 'Weiming Hu'];7654260e-79f9-45c5-9663-d72027cf88f3;IEEE International Conference on Computer Vision;conference;7;2021.0;Los Angeles;;;;;['Computer Science', 'Graph']
398d6f4432e6aa7acf21c0bbaaebac48998faad3;Graph Neural Networks for Social Recommendation;"In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key. However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the user-user social graph and the user-item graph). To address the three aforementioned challenges simultaneously, in this paper, we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec,";['41031455', '47009435', '1930238', '2145051005', '2109917536', '1736632', '50559722'];['Wenqi Fan', 'Yao Ma', 'Qing Li', 'Yuan He', 'Y. Zhao', 'Jiliang Tang', 'Dawei Yin'];e07422f9-c065-40c3-a37b-75e98dce79fe;The Web Conference;conference;8;2019.0;Abuja;;;;;['Neural Networks', 'Computer Science', 'Graph']
fd17bd9a5dc24a081ad9743570f50dd6750f54b2;Junction Tree Variational Autoencoder for Molecular Graph Generation;We seek to automate the design of molecules based on specific chemical properties. In computational terms, this task involves continuous embedding and generation of molecular graphs. Our primary contribution is the direct realization of molecular graphs, a task previously approached by generating linear SMILES strings instead of graphs. Our junction tree variational autoencoder generates molecular graphs in two phases, by first generating a tree-structured scaffold over chemical substructures, and then combining them into a molecule with a graph message passing network. This approach allows us to incrementally expand molecules while maintaining chemical validity at every step. We evaluate our model on multiple tasks ranging from molecular generation to optimization. Across these tasks, our model outperforms previous state-of-the-art baselines by a significant margin.;['2400119', '1741283', '35132120'];['Wengong Jin', 'R. Barzilay', 'T. Jaakkola'];fc0a208c-acb7-47dc-a0d4-af8190e21d29;International Conference on Machine Learning;conference;7;2018.0;Sydney;;;;;['Computer Science', 'Graph', 'Mathematics']
2503dff90685857ce7295e37d0045e2eef41c8b8;FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling;The graph convolutional networks (GCN) recently proposed by Kipf and Welling are an effective graph model for semi-supervised learning. This model, however, was originally designed to be learned with the presence of both training and test data. Moreover, the recursive neighborhood expansion across layers poses time and memory challenges for training with large, dense graphs. To relax the requirement of simultaneous availability of test data, we interpret graph convolutions as integral transforms of embedding functions under probability measures. Such an interpretation allows for the use of Monte Carlo approaches to consistently estimate the integrals, which in turn leads to a batched training scheme as we propose in this work---FastGCN. Enhanced with importance sampling, FastGCN not only is efficient for training but also generalizes well for inference. We show a comprehensive set of experiments to demonstrate its effectiveness compared with GCN and related models. In particular, training is orders of magnitude;[None, '40411766', '145781464'];['Jie Chen', 'Tengfei Ma', 'Cao Xiao'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;8;2018.0;Beijing;;;;;['Computer Science', 'Graph', 'Mathematics']
e4715a13f6364b1c81e64f247651c3d9e80b6808;Link Prediction Based on Graph Neural Networks;Link prediction is a key problem for network-structured data. Link prediction heuristics use some score functions, such as common neighbors and Katz index, to measure the likelihood of links. They have obtained wide practical uses due to their simplicity, interpretability, and for some of them, scalability. However, every heuristic has a strong assumption on when two nodes are likely to link, which limits their effectiveness on networks where these assumptions fail. In this regard, a more reasonable way should be learning a suitable heuristic from a given network instead of using predefined ones. By extracting a local subgraph around each target link, we aim to learn a function mapping the subgraph patterns to link existence, thus automatically learning a `heuristic' that suits the current network. In this paper, we study this heuristic learning paradigm for link prediction. First, we develop a novel $\gamma$-decaying heuristic theory. The theory unifies a wide;['3098251', '9527255'];['Muhan Zhang', 'Yixin Chen'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;20;2018.0;New York;;;;;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
348cd9726be5e5740ab751c15fbad4b60d98246d;Patterns in Hydrogen Bonding: Functionality and Graph Set Analysis in Crystals;Whereas much of organic chemistry has classically dealt with the preparation and study of the properties of individual molecules, an increasingly significant portion of the activity in chemical research involves understanding and utilizing the nature of the interactions between molecules. Two representative areas of this evolution are supramolecular chemistry and molecular recognition. The interactions between molecules are governed by intermolecular forces whose energetic and geometric properties are much less well understood than those of classical chemical bonds between atoms. Among the strongest of these interactions, however, are hydrogen bonds, whose directional properties are better understood on the local level (that is, for a single hydrogen bond) than many other types of non-bonded interactions. Nevertheless, the means by which to characterize, understand, and predict the consequences of many hydrogen bonds among molecules, and the resulting formation of molecular aggregates (on the microscopic scale) or crystals (on the macroscopic scale) has remained;['144302936', '48778365', '2308579', '143976370'];['J. Bernstein', 'Raymond E. Davis', 'L. Shimoni', 'N. Chang'];;;;;;;8tq3bg3t;Angewandte Chemie;1995.0;34;['Graph', 'Chemistry']
04f3203f1214063436d81ce0c2ad7623204da488;Geom-GCN: Geometric Graph Convolutional Networks;Message-passing neural networks (MPNNs) have been successfully applied in a wide variety of applications in the real world. However, two fundamental weaknesses of MPNNs' aggregators limit their ability to represent graph-structured data: losing the structural information of nodes in neighborhoods and lacking the ability to capture long-range dependencies in disassortative graphs. Few studies have noticed the weaknesses from different perspectives. From the observations on classical neural network and network geometry, we propose a novel geometric aggregation scheme for graph neural networks to overcome the two weaknesses. The behind basic idea is the aggregation on a graph can benefit from a continuous space underlying the graph. The proposed aggregation scheme is permutation-invariant and consists of three modules, node embedding, structural neighborhood, and bi-level aggregation. We also present an implementation of the scheme in graph convolutional networks, termed Geom-GCN, to perform transductive learning on graphs. Experimental results show the proposed Geom-GCN achieved;['1866075', '15763974', '143922493', '2113651237', '2119658599'];['Hongbin Pei', 'Bingzhen Wei', 'K. Chang', 'Yu Lei', 'Bo Yang'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;8;2020.0;Sydney;;;;;['Computer Science', 'Graph', 'Mathematics']
21e33bd0ad95ee1f79d8b778e693fd316cbb72d4;Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs;We investigate the representation power of graph neural networks in the semi-supervised node classification task under heterophily or low homophily, i.e., in networks where connected nodes may have different class labels and dissimilar features. Many popular GNNs fail to generalize to this setting, and are even outperformed by models that ignore the graph structure (e.g., multilayer perceptrons). Motivated by this limitation, we identify a set of key designs -- ego- and neighbor-embedding separation, higher-order neighborhoods, and combination of intermediate representations -- that boost learning from the graph structure under heterophily. We combine them into a graph neural network, H2GCN, which we use as the base method to empirically evaluate the effectiveness of the identified designs. Going beyond the traditional benchmarks with strong homophily, our empirical analysis shows that the identified designs increase the accuracy of GNNs by up to 40% and 27% over models without them on synthetic and real;['50077183', '7957569', '21613538', '35505461', '3255268', '2479152'];['Jiong Zhu', 'Yujun Yan', 'Lingxiao Zhao', 'Mark Heimann', 'L. Akoglu', 'Danai Koutra'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;6;2020.0;New York;;;;;['Neural Networks', 'Computer Science', 'Graph']
699d4d8c8b91b1a34dd6f47d28e3fe1236f25944;Saliency Detection via Graph-Based Manifold Ranking;Most existing bottom-up methods measure the foreground saliency of a pixel or region based on its contrast within a local context or the entire image, whereas a few methods focus on segmenting out background regions and thereby salient objects. Instead of considering the contrast between the salient objects and their surrounding regions, we consider both foreground and background cues in a different way. We rank the similarity of the image elements (pixels or regions) with foreground cues or background cues via graph-based manifold ranking. The saliency of the image elements is defined based on their relevances to the given seeds or queries. We represent the image as a close-loop graph with super pixels as nodes. These nodes are ranked based on the similarity to background and foreground queries, based on affinity matrices. Saliency detection is carried out in a two-stage scheme to extract background regions and foreground salient objects efficiently.;['2154926843', '50081215', '153176123', '144526777', '1715634'];['Chuan Yang', 'L. Zhang', 'Huchuan Lu', 'Xiang Ruan', 'Ming-Hsuan Yang'];;;;;;;rv4ua6oq;2013 IEEE Conference on Computer Vision and Pattern Recognition;2013.0;24;['Computer Science', 'Graph']
c2d40522eaa5523d67a0de5e4098e7031fdccb3d;Pitfalls of Graph Neural Network Evaluation;Semi-supervised node classification in graphs is a fundamental problem in graph mining, and the recently proposed graph neural networks (GNNs) have achieved unparalleled results on this task. Due to their massive success, GNNs have attracted a lot of attention, and many novel architectures have been put forward. In this paper we show that existing evaluation strategies for GNN models have serious shortcomings. We show that using the same train/validation/test splits of the same datasets, as well as making significant changes to the training procedure (e.g. early stopping criteria) precludes a fair comparison of different architectures. We perform a thorough empirical evaluation of four prominent GNN models and show that considering different splits of the data leads to dramatically different rankings of models. Even more importantly, our findings suggest that simpler GNN architectures are able to outperform the more sophisticated ones if the hyperparameters and the training procedure are tuned fairly;['32724677', '51896688', '11754930', '3075189'];['Oleksandr Shchur', 'Maximilian Mumme', 'Aleksandar Bojchevski', 'Stephan Günnemann'];;;;;;;fupmn9ww;ArXiv;2018.0;abs/1811.05868;['Computer Science', 'Graph', 'Mathematics']
75739ed2ddebd7982042f516f407553f8d3110f8;Self-supervised Graph Learning for Recommendation;"Representation learning on user-item graph for recommendation has evolved from using single ID or interaction history to exploiting higher-order neighbors. This leads to the success of graph convolution networks (GCNs) for recommendation such as PinSage and LightGCN. Despite effectiveness, we argue that they suffer from two limitations: (1) high-degree nodes exert larger impact on the representation learning, deteriorating the recommendations of low-degree (long-tail) items; and (2) representations are vulnerable to noisy interactions, as the neighborhood aggregation scheme further enlarges the impact of observed edges. In this work, we explore self-supervised learning on user-item graph, so as to improve the accuracy and robustness of GCNs for recommendation. The idea is to supplement the classical supervised task of recommendation with an auxiliary self-supervised task, which reinforces node representation learning via self-discrimination. Specifically, we generate multiple views of a node, maximizing the agreement between different views of the same node compared to that";['1491035012', '2144796537', '2163400298', '7792071', '1853048147', '2813328', '2110972323'];['Jiancan Wu', 'Xiang Wang', 'Fuli Feng', 'Xiangnan He', 'Liang Chen', 'Jianxun Lian', 'Xing Xie'];8dce23a9-44e0-4381-a39e-2acc1edff700;Annual International ACM SIGIR Conference on Research and Development in Information Retrieval;conference;7;2020.0;Abuja;;;;;['Computer Science', 'Graph']
e3d662bbd0e5539fe22a85f3518f960595b9914e;Heterogeneous Graph Neural Network;Representation learning in heterogeneous graphs aims to pursue a meaningful vector representation for each node so as to facilitate downstream applications such as link prediction, personalized recommendation, node classification, etc. This task, however, is challenging not only because of the demand to incorporate heterogeneous structural (graph) information consisting of multiple types of nodes and edges, but also due to the need for considering heterogeneous attributes or contents (e.g., text or image) associated with each node. Despite a substantial amount of effort has been made to homogeneous (or heterogeneous) graph embedding, attributed graph embedding as well as graph neural networks, few of them can jointly consider heterogeneous structural (graph) information as well as heterogeneous contents information of each node effectively. In this paper, we propose HetGNN, a heterogeneous graph neural network model, to resolve this issue. Specifically, we first introduce a random walk with restart strategy to sample a fixed size;['3407809', '2451800', '144277661', '144231976', '144539424'];['Chuxu Zhang', 'Dongjin Song', 'Chao Huang', 'A. Swami', 'N. Chawla'];a0edb93b-1e95-4128-a295-6b1659149cef;Knowledge Discovery and Data Mining;conference;17;2019.0;New York;;;;;['Computer Science', 'Graph']
44fca068eecce2203d111213e3691647914a3945;LexRank: Graph-based Lexical Centrality as Salience in Text Summarization;We introduce a stochastic graph-based method for computing relative importance of textual units for Natural Language Processing. We test the technique on the problem of Text Summarization (TS). Extractive TS relies on the concept of sentence salience to identify the most important sentences in a document or set of documents. Salience is typically defined in terms of the presence of particular important words or in terms of similarity to a centroid pseudo-sentence. We consider a new approach, LexRank, for computing sentence importance based on the concept of eigenvector centrality in a graph representation of sentences. In this model, a connectivity matrix based on intra-sentence cosine similarity is used as the adjacency matrix of the graph representation of sentences. Our system, based on LexRank ranked in first place in more than one task in the recent DUC 2004 evaluation. In this paper we present a detailed analysis of our approach and;['2158159', '9215251'];['Günes Erkan', 'Dragomir R. Radev'];;;;;;;1cbqjled;ArXiv;2004.0;abs/1109.2128;['Computer Science', 'Graph', 'Mathematics', 'Centrality']
5863d7b35ea317c19f707376978ef1cc53e3534c;Rethinking Graph Transformers with Spectral Attention;In recent years, the Transformer architecture has proven to be very successful in sequence processing, but its application to other data structures, such as graphs, has remained limited due to the difficulty of properly defining positions. Here, we present the $\textit{Spectral Attention Network}$ (SAN), which uses a learned positional encoding (LPE) that can take advantage of the full Laplacian spectrum to learn the position of each node in a given graph. This LPE is then added to the node features of the graph and passed to a fully-connected Transformer. By leveraging the full spectrum of the Laplacian, our model is theoretically powerful in distinguishing graphs, and can better detect similar sub-structures from their resonance. Further, by fully connecting the graph, the Transformer does not suffer from over-squashing, an information bottleneck of most GNNs, and enables better modeling of physical phenomenons such as heat transfer and electric interaction. When tested empirically;['2107709516', '51034451', '2057555930', '2067158294', '12611623'];"['Devin Kreuzer', 'D. Beaini', 'William L. Hamilton', ""Vincent L'etourneau"", 'Prudencio Tossou']";d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;3;2021.0;Paris;;;;;['Computer Science', 'Graph']
47ae807cd511b35e78a2cd4e198283dea6dafd41;Do Transformers Really Perform Bad for Graph Representation?;The Transformer architecture has become a dominant choice in many domains, such as natural language processing and computer vision. Yet, it has not achieved competitive performance on popular leaderboards of graph-level prediction compared to mainstream GNN variants. Therefore, it remains a mystery how Transformers could perform well for graph representation learning. In this paper, we solve this mystery by presenting Graphormer, which is built upon the standard Transformer architecture, and could attain excellent results on a broad range of graph representation learning tasks, especially on the recent OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the graph is the necessity of effectively encoding the structural information of a graph into the model. To this end, we propose several simple yet effective structural encoding methods to help Graphormer better model graph-structured data. Besides, we mathematically characterize the expressive power of Graphormer and exhibit that with our ways of encoding;['2051552141', '123970124', '2108801920', '150311931', '35286545', '1391126980', '2115437382', '2110264337'];['Chengxuan Ying', 'Tianle Cai', 'Shengjie Luo', 'Shuxin Zheng', 'Guolin Ke', 'Di He', 'Yanming Shen', 'Tie-Yan Liu'];;;;;;;nkepe5ms;ArXiv;2021.0;abs/2106.05234;['Computer Science', 'Graph']
06c9cbf943185d1d1554e760279412598c6d81a6;Are Graph Augmentations Necessary?: Simple Graph Contrastive Learning for Recommendation;Contrastive learning (CL) recently has spurred a fruitful line of research in the field of recommendation, since its ability to extract self-supervised signals from the raw data is well-aligned with recommender systems' needs for tackling the data sparsity issue. A typical pipeline of CL-based recommendation models is first augmenting the user-item bipartite graph with structure perturbations, and then maximizing the node representation consistency between different graph augmentations. Although this paradigm turns out to be effective, what underlies the performance gains is still a mystery. In this paper, we first experimentally disclose that, in CL-based recommendation models, CL operates by learning more uniform user/item representations that can implicitly mitigate the popularity bias. Meanwhile, we reveal that the graph augmentations, which used to be considered necessary, just play a trivial role. Based on this finding, we propose a simple CL method which discards the graph augmentations and instead adds uniform noises to;['28584977', '2416851', '2077454936', '1490931831', '101457473', '144133815'];['Junliang Yu', 'Hongzhi Yin', 'Xin Xia', 'Tong Chen', 'Li-zhen Cui', 'Q. Nguyen'];8dce23a9-44e0-4381-a39e-2acc1edff700;Annual International ACM SIGIR Conference on Research and Development in Information Retrieval;conference;13;2021.0;Paris;;;;;['Computer Science', 'Graph']
4bf76588122827157c43a59e656dccc6b6a22e90;Deep Graph Contrastive Representation Learning;Graph representation learning nowadays becomes fundamental in analyzing graph-structured data. Inspired by recent success of contrastive methods, in this paper, we propose a novel framework for unsupervised graph representation learning by leveraging a contrastive objective at the node level. Specifically, we generate two graph views by corruption and learn node representations by maximizing the agreement of node representations in these two views. To provide diverse node contexts for the contrastive objective, we propose a hybrid scheme for generating graph views on both structure and attribute levels. Besides, we provide theoretical justification behind our motivation from two perspectives, mutual information and the classical triplet loss. We perform empirical experiments on both transductive and inductive learning tasks using a variety of real-world datasets. Experimental experiments demonstrate that despite its simplicity, our proposed method consistently outperforms existing state-of-the-art methods by large margins. Moreover, our unsupervised method even surpasses its supervised counterparts on transductive;['2653121', '47103911', '2155385667', '48873756', '50425438', '123865558'];['Yanqiao Zhu', 'Yichen Xu', 'Feng Yu', 'Q. Liu', 'Shu Wu', 'Liang Wang'];;;;;;;dlh688gt;ArXiv;2020.0;abs/2006.04131;['Computer Science', 'Graph', 'Mathematics']
aa9ae8096216163ed40dd787917215b5ae4d3d90;Adversarial Graph Augmentation to Improve Graph Contrastive Learning;Self-supervised learning of graph neural networks (GNN) is in great need because of the widespread label scarcity issue in real-world graph/network data. Graph contrastive learning (GCL), by training GNNs to maximize the correspondence between the representations of the same graph in its different augmented forms, may yield robust and transferable GNNs even without using labels. However, GNNs trained by traditional GCL often risk capturing redundant graph features and thus may be brittle and provide sub-par performance in downstream tasks. Here, we propose a novel principle, termed adversarial-GCL (AD-GCL), which enables GNNs to avoid capturing redundant information during the training by optimizing adversarial graph augmentation strategies used in GCL. We pair AD-GCL with theoretical explanations and design a practical instantiation based on trainable edge-dropping graph augmentation. We experimentally validate AD-GCL by comparing with the state-of-the-art GCL methods and achieve performance gains of up-to $14\%$ in unsupervised, $6\%$ in transfer, and $3\%$;['31591568', '1561672016', '145462792', '144050371'];['Susheel Suresh', 'Pan Li', 'Cong Hao', 'Jennifer Neville'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;7;2021.0;Los Angeles;;;;;['Computer Science', 'Graph']
93ee8e1c05d11d63aa3d61653b2c8bae75e0aecd;The Network Data Repository with Interactive Graph Analytics and Visualization;NetworkRepository (NR) is the first interactive data repository with a web-based platform for visual interactive analytics. Unlike other data repositories (e.g., UCI ML Data Repository, and SNAP), the network data repository (networkrepository.com) allows users to not only download, but to interactively analyze and visualize such data using our web-based interactive graph analytics platform. Users can in real-time analyze, visualize, compare, and explore data along many different dimensions. The aim of NR is to make it easy to discover key insights into the data extremely fast with little effort while also providing a medium for users to share data, visualizations, and insights. Other key factors that differentiate NR from the current data repositories is the number of graph datasets, their size, and variety. While other data repositories are static, they also lack a means for users to collaboratively discuss a particular dataset, corrections, or challenges with using the data for certain;['1862090', '47699955'];['Ryan A. Rossi', 'Nesreen Ahmed'];bdc2e585-4e48-4e36-8af1-6d859763d405;AAAI Conference on Artificial Intelligence;conference;19;2015.0;Paris;;;;;['Computer Science', 'Graph', 'Analytics']
3950b578a93674d7a8dc6829581058f76823136e;Disentangling and Unifying Graph Convolutions for Skeleton-Based Action Recognition;Spatial-temporal graphs have been widely used by skeleton-based action recognition algorithms to model human action dynamics. To capture robust movement patterns from these graphs, long-range and multi-scale context aggregation and spatial-temporal dependency modeling are critical aspects of a powerful feature extractor. However, existing methods have limitations in achieving (1) unbiased long-range joint relationship modeling under multi-scale operators and (2) unobstructed cross-spacetime information flow for capturing complex spatial-temporal dependencies. In this work, we present (1) a simple method to disentangle multi-scale graph convolutions and (2) a unified spatial-temporal graph convolutional operator named G3D. The proposed multi-scale aggregation scheme disentangles the importance of nodes in different neighborhoods for effective long-range modeling. The proposed G3D module leverages dense cross-spacetime edges as skip connections for direct information propagation across the spatial-temporal graph. By coupling these proposals, we develop a powerful feature extractor named MS-G3D based on which our model outperforms previous state-of-the-art methods on;['2117942226', '49724467', '2075098', '2108503703', '3001348'];['Ken Ziyu Liu', 'Hongwen Zhang', 'Zhenghao Chen', 'Zhiyong Wang', 'Wanli Ouyang'];768b87bb-8a18-4d9c-a161-4d483c776bcf;Computer Vision and Pattern Recognition;conference;6;2020.0;Barcelona;;;;;['Computer Science', 'Graph']
0d67d3ddca1c4e370eaf1e99ec674f612c39c66c;Graph Contrastive Learning with Adaptive Augmentation;Recently, contrastive learning (CL) has emerged as a successful method for unsupervised graph representation learning. Most graph CL methods first perform stochastic augmentation on the input graph to obtain two graph views and maximize the agreement of representations in the two views. Despite the prosperous development of graph CL methods, the design of graph augmentation schemes—a crucial component in CL—remains rarely explored. We argue that the data augmentation schemes should preserve intrinsic structures and attributes of graphs, which will force the model to learn representations that are insensitive to perturbation on unimportant nodes and edges. However, most existing methods adopt uniform data augmentation schemes, like uniformly dropping edges and uniformly shuffling features, leading to suboptimal performance. In this paper, we propose a novel graph contrastive representation learning method with adaptive augmentation that incorporates various priors for topological and semantic aspects of the graph. Specifically, on the topology level, we design;['2653121', '47103911', '2155385667', '48873756', '50425438', '123865558'];['Yanqiao Zhu', 'Yichen Xu', 'Feng Yu', 'Q. Liu', 'Shu Wu', 'Liang Wang'];e07422f9-c065-40c3-a37b-75e98dce79fe;The Web Conference;conference;13;2020.0;Abuja;;;;;['Computer Science', 'Graph']
8b163b75a6b833911c4e958f8bd52124205382ec;Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting;"Modeling complex spatial and temporal correlations in the correlated time series data is indispensable for understanding the traffic dynamics and predicting the future status of an evolving traffic system. Recent works focus on designing complicated graph neural network architectures to capture shared patterns with the help of pre-defined graphs. In this paper, we argue that learning node-specific patterns is essential for traffic forecasting while the pre-defined graph is avoidable. To this end, we propose two adaptive modules for enhancing Graph Convolutional Network (GCN) with new capabilities: 1) a Node Adaptive Parameter Learning (NAPL) module to capture node-specific patterns; 2) a Data Adaptive Graph Generation (DAGG) module to infer the inter-dependencies among different traffic series automatically. We further propose an Adaptive Graph Convolutional Recurrent Network (AGCRN) to capture fine-grained spatial and temporal correlations in traffic series automatically based on the two modules and recurrent networks. Our experiments on two real-world traffic";['50010487', '2082966', '2118036284', '2877263', '2117934428'];['Lei Bai', 'Lina Yao', 'Can Li', 'Xianzhi Wang', 'Can Wang'];d9720b90-d60b-48bc-9df8-87a30b9a60dd;Neural Information Processing Systems;conference;18;2020.0;Chicago;;;;;['Computer Science', 'Graph', 'Mathematics']
fc3e99ebc07b3014f6736a6a7b077edf2f1634c0;GraphSAINT: Graph Sampling Based Inductive Learning Method;"Graph Convolutional Networks (GCNs) are powerful models for learning representations of attributed this http URL scale GCNs to large graphs, state-of-the-art methods use various layer sampling techniques to alleviate the ""neighbor explosion"" problem during minibatch training. Here we proposeGraphSAINT, a graph sampling based inductive learning method that improves training efficiency in a fundamentally different way. By a change of perspective, GraphSAINT constructs minibatches by sampling the training graph, rather than the nodes or edges across GCN layers. Each iteration, a complete GCN is built from the properly sampled subgraph. Thus, we ensure fixed number of well-connected nodes in all layers. We further propose normalization technique to eliminate bias, and sampling algorithms for variance reduction. Importantly, we can decouple the sampling process from the forward and backward propagation of training, and extend GraphSAINT with other graph samplers and GCN variants. Comparing with strong baselines using layer sampling, GraphSAINT demonstrates superior performance";['33352252', '1443735039', '2215594', '2286832947', '1728271'];['Hanqing Zeng', 'Hongkuan Zhou', 'Ajitesh Srivastava', 'R. Kannan', 'V. Prasanna'];939c6e1d-0d17-4d6e-8a82-66d960df0e40;International Conference on Learning Representations;conference;3;2019.0;New York;;;;;['Computer Science', 'Graph', 'Mathematics']
69381b5efd97e7c55f51c2730caccab3d632d4d2;Graph Embedding and Extensions: A General Framework for Dimensionality Reduction;"A large family of algorithms - supervised or unsupervised; stemming from statistics or geometry theory - has been designed to provide different solutions to the problem of dimensionality reduction. Despite the different motivations of these algorithms, we present in this paper a general formulation known as graph embedding to unify them within a common framework. In graph embedding, each algorithm can be considered as the direct graph embedding or its linear/kernel/tensor extension of a specific intrinsic graph that describes certain desired statistical or geometric properties of a data set, with constraints from scale normalization or a penalty graph that characterizes a statistical or geometric property that should be avoided. Furthermore, the graph embedding framework can be used as a general platform for developing new dimensionality reduction algorithms. By utilizing this framework as a tool, we propose a new supervised dimensionality reduction algorithm called marginal Fisher analysis in which the intrinsic";['143653681', '38188040', '2158301', '2144973386', '152290618', '145676588'];['Shuicheng Yan', 'Dong Xu', 'Benyu Zhang', 'HongJiang Zhang', 'Qiang Yang', 'Stephen Lin'];;;;;;;o0yx5117;IEEE Transactions on Pattern Analysis and Machine Intelligence;2007.0;29;['Medicine', 'Computer Science', 'Mathematics', 'Graph']
150f95f9c73820e0a0fa1546140e9f2bdfd25954;Temporal Graph Networks for Deep Learning on Dynamic Graphs;Graph Neural Networks (GNNs) have recently become increasingly popular due to their ability to learn complex systems of relations or interactions arising in a broad spectrum of problems ranging from biology and particle physics to social networks and recommendation systems. Despite the plethora of different models for deep learning on graphs, few approaches have been proposed thus far for dealing with graphs that present some sort of dynamic nature (e.g. evolving features or connectivity over time). In this paper, we present Temporal Graph Networks (TGNs), a generic, efficient framework for deep learning on dynamic graphs represented as sequences of timed events. Thanks to a novel combination of memory modules and graph-based operators, TGNs are able to significantly outperform previous approaches being at the same time more computationally efficient. We furthermore show that several previous models for learning on dynamic graphs can be cast as specific instances of our framework. We;['2056294358', '2029302', '51484149', '1775620', '2500309', '1732570'];['Emanuele Rossi', 'B. Chamberlain', 'Fabrizio Frasca', 'D. Eynard', 'Federico Monti', 'M. Bronstein'];;;;;;;2xew3e7v;ArXiv;2020.0;abs/2006.10637;['Computer Science', 'Graph', 'Deep Learning', 'Mathematics']
fdc708aaa0d18c791f878ff2214201410fa52439;UvA-DARE ( Digital Academic Repository ) Graph Convolutional Matrix Completion;We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.;['9965217', '41016725', '1678311'];['Rianne van den Berg', 'Thomas Kipf', 'M. Welling'];;;;;;;qi3gdcnu;Science Magazine (2017.0);2017.0;67;['Graph']
c7fd29fdd2e0b50a571db4f607eab138e9ecb644;MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding;A large number of real-world graphs or networks are inherently heterogeneous, involving a diversity of node types and relation types. Heterogeneous graph embedding is to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing models usually define multiple metapaths in a heterogeneous graph to capture the composite relations and guide neighbor selection. However, these models either omit node content features, discard intermediate nodes along the metapath, or only consider one metapath. To address these three limitations, we propose a new model named Metapath Aggregated Graph Neural Network (MAGNN) to boost the final performance. Specifically, MAGNN employs three major components, i.e., the node content transformation to encapsulate input node attributes, the intra-metapath aggregation to incorporate intermediate semantic nodes, and the inter-metapath aggregation to combine messages from multiple metapaths. Extensive experiments on three real-world heterogeneous graph datasets for node classification, node clustering, and link prediction show;['15473346', '73329314', '1491449344', '145310663'];['Xinyu Fu', 'Jiani Zhang', 'Ziqiao Meng', 'Irwin King'];e07422f9-c065-40c3-a37b-75e98dce79fe;The Web Conference;conference;5;2020.0;Houston;;;;;['Computer Science', 'Graph']
4f08a18f205e41c786fc80160ce8e133d50832dc;On the shortest spanning subtree of a graph and the traveling salesman problem;7. A. Kurosh, Ringtheoretische Probleme die mit dem Burnsideschen Problem uber periodische Gruppen in Zussammenhang stehen, Bull. Acad. Sei. URSS, Ser. Math. vol. 5 (1941) pp. 233-240. 8. J. Levitzki, On the radical of a general ring, Bull. Amer. Math. Soc. vol. 49 (1943) pp. 462^66. 9. -, On three problems concerning nil rings, Bull. Amer. Math. Soc. vol. 49 (1943) pp. 913-919. 10. -, On the structure of algebraic algebras and related rings, Trans. Amer. Math. Soc. vol. 74 (1953) pp. 384-409.;['10398168'];['J. Kruskal'];;;;;;;k2gjuv6c;Mathematics Bulletin (1956.0);1956.0;7;['Graph', 'Mathematics']
006906b6bbe5c1f378cde9fd86de1ce9e6b131da;A Comprehensive Survey of Graph Embedding: Problems, Techniques, and Applications;Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximumly preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work;['143754377', '3113725', '143922493'];['Hongyun Cai', 'V. Zheng', 'K. Chang'];;;;;;;2lkth5us;IEEE Transactions on Knowledge and Data Engineering;2017.0;30;['Computer Science', 'Graph']
0da8af8d81e84381ffe656a0bbf2f3937ffac618;Neural Motifs: Scene Graph Parsing with Global Context;We investigate the problem of producing structured graph representations of visual scenes. Our work analyzes the role of motifs: regularly appearing substructures in scene graphs. We present new quantitative insights on such repeated structures in the Visual Genome dataset. Our analysis shows that object labels are highly predictive of relation labels but not vice-versa. We also find that there are recurring patterns even in larger subgraphs: more than 50% of graphs contain motifs involving at least two relations. Our analysis motivates a new baseline: given object detections, predict the most frequent relation between object pairs with the given labels, as seen in the training set. This baseline improves on the previous state-of-the-art by an average of 3.6% relative improvement across evaluation settings. We then introduce Stacked Motif Networks, a new architecture designed to capture higher order motifs in scene graphs that further improves over our strong baseline by an average;['2545335', '2064210', '38094552', '1699545'];['Rowan Zellers', 'Mark Yatskar', 'Sam Thomson', 'Yejin Choi'];;;;;;;vgw16g0z;2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition;2017.0;4;['Computer Science', 'Graph']
91fb815361fdbf80ff15ce4d783a41846bd99232;GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training;Graph representation learning has emerged as a powerful technique for addressing real-world problems. Various downstream graph learning tasks have benefited from its recent developments, such as node classification, similarity search, and graph classification. However, prior arts on graph representation learning focus on domain specific problems and train a dedicated model for each graph dataset, which is usually non-transferable to out-of-domain data. Inspired by the recent advances in pre-training from natural language processing and computer vision, we design Graph Contrastive Coding (GCC) --- a self-supervised graph neural network pre-training framework --- to capture the universal network topological properties across multiple networks. We design GCC's pre-training task as subgraph instance discrimination in and across networks and leverage contrastive learning to empower graph neural networks to learn the intrinsic and transferable structural representations. We conduct extensive experiments on three graph learning tasks and ten graph datasets. The results show that GCC pre-trained on;['40125294', '50282546', '2047998', '39772285', '38385080', '2055623340', '1748169', '46199760'];['J. Qiu', 'Qibin Chen', 'Yuxiao Dong', 'Jing Zhang', 'Hongxia Yang', 'Ming Ding', 'Kuansan Wang', 'Jie Tang'];a0edb93b-1e95-4128-a295-6b1659149cef;Knowledge Discovery and Data Mining;conference;2;2020.0;São Paulo;;;;;['Computer Science', 'Graph', 'Mathematics']
6c44f8e62d824bcda4f291c679a5518bbd4225f6;Adversarial Attacks on Neural Networks for Graph Data;Deep learning models for graphs have achieved strong performance for the task of node classification. Despite their proliferation, currently there is no study of their robustness to adversarial attacks. Yet, in domains where they are likely to be used, e.g. the web, adversaries are common. Can deep learning models for graphs be easily fooled? In this work, we introduce the first study of adversarial attacks on attributed graphs, specifically focusing on models exploiting ideas of graph convolutions. In addition to attacks at test time, we tackle the more challenging class of poisoning/causative attacks, which focus on the training phase of a machine learning model.We generate adversarial perturbations targeting the node's features and the graph structure, thus, taking the dependencies between instances in account. Moreover, we ensure that the perturbations remain unnoticeable by preserving important data characteristics. To cope with the underlying discrete domain we propose an efficient algorithm Nettack exploiting;['3156540', '46256784', '3075189'];['Daniel Zügner', 'Amir Akbarnejad', 'Stephan Günnemann'];a0edb93b-1e95-4128-a295-6b1659149cef;Knowledge Discovery and Data Mining;conference;17;2018.0;London;;;;;['Neural Networks', 'Computer Science', 'Graph', 'Mathematics']
