doi,title,abstract,citationCount
10f919b1a5161b560504c225cfb2d1b3a4768f80,"Artificial intelligence in healthcare: past, present and future","Artificial intelligence (AI) aims to mimic human cognitive functions. It is bringing a paradigm shift to healthcare, powered by increasing availability of healthcare data and rapid progress of analytics techniques. We survey the current status of AI applications in healthcare and discuss its future. AI can be applied to various types of healthcare data (structured and unstructured). Popular AI techniques include machine learning methods for structured data, such as the classical support vector machine and neural network, and the modern deep learning, as well as natural language processing for unstructured data. Major disease areas that use AI tools include cancer, neurology and cardiology. We then review in more details the AI applications in stroke, in the three major areas of early detection and diagnosis, treatment, as well as outcome prediction and prognosis evaluation. We conclude with discussion about pioneer AI systems, such as IBM Watson, and hurdles for real-life deployment",10
530a059cb48477ad1e3d4f8f4b153274c8997332,"Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",25
8ebd4ae177fb1a62298d19891fd6e45e2a5f7685,Artificial Intelligence A Modern Approach 3rd,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
21dff47a4142445f83016da0819ffe6dd2947f66,Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI),"At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the",12
378236591fc05e79204fd904e9f864efa31cdc74,An Overview of Artificial Intelligence Ethics,"Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This article will give a comprehensive overview of this field by summarizing and analyzing the",1
3ddbc58b463156b83c1a6ab792c98898e32aeb7d,Smart farming using artificial intelligence: A review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
2eeff0f534d303581bc1199671600fbd04a2d01c,Empowering Education with Generative Artificial Intelligence Tools: Approach with an Instructional Design Matrix,"This study focuses on the potential of generative artificial intelligence tools in education, particularly through the practical application of the 4PADAFE instructional design matrix. The objective was to evaluate how these tools, in combination with the matrix, can enhance education and improve the teaching–learning process. Through surveys conducted with teachers from the University of ESPE Armed Forces who participated in the MOOC course “Generative Artificial Intelligence Tools for Education: GPT Chat Techniques”, the study explores the impact of these tools on education. The findings reveal that generative artificial intelligence tools are crucial in developing massive MOOC virtual classrooms when integrated with an instructional design matrix. The results demonstrate the potential of generative artificial intelligence tools in university education. By utilizing these tools in conjunction with an instructional design matrix, educators can design and deliver personalized and enriching educational experiences. The devices offer opportunities to enhance the teaching–learning process and tailor",5
b8f20b0b8a37e7b2e19d416fba80d147b75c887f,Artificial intelligence-based solutions for climate change: a review,"Climate change is a major threat already causing system damage to urban and natural systems, and inducing global economic losses of over $500 billion. These issues may be partly solved by artificial intelligence because artificial intelligence integrates internet resources to make prompt suggestions based on accurate climate change predictions. Here we review recent research and applications of artificial intelligence in mitigating the adverse effects of climate change, with a focus on energy efficiency, carbon sequestration and storage, weather and renewable energy forecasting, grid management, building design, transportation, precision agriculture, industrial processes, reducing deforestation, and resilient cities. We found that enhancing energy efficiency can significantly contribute to reducing the impact of climate change. Smart manufacturing can reduce energy consumption, waste, and carbon emissions by 30–50% and, in particular, can reduce energy consumption in buildings by 30–50%. About 70% of the global natural gas industry utilizes artificial intelligence technologies to enhance the",1
0e98bd81aadc503e77411e17eafd9bfe58ac33a4,Accuracy of a Generative Artificial Intelligence Model in a Complex Diagnostic Challenge.,This study assesses the diagnostic accuracy of the Generative Pre-trained Transformer 4 (GPT-4) artificial intelligence (AI) model in a series of challenging cases.,3
b9ede5f604668d0b62a306392cd03f47086e245e,Artificial intelligence in radiology,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
f134abeaf9bfd41f29b97aec675ec31895bf541d,High-performance medicine: the convergence of human and artificial intelligence,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",13
8d984ee2eeabb630014f31fc759d4980830c4bdb,Can artificial intelligence help for scientific writing?,"This paper discusses the use of Artificial Intelligence Chatbot in scientific writing. ChatGPT is a type of chatbot, developed by OpenAI, that uses the Generative Pre-trained Transformer (GPT) language model to understand and respond to natural language inputs. AI chatbot and ChatGPT in particular appear to be useful tools in scientific writing, assisting researchers and scientists in organizing material, generating an initial draft and/or in proofreading. There is no publication in the field of critical care medicine prepared using this approach; however, this will be a possibility in the next future. ChatGPT work should not be used as a replacement for human judgment and the output should always be reviewed by experts before being used in any critical decision-making or application. Moreover, several ethical issues arise about using these tools, such as the risk of plagiarism and inaccuracies, as well as a potential imbalance in its accessibility between high- and",6
9dafa6c5c609348b46734fc8997b93b3587fec6e,Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education,Generative artificial intelligence (AI) is ushering in an era of potential transformation of journalism and media content. This essay considers one notable generative AI platform called ChatGPT made available to the public in 2022 for free use. ChatGPT allows users to enter text prompts and rapidly generates text responses drawn from its knowledge acquired via machine learning in engagement with the internet. This essay is coauthored by a human journalism and media professor in collaboration with ChatGPT. The essay demonstrates the capacity and limitations of ChatGPT and offers reflections on the implications of generative AI for journalism and media education.,10
7b72711ac2ea7bd7f519cac162a4a6578bbb7d0d,ARTIFICIAL INTELLIGENCE FOR THE REAL WORLD,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
ff97adbdf7ba45c08c6abe277aba04b41e85e5b0,Evaluation of artificial intelligence techniques in disease diagnosis and prediction,"A broad range of medical diagnoses is based on analyzing disease images obtained through high-tech digital devices. The application of artificial intelligence (AI) in the assessment of medical images has led to accurate evaluations being performed automatically, which in turn has reduced the workload of physicians, decreased errors and times in diagnosis, and improved performance in the prediction and detection of various diseases. AI techniques based on medical image processing are an essential area of research that uses advanced computer algorithms for prediction, diagnosis, and treatment planning, leading to a remarkable impact on decision-making procedures. Machine Learning (ML) and Deep Learning (DL) as advanced AI techniques are two main subfields applied in the healthcare system to diagnose diseases, discover medication, and identify patient risk factors. The advancement of electronic medical records and big data technologies in recent years has accompanied the success of ML and DL algorithms. ML includes neural",3
8d020275181c69e5e768c6ffc40e09710a6f54f1,Experimental evidence on the productivity effects of generative artificial intelligence,"We examined the productivity effects of a generative artificial intelligence (AI) technology, the assistive chatbot ChatGPT, in the context of midlevel professional writing tasks. In a preregistered online experiment, we assigned occupation-specific, incentivized writing tasks to 453 college-educated professionals and randomly exposed half of them to ChatGPT. Our results show that ChatGPT substantially raised productivity: The average time taken decreased by 40% and output quality rose by 18%. Inequality between workers decreased, and concern and excitement about AI temporarily rose. Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment. Description Editor’s summary Automation has historically displaced human workers in factories (e.g., automotive manufacturing) or in performing routine computational tasks. Will generative artificial intelligence (AI) tools such as ChatGPT disrupt the labor market by making",6
4583725945ff17f139215b210878b0a2e2d29bc2,"Artificial Intelligence and Machine Learning in Clinical Medicine, 2023.","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c,Sparks of Artificial General Intelligence: Early experiments with GPT-4,"Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks,",6
635c01476986099adc4ce122bb28ebc6deb46671,Empowering learners for the age of artificial intelligence,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
288078127a3078332230442170f6745ed333c700,"A Conversation on Artificial Intelligence, Chatbots, and Plagiarism in Higher Education","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
973650310963f8cdc39c71e79724513004adde2a,Trustworthy artificial intelligence,"This paper develops an account of trustworthy AI. Its central idea is that whether AIs are trustworthy is a matter of whether they live up to their function-based obligations. We argue that this account serves to advance the literature in a couple of important ways. First, it serves to provide a rationale for why a range of properties that are widely assumed in the scientific literature, as well as in policy, to be required of trustworthy AI, such as safety, justice, and explainability, are properties (often) instantiated by trustworthy AI. Second, we connect the discussion on trustworthy AI in policy, industry, and the sciences with the philosophical discussion of trustworthiness. We argue that extant accounts of trustworthiness in the philosophy literature cannot make proper sense of trustworthy AI and that our account compares favourably with its competitors on this front.",1
4b4279db68b16e20fbc56f9d41980a950191d30a,"Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence","From the Publisher: Genetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits. Adaptation in Natural and Artificial Systems is the book that initiated this field of study, presenting the theoretical foundations and exploring applications. In its most familiar form, adaptation is a biological process, whereby organisms evolve by rearranging genetic material to survive in environments confronting them. In this now classic work, Holland presents a mathematical model that allows for the nonlinearity of such complex interactions. He demonstrates the model's universality by applying it to economics, physiological psychology, game theory, and artificial intelligence and then outlines the way in which this approach modifies the traditional views of mathematical genetics. Initially applying his concepts to simply defined artificial systems",3
f92922a9fe4e6bb603291249796d80d09d1fd9f3,Impact of Artificial Intelligence in Customer Journey,"The entire gamut of Customer journey is undergoing a massive transformation due to the rapid advancement of Artificial Intelligence (AI). Leveraging the power of AI , CRM & systems have refined the aspect of how businesses manage and optimize the customer journey. AI-powered systems have significant impact across various stages of the customer lifecycle by use of techniques such as machine learning to empower businesses to use systems that can analyse vast amounts of customer dataset in real-time, enabling them to gain deeper insights in customer behaviours, preferences, & sentiment. The AI-driven techniques help businesses to drive more personalized & targeted marketing campaigns, tailored recommendations, and extend efficient customer service leading ultimately to enhancing customer satisfaction and loyalty. Moreover, AI-powered systems have capabilities of offering predictive analytics which empower businesses to forecast customer behaviours and anticipate their needs. The capabilities help businesses in effective resource optimization and improve efficiency. For",3
5c128102d50d7ed96784ece1eb25533bb4ff3078,Drawbacks of Artificial Intelligence and Their Potential Solutions in the Healthcare Sector,"Artificial intelligence (AI) has the potential to make substantial progress toward the goal of making healthcare more personalized, predictive, preventative, and interactive. We believe AI will continue its present path and ultimately become a mature and effective tool for the healthcare sector. Besides this AI-based systems raise concerns regarding data security and privacy. Because health records are important and vulnerable, hackers often target them during data breaches. The absence of standard guidelines for the moral use of AI and ML in healthcare has only served to worsen the situation. There is debate about how far artificial intelligence (AI) may be utilized ethically in healthcare settings since there are no universal guidelines for its use. Therefore, maintaining the confidentiality of medical records is crucial. This study enlightens the possible drawbacks of AI in the implementation of healthcare sector and their solutions to overcome these situations. Graphical Abstract",5
bb01d7be9b49c8a018e134c7f132c39b7d9973ad,Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
a7a407968c13ced804a063259d72315a43b84f29,Artificial Intelligence in Education: A Review,"The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and",9
f08060425aa8a212d74185ee23a08329b89abcd2,Scientific discovery in the age of artificial intelligence,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
de4b9bc12ddb6b9f6090c032ef5c6290bd64ef36,Artificial Intelligence,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
b67cb8cac83ec0cb683d5378a0ca4d96c8176013,Artificial intelligence in healthcare and education,"Artificial intelligence (AI) is rapidly transforming the healthcare and medical and dental education sectors. With advancements in AI technology and its integration into routine tasks, the field of healthcare and education is rapidly evolving. This article aims to provide an in-depth analysis of the impact of AI in these sectors and to discuss the advantages and disadvantages of its integration. The article will begin by examining the use of AI in healthcare, including its impact on patient care, diagnosis and treatment, and the benefits it brings to medical professionals and patients alike. The article will then delve into the use of AI in medical and dental education, exploring its impact on student learning and teaching practices, and the benefits and challenges it presents for educators and students. Additionally, this article will also cover the impact of AI on the publishing of scientific articles in journals. With the increasing volume of",2
e1d2f2a717aa03280126f87c8e5fad695f52bf7c,Explainable Artificial Intelligence (XAI),"Explainable Artificial Intelligence (XAI) has emerged as a critical facet in the realm of machine learning and artificial intelligence, responding to the increasing complexity of models, particularly deep neural networks, and the subsequent need for transparent decision making processes. This research paper delves into the essence of XAI, unraveling its significance across diverse domains such as healthcare, finance, and criminal justice. As a countermeasure to the opacity of intricate models, the paper explores various XAI methods and techniques, including LIME and SHAP, weighing their interpretability against computational efficiency and accuracy. Through an examination of real-world applications, the research elucidates how XAI not only enhances decision-making processes but also influences user trust and acceptance in AI systems. However, the paper also scrutinizes the delicate balance between interpretability and performance, shedding light on instances where the pursuit of accuracy may compromise explain-ability. Additionally, it navigates through the current challenges and limitations in",3
5cde474869cb230a29b3ba0f6f685f5162b1a1a1,Revolutionizing healthcare: the role of artificial intelligence in clinical practice,"Introduction Healthcare systems are complex and challenging for all stakeholders, but artificial intelligence (AI) has transformed various fields, including healthcare, with the potential to improve patient care and quality of life. Rapid AI advancements can revolutionize healthcare by integrating it into clinical practice. Reporting AI’s role in clinical practice is crucial for successful implementation by equipping healthcare providers with essential knowledge and tools. Research Significance This review article provides a comprehensive and up-to-date overview of the current state of AI in clinical practice, including its potential applications in disease diagnosis, treatment recommendations, and patient engagement. It also discusses the associated challenges, covering ethical and legal considerations and the need for human expertise. By doing so, it enhances understanding of AI’s significance in healthcare and supports healthcare organizations in effectively adopting AI technologies. Materials and Methods The current investigation analyzed the use of AI in the healthcare system with a comprehensive",3
e89dfa306723e8ef031765e9c44e5f6f94fd8fda,Explanation in Artificial Intelligence: Insights from the Social Sciences,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",16
22ff1f6f4df0497323ac03f446cbc49463128486,Appropriateness of Cardiovascular Disease Prevention Recommendations Obtained From a Popular Online Chat-Based Artificial Intelligence Model.,This study examines the appropriateness of artificial intelligence model responses to fundamental cardiovascular disease prevention questions.,1
12c6be503e4e5b7c9cb1810152d4364f26628a8d,Data-centric Artificial Intelligence: A Survey,"Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI . The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages",2
e251ba9fe7992fc07a01365a5f8f2b4d9020b875,Artificial intelligence in higher education: the state of the field,"This systematic review provides unique findings with an up-to-date examination of artificial intelligence (AI) in higher education (HE) from 2016 to 2022. Using PRISMA principles and protocol, 138 articles were identified for a full examination. Using a priori, and grounded coding, the data from the 138 articles were extracted, analyzed, and coded. The findings of this study show that in 2021 and 2022, publications rose nearly two to three times the number of previous years. With this rapid rise in the number of AIEd HE publications, new trends have emerged. The findings show that research was conducted in six of the seven continents of the world. The trend has shifted from the US to China leading in the number of publications. Another new trend is in the researcher affiliation as prior studies showed a lack of researchers from departments of education. This has now changed to be the most dominant",3
9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a,Foundation models for generalist medical artificial intelligence,"The exceptionally rapid development of highly flexible, reusable artificial intelligence (AI) models is likely to usher in newfound capabilities in medicine. We propose a new paradigm for medical AI, which we refer to as generalist medical AI (GMAI). GMAI models will be capable of carrying out a diverse set of tasks using very little or no task-specific labelled data. Built through self-supervision on large, diverse datasets, GMAI will flexibly interpret different combinations of medical modalities, including data from imaging, electronic health records, laboratory results, genomics, graphs or medical text. Models will in turn produce expressive outputs such as free-text explanations, spoken recommendations or image annotations that demonstrate advanced medical reasoning abilities. Here we identify a set of high-impact potential applications for GMAI and lay out specific technical capabilities and training datasets necessary to enable them. We expect that GMAI-enabled applications will challenge current strategies for regulating and validating AI devices",1
5a5e03c3c8bf5052a99f4631e874b1e608e59319,Artificial intelligence in developing countries: The impact of generative artificial intelligence (AI) technologies for development,"This paper explores the potential impact of Generative Artificial Intelligence (Generative AI) on developing countries, considering both positive and negative effects across various domains of information, culture, and industry. Generative Artificial Intelligence refers to artificial intelligence (AI) systems that generate content, such as text, audio, or video, aiming to produce novel and creative outputs based on training data. Compared to conversational artificial intelligence, generative artificial intelligence systems have the unique capability of not only providing replies but also generating the content of those responses. Recent advancements in Artificial Intelligence during the Fourth Industrial Revolution, exemplified by tools like ChatGPT, have gained popularity and reshaped content production and creation. However, the benefits of generative artificial intelligence are not equally accessible to all, especially in developing countries, where limited access to cutting-edge technologies and inadequate infrastructure pose challenges. This paper seeks to understand the potential impact of generative AI technologies on developing",2
31f76619329aba7987394ccb8cac6c9a6dd58a56,Managing artificial intelligence,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
e8441a9d8c22f333b4092d3a95d3fbb64a36d428,Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?,"The legal and ethical issues that confront society due to Artificial Intelligence (AI) include privacy and surveillance, bias or discrimination, and potentially the philosophical challenge is the role of human judgment. Concerns about newer digital technologies becoming a new source of inaccuracy and data breaches have arisen as a result of its use. Mistakes in the procedure or protocol in the field of healthcare can have devastating consequences for the patient who is the victim of the error. Because patients come into contact with physicians at moments in their lives when they are most vulnerable, it is crucial to remember this. Currently, there are no well-defined regulations in place to address the legal and ethical issues that may arise due to the use of artificial intelligence in healthcare settings. This review attempts to address these pertinent issues highlighting the need for algorithmic transparency, privacy, and protection of all the beneficiaries",4
10c64e5aaff9f70dffc8c29a577376d085e9340b,A Review of the Role of Artificial Intelligence in Healthcare,"Artificial intelligence (AI) applications have transformed healthcare. This study is based on a general literature review uncovering the role of AI in healthcare and focuses on the following key aspects: (i) medical imaging and diagnostics, (ii) virtual patient care, (iii) medical research and drug discovery, (iv) patient engagement and compliance, (v) rehabilitation, and (vi) other administrative applications. The impact of AI is observed in detecting clinical conditions in medical imaging and diagnostic services, controlling the outbreak of coronavirus disease 2019 (COVID-19) with early diagnosis, providing virtual patient care using AI-powered tools, managing electronic health records, augmenting patient engagement and compliance with the treatment plan, reducing the administrative workload of healthcare professionals (HCPs), discovering new drugs and vaccines, spotting medical prescription errors, extensive data storage and analysis, and technology-assisted rehabilitation. Nevertheless, this science pitch meets several technical, ethical, and social challenges, including privacy, safety, the right to decide and try, costs,",0
eac11727ef9c7c29711cb1ba82ef6f011e8ad78d,New Era of Artificial Intelligence in Education: Towards a Sustainable Multifaceted Revolution,"The recent high performance of ChatGPT on several standardized academic tests has thrust the topic of artificial intelligence (AI) into the mainstream conversation about the future of education. As deep learning is poised to shift the teaching paradigm, it is essential to have a clear understanding of its effects on the current education system to ensure sustainable development and deployment of AI-driven technologies at schools and universities. This research aims to investigate the potential impact of AI on education through review and analysis of the existing literature across three major axes: applications, advantages, and challenges. Our review focuses on the use of artificial intelligence in collaborative teacher–student learning, intelligent tutoring systems, automated assessment, and personalized learning. We also report on the potential negative aspects, ethical issues, and possible future routes for AI implementation in education. Ultimately, we find that the only way forward is to embrace the new technology, while",2
438ea4f6becaadca82c9f9904208a423a0cfeba0,Artificial Intelligence in Pharmaceutical Technology and Drug Delivery Design,"Artificial intelligence (AI) has emerged as a powerful tool that harnesses anthropomorphic knowledge and provides expedited solutions to complex challenges. Remarkable advancements in AI technology and machine learning present a transformative opportunity in the drug discovery, formulation, and testing of pharmaceutical dosage forms. By utilizing AI algorithms that analyze extensive biological data, including genomics and proteomics, researchers can identify disease-associated targets and predict their interactions with potential drug candidates. This enables a more efficient and targeted approach to drug discovery, thereby increasing the likelihood of successful drug approvals. Furthermore, AI can contribute to reducing development costs by optimizing research and development processes. Machine learning algorithms assist in experimental design and can predict the pharmacokinetics and toxicity of drug candidates. This capability enables the prioritization and optimization of lead compounds, reducing the need for extensive and costly animal testing. Personalized medicine approaches can be facilitated through AI algorithms that analyze real-world",4
7c1933359a6860fe49d15c6353a241763879e81f,"From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where","Nowadays, Industry 4.0 can be considered a reality, a paradigm integrating modern technologies and innovations. Artificial intelligence (AI) can be considered the leading component of the industrial transformation enabling intelligent machines to execute tasks autonomously such as self-monitoring, interpretation, diagnosis, and analysis. AI-based methodologies (especially machine learning and deep learning support manufacturers and industries in predicting their maintenance needs and reducing downtime. Explainable artificial intelligence (XAI) studies and designs approaches, algorithms and tools producing human-understandable explanations of AI-based systems information and decisions. This article presents a comprehensive survey of AI and XAI-based methods adopted in the Industry 4.0 scenario. First, we briefly discuss different technologies enabling Industry 4.0. Then, we present an in-depth investigation of the main methods used in the literature: we also provide the details of what, how, why, and where these methods have been applied for Industry 4.0. Furthermore, we illustrate the opportunities and challenges that elicit",4
b313140bde3d9d8ed96f405674fd243e270104fb,Artificial intelligence for digital and computational pathology,"Advances in digitizing tissue slides and the fast-paced progress in artificial intelligence, including deep learning, have boosted the field of computational pathology. This field holds tremendous potential to automate clinical diagnosis, predict patient prognosis and response to therapy, and discover new morphological biomarkers from tissue images. Some of these artificial intelligence-based systems are now getting approved to assist clinical diagnosis; however, technical barriers remain for their widespread clinical adoption and integration as a research tool. This Review consolidates recent methodological advances in computational pathology for predicting clinical end points in whole-slide images and highlights how these developments enable the automation of clinical practice and the discovery of new biomarkers. We then provide future perspectives as the field expands into a broader range of clinical and research tasks with increasingly diverse modalities of clinical data. Advances in digitizing human tissue slides and progress in artificial intelligence have boosted progress in the",2
64e750a466549aa39b91799a740ea293b3d21bb5,Artificial Intelligence in Medicine,"Artificial Intelligence in Medicine is looking for novelty in the methodological and/or theoretical content of submitted papers. Such kind of novelty has to be mainly acknowledged in the area of AI and Computer Science. Methodological papers deal with the proposal of some strategy and related methods to solve some scientific issues in specific domains. They must show, usually through an experimental evaluation, how the proposed methodology can be applied to medicine, medicallyoriented human biology, and health care, respectively. They have also to provide a comparison with other proposals, and explicitly discuss elements of novelty. Theoretical papers focus on more fundamental, general and formal topics of AI and must show the novel expected effects of the proposed solution in some medical or healthcare field.",5
712fde4644bc9c7e3a59695396a2614bbde1fcb3,CS 188 Introduction to Artificial Intelligence Fall 2023,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",11
6f4486c3d8ccd638c2a6bcbfafa01b5a3225bcab,Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence,"The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT’s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to",2
2633a948f06a02417a39c9ff4e9c948bbad460d7,Artificial Intelligence and the Future of Work,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
dfd1d219c7e1993bef152f79b81204a828b77d21,"Generative artificial intelligence empowers educational reform: current status, issues, and prospects","The emergence of Chat GPT has once again sparked a wave of information revolution in generative artificial intelligence. This article provides a detailed overview of the development and technical support of generative artificial intelligence. It conducts an in-depth analysis of the current application of generative artificial intelligence in the field of education, and identifies problems in four aspects: opacity and unexplainability, data privacy and security, personalization and fairness, and effectiveness and reliability. Corresponding solutions are proposed, such as developing explainable and fair algorithms, upgrading encryption technology, and formulating relevant laws and regulations to protect data, as well as improving the quality and quantity of datasets. The article also looks ahead to the future development trends of generative artificial intelligence in education from four perspectives: personalized education, intelligent teaching, collaborative education, and virtual teaching. The aim of the study is to provide important reference value for research and practice in this",4
b9e9f449da63fbb783ce39db15bf1626a9bb4a44,Artificial intelligence for waste management in smart cities: a review,"The rising amount of waste generated worldwide is inducing issues of pollution, waste management, and recycling, calling for new strategies to improve the waste ecosystem, such as the use of artificial intelligence. Here, we review the application of artificial intelligence in waste-to-energy, smart bins, waste-sorting robots, waste generation models, waste monitoring and tracking, plastic pyrolysis, distinguishing fossil and modern materials, logistics, disposal, illegal dumping, resource recovery, smart cities, process efficiency, cost savings, and improving public health. Using artificial intelligence in waste logistics can reduce transportation distance by up to 36.8%, cost savings by up to 13.35%, and time savings by up to 28.22%. Artificial intelligence allows for identifying and sorting waste with an accuracy ranging from 72.8 to 99.95%. Artificial intelligence combined with chemical analysis improves waste pyrolysis, carbon emission estimation, and energy conversion. We also explain how efficiency can be increased and costs can be reduced by artificial intelligence",3
33dc37f5391789ce81061f303923ffec07dde1d1,Combining Planning with Gaze for Online Human Intention Recognition,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
d0284c9889eb38f70d3c3acba13e20c00d7cbc45,Consequentialism,This chapter explains the consequentialist approach to ethical analysis. It distinguishes act utilitarianism and rule utilitarianism. It also considers different possibilities as to which outcomes should be considered relevant for consequentialists. It considers a number of challenges and objections to consequentialist ethics.,6
d553d008f643622e87e3ac061226865cad3b2928,Engineering Education in the Era of ChatGPT: Promise and Pitfalls of Generative AI for Education,"Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented",8
ff2a00554d8535c54da7149c2262bbdd94a39d9f,Early Extracorporeal CPR for Refractory Out-of-Hospital Cardiac Arrest.,"BACKGROUND Extracorporeal cardiopulmonary resuscitation (CPR) restores perfusion and oxygenation in a patient who does not have spontaneous circulation. The evidence with regard to the effect of extracorporeal CPR on survival with a favorable neurologic outcome in refractory out-of-hospital cardiac arrest is inconclusive. METHODS In this multicenter, randomized, controlled trial conducted in the Netherlands, we assigned patients with an out-of-hospital cardiac arrest to receive extracorporeal CPR or conventional CPR (standard advanced cardiac life support). Eligible patients were between 18 and 70 years of age, had received bystander CPR, had an initial ventricular arrhythmia, and did not have a return of spontaneous circulation within 15 minutes after CPR had been initiated. The primary outcome was survival with a favorable neurologic outcome, defined as a Cerebral Performance Category score of 1 or 2 (range, 1 to 5, with higher scores indicating more severe disability) at 30 days. Analyses were performed on an intention-to-treat",4
ffb6ba31c0e95a6de49a861bfb2b33e0a528efac,Predicting the Onset of Diabetes with Machine Learning Methods,"The number of people suffering from diabetes in Taiwan has continued to rise in recent years. According to the statistics of the International Diabetes Federation, about 537 million people worldwide (10.5% of the global population) suffer from diabetes, and it is estimated that 643 million people will develop the condition (11.3% of the total population) by 2030. If this trend continues, the number will jump to 783 million (12.2%) by 2045. At present, the number of people with diabetes in Taiwan has reached 2.18 million, with an average of one in ten people suffering from the disease. In addition, according to the Bureau of National Health Insurance in Taiwan, the prevalence rate of diabetes among adults in Taiwan has reached 5% and is increasing each year. Diabetes can cause acute and chronic complications that can be fatal. Meanwhile, chronic complications can result in a variety of disabilities or organ decline.",4
34f6569f8000a8a33ffe8820fe3a3bd91a02d3f2,ChatGPT's Response to the Diabetes Knowledge Questionnaire: Implications for Diabetes Education.,"The diabetes epidemic which impacts many people globally necessitates patient education to enhance self-management. Artificial intelligence (AI) chatbots hold promise in automizing patient education and lessening healthcare providers' burden. This study assesses the utility of ChatGPT, an AI chatbot created by OpenAI, in responding to the diabetes knowledge questionnaire (24-DKQ). The 24-DKQ, consisting of 24 items, is specifically designed to evaluate patients' diabetes knowledge. We found that ChatGPT accurately answered all 24 questions of the 24-DKQ, and was also able to expand and provide decent explanations. AI technology can serve as an opportunity to create personalized and automated diabetes patient education materials. However, despite AI technology's great potential, its effectiveness remains unclear. It is crucial for researchers, developers, and healthcare professionals to collaborate in order to create AI programs that are validated, reliable, and accurately tailored to the individual needs of people living with diabetes.",2
7c663204f4b1f5c0a112bce0d84b21e1c1b7f798,Artificial intelligence for education: Knowledge and its assessment in AI-enabled learning ecologies,"Abstract Over the past ten years, we have worked in a collaboration between educators and computer scientists at the University of Illinois to imagine futures for education in the context of what is loosely called “artificial intelligence.” Unhappy with the first generation of digital learning environments, our agenda has been to design alternatives and research their implementation. Our starting point has been to ask, what is the nature of machine intelligence, and what are its limits and potentials in education? This paper offers some tentative answers, first conceptually, and then practically in an overview of the results of a number of experimental implementations documented in greater detail elsewhere. Our key finding is that artificial intelligence—in the context of the practices of electronic computing developing over the past three quarters of a century—will never in any sense “take over” the role of teacher, because how it works and what it does",5
820c4c1852411d2c03201a66a122fb77c1d6578e,"Please Take Over: Xai, Delegation of Authority, and Domain Knowledge","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
a02fbaf22237a1aedacb1320b6007cd70c1fe6ec,Robust Speech Recognition via Large-Scale Weak Supervision,"We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results but in a zero-shot transfer setting without the need for any fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.",3
6896a3dd47803ddfcd0a0ded106a42bc0718c999,Do technology and renewable energy contribute to energy efficiency and carbon neutrality? Evidence from top ten manufacturing countries,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
7dd2232cab97c678bbe5b36f37e4c997cffbdb37,Sustainable Fashion: Exploring the Concept of Greenwashing and New Trends in the Fashion Industry,"The fashion industry, characterized by rapid cycles of production and consumption, has emerged as a global economic powerhouse, generating significant revenue and employment opportunities worldwide. However, this growth has come at a substantial environmental and social cost, marked by extensive resource consumption, greenhouse gas emissions, and labor exploitation. This paper critically examines the environmental and social impacts of the fashion industry, focusing on issues such as textile waste, water pollution, and unethical labor practices. It explores the transition towards sustainable fashion practices, highlighting initiatives like circular fashion and consumer behavior shifts towards eco-friendly choices. The study employs a comprehensive review of current literature and case studies to analyze the challenges and opportunities for achieving sustainability within the fashion sector. By synthesizing diverse perspectives and research findings, this paper proposes strategies to combat greenwashing, enhance transparency, and foster a circular economy in fashion. Ultimately, it aims to provide a framework for",3
ecea364c75590b2bcd2a39077c41e18ccc0e44c6,Identifying distributions of urban ecosystem health based on Latin-hypercube sampling and multi-criteria decision analysis framework,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
f609bc765bb05b904f744b53cac6a2b96ae79d63,An artificial neural network model to predict the mortality of COVID-19 patients using routine blood samples at the time of hospital admission,"Supplemental Digital Content is available in the text Abstract Background: In a pandemic situation (e.g., COVID-19), the most important issue is to select patients at risk of high mortality at an early stage and to provide appropriate treatments. However, a few studies applied the model to predict in-hospital mortality using routine blood samples at the time of hospital admission. This study aimed to develop an app, name predict the mortality of COVID-19 patients (PMCP) app, to predict the mortality of COVID-19 patients at hospital-admission time. Methods: We downloaded patient records from 2 studies, including 361 COVID-19 patients in Wuhan, China, and 106 COVID-19 patients in 3 Korean medical institutions. A total of 30 feature variables were retrieved, consisting of 28 blood biomarkers and 2 demographic variables (i.e., age and gender) of patients. Two models, namely, artificial neural network (ANN) and convolutional neural network (CNN), were compared with each other across",3
75791cfcb2a7f00c58ddb4dffd95229875d8f02c,Are Aggressive Agents as Scary as Aggressive Humans?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
2615eee08a0f7b7e57d43165daac6ce3b4f9e200,Gamma Power Reductions Accompany Stimulus-Specific Representations of Dynamic Events,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
ef10b30de48ce654d435e62594441b5b317f3cda,CatAlyst: Domain-Extensible Intervention for Preventing Task Procrastination Using Large Generative Models,"CatAlyst uses generative models to help workers’ progress by influencing their task engagement instead of directly contributing to their task outputs. It prompts distracted workers to resume their tasks by generating a continuation of their work and presenting it as an intervention that is more context-aware than conventional (predetermined) feedback. The prompt can function by drawing their interest and lowering the hurdle for resumption even when the generated continuation is insufficient to substitute their work, while recent human-AI collaboration research aiming at work substitution depends on a stable high accuracy. This frees CatAlyst from domain-specific model-tuning and makes it applicable to various tasks. Our studies involving writing and slide-editing tasks demonstrated CatAlyst’s effectiveness in helping workers swiftly resume tasks with a lowered cognitive load. The results suggest a new form of human-AI collaboration where large generative models publicly available but imperfect for each individual domain can contribute to workers’ digital",7
74b2b38b61329186f0192ead46098e65224b3bf0,Active Ensemble Learning for Knowledge Graph Error Detection,"Knowledge graphs (KGs) could effectively integrate a large number of real-world assertions, and improve the performance of various applications, such as recommendation and search. KG error detection has been intensively studied since real-world KGs inevitably contain erroneous triples. While existing studies focus on developing a novel algorithm dedicated to one or a few data characteristics, we explore advancing KG error detection by assembling a set of state-of-the-art (SOTA) KG error detectors. However, it is nontrivial to develop a practical ensemble learning framework for KG error detection. Existing ensemble learning models heavily rely on labels, while it is expensive to acquire labeled errors in KGs. Also, KG error detection itself is challenging since triples contain rich semantic information and might be false because of various reasons. To this end, we propose to leverage active learning to minimize human efforts. Our proposed framework - KAEL, could effectively assemble a set of off-the-shelf",6
f63b66a3ca43084b668c1cce19ee00e68356867d,"Artificial Intelligence in Drug Metabolism and Excretion Prediction: Recent Advances, Challenges, and Future Perspectives","Drug metabolism and excretion play crucial roles in determining the efficacy and safety of drug candidates, and predicting these processes is an essential part of drug discovery and development. In recent years, artificial intelligence (AI) has emerged as a powerful tool for predicting drug metabolism and excretion, offering the potential to speed up drug development and improve clinical success rates. This review highlights recent advances in AI-based drug metabolism and excretion prediction, including deep learning and machine learning algorithms. We provide a list of public data sources and free prediction tools for the research community. We also discuss the challenges associated with the development of AI models for drug metabolism and excretion prediction and explore future perspectives in the field. We hope this will be a helpful resource for anyone who is researching in silico drug metabolism, excretion, and pharmacokinetic properties.",5
5a325803c2ddc7793a08b03479cd884c034568de,“Connecting concepts helps put main ideas together”: cognitive load and usability in learning biology with an AI-enriched textbook,"Rapid developments in educational technology in higher education are intended to make learning more engaging and effective. At the same time, cognitive load theory stresses limitations of human cognitive architecture and urges educational developers to design learning tools that optimise learners’ mental capacities. In a 2-month study we investigated university students’ learning with an AI-enriched digital biology textbook that integrates a 5000-concept knowledge base and algorithms offering the possibility to ask questions and receive answers. The study aimed to shed more light on differences between three sub-types (intrinsic, germane and extraneous) of cognitive load and their relationship with learning gain, self-regulated learning and usability perception while students interacted with the AI-enriched book during an introductory biology course. We found that students displayed a beneficial learning pattern with germane cognitive load significantly higher than both intrinsic and extraneous loads showing that they were engaged in meaningful learning throughout the study. A",6
8da43f1800ba0c3d806705abf586f7ca0af888a6,Suspicious Behavior Detection with Temporal Feature Extraction and Time-Series Classification for Shoplifting Crime Prevention,"The rise in crime rates in many parts of the world, coupled with advancements in computer vision, has increased the need for automated crime detection services. To address this issue, we propose a new approach for detecting suspicious behavior as a means of preventing shoplifting. Existing methods are based on the use of convolutional neural networks that rely on extracting spatial features from pixel values. In contrast, our proposed method employs object detection based on YOLOv5 with Deep Sort to track people through a video, using the resulting bounding box coordinates as temporal features. The extracted temporal features are then modeled as a time-series classification problem. The proposed method was tested on the popular UCF Crime dataset, and benchmarked against the current state-of-the-art robust temporal feature magnitude (RTFM) method, which relies on the Inflated 3D ConvNet (I3D) preprocessing method. Our results demonstrate an impressive 8.45-fold increase in detection inference speed",3
09358d4949078c891c2bb2dd662693b51830013c,Automation and New Tasks: How Technology Displaces and Reinstates Labor,"We present a framework for understanding the effects of automation and other types of technological changes on labor demand, and use it to interpret changes in US employment over the recent past. At the center of our framework is the allocation of tasks to capital and labor—the task content of production. Automation, which enables capital to replace labor in tasks it was previously engaged in, shifts the task content of production against labor because of a displacement effect. As a result, automation always reduces the labor share in value added and may reduce labor demand even as it raises productivity. The effects of automation are counterbalanced by the creation of new tasks in which labor has a comparative advantage. The introduction of new tasks changes the task content of production in favor of labor because of a reinstatement effect, and always raises the labor share and labor demand. We show",9
4fa5dbfb2f62391ed73a23a8867e31a94feb971e,Integrating drone-borne thermal imaging with artificial intelligence to locate bird nests on agricultural land,"In conservation, the use of unmanned aerial vehicles (drones) carrying various sensors and the use of deep learning are increasing, but they are typically used independently of each other. Untapping their large potential requires integrating these tools. We combine drone-borne thermal imaging with artificial intelligence to locate ground-nests of birds on agricultural land. We show, for the first time, that this semi-automated system can identify nests with a high performance. However, local weather, type of arable field and height of the drone can affect performance. The results’ implications are particularly relevant to conservation practitioners working across sectors, such as biodiversity conservation and food production in farmland. Under a rapidly changing world, studies like this can help uncover the potential of technology for conservation and embrace cross-sectoral transformations from the onset; for example, by integrating nest detection within the precision agriculture system that heavily relies on drone-borne sensors.",1
c082ccfcfe1afc696e371374146ba9380b84061e,The Role of ChatGPT in Data Science: How AI-Assisted Conversational Interfaces Are Revolutionizing the Field,"ChatGPT, a conversational AI interface that utilizes natural language processing and machine learning algorithms, is taking the world by storm and is the buzzword across many sectors today. Given the likely impact of this model on data science, through this perspective article, we seek to provide an overview of the potential opportunities and challenges associated with using ChatGPT in data science, provide readers with a snapshot of its advantages, and stimulate interest in its use for data science projects. The paper discusses how ChatGPT can assist data scientists in automating various aspects of their workflow, including data cleaning and preprocessing, model training, and result interpretation. It also highlights how ChatGPT has the potential to provide new insights and improve decision-making processes by analyzing unstructured data. We then examine the advantages of ChatGPT’s architecture, including its ability to be fine-tuned for a wide range of language-related tasks and generate synthetic data.",2
25ca87d83b99831af6c75c4f962e63c18f2cd298,Explaining Explanations: An Approach to Evaluating Interpretability of Machine Learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
6d5852cf840761ac76fbdebaaefd5f908ae8130b,Research on predicting learning achievement in a flipped classroom based on MOOCs by big data analysis,"In the era of big data mining, educational data mining has become a principal research focus, with online education mining, such as massive open online courses' (MOOC) data analysis, representing an important source of it. Recent studies have found that learners have low passing rates on MOOCs. A number of studies have proposed prediction models for the dropout rate of learners on MOOCs. The improvement of MOOCs and the promotion of personalized education are the key points of online education. However, the selection and intervention of students with a tendency to drop out slows down the efficiency of teaching and increases the burden on teachers. This study's aim is to utilize back propagation neural networks and radar graphs in a flipped classroom based on MOOCs to predict students' future grades and to analyze the influence of teaching from various perspectives to support the promotion and reform of teaching and curriculum.",3
508edca55bc8b5e0bd3223a46a2b7cfc80ef96c6,Eye-Tracking Causality,"How do people make causal judgments? What role, if any, does counterfactual simulation play? Counterfactual theories of causal judgments predict that people compare what actually happened with what would have happened if the candidate cause had been absent. Process theories predict that people focus only on what actually happened, to assess the mechanism linking candidate cause and outcome. We tracked participants’ eye movements while they judged whether one billiard ball caused another one to go through a gate or prevented it from going through. Both participants’ looking patterns and their judgments demonstrated that counterfactual simulation played a critical role. Participants simulated where the target ball would have gone if the candidate cause had been removed from the scene. The more certain participants were that the outcome would have been different, the stronger the causal judgments. These results provide the first direct evidence for spontaneous counterfactual simulation in an important domain",6
c874577384095c5edec60499461275e308dff797,Can Post-hoc Explanations Effectively Detect Out-of-Distribution Samples?,"Today there is consensus around the importance of explainability as a mandatory feature in practical deployments of Artificial Intelligence (AI) models. Most research activity reported so far in the eXplainable AI (XAI) research arena has stressed on proposing new techniques for eliciting such explanations, together with different approaches for measuring their effectivity to increase the trustworthiness of the audience for which explanations are furnished. However, alternative uses of explanations beyond their original purpose have been very scarcely explored. In this work we investigate whether local explanations can be utilized for detecting Out-of-Distribution (OoD) test samples in machine learning classifiers, i.e., to identify whether query examples of an already trained classification model can be thought to belong to the distribution of the training data. To this end, we devise and assess the performance of a clustering-based OoD detection approach that exemplifies how heatmaps produced by well-established local explanation methods can be",1
211ffacc2cb4d1a68616dfe125b89377fa76aa63,"Legal and human rights issues of AI: Gaps, challenges and vulnerabilities","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
8b6f5784419fcf9c1057e7a3599f030b3723b59b,Lightly-supervised Representation Learning with Global Interpretability,"We propose a lightly-supervised approach for information extraction, in particular named entity classification, which combines the benefits of traditional bootstrapping, i.e., use of limited annotations and interpretability of extraction patterns, with the robust learning approaches proposed in representation learning. Our algorithm iteratively learns custom embeddings for both the multi-word entities to be extracted and the patterns that match them from a few example entities per category. We demonstrate that this representation-based approach outperforms three other state-of-the-art bootstrapping approaches on two datasets: CoNLL-2003 and OntoNotes. Additionally, using these embeddings, our approach outputs a globally-interpretable model consisting of a decision list, by ranking patterns based on their proximity to the average entity embedding in a given class. We show that this interpretable model performs close to our complete bootstrapping model, proving that representation learning can be used to produce interpretable models with small loss in performance. This decision list can be edited",4
c61e47b0b2c91bdd6a539ec25b019ab2f182bf77,"Barriers and Strategies for Digitalisation of Economy in Developing Countries: Pakistan, a Case in Point","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
ad3dfb2514cb0c899fcb9a14d229ff2a6018892f,Deep Bidirectional Language-Knowledge Graph Pretraining,"Pretraining a language model (LM) on text has been shown to help various downstream NLP tasks. Recent works show that a knowledge graph (KG) can complement text data, offering structured background knowledge that provides a useful scaffold for reasoning. However, these works are not pretrained to learn a deep fusion of the two modalities at scale, limiting the potential to acquire fully joint representations of text and KG. Here we propose DRAGON (Deep Bidirectional Language-Knowledge Graph Pretraining), a self-supervised approach to pretraining a deeply joint language-knowledge foundation model from text and KG at scale. Specifically, our model takes pairs of text segments and relevant KG subgraphs as input and bidirectionally fuses information from both modalities. We pretrain this model by unifying two self-supervised reasoning tasks, masked language modeling and KG link prediction. DRAGON outperforms existing LM and LM+KG models on diverse downstream tasks including question answering across general and biomedical",9
e017e0034fba16b37958b517064d9bf7ecac5f54,Artificial intelligence foundation for therapeutic science,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
a1d8bbee9798b4f5cc9c09ba83d09248ab849d4f,The Graphic Language of Neville Brody,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
8a9f05cdfd0ea7411e83f95b39647167ee82c087,ChatGPT in higher education: Considerations for academic integrity and student learning,"The release of ChatGPT has sparked significant academic integrity concerns in higher education. However, some commentators have pointed out that generative artificial intelligence (AI) tools such as ChatGPT can enhance student learning, and consequently, academics should adapt their teaching and assessment practices to embrace the new reality of living, working, and studying in a world where AI is freely available. Despite this important debate, there has been very little academic literature published on ChatGPT and other generative AI tools. This article uses content analysis to examine news articles (N=100) about how ChatGPT is disrupting higher education, concentrating specifically on Australia, New Zealand, the United States",6
b40f8e68816a0adb55afeb982535e346e21d6174,"Artificial Intelligence, Jobs and the Future of Work: Racing with the Machines","Abstract Artificial intelligence is rapidly entering our daily lives in the form of driverless cars, automated online assistants and virtual reality experiences. In so doing, AI has already substituted human employment in areas that were previously thought to be uncomputerizable. Based on current trends, the technological displacement of labor is predicted to be significant in the future – if left unchecked this will lead to catastrophic societal unemployment levels. This paper presents a means to mitigate future technological unemployment through the introduction of a Basic Income scheme, accompanied by reforms in school curricula and retraining programs. Our proposal argues that such a scheme can be funded by a special tax on those industries that make use of robotic labour; it includes a practical roadmap that would see a government take this proposal from the conceptual phase and implement it nationwide in the span of one decade.",4
a38f1165e6153c5a699f8944cecb52ea40debeb6,The use of chatbots in university EFL settings: Research trends and pedagogical implications,"This mini-review aims to identify major research trends, models, and theories and provide specific pedagogical implications for teaching when using chatbots in EFL classes. This study follows the guidelines of the PRISMA methodology and searches for open-access empirical studies in two reputable databases, Web of Science and Scopus. The results of this mini-review confirm the findings of other research studies, which show that the present research on the use of chatbots in university EFL settings focuses on their effectiveness, motivation, satisfaction, exposure, and assessment. The key contribution of this study lies in its evaluation of the chatbot’s potential in applying and integrating the existing theories and concepts used in EFL teaching and learning, such as CEFR, mind mapping, or self-regulatory learning theory. This will address the gap in the literature because no previous review study has conducted such an analysis. Overall, the findings of this mini-review contribute with their specific",4
4ffb0130c2e19033a1696c32dac2239f702c8dc4,Reinforcement learning,"The discussion here considers a much more common learning condition where an agent, such as a human or a robot, has to learn to make decisions in the environment from simple feedback. Such feedback is provided only after periods of actions in the form of reward or punishment without detailing which of the actions has contributed to the outcome. This type of learning scenario is called reinforcement learning. This learning problem is formalized in a Markov decision-making process with a variety of related algorithms. The second part of this chapter will use function approximators with neural networks which have made recent progress as deep reinforcement learning.",6
a105c11c996faac8996b9ed251705c2023dd73af,Man/machine interface based on the discharge timings of spinal motor neurons after targeted muscle reinnervation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
de874d08354e2d53aade74c1daeaa9bc9b7e381f,The digital scribe,"Current generation electronic health records suffer a number of problems that make them inefficient and associated with poor clinical satisfaction. Digital scribes or intelligent documentation support systems, take advantage of advances in speech recognition, natural language processing and artificial intelligence, to automate the clinical documentation task currently conducted by humans. Whilst in their infancy, digital scribes are likely to evolve through three broad stages. Human led systems task clinicians with creating documentation, but provide tools to make the task simpler and more effective, for example with dictation support, semantic checking and templates. Mixed-initiative systems are delegated part of the documentation task, converting the conversations in a clinical encounter into summaries suitable for the electronic record. Computer-led systems are delegated full control of documentation and only request human interaction when exceptions are encountered. Intelligent clinical environments permit such augmented clinical encounters to occur in a fully digitised space where the environment",3
80f71a6a53cc496a0f7816a8158b0be86d3eb7a7,Solid implantable devices for sustained drug delivery.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
7db59437fc26b01979266fbe7f4b1992f787a627,"""Meaningful Information"" and the Right to Explanation","There is no single, neat statutory provision labeled the “right to explanation” in Europe’s new General Data Protection Regulation (GDPR). But nor is such a right illusory. Responding to two prominent papers that, in turn, conjure and critique the right to explanation in the context of automated decision-making, we advocate a return to the text of the GDPR. Articles 13-15 provide rights to “meaningful information about the logic involved” in automated decisions. This is a right to explanation, whether one uses the phrase or not. The right to explanation should be interpreted functionally, flexibly, and should, at a minimum, enable a data subject to exercise his or her rights under the GDPR and human rights law.",1
3602d529e715218372891879534299a81d71f8b1,Clinical research underlies ethical integration of healthcare artificial intelligence,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
0db2d732fda58a665706e0f348bf4b14038aa4f6,"Recycling municipal, agricultural and industrial waste into energy, fertilizers, food and construction materials, and economic feasibility: a review","The global amount of solid waste has dramatically increased as a result of rapid population growth, accelerated urbanization, agricultural demand, and industrial development. The world's population is expected to reach 8.5 billion by 2030, while solid waste production will reach 2.59 billion tons. This will deteriorate the already strained environment and climate situation. Consequently, there is an urgent need for methods to recycle solid waste. Here, we review recent technologies to treat solid waste, and we assess the economic feasibility of transforming waste into energy. We focus on municipal, agricultural, and industrial waste. We found that methane captured from landfilled-municipal solid waste in Delhi could supply 8–18 million houses with electricity and generate 7140 gigawatt-hour, with a prospected potential of 31,346 and 77,748 gigawatt-hour by 2030 and 2060, respectively. Valorization of agricultural solid waste and food waste by anaerobic digestion systems could replace 61.46% of natural gas and 38.54% of",6
7c4ab671083d7e7e65ddcc94647d5219d8c42e87,Developing a Prediction Model of Demolition-Waste Generation-Rate via Principal Component Analysis,"Construction and demolition waste accounts for a sizable proportion of global waste and is harmful to the environment. Its management is therefore a key challenge in the construction industry. Many researchers have utilized waste generation data for waste management, and more accurate and efficient waste management plans have recently been prepared using artificial intelligence models. Here, we developed a hybrid model to forecast the demolition-waste-generation rate in redevelopment areas in South Korea by combining principal component analysis (PCA) with decision tree, k-nearest neighbors, and linear regression algorithms. Without PCA, the decision tree model exhibited the highest predictive performance (R2 = 0.872) and the k-nearest neighbors (Chebyshev distance) model exhibited the lowest (R2 = 0.627). The hybrid PCA–k-nearest neighbors (Euclidean uniform) model exhibited significantly better predictive performance (R2 = 0.897) than the non-hybrid k-nearest neighbors (Euclidean uniform) model (R2 = 0.664) and the decision tree model. The mean of the observed",3
9c5ac20a248f04533cbc0e1a10974e2e5c1e92e9,Predicting solid waste generation based on the ensemble artificial intelligence models under uncertainty analysis,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
389e53cbae1b4a3d3b4dc30c2cd743dd694d721e,Are superintelligent robots entitled to human rights?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
a06bb1f9d61aff99f803cbfecda13a964a0f8490,Graph neural networks at the Large Hadron Collider,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
b9b0bcfe881b6c90f76dfe7a913b0e022682ceb5,Research on the Impact of Geopolitical Instability on Russian Trade,"This study examines how global and country- specific geopolitical instability affects Russian trade using data from 1996 to 2021. A panel regression model analyzes trade between Russia and its 15 top trading partners, exploring both direct and indirect effects. The analysis focuses on how accumulated foreign direct investment (FDI) and exchange rate fluctuations mediate these relationships. The findings reveal that global geopolitical instability decrease Russian trade by 0.0558. Interestingly, this negative impact is partially mediated by a decrease in FDI (-0.0805). This aligns with the Structural Equation Modeling (SEM) results, which show a significant negative effect of global geopolitical instability on FDI (-1.209). This suggests that FDI acts as a key transmitter of the negative effects of global instability on Russian trade. The role of exchange rate fluctuations, however, is more complex. While the Sobel Test indicated a negative indirect effect, the SEM analysis shows a positive indirect effect through",5
5baa91bb19c7387ecdfa1b5d504014e3c1a29840,A multi-task convolutional deep neural network for variant calling in single molecule sequencing,"The accurate identification of DNA sequence variants is an important, but challenging task in genomics. It is particularly difficult for single molecule sequencing, which has a per-nucleotide error rate of ~5–15%. Meeting this demand, we developed Clairvoyante, a multi-task five-layer convolutional neural network model for predicting variant type (SNP or indel), zygosity, alternative allele and indel length from aligned reads. For the well-characterized NA12878 human sample, Clairvoyante achieves 99.67, 95.78, 90.53% F1-score on 1KP common variants, and 98.65, 92.57, 87.26% F1-score for whole-genome analysis, using Illumina, PacBio, and Oxford Nanopore data, respectively. Training on a second human sample shows Clairvoyante is sample agnostic and finds variants in less than 2 h on a standard server. Furthermore, we present 3,135 variants that are missed using Illumina but supported independently by both PacBio and Oxford Nanopore reads. Clairvoyante is available open-source (https://github.com/aquaskyline/Clairvoyante), with modules to train, utilize and visualize the model. Single",1
fa02cd80e87cec4c78af29e5b9e754dfbe1922fd,SkiNet: A deep learning framework for skin lesion diagnosis with uncertainty estimation and explainability,"Skin cancer is considered to be the most common human malignancy. Around 5 million new cases of skin cancer are recorded in the United States annually. Early identification and evaluation of skin lesions are of great clinical significance, but the disproportionate dermatologist-patient ratio poses a significant problem in most developing nations. Therefore a novel deep architecture, named as SkiNet, is proposed to provide faster screening solution and assistance to newly trained physicians in the process of clinical diagnosis of skin cancer. The main motive behind SkiNet’s design and development is to provide a white box solution, addressing a critical problem of trust and interpretability which is crucial for the wider adoption of Computer-aided diagnosis systems by medical practitioners. The proposed SkiNet is a two-stage pipeline wherein the lesion segmentation is followed by the lesion classification. Monte Carlo dropout and test time augmentation techniques have been employed in the proposed method",5
2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0,"Sustainable AI: Environmental Implications, Challenges and Opportunities","This paper explores the environmental impact of the super-linear growth trends for AI from a holistic perspective, spanning Data, Algorithms, and System Hardware. We characterize the carbon footprint of AI computing by examining the model development cycle across industry-scale machine learning use cases and, at the same time, considering the life cycle of system hardware. Taking a step further, we capture the operational and manufacturing carbon footprint of AI computing and present an end-to-end analysis for what and how hardware-software design and at-scale optimization can help reduce the overall carbon footprint of AI. Based on the industry experience and lessons learned, we share the key challenges and chart out important development directions across the many dimensions of AI. We hope the key messages and insights presented in this paper can inspire the community to advance the field of AI in an environmentally-responsible manner.",5
dfdf7ff01aa6f691831e663fd29bc71890be39e2,"ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns","ChatGPT is an artificial intelligence (AI)-based conversational large language model (LLM). The potential applications of LLMs in health care education, research, and practice could be promising if the associated valid concerns are proactively examined and addressed. The current systematic review aimed to investigate the utility of ChatGPT in health care education, research, and practice and to highlight its potential limitations. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar (published research or preprints) that examined ChatGPT in the context of health care education, research, or practice. A total of 60 records were eligible for inclusion. Benefits of ChatGPT were cited in 51/60 (85.0%) records and included: (1) improved scientific writing and enhancing research equity and versatility; (2) utility in health care research (efficient analysis of datasets, code generation, literature reviews, saving time to focus on experimental design, and drug discovery and",8
68fb780a7975e890031872d9bc59db59784054e5,Building Trustworthy AI Solutions: A Case for Practical Solutions for Small Businesses,"Building trustworthy artificial intelligence (AI) solutions, whether in academia or industry, must take into consideration a number of dimensions including legal, social, ethical, public opinion, and environmental aspects. A plethora of guidelines, principles, and toolkits have been published globally, but have seen limited grassroots implementation, especially among small- and medium-sized enterprises (SMEs), mainly due to the lack of knowledge, skills, and resources. In this article, we report on qualitative SME consultations over two events to establish their understanding of both data and AI ethical principles and to identify the key barriers SMEs face in their adoption of ethical AI approaches. We then use independent experts to review and code 77 published toolkits designed to build and support ethical and responsible AI practices, based on 33 evaluation criteria. The toolkits were evaluated considering their scope to address the identified SME barriers to adoption, human-centric AI principles, AI life cycle stages, and",1
6ee01c85003010e35356b9db249b3160d224714f,Predicting drug adverse effects using a new Gastro-Intestinal Pacemaker Activity Drug Database (GIPADD),"Electrical data could be a new source of big-data for training artificial intelligence (AI) for drug discovery. A Gastro-Intestinal Pacemaker Activity Drug Database (GIPADD) was built using a standardized methodology to test drug effects on electrical gastrointestinal (GI) pacemaker activity. The current report used data obtained from 89 drugs with 4867 datasets to evaluate the potential use of the GIPADD for predicting drug adverse effects (AEs) using a machine-learning (ML) approach and to explore correlations between AEs and GI pacemaker activity. Twenty-four “electrical” features (EFs) were extracted using an automated analytical pipeline from the electrical signals recorded before and after acute drug treatment at three concentrations (or more) on four-types of GI tissues (stomach, duodenum, ileum and colon). Extracted features were normalized and merged with an online side-effect resource (SIDER) database. Sixty-six common AEs were selected. Different algorithms of classification ML models, including Naïve Bayes, discriminant analysis, classification tree, k-nearest",5
5a23a489bb9e742edacc8b8e778b06e1594365d3,Generative AI at Work,"We study the staggered introduction of a generative AI–based conversational assistant using data from 5,172 customer-support agents. Access to AI assistance increases worker productivity, as measured by issues resolved per hour, by 15% on average, with substantial heterogeneity across workers. The effects vary significantly across different agents. Less experienced and lower-skilled workers improve both the speed and quality of their output, while the most experienced and highest-skilled workers see small gains in speed and small declines in quality. We also find evidence that AI assistance facilitates worker learning and improves English fluency, particularly among international agents. While AI systems improve with more training data, we find that the gains from AI adoption are largest for moderately rare problems, where human agents have less baseline experience but the system still has adequate training data. Finally, we provide evidence that AI assistance improves the experience of work along several dimensions: customers are",2
666a7d0165514f31d58cc20d4698bbd5dedc3196,Systematic review of data-centric approaches in artificial intelligence and machine learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1,Scaling Instruction-Finetuned Language Models,"Finetuning language models on a collection of datasets phrased as instructions has been shown to improve model performance and generalization to unseen tasks. In this paper we explore instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain-of-thought data. We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation). For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PALM 540B by a large margin (+9.4% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. We also publicly release Flan-T5 checkpoints, which achieve strong few-shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the",4
d9cf759933ca5805942e4d2d16cab77f6624dcdc,Engineered exosomes for cancer theranostics: Next-generation tumor targeting,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
6af0bdfed1f4607b78409743ac72dd918e7d6160,Ground-glass opacities: A curable disease but a big challenge for surgeons.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
0fcb79c1bf66786701ebc415a7decfe9b4fbf72a,"Ai, Skill, and Productivity: The Case of Taxi Drivers","Preliminary and Incomplete. Comments are more than welcome. Abstract Artiﬁcial Intelligence (AI) is documented to have diﬀerential impacts across occupations. However, micro-level evidence is scant on how AI aﬀects the productivity of workers with diﬀerent skill levels within occupation. We study the impact of a demand-forecasting AI on productivity in the context of taxi drivers. We ﬁnd that the AI improves drivers’ productivity by shortening the time to search for customers by 5% on average. Importantly, the productivity gain is concentrated on low-skilled drivers (10%) whereas the corresponding gain on high-skilled drivers is nearly zero. This result suggests that AI, unlike past technologies, may not accompany skill-biased technological change.",5
b31c4335cd310a970b617f688b82416968a89bad,Artificial intelligence-The next frontier of scientific publications?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
19b3f04f4314ea83025ad4537c7be4055b77cd2c,Towards Personalized Preprocessing Pipeline Search,"Feature preprocessing, which transforms raw input features into numerical representations, is a crucial step in automated machine learning (AutoML) systems. However, the existing systems often have a very small search space for feature preprocessing with the same preprocessing pipeline applied to all the numerical features. This may result in sub-optimal performance since different datasets often have various feature characteristics, and features within a dataset may also have their own preprocessing preferences. To bridge this gap, we explore personalized preprocessing pipeline search, where the search algorithm is allowed to adopt a different preprocessing pipeline for each feature. This is a challenging task because the search space grows exponentially with more features. To tackle this challenge, we propose ClusterP3S, a novel framework for Personalized Preprocessing Pipeline Search via Clustering. The key idea is to learn feature clusters such that the search space can be significantly reduced by using the same preprocessing pipeline",2
b2a944853e0130244df5af15e675a1c9773e691d,"Who Is Responsible for Killer Robots? Autonomous Weapons, Group Agency, and the Military‐Industrial Complex","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
cc07fc48ce2a381e7f39235cef5fd10b939182c4,The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
a1a210d462c8bce133001b7c22913595531e1b05,Harnessing the Promise of Artificial Intelligence Responsibly.,This Viewpoint discusses the benefits and potential harms of using artificial intelligence (AI) algorithms in medicine and proposes the collaborative creation of a Code of Conduct for AI in Health Care.,5
e3b6d42ab070a148086478bb980a6a30c4d16176,Power to the Teachers: An Exploratory Review on Artificial Intelligence in Education,"This exploratory review attempted to gather evidence from the literature by shedding light on the emerging phenomenon of conceptualising the impact of artificial intelligence in education. The review utilised the PRISMA framework to review the analysis and synthesis process encompassing the search, screening, coding, and data analysis strategy of 141 items included in the corpus. Key findings extracted from the review incorporate a taxonomy of artificial intelligence applications with associated teaching and learning practice and a framework for helping teachers to develop and self-reflect on the skills and capabilities envisioned for employing artificial intelligence in education. Implications for ethical use and a set of propositions for enacting teaching and learning using artificial intelligence are demarcated. The findings of this review contribute to developing a better understanding of how artificial intelligence may enhance teachers’ roles as catalysts in designing, visualising, and orchestrating AI-enabled teaching and learning, and this will, in turn,",3
9e7cd4ce1ed4b842e8a428c3774bd06ca3a5b769,"The role of ChatGPT in higher education: Benefits, challenges, and future research directions",Abstract,4
a2c68dcfb842c327044dd15bcf4b62b1d22c57c3,A survey on XAI and natural language explanations,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
6e487e18c2aa3c08232c6167a2a8cb1e99574984,"Educational data journeys: Where are we going, what are we taking and making for AI?","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
5f996fd3592478b6923590ed5347d6206357e95a,What ChatGPT and generative AI mean for science,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
a84bc5bffba05777850852a334706eadc41d5aa6,Gradient boosting trees for auto insurance loss cost modeling and prediction,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
adf19a10b21bbc78ed0be831b6fc34d07e19f873,Evaluation of medical decision support systems (DDX generators) using real medical cases of varying complexity and origin,"Background Medical decision support systems (CDSSs) are increasingly used in medicine, but their utility in daily medical practice is difficult to evaluate. One variant of CDSS is a generator of differential diagnoses (DDx generator). We performed a feasibility study on three different, publicly available data sets of medical cases in order to identify the frequency in which two different DDx generators provide helpful information (either by providing a list of differential diagnosis or recognizing the expert diagnosis if available) for a given case report. Methods Used data sets were n = 105 cases from a web-based forum of telemedicine with real life cases from Afghanistan (Afghan data set; AD), n = 124 cases discussed in a web-based medical forum (Coliquio data set; CD). Both websites are restricted for medical professionals only. The third data set consisted 50 special case reports published in the New England Journal of Medicine (NEJM). After",2
36a8de88bddab9218e5208da6889dfb7088df217,Towards a Socially Adaptive Virtual Agent,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
5501d00310b06e00351295529498cc684187148d,GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models,"We investigate the potential implications of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to",8
7b6a8c6d44e0f77bf930484e438d77b7465a69fb,Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning,"Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment",4
d1449988086f11f1888788d42655ea20d22db97a,"The Analysis of Pethidine Pharmacokinetics in Newborn Saliva, Plasma, and Brain Extracellular Fluid After Prenatal Intrauterine Exposure from Pregnant Mothers Receiving Intramuscular Dose Using PBPK Modeling","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
49b66b980c91f989637b089c2e8284af443aaa25,"Students’ voices on generative AI: perceptions, benefits, and challenges in higher education","This study explores university students’ perceptions of generative AI (GenAI) technologies, such as ChatGPT, in higher education, focusing on familiarity, their willingness to engage, potential benefits and challenges, and effective integration. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Students recognized the potential for personalized learning support, writing and brainstorming assistance, and research and analysis capabilities. However, concerns about accuracy, privacy, ethical issues, and the impact on personal development, career prospects, and societal values were also expressed. According to John Biggs’ 3P model, student perceptions significantly influence learning approaches and outcomes. By understanding students’ perceptions, educators and policymakers can tailor GenAI technologies to address needs and concerns while promoting effective learning outcomes. Insights from this study can inform policy development around the integration of GenAI technologies into higher education. By understanding students’ perceptions",2
3de49d40bde9066c203cd7a04380483f39a907a5,Artificial intelligence explainability: the technical and ethical dimensions,"In recent years, several new technical methods have been developed to make AI-models more transparent and interpretable. These techniques are often referred to collectively as ‘AI explainability’ or ‘XAI’ methods. This paper presents an overview of XAI methods, and links them to stakeholder purposes for seeking an explanation. Because the underlying stakeholder purposes are broadly ethical in nature, we see this analysis as a contribution towards bringing together the technical and ethical dimensions of XAI. We emphasize that use of XAI methods must be linked to explanations of human decisions made during the development life cycle. Situated within that wider accountability framework, our analysis may offer a helpful starting point for designers, safety engineers, service providers and regulators who need to make practical judgements about which XAI methods to employ or to require. This article is part of the theme issue ‘Towards symbiotic autonomous systems’.",4
985675f8c89b8c70c47e61cbc472d508fedd2050,"Current Perspective of Metaverse Application in Medical Education, Research and Patient Care","As virtual and augmented reality simulation technologies advance, the use of such technologies in medicine is widespread. The advanced virtual and augmented systems coupled with a complex interactive, immersive environment create a metaverse. The metaverse enables us to connect with others in a virtual world free of spatial restrictions and time constraints. In the educational aspect, it allows collaboration among peers and educators in an immersive 3D environment that can imitate the actual classroom setting with learning tools. Metaverse technology enables visualization of virtual 3D structures, facilitates collaboration and small group activities, improves mentor–mentee interactions, provides opportunities for self-directed learning experiences, and helps develop teamwork skills. The metaverse will be adapted rapidly in healthcare, boost digitalization, and grow in use in surgical procedures and medical education. The potential advantages of using the metaverse in diagnosing and treating patients are tremendous. This perspective paper provides the current state of technology in",8
6361183fc8bd4ee0f5547956f287d63cb43d66e2,Towards a more efficient computation of individual attribute and policy contribution for post-hoc explanation of cooperative multi-agent systems using Myerson values,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
c0568670ef438aaaa6872530947c8c76de7ec53f,Sexual Secrets: The Alchemy of Ecstasy,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
cad4e03a11703fa2e9395246611be6477f9c791b,Explainable Artificial Intelligence for Process Mining: A General Overview and Application of a Novel Local Explanation Approach for Predictive Process Monitoring,"The contemporary process-aware information systems possess the capabilities to record the activities generated during the process execution. To leverage these process specific fine-granular data, process mining has recently emerged as a promising research discipline. As an important branch of process mining, predictive business process management, pursues the objective to generate forward-looking, predictive insights to shape business processes. In this study, we propose a conceptual framework sought to establish and promote understanding of decision-making environment, underlying business processes and nature of the user characteristics for developing explainable business process prediction solutions. Consequently, with regard to the theoretical and practical implications of the framework, this study proposes a novel local post-hoc explanation approach for a deep learning classifier that is expected to facilitate the domain experts in justifying the model decisions. In contrary to alternative popular perturbation-based local explanation approaches, this study defines the local regions from the validation dataset by using",1
ae5b587fb5ff55c074a770acf81c27d9d3046748,Knowledge Graph Quality Management: A Comprehensive Survey,"As a powerful expression of human knowledge in a structural form, knowledge graph (KG) has drawn great attention from both the academia and the industry and a large number of construction and application technologies have been proposed. Large-scale knowledge graphs such as DBpedia, YAGO and Wikidata are published and widely used in various tasks. However, most of them are far from perfect and have many quality issues. For example, they may contain inaccurate or outdated entries and do not cover enough facts, which limits their credibility and further utility. Data quality has a long research history in the field of traditional relational data and recently attracts more knowledge graph experts. In this paper, we provide a systematic and comprehensive review of the quality management on knowledge graphs, covering overall research topics about not only quality issues, dimentions and metrics, but also quality management processes from quality assessment and error detection,",3
c710e8455fb50db5986a04edd6ad75f1ea6bf343,Implicaciones técnicas y prácticas de las Redes Adversarias Generativas a la Ciencia Abierta en Educación,"Generative Adversarial Networks (GANs), which are characteristic of Artificial Intelligence, allow the creation of synthetic anonymised data useful for Open Science in educational research. This study experiments with the creation of artificial data from a dataset obtained from a survey on levels of use of digital tools and frequency of personal activities with technology. The original data belong to a sample of students from postgraduate degrees at the University of La Laguna. The results show an adequate degree of similarity between the original data set and the set artificially created through predictive algorithms. Obtaining synthetic datasets equivalent to the original ones in structure, shape and extension allows the release of the data to the academic community, safeguarding the protection of confidential information and contrasting a technique that allows the promotion of Open Science from the collection and processing of the data. Generative Adversarial Networks can be used in educational research",3
20916d373131f2d58b1f7a3bd54aab0b51a3ffef,The role of artificial intelligence-driven soft sensors in advanced sustainable process industries: A critical review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
50aea7bae4c478e850f218e58da0e24f501ab8fc,Abstracts written by ChatGPT fool scientists,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
6a84b0472abfc6bd872ea021e32602baf3f6093a,Correspondence Bias,"When drawing inferences about a person’s personal characteristics from their actions, “correspondence bias” is the tendency to overestimate the influence of those characteristics and underestimate the influence of situational factors, such as incentives the individual faces. We build a simple framework to formalize correspondence bias, and test its predictions in an online experiment. Consistent with correspondence bias, subjects are, on average, willing to pay to receive the dictator-game givings of an individual with whom they are randomly assigned to play a game that encourages cooperation rather than one with whom they play a game that encourages selfish behavior. We show, further, that experiencing both games oneself, as opposed to playing one and observing the other, reduces the bias, and receiving information about how each of the players behaved in both games, eliminates it.",4
6052486bc9144dc1730c12bf35323af3792a1fd0,Large language models encode clinical knowledge,"Med-PaLM, a state-of-the-art large language model for medicine, is introduced and evaluated across several medical question answering tasks, demonstrating the promise of these models in this domain. Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model^ 1 (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM^ 2 on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset",1
ad07d3499faade81e6c33069902c45b13ba90c44,Broadly applicable and accurate protein design by integrating structure prediction networks and diffusion generative models,"There has been considerable recent progress in designing new proteins using deep learning methods1–9. Despite this progress, a general deep learning framework for protein design that enables solution of a wide range of design challenges, including de novo binder design and design of higher order symmetric architectures, has yet to be described. Diffusion models10,11 have had considerable success in image and language generative modeling but limited success when applied to protein modeling, likely due to the complexity of protein backbone geometry and sequence-structure relationships. Here we show that by fine tuning the RoseTTAFold structure prediction network on protein structure denoising tasks, we obtain a generative model of protein backbones that achieves outstanding performance on unconditional and topology-constrained protein monomer design, protein binder design, symmetric oligomer design, enzyme active site scaffolding, and symmetric motif scaffolding for therapeutic and metal-binding protein design. We demonstrate the power and generality of the method, called",2
7b80ecb43658bd419f7294229f3e79f2526aabb6,Design and Research of Artificial Intelligence in Multimedia Intelligent Question-Answering System and Self-Test System,"With the development of computer science and technology, online education is gradually accepted by more and more users, and has become one of the main teaching methods in schools under the influence of the epidemic in recent years. In addition, online vocational education or higher education has also captured the psychology of national learning, and online tutoring has gradually entered into nonstudent groups such as office workers. Although online education has the advantages of low cost and no limitation of time and space, it also has some problems, such as low classroom satisfaction, delayed feedback from students, and poor teaching effect. Therefore, this paper aims at this problem by combining the development background of foreign intelligent answer system and self-test system, and introducing it into our computer application, using artificial intelligence for natural language processing, aiming at online teaching students cannot get timely answer, and self-test questions intelligent system design.",2
da9683e826c37a6383c124b5c6cddefcb35ee8fd,ChatGPT and a new academic reality: Artificial Intelligence‐written research papers and the ethics of the large language models in scholarly publishing,"This article discusses OpenAI's ChatGPT, a generative pre‐trained transformer, which uses natural language processing to fulfill text‐based user requests (i.e., a “chatbot”). The history and principles behind ChatGPT and similar models are discussed. This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing. ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts. Potential ethical issues that could arise with the emergence of large language models like GPT‐3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing.",2
0c7652599771851a5b35a1451cc1e31f6de4ebf9,Synthesis and Characterization of Cyclodextrin-Based Scaffold Incorporating Ciprofloxacin Antibacterial Agent for Skin Infection Prevention,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
1be3dad6ded1d3a58d9592b72b37fe3c35cb1d92,PLENARY: Explaining black-box models in natural language through fuzzy linguistic summaries,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
1bd32735fa93c37577ce25c45ba862ef50d5c3d6,Using Perceptual and Cognitive Explanations for Enhanced Human-Agent Team Performance,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
0403275945c0f6d96fb22f69447b70c8967403f1,Explainable AI: Beware of Inmates Running the Asylum Or: How I Learnt to Stop Worrying and Love the Social and Behavioural Sciences,"In his seminal book `The Inmates are Running the Asylum: Why High-Tech Products Drive Us Crazy And How To Restore The Sanity' [2004, Sams Indianapolis, IN, USA], Alan Cooper argues that a major reason why software is often poorly designed (from a user perspective) is that programmers are in charge of design decisions, rather than interaction designers. As a result, programmers design software for themselves, rather than for their target audience, a phenomenon he refers to as the `inmates running the asylum'. This paper argues that explainable AI risks a similar fate. While the re-emergence of explainable AI is positive, this paper argues most of us as AI researchers are building explanatory agents for ourselves, rather than for the intended users. But explainable AI is more likely to succeed if researchers and practitioners understand, adopt, implement, and improve models from the vast and valuable bodies of research in philosophy, psychology,",7
5a7f3f0fdbdc29fddc7a41098ee8bbc3f7cfd1a1,Toward Human Parity in Conversational Speech Recognition,"Conversational speech recognition has served as a flagship speech recognition task since the release of the Switchboard corpus in the 1990s. In this paper, we measure a human error rate on the widely used NIST 2000 test set for commercial bulk transcription. The error rate of professional transcribers is 5.9% for the Switchboard portion of the data, in which newly acquainted pairs of people discuss an assigned topic, and 11.3% for the CallHome portion, where friends and family members have open-ended conversations. In both cases, our automated system edges past the human benchmark, achieving error rates of 5.8% and 11.0%, respectively. The key to our system's performance is the use of various convolutional and long-short-term memory acoustic model architectures, combined with a novel spatial smoothing method and lattice-free discriminative acoustic training, multiple recurrent neural network language modeling approaches, and a systematic use of system combination. Comparing frequent errors in our",3
34b9635d7779e219e9d60e0d3d33919ca9bc123c,Publisher's Note,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",20
b099ca77c4b9acbcdc9011e8f3a12c09f9b402fb,On Defining Artificial Intelligence,"Abstract This article systematically analyzes the problem of defining “artificial intelligence.” It starts by pointing out that a definition influences the path of the research, then establishes four criteria of a good working definition of a notion: being similar to its common usage, drawing a sharp boundary, leading to fruitful research, and as simple as possible. According to these criteria, the representative definitions in the field are analyzed. A new definition is proposed, according to it intelligence means “adaptation with insufficient knowledge and resources.” The implications of this definition are discussed, and it is compared with the other definitions. It is claimed that this definition sheds light on the solution of many existing problems and sets a sound foundation for the field.",6
187decfef0b1fa036bdf23d31e962688982a20ac,Towards Intelligent-TPACK: An empirical study on teachers' professional knowledge to ethically integrate artificial intelligence (AI)-based tools into education,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
ad86edb79ac10c85bd437bc9507a498ccb7bc68c,Assessment in the age of artificial intelligence,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
dda118e8154765f73cb8f5e2b1b8daa75faf726f,Multimodal biomedical AI,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
dfede6a85afe6595130ec0bfcb73bd77de5b0232,Sparse HDLSS discrimination with constrained data piling,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
5aeea559f7f6ea5747507f55b9d5e5b5787e617b,Extending the Nested Model for User-Centric XAI: A Design Study on GNN-based Drug Repurposing,"Whether AI explanations can help users achieve specific tasks efficiently (i.e., usable explanations) is significantly influenced by their visual presentation. While many techniques exist to generate explanations, it remains unclear how to select and visually present AI explanations based on the characteristics of domain users. This paper aims to understand this question through a multidisciplinary design study for a specific problem: explaining graph neural network (GNN) predictions to domain experts in drug repurposing, i.e., reuse of existing drugs for new diseases. Building on the nested design model of visualization, we incorporate XAI design considerations from a literature review and from our collaborators' feedback into the design process. Specifically, we discuss XAI-related design considerations for usable visual explanations at each design layer: target user, usage context, domain explanation, and XAI goal at the domain layer; format, granularity, and operation of explanations at the abstraction layer; encodings and interactions at the visualization",3
3f78a5cd1514c6aeaa9c1bf12d6eb61b7d122794,Artificial intelligence assists nanoparticles to enter solid tumours,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
0d2c38b39f73003ec23ee3e2382e319e20bd5d18,Using Machine Learning to Identify Diseases and Perform Sorting in Apple Fruit,"Fruit diseases play a major role in global agriculture, leading to substantial crop losses and influencing food production and economic stability. In this age of Industry 4.0 the fruit sorting is an important part in the food processing wherein this work plays a vital role. In this study, a solution for the detection and classification of apple fruit diseases is proposed and experimentally validated. Deep learning models offer promise for automating disease identification using fruit images, but encounter obstacles such as therequirement for extensive training data, computational complexity, and the risk of overfitting. This study introduces an innovative convolutional neural network (CNN) architecture aimed at addressing these challenges by incorporating a reduced number of layers, thus alleviating computational burdens while maintaining performance. Additionally, augmentation techniques such as shift, shear, scaling, zoom, and flipping are employed to diversify the training set without additional image acquisition. Our CNN model is specifically trained",4
e9d53197af401bf5a68c457f22f865f8912744be,Machine learning techniques for mortality modeling,"Various stochastic models have been proposed to estimate mortality rates. In this paper we illustrate how machine learning techniques allow us to analyze the quality of such mortality models. In addition, we present how these techniques can be used for differentiating the different causes of death in mortality modeling.",2
98fe695240b3ab9cd0ef771dd094a1d5f13c28b6,Is Probability Theory Sufficient for Dealing with Uncertainty in AI: A Negative View,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
c1a26a507b79e510916956ecf13156c9e4b33c31,Multi-domain medical image translation generation for lung image classification based on generative adversarial networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
9a846de6cbd1aed0ff8b93160af59783e6bdd66b,Could AI help you to write your next paper?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
c0c789bfcac6c5d723f49feb47e939a9afe8a219,Expl(AI)n It to Me – Explainable AI and Information Systems Research,"The field of Artificial Intelligence has seen dramatic progress over the last 15 years. Using machine learning methods, software systems that automatically learn and improve relationships using digitized experience, researchers and practitioners alike have developed practical applications that are indispensable and strongly facilitate people's everyday life [Jordan and Mitchell 2015]. Pervasive examples include object recognition (e.g., Facebook's Moments and Intel Security's True Key), natural language processing (e.g., DeepL and Google Translate), recommender systems (e.g., recommendations by Netflix or iTunes), and digital assistants (e.g., Alexa and Siri). At its core, these applications have in common that highly complex and increasingly opaque networks of mathematical constructs are trained using historical data to make predictions about an uncertain state of the world. Based on large sets of labeled images, Deep Convolutional Neural Networks, for instance, can learn to make highly accurate individual-level predictions about the presence of diseases. This includes predicting positive COVID-19",5
827d8e365604cb454258df7f69f259f10de51efd,A survey on data fusion in internet of things: Towards secure and privacy-preserving fusion,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
7717fb014261b44734acf41715dddcbc011397c3,"Reasoning foundations of medical diagnosis; symbolic logic, probability, and value theory aid our understanding of how physicians reason.","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
f527bacebbbfc46719d50eed61a8b2114a39bb72,The Book of Why: The New Science of Cause and Effect,"This week on the Science podcast, Judea Pearl and Dana Mackenzie discuss strategies for causal thinking and describe its implications for artificial intelligence.",4
ba7a63f8636c7509f0af0538edb2e1f82fd421fd,Measuring Data Leakage in Machine-Learning Models with Fisher Information,"Machine-learning models contain information about the data they were trained on. This information leaks either through the model itself or through predictions made by the model. Consequently, when the training data contains sensitive attributes, assessing the amount of information leakage is paramount. We propose a method to quantify this leakage using the Fisher information of the model about the data. Unlike the worst-case a priori guarantees of differential privacy, Fisher information loss measures leakage with respect to specific examples, attributes, or sub-populations within the dataset. We motivate Fisher information loss through the Cramer-Rao bound and delineate the implied threat model. We provide efficient methods to compute Fisher information loss for output-perturbed generalized linear models. Finally, we empirically validate Fisher information loss as a useful measure of information leakage.",2
e0ac105018b58ed692412a8ef339b46866fa11f3,Development and Validation of Deep Learning-based Automatic Detection Algorithm for Malignant Pulmonary Nodules on Chest Radiographs.,"Purpose To develop and validate a deep learning-based automatic detection algorithm (DLAD) for malignant pulmonary nodules on chest radiographs and to compare its performance with physicians including thoracic radiologists. Materials and Methods For this retrospective study, DLAD was developed by using 43 292 chest radiographs (normal radiograph-to-nodule radiograph ratio, 34 067:9225) in 34 676 patients (healthy-to-nodule ratio, 30 784:3892; 19 230 men [mean age, 52.8 years; age range, 18-99 years]; 15 446 women [mean age, 52.3 years; age range, 18-98 years]) obtained between 2010 and 2015, which were labeled and partially annotated by 13 board-certified radiologists, in a convolutional neural network. Radiograph classification and nodule detection performances of DLAD were validated by using one internal and four external data sets from three South Korean hospitals and one U.S. hospital. For internal and external validation, radiograph classification and nodule detection performances of DLAD were evaluated by using the area under the",7
358fdbe82307cf7f77c5b0f6fbfee2b64760c681,On Chatbots and Generative Artificial Intelligence.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
448172b572745af591f3be00094585ff3841e3fa,AI technologies and employment: micro evidence from the supply side,"ABSTRACT In this work we investigate the possible job-creation impact of artificial intelligence (AI) technologies, focusing on the supply side, where the development of these technologies can be conceived as product innovations in upstream sectors. The empirical analysis is based on a worldwide longitudinal sample (obtained by merging the EPO PATSTAT and BvD-ORBIS databases) of more than 3,500 front-runner companies that patented AI-related inventions over the period 2000–2016. Based on system GMM estimates of dynamic panel models, our results show a positive and significant impact of AI patent families on employment, supporting the labour-friendly nature of AI product innovation.",3
5425de16356015c2f26d2a50684c6c46d6998f51,"MIMIC-IV, a freely accessible electronic health record dataset","Digital data collection during routine clinical practice is now ubiquitous within hospitals. The data contains valuable information on the care of patients and their response to treatments, offering exciting opportunities for research. Typically, data are stored within archival systems that are not intended to support research. These systems are often inaccessible to researchers and structured for optimal storage, rather than interpretability and analysis. Here we present MIMIC-IV, a publicly available database sourced from the electronic health record of the Beth Israel Deaconess Medical Center. Information available includes patient measurements, orders, diagnoses, procedures, treatments, and deidentified free-text clinical notes. MIMIC-IV is intended to support a wide array of research studies and educational material, helping to reduce barriers to conducting clinical research. Measurement(s) Homo sapiens Technology Type(s) Electronic Health Record Sample Characteristic - Organism Homo sapiens Sample Characteristic - Environment hospital Sample Characteristic - Location Commonwealth of Massachusetts",2
4e4fdc150434a27762fbf4a7190b2c0a81c63cbf,CRISPR/Cas9 Genome Editing for Tissue‐Specific In Vivo Targeting: Nanomaterials and Translational Perspective,"Clustered randomly interspaced short palindromic repeats (CRISPRs) and its associated endonuclease protein, i.e., Cas9, have been discovered as an immune system in bacteria and archaea; nevertheless, they are now being adopted as mainstream biotechnological/molecular scissors that can modulate ample genetic and nongenetic diseases via insertion/deletion, epigenome editing, messenger RNA editing, CRISPR interference, etc. Many Food and Drug Administration‐approved and ongoing clinical trials on CRISPR adopt ex vivo strategies, wherein the gene editing is performed ex vivo, followed by reimplantation to the patients. However, the in vivo delivery of the CRISPR components is still under preclinical surveillance. This review has summarized the nonviral nanodelivery strategies for gene editing using CRISPR/Cas9 and its recent advancements, strategic points of view, challenges, and future aspects for tissue‐specific in vivo delivery of CRISPR/Cas9 components using nanomaterials.",1
3dbe2b18393c34dc30f057949e6d31e3ef6efd90,Deep neural network improves fracture detection by clinicians,"Significance Historically, computer-assisted detection (CAD) in radiology has failed to achieve improvements in diagnostic accuracy, decreasing clinician sensitivity and leading to unnecessary further diagnostic tests. With the advent of deep learning approaches to CAD, there is great excitement about its application to medicine, yet there is little evidence demonstrating improved diagnostic accuracy in clinically-relevant applications. We trained a deep learning model to detect fractures on radiographs with a diagnostic accuracy similar to that of senior subspecialized orthopedic surgeons. We demonstrate that when emergency medicine clinicians are provided with the assistance of the trained model, their ability to accurately detect fractures significantly improves. Suspected fractures are among the most common reasons for patients to visit emergency departments (EDs), and X-ray imaging is the primary diagnostic tool used by clinicians to assess patients for fractures. Missing a fracture in a radiograph often has severe consequences for patients, resulting in delayed treatment and",6
aa1281dab5a23b7f603f1d5386b2dc0e8d8b0b0a,Large-scale identification of patients with cerebral aneurysms using natural language processing,"Objective: To use natural language processing (NLP) in conjunction with the electronic medical record (EMR) to accurately identify patients with cerebral aneurysms and their matched controls. Methods: ICD-9 and Current Procedural Terminology codes were used to obtain an initial data mart of potential aneurysm patients from the EMR. NLP was then used to train a classification algorithm with .632 bootstrap cross-validation used for correction of overfitting bias. The classification rule was then applied to the full data mart. Additional validation was performed on 300 patients classified as having aneurysms. Controls were obtained by matching age, sex, race, and healthcare use. Results: We identified 55,675 patients of 4.2 million patients with ICD-9 and Current Procedural Terminology codes consistent with cerebral aneurysms. Of those, 16,823 patients had the term aneurysm occur near relevant anatomic terms. After training, a final algorithm consisting of 8 coded and 14 NLP variables was selected, yielding an",3
9ae70ff3f55f38f815bcd8ac0ed93f361dee35d1,Getting value from artificial intelligence in agriculture,"Artificial intelligence (AI) is beginning to live up to its promise of delivering real value, driven by recent advances in the availability of relevant data, computation and algorithms. In the present paper, I discuss the value to agriculture from AI over the next decade. The more immediate applications will be to improve precision information about what is happening on the farm by improving what is being detected and measured. A consequence of this are more accurate alerts to farmers. Another is an increased ability to understand why phenomena occur in farm systems, so as to improve their management. From improved data and understanding come improved predictions, enabling more optimal decisions about how to manage farm systems and stimulating the development of decision support and recommender systems. In many cases, robotics and automated systems will remove much of the need for human decision-making and improve farm efficiencies and farm health. Artificial",5
58bb24b72fea6d0ce172bdaf9c2f16c2bd7649e9,Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI,"The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and human rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles,"" there has been little scholarly focus on understanding these efforts either individually or as contextualized within an expanding universe of principles with discernible trends. To that end, this white paper and its associated data visualization compare the contents of thirty-six prominent AI principles documents side-by-side. This effort uncovered a growing consensus around eight key thematic trends: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. Underlying this “normative core,” our analysis examined the forty-seven individual principles that make up the themes, detailing notable similarities and differences in interpretation found across the documents. In sharing these observations, it is our hope that policymakers,",2
d9b34c6b616f75485856794478bfbeab1ea93b81,Perspectives in machine learning for wildlife conservation,"Inexpensive and accessible sensors are accelerating data acquisition in animal ecology. These technologies hold great potential for large-scale ecological understanding, but are limited by current processing approaches which inefficiently distill data into relevant information. We argue that animal ecologists can capitalize on large datasets generated by modern sensors by combining machine learning approaches with domain knowledge. Incorporating machine learning into ecological workflows could improve inputs for ecological models and lead to integrated hybrid modeling tools. This approach will require close interdisciplinary collaboration to ensure the quality of novel approaches and train a new generation of data scientists in ecology and conservation. Animal ecologists are increasingly limited by constraints in data processing. Here, Tuia and colleagues discuss how collaboration between ecologists and data scientists can harness machine learning to capitalize on the data generated from technological advances and lead to novel modeling approaches.",4
363e72aab77a9914f1aca06a8263b8e397340c91,Emerging-market consumers' interactions with banking chatbots,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
c56b9e84f113f3e558b1d8fcccf92fbbbf6b5174,Comprehensibility of Classification Trees–Survey Design,": Comprehensibility is the decisive factor for application of classifiers in practice. However, most algorithms that learn comprehensible classifiers use classification model size as a metric that guides the search in the space of all possible classifiers instead of comprehensibility - which is ill-defined. Several surveys have shown that such simple complexity metrics do not correspond well to the comprehensibility of classification trees. This paper therefore suggests a classification tree comprehensibility survey in order to derive an exhaustive comprehensibility metrics better reflecting the human sense of classifier comprehensibility and obtain new insights about comprehensibility of classification trees",2
0d25a53184a9c56084416b292de9a8fef4b27347,Tools such as ChatGPT threaten transparent science; here are our ground rules for their use,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
380a6de689a2000b964fef006442147e2a88a07c,A single trial analysis of EEG in recognition memory: Tracking the neural correlates of memory strength,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
aa12a2375d98ee30b19ad55b66f8cda225eaff1a,Estimating diagnostic uncertainty in artificial intelligence assisted pathology using conformal prediction,"Unreliable predictions can occur when an artificial intelligence (AI) system is presented with data it has not been exposed to during training. We demonstrate the use of conformal prediction to detect unreliable predictions, using histopathological diagnosis and grading of prostate biopsies as example. We digitized 7788 prostate biopsies from 1192 men in the STHLM3 diagnostic study, used for training, and 3059 biopsies from 676 men used for testing. With conformal prediction, 1 in 794 (0.1%) predictions is incorrect for cancer diagnosis (compared to 14 errors [2%] without conformal prediction) while 175 (22%) of the predictions are flagged as unreliable when the AI-system is presented with new data from the same lab and scanner that it was trained on. Conformal prediction could with small samples (N = 49 for external scanner, N = 10 for external lab and scanner, and N = 12 for external lab, scanner and pathology assessment) detect",4
18961b843e322bfea7f37cda5ef73fb0e432400c,Explainability-Based Mix-Up Approach for Text Data Augmentation,"Text augmentation is a strategy for increasing the diversity of training examples without explicitly collecting new data. Owing to the efficiency and effectiveness of text augmentation, numerous augmentation methodologies have been proposed. Among them, the method based on modification, particularly the mix-up method of swapping words between two or more sentences, is widely used because it can be applied simply and shows good levels of performance. However, the existing mix-up approaches are limited; they do not reflect the importance of the manipulated word. That is, even if a word that has a critical effect on the classification result is manipulated, it is not considered significant in labeling the augmented data. Therefore, in this study, we propose an effective text augmentation technique that explicitly derives the importance of manipulated words and reflects this importance in the labeling of augmented data. The importance of each word, in other words, explainability, is calculated,",7
ef76b9a961d152f79484ee9326baaa9f7bb089ab,Data-centric AI: Perspectives and Challenges,"The role of data in building AI systems has recently been significantly magnified by the emerging concept of data-centric AI (DCAI), which advocates a fundamental shift from model advancements to ensuring data quality and reliability. Although our community has continuously invested efforts into enhancing data in different aspects, they are often isolated initiatives on specific tasks. To facilitate the collective initiative in our community and push forward DCAI, we draw a big picture and bring together three general missions: training data development, inference data development, and data maintenance. We provide a top-level discussion on representative DCAI tasks and share perspectives. Finally, we list open challenges. More resources are summarized at https://github.com/daochenzha/data-centric-AI",9
d5f47c2b4b729dd067706159e9c4857a41f8ef98,Knowledge fusion patterns: A survey,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
0e0718efb66091795b780190132be89ab5e11f05,Discrete tree seed algorithm for urban land readjustment,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
1b32b77718be22ca31c2a0dba709c815e19d4672,Ethics Guidelines for Trustworthy AI,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
4638c153cdefafcf5a80588ec93ade6a5558d490,SIMCal: A High-Performance Toolkit For Calibrating Traffic Simulation,"Traffic simulators have many parameters that describe vehicle characteristics and driving behaviors. However, driving behaviors differ across urban, suburban, and rural areas. Even in the same area, driving behavior can be affected by the time of day or weather conditions. Therefore, it is difficult to get an accurate parameter set that is suitable for all scenarios. As a result, default parameters of simulators are usually determined only for a specific test case. To simulate a traffic scenario, researchers need to perform calibration to determine a suitable parameter set, which can provide more reliable simulated traffic than the default parameter set. A popular approach is manual calibration using human experience, but it is usually not effective due to the huge space of possible parameters. Although some studies proposed automated methods using evolutionary algorithms, implementing these methods is a time-consuming job. In this paper, we introduce a toolkit for researchers to easily",5
4c48b91583a3ec5bc35137b02873d5f98a8430a3,"""What Can ChatGPT Do?"" Analyzing Early Reactions to the Innovative AI Chatbot on Twitter","In this study, the author collected tweets about ChatGPT, an innovative AI chatbot, in the first month after its launch. A total of 233,914 English tweets were analyzed using the latent Dirichlet allocation (LDA) topic modeling algorithm to answer the question “what can ChatGPT do?”. The results revealed three general topics: news, technology, and reactions. The author also identified five functional domains: creative writing, essay writing, prompt writing, code writing, and answering questions. The analysis also found that ChatGPT has the potential to impact technologies and humans in both positive and negative ways. In conclusion, the author outlines four key issues that need to be addressed as a result of this AI advancement: the evolution of jobs, a new technological landscape, the quest for artificial general intelligence, and the progress-ethics conundrum.",6
a9c0d7bad124697e370a1b345508b6bc618a4f64,Ethics of generative AI,"Artificial intelligence (AI) and its introduction into clinical pathways presents an array of ethical issues that are being discussed in the JME. The development of AI technologies that can produce text that will pass plagiarism detectors and are capable of appearing to be written by a human author present new issues for medical ethics. One set of worries concerns authorship and whether it will now be possible to know that an author or student in fact produced submitted work. That seems likely to be a general worry for secondary and higher education, as well as for all academic journals. Thus far generative AI chatbots do not seem to be able to produce a fully referenced and wellargued ethics article, but they probably could generate a blog or student essay that would be hard to detect after very minor edits. Many schools and universities have moved to online forms of assessment,",6
1ada6fe96d54e9dfbd4fd16016f53bd0b2d3936b,"Automation After the Assembly Line: Computerized Machine Tools, Employment and Productivity in the United States","Since the 1970s, computerized machine tools have been replacing semi-skilled manufacturing workers, contributing to factory automation. We build a novel measure of exposure to computer numerical control (CNC) based on initial variation in tool types across industries and differential shifts toward CNC technology by tool type over time. Industries more exposed to CNC increased capital investment and experienced higher labor productivity. Total employment rose, with gains for college-educated workers and abstract tasks compensating for losses of less-educated workers and routine tasks. Employment gains were strongest for unionized jobs. Workers in exposed industries returned to school and relevant degree programs expanded. Leah Platt Boustan Princeton University Industrial Relations Section Louis A. Simpson International Bldg. Princeton, NJ 08544 and NBER lboustan@princeton.edu Jiwon Choi Industrial Relations Section Louis A. Simpson International Bldg. Princeton University Princeton, NJ 08544 jwchoi@princeton.edu David Clingingsmith Department of Economics Case Western Reserve University 10900 Euclid Ave. Cleveland, OH 44106",5
769b9bfc65ccf7d32925f813a39b26e59bbda810,Affordances and challenges of artificial intelligence in K-12 education: a systematic review,"Abstract Artificial Intelligence in Education (AIEd) has experienced a rapid rise in the past decade. This systematic review is the first examining the use of AIEd in K-12 including 169 extant studies from 2011 to 2021. This study provides contextual information from the research, such as the educational disciplines, educational levels, research purposes, methodologies, year published and who the AI was intended to support. The grounded coding revealed affordances fit into three main themes of AIEd connecting to pedagogies (e.g., gaming, personalization), administration (e.g., diagnostic tools), and subject content. Challenges in AIEd K-12 included issues toward negative perceptions, lack of student and teacher technology skills, ethical concerns, and issues directly with the ease of use and design of the AI tools.",4
fd44d398b2945b4c20da8ec3cc32becd5e08100e,Local Rule-Based Explanations of Black Box Decision Systems,"The recent years have witnessed the rise of accurate but obscure decision systems which hide the logic of their internal decision processes to the users. The lack of explanations for the decisions of black box systems is a key ethical issue, and a limitation to the adoption of machine learning components in socially sensitive and safety-critical contexts. %Therefore, we need explanations that reveals the reasons why a predictor takes a certain decision. In this paper we focus on the problem of black box outcome explanation, i.e., explaining the reasons of the decision taken on a specific instance. We propose LORE, an agnostic method able to provide interpretable and faithful explanations. LORE first leans a local interpretable predictor on a synthetic neighborhood generated by a genetic algorithm. Then it derives from the logic of the local interpretable predictor a meaningful explanation consisting of: a decision rule, which explains the reasons of",7
4fbd3d65628185bc301f98977d01acbd8126a709,CRISPR/Cas9 Genome Editing for Tissue‐Specific In Vivo Targeting: Nanomaterials and Translational Perspective,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
5b7b6eb10da360ada5861dad700d4515003d3f9a,Data Management and Integration of Low Power Consumption Embedded Devices IoT for Transforming Smart Agriculture into Actionable Knowledge,"Smart agriculture today uses a wide range of wireless communication technologies. Low Power Consumption Embedded Devices (LPCED), such as the Internet of Things (IoT) and Wireless Sensor Networks, make it possible to work over great distances at a reduced cost but with limited transferable data volumes. However, data management (DM) in intelligent agriculture is still not well understood due to the fact that there are not enough scientific publications available on this. Though data management (DM) benefits are factual and substantial, many challenges must be addressed in order to fully realize the DM’s potential. The main difficulties are data integration complexities, the lack of skilled personnel and sufficient resources, inadequate infrastructure, and insignificant data warehouse architecture. This work proposes a comprehensive architecture that includes big data technologies, IoT components, and knowledge-based systems. We proposed an AI-based architecture for smart farming. This architecture called, Smart Farming Oriented Big-Data Architecture (SFOBA), is",2
16089042763013220961bacbc598fff544985944,Augmented Attention: Enhancing Morph Detection in Face Recognition,"Face Morphing is a technique that involves blending two or more faces to create new often realistic- looking images. These morphed images are generated or created using morphing techniques or photo manipulation tools pose a significant peril to face recognition systems. In this paper, we proposed a method to improve deep learning based face morphing detection systems to be more robust against face morphing attacks. Leveraging deep learning models and algorithms including MTCNN (Multitask Cascaded Convolutional Neural Network) for efficient face extraction from original and morphed faces with a high accuracy and FaceNet for extracting unified embeddings from the faces. The project aims to push the boundaries of face morphing detection capabilities by leveraging feature combination techniques using cosine distance and SSIM(structural similarity index measure) for identifying the similarity between faces and applying spatial attention mechanism which aims to enhance the feature representation learned by the model by focusing on",3
55025d2119f6cae223e68a69796a654f0749a970,Preparing teachers for the application of AI-powered technologies in foreign language education,"Abstract As any other area of human lives, current state of foreign language education has been greatly influenced by the latest developments in the modern information communication technologies. The paper focuses specifically on the incorporation of artificial intelligence (AI), which includes a wide range of technologies and methods, such as machine learning, adaptive learning, natural language processing, data mining, crowdsourcing, neural networks or an algorithm, into foreign language learning and teaching. First, the paper is concerned with changes brought to foreign language education specifically through the application of AI-powered tools and discusses ICALL (intelligent computer assisted language learning) as a subset of CALL. Second, it summarizes eight types of AI-powered tools for foreign language education and related results of the existing research, however scarce it is. Third, it discusses the frame for effective preparation of foreign language teachers in order to integrate AI-powered tools into their teaching to make it",6
55b59cf4404f121edb15f69c2493c87eb36a5530,Explainable Artificial Intelligence in education,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
8ef09c4e16f8215a5e545c45d65900306544d885,Deep learning-guided discovery of an antibiotic targeting Acinetobacter baumannii,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
3b7236a0c0163ed13b9f5eb4ba91c462b81e4d6e,Deep learning-based quantification of NAFLD/NASH progression in human liver biopsies,"Non-alcoholic fatty liver disease (NAFLD) affects about 24% of the world's population. Progression of early stages of NAFLD can lead to the more advanced form non-alcoholic steatohepatitis (NASH), and ultimately to cirrhosis or liver cancer. The current gold standard for diagnosis and assessment of NAFLD/NASH is liver biopsy followed by microscopic analysis by a pathologist. The Kleiner score is frequently used for a semi-quantitative assessment of disease progression. In this scoring system the features of active injury (steatosis, inflammation, and ballooning) and a separated fibrosis score are quantified. The procedure is time consuming for pathologists, scores have limited resolution and are subject to variation. We developed an automated deep learning method that provides full reproducibility and higher resolution. The system was established with 296 human liver biopsies and tested on 171 human liver biopsies with pathologist ground truth scores. The method is inspired by the way pathologist's analyze liver biopsies.",3
04dec21662614458207509ba7389f75838180c5f,IoT-Driven Artificial Intelligence Technique for Fertilizer Recommendation Model,"Smart farming systems emphasize the need for modern technologies like the Internet of Things, Cloud, and Artificial Intelligence (AI) in the agricultural process. The digital transformation accelerates conventional farming practices to increase crop production with quality. Earlier works failed to integrate AI with sensor technology, guiding agricultural practitioners in a successful direction. Therefore, we propose an architectural model with four layers, including sensor, network, service, and application, aid in deploying a smart farming system with limited energy consumption. Moreover, focusing on the application layer, we implement a deep learning approach to build a fertilizer recommendation system that matches the expert's opinion. Finally, the whole system outcomes are presented as a single mobile application for farmers’ ease of use.",3
170f4e654e96e08d7c3d8150a03229317ea77ca4,Greybox XAI: a Neural-Symbolic learning framework to produce interpretable predictions for image classification,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
ed15d0f9a8eb3728931e772822314efde340e0b1,The Future of AI in Medicine: A Perspective from a Chatbot,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
9d39f163d741e1fd4c0376735319d24d68a8ef51,GENERATIVE PRE-TRAINED TRANSFORMER 3,"GPT (Generative Pre-training Transformer) — це тип штучного інтелекту (AI), який використовує алгоритми машинного навчання для створення тексту природною мовою. Перша версія GPT, випущена в 2018 році, стала революційним досягненням у сфері ШІ та обробки природної мови (NLP). Однак він також мав деякі обмеження та проблеми, які були розглянуті в наступних версіях моделі. Однією з головних проблем першої версії GPT була відсутність контролю над контентом, який вона генерувала. Модель було навчено на великому наборі даних тексту, створеного людиною, і вона змогла створити зв’язний і, здавалося б, людиноподібний текст на широкий спектр тем. Однак він часто створював текст, який був упередженим, образливим або іншим чином недоречним, оскільки він не міг повністю зрозуміти контекст або значення використаних слів. Іншою проблемою першої версії GPT була її нездатність виконувати складніші завдання NLP, такі як переклад або конспектування. Хоча він міг створити зв’язний текст, він не міг зрозуміти значення чи структуру тексту так, як це",3
3090f615feb56cb13da0cfc7bbcb1b6b8dbe0a7d,Gentle Introduction to Artificial Intelligence for High-School Students Using Scratch,"The importance of educating the next generations in the understanding of the fundamentals of the upcoming scientific and technological innovations that will force a broad social and economical paradigm change can not be overstressed. One such breakthrough technologies is Artificial Intelligence (AI), specifically machine learning algorithms. Nowadays, the public has little understanding of the workings and implications of AI techniques that are already entering their lives in many ways. We aim to achieve widespread public understanding of these issues in an experiential learning framework. Following a design based research approach, we propose to implement program coding scaffoldings to teach and experiment some basic mechanisms of AI systems. Such experiments would be shedding new light into AI potentials and limitations. In this paper we focus on innovative ways to introduce high school students to the fundamentals and operation of two of the most popular AI algorithms. We describe the elements of",4
6d0f8427064a7eaa04947a2ba4c91c98efa734da,Get a Model! Model Hijacking Attack Against Machine Learning Models,"Machine learning (ML) has established itself as a cornerstone for various critical applications ranging from autonomous driving to authentication systems. However, with this increasing adoption rate of machine learning models, multiple attacks have emerged. One class of such attacks is training time attack, whereby an adversary executes their attack before or during the machine learning model training. In this work, we propose a new training time attack against computer vision based machine learning models, namely model hijacking attack. The adversary aims to hijack a target model to execute a different task than its original one without the model owner noticing. Model hijacking can cause accountability and security risks since a hijacked model owner can be framed for having their model offering illegal or unethical services. Model hijacking attacks are launched in the same way as existing data poisoning attacks. However, one requirement of the model hijacking attack is to be",5
833c81f290b27386eb750afca760d3522c6b8f6c,Evidence for intrinsic charm quarks in the proton,"The theory of the strong force, quantum chromodynamics, describes the proton in terms of quarks and gluons. The proton is a state of two up quarks and one down quark bound by gluons, but quantum theory predicts that in addition there is an infinite number of quark–antiquark pairs. Both light and heavy quarks, whose mass is respectively smaller or bigger than the mass of the proton, are revealed inside the proton in high-energy collisions. However, it is unclear whether heavy quarks also exist as a part of the proton wavefunction, which is determined by non-perturbative dynamics and accordingly unknown: so-called intrinsic heavy quarks1. It has been argued for a long time that the proton could have a sizable intrinsic component of the lightest heavy quark, the charm quark. Innumerable efforts to establish intrinsic charm in the proton2 have remained inconclusive. Here we provide evidence for intrinsic charm by exploiting a",4
8afe1a3072bb8e42ae91cc6f1fbf4b662be74178,Quality Control to Reduce Appearance Defects at PT. Musical Instrument,"This research was conducted at PT. Musical Instruments that aim to analyze quality control to reduce appearance defects in piano products on the assembling production line. The problem faced by the company is the high level of product defects which has an impact on decreasing quality and customer satisfaction. The research method used is Six sigma with a DMAIC (Define, Measure, Analyze, Improve, Control) approach. This type of research is quantitative, with data collected in the form of the number of production defects in pianos. To analyze the causes of defects, a fishbone diagram with 4M + 1E factors is used, namely Man, Machine, Method, Material, and Environment. The results of the analysis show that the main factors causing appearance defects in piano products include incompatibility with work methods, lack of worker training, use of non-standard materials, suboptimal jig conditions, and unsupportive working environment. Based on these findings, improvement proposals",4
b36acdfc67612d707c95d1ed282672d3ca262be7,"Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers","Background Large language models such as ChatGPT can produce increasingly realistic text, with unknown information on the accuracy and integrity of using these models in scientific writing. Methods We gathered ten research abstracts from five high impact factor medical journals (n=50) and asked ChatGPT to generate research abstracts based on their titles and journals. We evaluated the abstracts using an artificial intelligence (AI) output detector, plagiarism detector, and had blinded human reviewers try to distinguish whether abstracts were original or generated. Results All ChatGPT-generated abstracts were written clearly but only 8% correctly followed the specific journal’s formatting requirements. Most generated abstracts were detected using the AI output detector, with scores (higher meaning more likely to be generated) of median [interquartile range] of 99.98% [12.73, 99.98] compared with very low probability of AI-generated output in the original abstracts of 0.02% [0.02, 0.09]. The AUROC of the AI output detector was 0.94.",6
dd4e4c2e529f4daed5f5c3c834d4a801953cc379,"How does the ""Zero-waste City"" strategy contribute to carbon footprint reduction in China?","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
46be66dd304031b01941b2a58eb16e47f48b920b,Publisher Correction: Enabling precision medicine by unravelling disease pathophysiology: quantifying signal transduction pathway activity across cell and tissue types,An amendment to this paper has been published and can be accessed via a link at the top of the paper.,3
e3bd45892ff2d502eaad65e9b0858d213111e9ae,An explainable predictive model for suicide attempt risk using an ensemble learning and Shapley Additive Explanations (SHAP) approach.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
064136131d79ea011e07b6a7766f1634ac1a5a34,Self-Driving Car Steering Angle Prediction Based on Image Recognition,"Self-driving vehicles have expanded dramatically over the last few years. Udacity has release a dataset containing, among other data, a set of images with the steering angle captured during driving. The Udacity challenge aimed to predict steering angle based on only the provided images. We explore two different models to perform high quality prediction of steering angles based on images using different deep learning techniques including Transfer Learning, 3D CNN, LSTM and ResNet. If the Udacity challenge was still ongoing, both of our models would have placed in the top ten of all entries.",6
da7ac4bebc7c11f30026b0db76bcd9ba474c3372,Contrastive Constraints Guide Explanation-Based Category Learning,"This paper provides evidence for a contrastive account of explanation that is motivated by pragmatic theories that recognize the contribution that context makes to the interpretation of a prompt for explanation. This study replicates the primary findings of previous work in explanation-based category learning (Williams & Lombrozo, 2010), extending that work by illustrating the critical role of the context in this type of learning. Participants interacted with items from two categories either by describing the items or explaining their category membership. We manipulated the feature overlap between the categories and examined both the explanations generated and acquired knowledge of the categories. Explanations for membership in a given category were influenced by the unprompted contrast category, indicating an important role for contrastive processing in the generation of explanations. The influence of the contrast category was similarly seen in the transfer performance of the participants.",5
9b3e1573eb7baaefe23753ea71b61cefb036d03d,Strategies to save energy in the context of the energy crisis: a review,"New technologies, systems, societal organization and policies for energy saving are urgently needed in the context of accelerated climate change, the Ukraine conflict and the past coronavirus disease 2019 pandemic. For instance, concerns about market and policy responses that could lead to new lock-ins, such as investing in liquefied natural gas infrastructure and using all available fossil fuels to compensate for Russian gas supply cuts, may hinder decarbonization efforts. Here we review energy-saving solutions with a focus on the actual energy crisis, green alternatives to fossil fuel heating, energy saving in buildings and transportation, artificial intelligence for sustainable energy, and implications for the environment and society. Green alternatives include biomass boilers and stoves, hybrid heat pumps, geothermal heating, solar thermal systems, solar photovoltaics systems into electric boilers, compressed natural gas and hydrogen. We also detail case studies in Germany which is planning a 100% renewable energy switch by 2050 and",5
a6165cd7ae9d94dec4469b757f9f88318237fa1b,On the prediction of claim duration for income protection insurance policyholders,"Abstract This paper explores how we can apply various modern data mining techniques to better understand Australian Income Protection Insurance (IPI). We provide a fast and objective method of scoring claims into different portfolios using available rating factors. Results from fitting several prediction models are compared based on not only the conventional loss prediction error function, but also a modified loss function. We demonstrate that the prediction power of all the data mining methods under consideration is clearly evident using a misclassification plot. We also point out that this predictability can be masked by looking at just the conventional prediction error function. We then suggest using the stepwise regression technique to reduce the number of variables used in the data mining methods. Apart from this variable selection method, we also look at principal components analysis to increase understanding of the rating factors that drive claim durations of insured lives. We",2
b4a04fe01ca31caf647e99c587123f7457fea721,Artificial Intelligence Education Programs for Health Care Professionals: Scoping Review,"Background As the adoption of artificial intelligence (AI) in health care increases, it will become increasingly crucial to involve health care professionals (HCPs) in developing, validating, and implementing AI-enabled technologies. However, because of a lack of AI literacy, most HCPs are not adequately prepared for this revolution. This is a significant barrier to adopting and implementing AI that will affect patients. In addition, the limited existing AI education programs face barriers to development and implementation at various levels of medical education. Objective With a view to informing future AI education programs for HCPs, this scoping review aims to provide an overview of the types of current or past AI education programs that pertains to the programs’ curricular content, modes of delivery, critical implementation factors for education delivery, and outcomes used to assess the programs’ effectiveness. Methods After the creation of a search strategy and keyword searches, a 2-stage screening process",6
570660cb220ffe7d542f193a279826ff8cd41f3b,The Minds of Many: Opponent Modeling in a Stochastic Game,"The Theory of Mind provides a framework for an agent to predict the actions of adversaries by building an abstract model of their strategies using recursive nested beliefs. In this paper, we extend a recently introduced technique for opponent modelling based on Theory of Mind reasoning. Our extended multi-agent Theory of Mind model explicitly considers multiple opponents simultaneously. We introduce a stereotyping mechanism, which segments the agent population into sub-groups of agents with similar behaviour. Sub-group profiles guide decision making. We evaluate our model using a multi-player stochastic game, which presents agents with the challenge of unknown adversaries in a partially-observable environment. Simulation results demonstrate that the model performs well under uncertainty and that stereotyping allows larger groups of agents to be modelled robustly. The findings show that Theory of Mind modelling is useful in many artificial intelligence applications.",5
30beb7f26e1ae8c9d3fb21daeae7d76275835cb8,Regulating scientific and technological uncertainty: The precautionary principle in the context of human genomics and AI,"Considered in isolation, the ethical and societal challenges posed by genomics and artificial intelligence (AI) are profound and include issues relating to autonomy, privacy, equality, bias, discrimination, and the abuse of power, amongst others. When these two technologies are combined, the ethical, legal and societal issues increase substantially, become much more complex, and can be scaled enormously, which increases the impact. Adding to these complexities, both genomics and AI-enabled technologies are rife with scientific and technological uncertainties, which makes the regulation of these technologies not only challenging in itself, but also creates legal uncertainties. In science, the precautionary principle has been used globally to govern uncertainty, with the specific aim to prevent irreversible harm to human beings. The regulation of uncertainties in AI-enabled technologies is based on risk as set out in the AI Regulation that was recently proposed by the European Commission. However, when genomics and artificial intelligence are",5
a046daa116020f482eeb94c97daa89571833bf3c,2019 ACC/AHA Guideline on the Primary Prevention of Cardiovascular Disease: A Report of the American College of Cardiology/American Heart Association Task Force on Clinical Practice Guidelines.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
60f78afe2040f33988c71d585c3f42f06814d0de,ChatGPT: the future of discharge summaries?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
cbec914257aafa6fee1dc34dfc5cfccc7adbd031,AUTOMATED FEEDBACK AND TEACHER FEEDBACK: WRITING ACHIEVEMENT IN LEARNING ENGLISH AS A FOREIGN LANGUAGE AT A DISTANCE,"Information and communication technologies have been transforming the way we teach and learn. Either for facilitating teaching practices or for making learning more interesting and joyful for the learners, artificial intelligence-based applications are utilized in recent years. In this connection, this study intends to examine if automated feedback and teacher feedback contribute to academic writing achievement and whether they differ in their effect on achievement in learning English as a foreign language in an open and distant learning context. The participants of the study were open education faculty students in a higher education institution in Turkey. In this quasi-experimental quantitative study repeated measures design was adopted. the participants were given writing tasks each week in a nine-week writing activity and they received feedback from their English language teachers for the first three tasks, and they received feedback from the software for the last three tasks. All participants wrote an English",7
0ae5b99f09b7ebacc4aeaed7644aff90534a3aaa,Deep Learning for Medical Image Analysis,"This report describes my research activities in the Hasso Plattner Institute and summarizes my Ph.D. plan and several novels, end-to-end trainable approaches for analyzing medical images using deep learning algorithm. In this report, as an example, we explore different novel methods based on deep learning for brain abnormality detection, recognition, and segmentation. This report prepared for the doctoral consortium in the AIME-2017 conference.",8
0c171e1cac6868ccf905245a7dd4400f9554b241,Optimization of Raw Material Inventory using Always Better Control (ABC) Analysis and Economic Order Quantity (EOQ) Method Approach in the Warehouse of a Bolt Manufacturing Factory in Indonesia,"There is a problem in the raw material procurement process at the Contractor Company, such as running out and excess stock of raw materials, as well as difficulties in determining how many raw materials to order that meet the company's economic value. Running out of raw material stock results in delays in production activities, while excess raw material stock can fill warehouse capacity, thereby increasing storage costs. To overcome this problem, research was carried out using a quantitative descriptive method to determine the level of production cost efficiency and production effectiveness level in order to achieve optimization of raw material supplies using Always Better Control (ABC) Analysis and the Economic Order Quantity (EOQ) Method at Bolt Companies. ABC analysis plays a role in determining which raw materials have the highest level of demand and the EOQ method plays a role in determining the amount of raw materials to be ordered",3
9941e3b0125bf9f17e391e18b656bde9d98abe26,A networked device for reproducing multisensory kissing,"Kissing is a universal and essential interaction in human communication, yet we are not able to transmit and reproduce the multisensory sensations of kissing over digital communication networks. A networked kissing device is proposed to sense the lip pressure of users and to produce accurate force feedback to simulate kissing sensations. The system is designed to engage multiple sensory modalities during user interaction, including touch, smell, video and voice. This device can be used to augment digital communication by transmitting intimate touch sensations between human and human remotely, or between human and virtual agents.",1
45073ad97f5c0e78b4f7cd80bbe2fd2be02c4c5a,The rise of generative artificial intelligence (AI) language models - challenges and opportunities for geographical and environmental education,"Much discussion has been surrounding generative AI language models, such as ChatGPT, and the advantages and threats they present to education. As an AI language model, ChatGPT has the potential to transform geography and environmental education. The extensive knowledge base and natural language processing abilities that ChatGPT possesses make it a perfect tool for this purpose; it can actively include students in conversation (as the chat in its name implies) while also providing them with quick feedback. Because of this, students are free to progress through the material at their own pace, using strategies that best suit them individually. Yet, this change has been criticised by others who worry about intellectual property violations and undermining academic integrity. As discussions continue about whether generative AI models are a boon or bane for education, we would like to focus on the problems and potential facing geography and environmental education in particular. We",4
697f2f3598057cd17cff7749d768cae0993c6727,A Framework for Pandemic Prediction Using Big Data Analytics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
5c23b88068d5912fee9b2bcbc2fdd4bdb4ea3eff,Petroleum Refinery Process Economics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
1a6581cdc1ba19856a193c262e3a37012a0733f1,"Drug repurposing for viral cancers: A paradigm of machine learning, deep learning, and virtual screening‐based approaches","Cancer management is major concern of health organizations and viral cancers account for approximately 15.4% of all known human cancers. Due to large number of patients, efficient treatments for viral cancers are needed. De novo drug discovery is time consuming and expensive process with high failure rate in clinical stages. To address this problem and provide treatments to patients suffering from viral cancers faster, drug repurposing emerges as an effective alternative which aims to find the other indications of the Food and Drug Administration approved drugs. Applied to viral cancers, drug repurposing studies following the niche have tried to find if already existing drugs could be used to treat viral cancers. Multiple drug repurposing approaches till date have been introduced with successful results in viral cancers and many drugs have been successfully repurposed various viral cancers. Here in this study, a critical review of viral cancer related databases, tools, and",2
36ab504f16b6ac49194da43d03171f5d32b80a9f,Global-and-local attention networks for visual recognition,"State-of-the-art deep convolutional networks (DCNs) such as squeeze-and- excitation (SE) residual networks implement a form of attention, also known as contextual guidance, which is derived from global image features. Here, we explore a complementary form of attention, known as visual saliency, which is derived from local image features. We extend the SE module with a novel global-and-local attention (GALA) module which combines both forms of attention -- resulting in state-of-the-art accuracy on ILSVRC. We further describe ClickMe.ai, a large-scale online experiment designed for human participants to identify diagnostic image regions to co-train a GALA network. Adding humans-in-the-loop is shown to significantly improve network accuracy, while also yielding visual features that are more interpretable and more similar to those used by human observers.",4
9da092d7c7674e96830f8d6713a9a4f8101f984c,Trustworthy artificial intelligence,"Artificial intelligence (AI) brings forth many opportunities to contribute to the wellbeing of individuals and the advancement of economies and societies, but also a variety of novel ethical, legal, social, and technological challenges. Trustworthy AI (TAI) bases on the idea that trust builds the foundation of societies, economies, and sustainable development, and that individuals, organizations, and societies will therefore only ever be able to realize the full potential of AI, if trust can be established in its development, deployment, and use. With this article we aim to introduce the concept of TAI and its five foundational principles (1) beneficence, (2) non-maleficence, (3) autonomy, (4) justice, and (5) explicability. We further draw on these five principles to develop a data-driven research framework for TAI and demonstrate its utility by delineating fruitful avenues for future research, particularly with regard to the distributed ledger technology-based realization of TAI.",3
df5f3ffe15207eb6ae2f00f3ccc818625b9bfbe7,Artificial Intelligence and Jobs: Evidence from Online Vacancies,"We study the impact of artificial intelligence (AI) on labor markets using establishment-level data on the near universe of online vacancies in the United States from 2010 onward. There is rapid growth in AI-related vacancies over 2010–18 that is driven by establishments whose workers engage in tasks compatible with AI’s current capabilities. As these AI-exposed establishments adopt AI, they simultaneously reduce hiring in non-AI positions and change the skill requirements of remaining postings. While visible at the establishment level, the aggregate impacts of AI-labor substitution on employment and wage growth in more exposed occupations and industries is currently too small to be detectable.",4
e6800a5cc92502789f9dfc7c5d9c112d9d2f3372,The Tacit Dimension,"In architecture, tacit knowledge plays a substantial role in both the design process and its reception. The essays in this book explore the tacit dimension of architecture in its aesthetic, material, cultural, design-based, and reflexive understanding of what we build. Tacit knowledge, described in 1966 by Michael Polanyi as what we ‘can know but cannot tell’, often denotes knowledge that escapes quantifiable dimensions of research. Much of architecture’s knowledge resides beneath the surface, in nonverbal instruments such as drawings and models that articulate the spatial imagination of the design process. Awareness of the tacit dimension helps to understand the many facets of the spaces we inhabit, from the ideas of the architect to the more hidden assumptions of our cultures. Beginning in the studio, where students are guided into becoming architects, the book follows a path through the tacit knowledge present in materials, conceptual structures, and the design process, revealing",5
af39bb30772a71ec2a620b3d2daa65e44f2a8e91,Design and Application of Artificial Intelligence Technology-Driven Education and Teaching System in Universities,"In recent years, many colleges and universities have been experimenting and exploring the evaluation of education and teaching system and have achieved certain results. In order to understand the quality of education and teaching system in colleges and universities, to improve the school conditions, and to promote the reform of teaching management, methods and means of evaluating the quality of education and teaching system in general higher education institutions are needed. Modern university education and teaching system should realize the combination of classroom teaching and practice teaching, and education and teaching system adopts the mode of the combination of on-campus practice and off-campus practice, so the design of teaching system is the key to the quality of teaching. Aiming at the current problem that talents cultivated by colleges and universities can hardly meet social demands in terms of engineering practice ability, innovation ability, and international competitiveness, this paper proposes the",3
df9ff5a3c7e0b925d703d13fb763c87105ce9d8c,The concept of hybrid human-AI regulation: Exemplifying how to support young learners' self-regulated learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
ec299c4c2398532d785f58ac6f848b43abdbbd78,Risk prediction model for food safety based on improved random forest integrating virtual sample,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
ce64abaf73a842b0487bdbf07097957408147b8d,Fairly Predicting Graft Failure in Liver Transplant for Organ Assigning,"Liver transplant is an essential therapy performed for severe liver diseases. The fact of scarce liver resources makes the organ assigning crucial. Model for End-stage Liver Disease (MELD) score is a widely adopted criterion when making organ distribution decisions. However, it ignores post-transplant outcomes and organ/donor features. These limitations motivate the emergence of machine learning (ML) models. Unfortunately, ML models could be unfair and trigger bias against certain groups of people. To tackle this problem, this work proposes a fair machine learning framework targeting graft failure prediction in liver transplant. Specifically, knowledge distillation is employed to handle dense and sparse features by combining the advantages of tree models and neural networks. A two-step debiasing method is tailored for this framework to enhance fairness. Experiments are conducted to analyze unfairness issues in existing models and demonstrate the superiority of our method in both prediction and fairness performance.",4
b3093a944ecf3be4040fc136a807d099d245614b,Literature review as a research methodology: An overview and guidelines,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
b3639a751c631deee8bf1e7a6dd41d76d830b47b,Sharing Knowledge,"Assertion is the central vehicle for the sharing of knowledge. Whether knowledge is shared successfully often depends on the quality of assertions: good assertions lead to successful knowledge sharing, while bad ones don't. In Sharing Knowledge, Christoph Kelp and Mona Simion investigate the relation between knowledge sharing and assertion, and develop an account of what it is to assert well. More specifically, they argue that the function of assertion is to share knowledge with others. It is this function that supports a central norm of assertion according to which a good assertion is one that has the disposition to generate knowledge in others. The book uses this functionalist approach to motivate further norms of assertion on both the speaker and the hearer side and investigates ramifications of this view for other questions about assertion.",4
220856b0d885ff7d18ce2064ed69daedae1f7638,"ChatGPT: Fundamentals, Applications and Social Impacts","Recent progress in large language models has pushed the boundaries of natural language processing, setting new standards for performance. It is remarkable how artificial intelligence can mimic human behavior and writing style in such a convincing way. As a result, it is hard to tell if a human or a machine wrote something. Deep learning and natural language processing have recently advanced large language models. These newer models can learn from large amounts of data to better capture the nuances of language, making them more accurate and robust than ever before. Additionally, these models can now be applied to tasks such as summarizing text, translating between languages, and even generating original content. ChatGPT is a natural language processing (NLP) model developed in 2022 by OpenAI for open-ended conversations. It is based on GPT-3.5, the third-generation language processing model from OpenAI. ChatGPT can power conversational AI applications like virtual assistants and",6
8de690ecc54990792d0990fa9a815f852341be57,An Intelligent System for Aggression De-Escalation Training,"Artificial Intelligence techniques are increasingly being used to develop smart training applications for professionals in various domains. This paper presents an intelligent training system that enables professionals in the public domain to practice their aggression de-escalation skills. The system is one of the main products of the STRESS project, an interdisciplinary research project involving partners from academia, industry and society. The system makes use of a variety of AI-related techniques, including simulation, virtual agents, sensor fusion, model-based analysis and adaptive support. A preliminary evaluation of the system has been conducted with two groups of potential end users, namely tram conductors and police academy students.",2
d407ca87e1944ea84d6899386a2a8812405e5525,"Artificial Intelligence in Drug Toxicity Prediction: Recent Advances, Challenges, and Future Perspectives","Toxicity prediction is a critical step in the drug discovery process that helps identify and prioritize compounds with the greatest potential for safe and effective use in humans, while also reducing the risk of costly late-stage failures. It is estimated that over 30% of drug candidates are discarded owing to toxicity. Recently, artificial intelligence (AI) has been used to improve drug toxicity prediction as it provides more accurate and efficient methods for identifying the potentially toxic effects of new compounds before they are tested in human clinical trials, thus saving time and money. In this review, we present an overview of recent advances in AI-based drug toxicity prediction, including the use of various machine learning algorithms and deep learning architectures, of six major toxicity properties and Tox21 assay end points. Additionally, we provide a list of public data sources and useful toxicity prediction tools for the research community and highlight",5
e6e87e3fc84ea1393a053d6e90a330c251094c38,Clinical Validation of Artificial Intelligence-Augmented Pathology Diagnosis Demonstrates Significant Gains in Diagnostic Accuracy in Prostate Cancer Detection.,"CONTEXT.— Prostate cancer diagnosis rests on accurate assessment of tissue by a pathologist. The application of artificial intelligence (AI) to digitized whole slide images (WSIs) can aid pathologists in cancer diagnosis, but robust, diverse evidence in a simulated clinical setting is lacking. OBJECTIVE.— To compare the diagnostic accuracy of pathologists reading WSIs of prostatic biopsy specimens with and without AI assistance. DESIGN.— Eighteen pathologists, 2 of whom were genitourinary subspecialists, evaluated 610 prostate needle core biopsy WSIs prepared at 218 institutions, with the option for deferral. Two evaluations were performed sequentially for each WSI: initially without assistance, and immediately thereafter aided by Paige Prostate (PaPr), a deep learning-based system that provides a WSI-level binary classification of suspicious for cancer or benign and pinpoints the location that has the greatest probability of harboring cancer on suspicious WSIs. Pathologists' changes in sensitivity and specificity between the assisted and unassisted modalities were assessed,",1
bdc3d1ea2cfcc762a5855c0fc39796922b0cc8ad,What do medical students actually need to know about artificial intelligence?,"With emerging innovations in artificial intelligence (AI) poised to substantially impact medical practice, interest in training current and future physicians about the technology is growing. Alongside comes the question of what, precisely, should medical students be taught. While competencies for the clinical usage of AI are broadly similar to those for any other novel technology, there are qualitative differences of critical importance to concerns regarding explainability, health equity, and data security. Drawing on experiences at the University of Toronto Faculty of Medicine and MIT Critical Data’s “datathons”, the authors advocate for a dual-focused approach: combining robust data science-focused additions to baseline health research curricula and extracurricular programs to cultivate leadership in this space.",3
a45ff64e22f8005d563fed1ee545ddc98aab9766,AI bot ChatGPT writes smart essays - should professors worry?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
dc1eb76fdd0c39c8e53985a447a5f049f860a7e9,An artificial intelligence platform for the multihospital collaborative management of congenital cataracts,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
5c45a5d05ac564adb67811eeb9d41d6460c70135,Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs.,"Importance Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation. Objective To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs. Design and Setting A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data",18
b181a887f4977a58de209edd694ed72237e5f640,How Useful are Educational Questions Generated by Large Language Models?,"Controllable text generation (CTG) by large language models has a huge potential to transform education for teachers and students alike. Specifically, high quality and diverse question generation can dramatically reduce the load on teachers and improve the quality of their educational content. Recent work in this domain has made progress with generation, but fails to show that real teachers judge the generated questions as sufficiently useful for the classroom setting; or if instead the questions have errors and/or pedagogically unhelpful content. We conduct a human evaluation with teachers to assess the quality and usefulness of outputs from combining CTG and question taxonomies (Bloom's and a difficulty taxonomy). The results demonstrate that the questions generated are high quality and sufficiently useful, showing their promise for widespread use in the classroom setting.",7
e656b0376ca11f533ea01097c70f98c0ff655c00,"""How do I fool you?"": Manipulating User Trust via Misleading Black Box Explanations","As machine learning black boxes are increasingly being deployed in critical domains such as healthcare and criminal justice, there has been a growing emphasis on developing techniques for explaining these black boxes in a human interpretable manner. There has been recent concern that a high-fidelity explanation of a black box ML model may not accurately reflect the biases in the black box. As a consequence, explanations have the potential to mislead human users into trusting a problematic black box. In this work, we rigorously explore the notion of misleading explanations and how they influence user trust in black box models. Specifically, we propose a novel theoretical framework for understanding and generating misleading explanations, and carry out a user study with domain experts to demonstrate how these explanations can be used to mislead users. Our work is the first to empirically establish how user trust in black box models can be",5
5fda8919788ee58647c9917dc50cef7ac4327250,The Productivity J-Curve: How Intangibles Complement General Purpose Technologies,"General purpose technologies (GPTs) like AI enable and require significant complementary investments. These investments are often intangible and poorly measured in national accounts. We develop a model that shows how this can lead to underestimation of productivity growth in a new GPTs early years and, later, when the benefits of intangible investments are harvested, productivity growth overestimation. We call this phenomenon the Productivity J-curve. We apply our method to US data and find that adjusting for intangibles related to computer hardware and software yields a TFP level that is 15.9 percent higher than official measures by the end of 2017. (JEL E22, E23, G31, L63, L86)",6
67a28e2a70871243951cc2375df793c79d4e0c12,Adaptive IIR Filtering in Signal Processing and Control,"Recursive filter structures the Beurling-Lax theorem, Hankel forms and classical identification adaptive IIR filtering in signal processing and control stability of time-varying recursive filters gradient descent algorithms the Steiglitz-McBride family of algorithms hyperstable algorithms adaptive notch filters perspectives and open problems computations with lattice filters.",3
0b9de138425b4d0374a88e0b0ae9d2faf5231c50,ChatGPT for healthcare services: An emerging stage for an innovative perspective,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
87538a3ca45cf2b54378260e6fbd7a8e61e1f6f5,Will ChatGPT transform healthcare?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
4e9dcd9d82775b89ae0e702236f79756226473d5,Just data? Solidarity and justice in data-driven medicine,"This paper argues that data-driven medicine gives rise to a particular normative challenge. Against the backdrop of a distinction between the good and the right , harnessing personal health data towards the development and refinement of data-driven medicine is to be welcomed from the perspective of the good . Enacting solidarity drives progress in research and clinical practice. At the same time, such acts of sharing could—especially considering current developments in big data and artificial intelligence—compromise the right by leading to injustices and affecting concrete modes of individual self-determination. In order to address this potential tension, two key elements for ethical reflection on data-driven medicine are proposed: the controllability of information flows, including technical infrastructures that are conducive towards controllability, and a paradigm shift towards output-orientation in governance and policy.",3
aea88c355c3471b82de3af7e5941f49c3bf993ce,Artificial intelligence and machine learning tools for high-performance microalgal wastewater treatment and algal biorefinery: A critical review.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
8029b005e1f97f81a2684fe700f8a63f91a8bedf,Dispositions,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
8c7ed130efb8dd61213784ec9e88f7681944a40a,AI-generated characters for supporting personalized learning and well-being,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
e1ec11a1cb3d9745fb18d3bf74247f95a6663d08,Dermatologist-level classification of skin cancer with deep neural networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",19
92be425544f1199535bb013bbf3f3e5be567b499,Application of stacking ensemble learning model in quantitative analysis of biomaterial activity,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
d407f106abb91a3c25795b8c8f831ccd70481848,A unifying force for the realization of medical AI,"Artificial Intelligence (AI) in medicine has grown rapidly, yet few algorithms have been deployed. It is not the problem with the AI itself but with the way functions and results are communicated. Regulatory science provides the appropriate language and solutions to this problem for three reasons: First, there is value in the intentionally interdisciplinary regulatory language. Second, regulatory concepts are important for AI researchers because these concepts enable tackling of risk and safety concerns as well as understanding of recently proposed regulations in the US and Europe. Third, regulatory science is a scientific discipline that evaluates and challenges current regulation—aiming for evidence-based improvements. Knowledge of the regulatory language, concepts, and science should be regarded a core competency for communicating medical innovation. Regulatory grade communication will be the key to bringing medical AI from hype to standard of care. Foregoing the possible benefits of regulatory science as a unifying force for",7
aa676ba32fe2fc249f468ee0cb6e7bde07e535b1,From certainty factors to belief networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
cf1f26e7cbed3958b3c2870656568c299fece6e3,Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models,"We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, even clinical decision-making.",13
a799caac53cdab687d3748dea4b7106fe654a7e6,ChatGPT and other artificial intelligence applications speed up scientific writing.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
c4d96dfef7b67ea371354b416d1e458aa65f8177,Is ChatGPT Leading Generative AI? What is Beyond Expectations?,"Generative AI has the potential to change the way we do things. The chatbot is one of the most popular implementation areas. Even though companies like Google and Meta had chatbots, ChatGPT became popular as it was made publicly available. Although ChatGPT is still in the early stages of its development, it attracted the attention of people and capital groups. It has taken the public interest; people from different fields, ages, and education levels started using ChatGPT. There have been many trials with ChatGPT. It is possible to see a lot of news and shares on the Internet. The study aims to shed light on what is happening in the literature and get an insight into the user expectations of ChatGPT and Generative AI. We also give information about the competitors of ChatGPT, such as Google’s Bard AI, Claude, Meta’s Wit.ai and Tencent’s HunyuanAide. We describe technical and structural fundamentals",4
721f3db2cf331f2581c86a257c79a51223a944e1,Organizational readiness for artificial intelligence in health care: insights for decision-making and practice.,"PURPOSE Artificial intelligence (AI) raises many expectations regarding its ability to profoundly transform health care delivery. There is an abundant literature on the technical performance of AI applications in many clinical fields (e.g. radiology, ophthalmology). This article aims to bring forward the importance of studying organizational readiness to integrate AI into health care delivery. DESIGN/METHODOLOGY/APPROACH The reflection is based on our experience in digital health technologies, diffusion of innovations and healthcare organizations and systems. It provides insights into why and how organizational readiness should be carefully considered. FINDINGS As an important step to ensure successful integration of AI and avoid unnecessary investments and costly failures, better consideration should be given to: (1) Needs and added-value assessment; (2) Workplace readiness: stakeholder acceptance and engagement; (3) Technology-organization alignment assessment and (4) Business plan: financing and investments. In summary, decision-makers and technology promoters should better address the complexity of AI and understand the",7
a1224ef0d9e9bfbb021278c482c2f4d02217320f,PulDi-COVID: Chronic obstructive pulmonary (lung) diseases with COVID-19 classification using ensemble deep convolutional neural network from chest X-ray images to minimize severity and mortality rates,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
d2d79513f32c4d09b6255b18514d7ad07ebf43fe,Explainable artificial intelligence: A survey,"In the last decade, with availability of large datasets and more computing power, machine learning systems have achieved (super)human performance in a wide variety of tasks. Examples of this rapid development can be seen in image recognition, speech analysis, strategic game planning and many more. The problem with many state-of-the-art models is a lack of transparency and interpretability. The lack of thereof is a major drawback in many applications, e.g. healthcare and finance, where rationale for model's decision is a requirement for trust. In the light of these issues, explainable artificial intelligence (XAI) has become an area of interest in research community. This paper summarizes recent developments in XAI in supervised learning, starts a discussion on its connection with artificial general intelligence, and gives proposals for further research directions.",9
d6c745efbc342279308e80f1e61f8b2ea35b7ad6,Accessibility challenges of e-commerce websites,"Today, there are many e-commerce websites, but not all of them are accessible. Accessibility is a crucial element that can make a difference and determine the success or failure of a digital business. The study was applied to 50 e-commerce sites in the top rankings according to the classification proposed by ecommerceDB. In evaluating the web accessibility of e-commerce sites, we applied an automatic review method based on a modification of Website Accessibility Conformance Evaluation Methodology (WCAG-EM) 1.0. To evaluate accessibility, we used Web Accessibility Evaluation Tool (WAVE) with the extension for Google Chrome, which helps verify password-protected, locally stored, or highly dynamic pages. The study found that the correlation between the ranking of e-commerce websites and accessibility barriers is 0.329, indicating that the correlation is low positive according to Spearman’s Rho. According to the WAVE analysis, the research results reveal that the top 10 most accessible websites are Sainsbury’s",4
4c4140cd59969f65f6bfc4a8632a8bfae7889097,CoRTX: Contrastive Framework for Real-time Explanation,"Recent advancements in explainable machine learning provide effective and faithful solutions for interpreting model behaviors. However, many explanation methods encounter efficiency issues, which largely limit their deployments in practical scenarios. Real-time explainer (RTX) frameworks have thus been proposed to accelerate the model explanation process by learning a one-feed-forward explainer. Existing RTX frameworks typically build the explainer under the supervised learning paradigm, which requires large amounts of explanation labels as the ground truth. Considering that accurate explanation labels are usually hard to obtain due to constrained computational resources and limited human efforts, effective explainer training is still challenging in practice. In this work, we propose a COntrastive Real-Time eXplanation (CoRTX) framework to learn the explanation-oriented representation and relieve the intensive dependence of explainer training on explanation labels. Specifically, we design a synthetic strategy to select positive and negative instances for the learning of explanation. Theoretical analysis show that our selection strategy",6
527311a925ed165b9186562f0bba8826a90b184a,Artificial intelligence in K-12 education,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
1e31a13f7bffc62c823e848728d4b1f9e6d483cc,Realizing private and practical pharmacological collaboration,"Sharing pharmaceutical research Increased collaboration will enhance our ability to predict new therapeutic drug candidates. Such data sharing is currently limited by concerns about intellectual property and competing commercial interests. Hie et al. introduce an end-to-end pipeline, using modern cryptographic tools, for secure pharmacological collaboration. Multiple entities can thus securely combine their private datasets to collectively obtain more accurate predictions of new drug-target interactions. The computational pipeline is practical, producing results with improved accuracy in a few days over a wide area network on a real dataset with more than a million interactions. Science, this issue p. 347 A computational protocol enables private pharmacological data to be securely combined. Although combining data from multiple entities could power life-saving breakthroughs, open sharing of pharmacological data is generally not viable because of data privacy and intellectual property concerns. To this end, we leverage modern cryptographic tools to introduce a computational protocol for",2
2e8aeb7725546ad99a70e3580290371709f28ac9,"Bias and Unfairness in Machine Learning Models: A Systematic Review on Datasets, Tools, Fairness Metrics, and Identification and Mitigation Methods","One of the difficulties of artificial intelligence is to ensure that model decisions are fair and free of bias. In research, datasets, metrics, techniques, and tools are applied to detect and mitigate algorithmic unfairness and bias. This study examines the current knowledge on bias and unfairness in machine learning models. The systematic review followed the PRISMA guidelines and is registered on OSF plataform. The search was carried out between 2021 and early 2022 in the Scopus, IEEE Xplore, Web of Science, and Google Scholar knowledge bases and found 128 articles published between 2017 and 2022, of which 45 were chosen based on search string optimization and inclusion and exclusion criteria. We discovered that the majority of retrieved works focus on bias and unfairness identification and mitigation techniques, offering tools, statistical approaches, important metrics, and datasets typically used for bias experiments. In terms of the primary forms of bias, data, algorithm,",2
ac4dc32dbeed10e3104c0c7f9641468bddd807f7,A Systematic Review on the Distribution of Invasive Plant Species Across Asia: Assessing the Rates of Invasion Success and Management,"The advancement of invasive plant species in a particular environment is threatening across Asia. When they are introduced, they could have a variety of different negative effects, either as minor inconveniences or a severe problem. The aim of this review is to compile a list of invasive plant species across Asia and organize a set of data according to their reproduction rates, growth rates, dispersal rates, and characterize the allelochemicals they produce and allelopathic effects they have on their environment. The target is to know the extent of their spread ability in the area that they inhibit and know what control measures can be done with that specific species. The data has been gathered by compiling research articles and obtaining pertinent data relating to the objective. This review also utilized the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) checklist to confirm the credibility of the collected references. To",6
18a8be054af68439e75a90cef401131e77dc1ae1,How can we design for learning in an AI world?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
7d3b7c8e60fd6e4e0e84fd72d717f4c86447a10c,"Artificial Intelligence education for young children: Why, what, and how in curriculum design and implementation","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
d8345ba0f7d0b357f4248c849807bc8cd9347952,"A Detailed Case Study on Deviation, Out-of-Specification(OOS) and CAPA Generation in Pharmaceutical Industry","This review provide an overview of the various documentation of quality management system, which includes deviations, OOS and CAPA. A detailed case study of deviations, out-of-Specification and CAPA generation is beneficial for improving pharmaceutical capabilities and understanding the documentation associated with a quality management system. It is essential for understanding deviations and out-of-spec in the pharmaceutical industry. The quality of medicines means that they meet the required specifications. The quality management system in the pharmaceutical industry is essential because the drugs or pharmaceutical products are delivered directly to the customer's body. Therefore, identity, purity, safety, and the quality of the products are critical. A Deviation can define as ""a deviation from an approved instruction or established standard"" The deviation process helps identify potential risks to product quality and patient safety and establish the root cause. Once the root cause identifies, appropriate corrective and preventive actions take to prevent reoccurrence. OOS",4
2378cf8bb6fb4a9c4cde69d40d423a2b963b78ff,Multistain deep learning for prediction of prognosis and therapy response in colorectal cancer,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
b6328d4664aed6b5d7e824f1867b653069d6f252,"In AI We Trust: Ethics, Artificial Intelligence, and Reliability","One of the main difficulties in assessing artificial intelligence (AI) is the tendency for people to anthropomorphise it. This becomes particularly problematic when we attach human moral activities to AI. For example, the European Commission’s High-level Expert Group on AI (HLEG) have adopted the position that we should establish a relationship of trust with AI and should cultivate trustworthy AI (HLEG AI Ethics guidelines for trustworthy AI, 2019, p. 35). Trust is one of the most important and defining activities in human relationships, so proposing that AI should be trusted, is a very serious claim. This paper will show that AI cannot be something that has the capacity to be trusted according to the most prevalent definitions of trust because it does not possess emotive states or can be held responsible for their actions—requirements of the affective and normative accounts of trust. While AI meets all of the requirements of",3
3db5c5a6c720091e2c9be8bb45b96fe7be313717,Privacy-Preserving Deep Learning: Revisited and Enhanced,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
a8dccd6166646b55680425370c9ae75469eccf0d,Socio-economic factor analysis for sustainable and smart precision agriculture: An ensemble learning approach,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
f22077969bc6dff0edb826e33b4faf9b105b1156,"The Impact of ESG (Environmental, Social, and Governance) Considerations on Corporate Mergers and Acquisitions: Strategies for Value Creation","The integration of Environmental, Social, and Governance (ESG) considerations in corporate mergers and acquisitions (M&A) has gained significant traction as companies recognize the strategic value of sustainability in dealmaking. This paper explores how ESG factors can be incorporated into M&A strategies to drive value creation, meet regulatory requirements, and enhance corporate reputation. Leveraging improved data and tracking methods, the study highlights the increasing importance of ESG in M&A, presenting a comprehensive analysis of environmental, social, and governance factors and their impact on M&A processes. Through case studies and an analytical framework, the research provides insights into the benefits and challenges of ESG integration, offering recommendations for companies aiming to achieve successful and sustainable M&A outcomes.",3
1ee88e64945503c93b68344e639a7ae085f6e37d,CNTK: Microsoft's Open-Source Deep-Learning Toolkit,"This tutorial will introduce the Computational Network Toolkit, or CNTK, Microsoft's cutting-edge open-source deep-learning toolkit for Windows and Linux. CNTK is a powerful computation-graph based deep-learning toolkit for training and evaluating deep neural networks. Microsoft product groups use CNTK, for example to create the Cortana speech models and web ranking. CNTK supports feed-forward, convolutional, and recurrent networks for speech, image, and text workloads, also in combination. Popular network types are supported either natively (convolution) or can be described as a CNTK configuration (LSTM, sequence-to-sequence). CNTK scales to multiple GPU servers and is designed around efficiency. The tutorial will give an overview of CNTK's general architecture and describe the specific methods and algorithms used for automatic differentiation, recurrent-loop inference and execution, memory sharing, on-the-fly randomization of large corpora, and multi-server parallelization. We will then show how typical uses looks like for relevant tasks like image recognition, sequence-to-sequence modeling, and speech recognition.",6
f884c9cd761732a2b41849c1ec0e0a33585ae854,Towards the simulation of clinical cognition. Taking a present illness by computer.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
695bfb7a3c6c1b29c189739b7556c59a8dc4f515,Roles and research foci of artificial intelligence in language education: an integrated bibliographic analysis and systematic review approach,"ABSTRACT This study explores the roles and research foci of AILEd (Artificial Intelligence in Language Education). The AILEd studies published from 1990 to 2020 in the WOS (Web of Science) database were included in the present study. Based on the well-recognized Technology-based Learning Review model, several dimensions, such as research methods, research sample groups, adopted technology, language skills, the role of AI in language education, and learning outcomes, were taken into account. The review results show that the main application domains of AILEd research were writing, reading, and vocabulary acquisition. In terms of applied technology and algorithms, AI in language education mostly adopted ITS (Intelligent Tutoring System) and NLP (Natural Language Processing). Besides, several commonly used AI algorithms were Statistical Learning, Data Mining, Machine Learning, and Natural Language Parsing. It was also found that some research focused on learning anxiety, willingness to communicate, knowledge acquisition, and classroom interaction. However, higher",3
0d0797e85ccadaefb08ec61c97328ba2394069f7,How To Be Trustworthy,"The book articulates and defends a core notion of trustworthiness as avoiding unfulfilled commitments. This is motivated via accounts of both trust and distrust in terms of perceived commitment. Avoiding unfufilled commitments is crucial both to practical trustworthiness, and to trustworthiness in speech; on this picture, assertion involves promising to speak truthfully, and simultaneously either keeping that promise or breaking it. Both assertion and the incurring of practical commitments are governed by competence norms, as well as norms of sincerity. So what should we do if we want to be trustworthy? Two perspectives are important: we need to act in line with our existing commitments, but in addition we need to approach potential new commitments with care. We can become untrustworthy by taking on too many—or over-challenging—commitments, no matter how well-meaning we are. Considered narrowly, trustworthiness typically directs us away from new commitments, but this creates significant costs both for",4
0030923414ff02a4180bc29809003d503be213e5,Explaining Models by Propagating Shapley Values of Local Components,"In healthcare, making the best possible predictions with complex models (e.g., neural networks, ensembles/stacks of different models) can impact patient welfare. In order to make these complex models explainable, we present DeepSHAP for mixed model types, a framework for layer wise propagation of Shapley values that builds upon DeepLIFT (an existing approach for explaining neural networks). We show that in addition to being able to explain neural networks, this new framework naturally enables attributions for stacks of mixed models (e.g., neural network feature extractor into a tree model) as well as attributions of the loss. Finally, we theoretically justify a method for obtaining attributions with respect to a background distribution (under a Shapley value framework).",2
e1d3ad60ae171c551bda293a91fabced1393d07d,Ethics and privacy of artificial intelligence: Understandings from bibliometrics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
d72e5c2e7bfda14ccb156a15f597ed499a9e9b7e,Outcomes and Complications After Endovascular Treatment of Brain Arteriovenous Malformations: A Prognostication Attempt Using Artificial Intelligence.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
5ee0ca09dca482eb8bb1e351a0c7575c3c144372,Is it time for robot rights? Moral status in artificial entities,"Some authors have recently suggested that it is time to consider rights for robots. These suggestions are based on the claim that the question of robot rights should not depend on a standard set of conditions for ‘moral status’; but instead, the question is to be framed in a new way, by rejecting the is/ought distinction, making a relational turn, or assuming a methodological behaviourism. We try to clarify these suggestions and to show their highly problematic consequences. While we find the suggestions ultimately unmotivated, the discussion shows that our epistemic condition with respect to the moral status of others does raise problems, and that the human tendency to empathise with things that do not have moral status should be taken seriously—we suggest that it produces a “derived moral status”. Finally, it turns out that there is typically no individual in real AI that could even be said to be",4
9e74c0864e11e0930aa066e344322f5142880c02,Analysis of Cylinder Comp Product Quality Control with Proposed Improvements at PT. Jakarta Automotive,"In the era of globalization, the manufacturing industry faces its biggest challenge, namely the demands of consumer needs with high quality standards. Various kinds of waste often occur in the production process, one of which is caused by a poor layout of facilities, for example the arrangement of machines on the production line that is not suitable. This is a problem in the production process of machining cylinder comp at PT. Jakarta Automotive. With the aim of finding out the factors that cause product defects in machining cylinder comp and finding design of improvement proposals to reduce the defects that occur, this study uses a quantitative method to find DPMO and sigma values as an analysis of the cause of the problem. The result of this study was the discovery of less than optimal engine layout settings that caused TAP NG defects in the product. So that a design of",4
29fa81a52b38eca815e3001b7895411fcc8e77af,Artificial intelligence in hospitals: providing a status quo of ethical considerations in academia to guide future research,"The application of artificial intelligence (AI) in hospitals yields many advantages but also confronts healthcare with ethical questions and challenges. While various disciplines have conducted specific research on the ethical considerations of AI in hospitals, the literature still requires a holistic overview. By conducting a systematic discourse approach highlighted by expert interviews with healthcare specialists, we identified the status quo of interdisciplinary research in academia on ethical considerations and dimensions of AI in hospitals. We found 15 fundamental manuscripts by constructing a citation network for the ethical discourse, and we extracted actionable principles and their relationships. We provide an agenda to guide academia, framed under the principles of biomedical ethics. We provide an understanding of the current ethical discourse of AI in clinical environments, identify where further research is pressingly needed, and discuss additional research questions that should be addressed. We also guide practitioners to acknowledge AI-related benefits in hospitals",4
7e27d24bf242671bc32115314d349a53abd5542c,The precision medicine process for treating rare disease using the artificial intelligence tool mediKanren,"There are over 6,000 different rare diseases estimated to impact 300 million people worldwide. As genetic testing becomes more common practice in the clinical setting, the number of rare disease diagnoses will continue to increase, resulting in the need for novel treatment options. Identifying treatments for these disorders is challenging due to a limited understanding of disease mechanisms, small cohort sizes, interindividual symptom variability, and little commercial incentive to develop new treatments. A promising avenue for treatment is drug repurposing, where FDA-approved drugs are repositioned as novel treatments. However, linking disease mechanisms to drug action can be extraordinarily difficult and requires a depth of knowledge across multiple fields, which is complicated by the rapid pace of biomedical knowledge discovery. To address these challenges, The Hugh Kaul Precision Medicine Institute developed an artificial intelligence tool, mediKanren, that leverages the mechanistic insight of genetic disorders to identify therapeutic options. Using knowledge graphs,",1
b45165aba7ff801d1e51811ec72dc280138d339d,AI-assisted prediction of differential response to antidepressant classes using electronic health records,"Antidepressant selection is largely a trial-and-error process. We used electronic health record (EHR) data and artificial intelligence (AI) to predict response to four antidepressants classes (SSRI, SNRI, bupropion, and mirtazapine) 4 to 12 weeks after antidepressant initiation. The final data set comprised 17,556 patients. Predictors were derived from both structured and unstructured EHR data and models accounted for features predictive of treatment selection to minimize confounding by indication. Outcome labels were derived through expert chart review and AI-automated imputation. Regularized generalized linear model (GLM), random forest, gradient boosting machine (GBM), and deep neural network (DNN) models were trained and their performance compared. Predictor importance scores were derived using SHapley Additive exPlanations (SHAP). All models demonstrated similarly good prediction performance (AUROCs ≥ 0.70, AUPRCs ≥ 0.68). The models can estimate differential treatment response probabilities both between patients and between antidepressant classes for the same patient. In addition, patient-specific factors driving response",5
e612bf867c7270240ceba6dd7352450a73bb8e48,Combined Method for Evaluating Accessibility in Serious Games,"Nowadays, one of the learning resources in the educational area are serious games, also called training games; they are games designed with a different purpose than fun, whose main objective is to reinforce the new concepts more creatively. However, not all existing serious games are accessible in a way that allows access to a more significant number of users. Therefore, this research proposes to apply a combined method to evaluate accessibility in serious games, considering the Web Content Accessibility Guidelines (WCAG) 2.1. As a case study, we evaluated the accessibility of 82 serious games developed by Physical Education Technology Interactive Simulations at the University of Colorado. We propose to replicate this combined method for users with various types of disabilities, considering the various accessibility barriers. As future work, we suggest generating an accessibility heuristic evaluation focused on serious games, based on the accessibility issues identified. Finally, we believe it is",5
51bb51b06f57fada5d8f338aa484a87f93226468,"Accelerating materials discovery using artificial intelligence, high performance computing and robotics","New tools enable new ways of working, and materials science is no exception. In materials discovery, traditional manual, serial, and human-intensive work is being augmented by automated, parallel, and iterative processes driven by Artificial Intelligence (AI), simulation and experimental automation. In this perspective, we describe how these new capabilities enable the acceleration and enrichment of each stage of the discovery cycle. We show, using the example of the development of a novel chemically amplified photoresist, how these technologies’ impacts are amplified when they are used in concert with each other as powerful, heterogeneous workflows.",2
21cf704a82f5b0b4ce2a240fb5bf27f59608c12c,Application of machine learning techniques in rice leaf disease detection,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
d163cf4672e4c90f4d12bbd9c731f20880b9a093,Experimental investigation and AI prediction modelling of ceramic waste powder concrete – An approach towards sustainable construction,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
7ab0f0da686cd4094fd96f5a30e0b6072525fd09,Deep Learning in Medical Image Analysis.,"This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement.",5
c44763df0d165e3fef6acbaf729f625704a427d3,"The emergent role of artificial intelligence, natural learning processing, and large language models in higher education and research.","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
d7a98e913fbceedbcba53158e7a551428abb33d7,Monitoring Jet Engines and the Health of People,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
462fc00c1f99596e17a08889d74b3ce9eeba7e50,Explaining Aha! moments in artificial agents through IKE-XAI: Implicit Knowledge Extraction for eXplainable AI,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
c7e5508112a96a7ee9b47cd483a7f21cb64a8626,Interpretable deep learning model to predict the molecular classification of endometrial cancer from haematoxylin and eosin-stained whole-slide images: a combined analysis of the PORTEC randomised trials and clinical cohorts.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
3c996ace0fc6c54dbd9035d92d731bd9a57f8c6d,Can Large Language Models Provide Feedback to Students? A Case Study on ChatGPT,"Educational feedback has been widely acknowledged as an effective approach to improving student learning. However, scaling effective practices can be laborious and costly, which motivated researchers to work on automated feedback systems (AFS). Inspired by the recent advancements in the pre-trained language models (e.g., ChatGPT), we posit that such models might advance the existing knowledge of textual feedback generation in AFS because of their capability to offer natural-sounding and detailed responses. Therefore, we aimed to investigate the feasibility of using ChatGPT to provide students with feedback to help them learn better. Our results show that i) ChatGPT is capable of generating more detailed feedback that fluently and coherently summarizes students' performance than human instructors; ii) ChatGPT achieved high agreement with the instructor when assessing the topic of students' assignments; and iii) ChatGPT could provide feedback on the process of students completing the task, which might benefit students developing learning skills.",4
fd4ea16ce58f623fb3b51da2f3dde01a9f8936d1,An Explainable Artificial Intelligence Approach for Unsupervised Fault Detection and Diagnosis in Rotating Machinery,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
5416c09605ff6e5078cf75b77c124d856a54b078,Automatic waste detection with few annotated samples: Improving waste management efficiency,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
0d926a029483beb8013d8dbe56dc11bf011a03d0,A hybrid deep learning and ensemble learning mechanism for damaged power line detection in smart grids,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
ee245998ee246084c764dfe2337fe0aa870e080f,Artificial Intelligence in Education,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
aaa9de6a91833865fc4407042a14b41ed5761028,Using electronic medical record data to report laboratory adverse events,"Despite the importance of adverse event (AE) reporting, AEs are under‐reported on clinical trials. We hypothesized that electronic medical record (EMR) data can ascertain laboratory‐based AEs more accurately than those ascertained manually. EMR data on 12 AEs for patients enrolled on two Children's Oncology Group (COG) trials at one institution were extracted, processed and graded. When compared to gold standard chart data, COG AE report sensitivity and positive predictive values (PPV) were 0–21·1% and 20–100%, respectively. EMR sensitivity and PPV were >98·2% for all AEs. These results demonstrate that EMR‐based AE ascertainment and grading substantially improves laboratory AE reporting accuracy.",4
89f3faf056c5f8c50646ffc24b196adbea377f12,Intelligence in Education,The articles in this special issue provide an overview of the wide breadth of questions and methodologies that arise when the research devoted to intelligence intersect with the research devoted to U.S. education. The unique contributions of each paper are highlighted and discussed based on their contribution to the literature. The implications of these findings for educational research and policy are briefly discussed.,2
a011e9c82781288689b86b4451de0d30b95a12eb,"Work of the Past, Work of the Future","US cities today are vastly more educated and skill-intensive than they were five decades ago. Yet, urban non-college workers perform substantially less skilled jobs than decades earlier. This deskilling reflects the joint effects of automation and, secondarily, rising international trade, which have eliminated the bulk of non-college production, administrative support, and clerical jobs, yielding a disproportionate polarization of urban labor markets. The unwinding of the urban non-college occupational skill gradient has, I argue, abetted a secular fall in real non-college wages by: (1) shunting non-college workers out of specialized middle-skill occupations into low-wage occupations that require only generic skills; (2) diminishing the set of non-college workers that hold middle-skill jobs in high-wage cities; and (3) attenuating, to a startling degree, the steep urban wage premium for non-college workers that prevailed in earlier decades. Changes in the nature of work--many of which are technological in origin--have been more disruptive and less",5
24605abbd047e294a806ee97df3c28965bc14226,The Digital Divide: Addressing Artificial Intelligence in Communication Education,"Artificial intelligence (AI) has gained both momentum and importance within society over the past several years. This article provides an opening for further discussion to the broader social and digital media research community and those interested in answering important questions related to these areas by leveraging a focused, productive approach. In supporting future educational endeavors within the communication classroom, and specifically to this topic, we propose five important considerations that will move the conversation forward. The considerations within this article are meant to engage scholars in intellectual conversation and to provide an initial foundation for the direction of communication education. They are not meant to be an exhaustive list, but rather initiate discussions within education and research addressing implications emerging technologies have had on our field and what could be incorporated into the media and communication curriculum to prepare educators and students alike.",5
dc1f8bac44b0376d2d043f114a6304aa2526095a,Application of Semi-Supervised Convolutional Neural Network Regression Model Based on Data Augmentation and Process Spectral Labeling in Raman Predictive Modeling of Cell Culture Processes,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
1e490d1e7ba2d4698169a058bdb3b2eb267ab101,Interpretation of symptoms with a data-processing machine.,"Recognizing that machines in the practice of medicine are here to stay, physicians have the obligation to learn as much of their advantages and limitations as they can comprehend. The machine described here merely correlates symptoms set down by the patient and draws conclusions on the basis of what it has ""learned"" from physicians. Hence it makes the same errors as the human brain which ""taught"" it plus others that arc inherent in its inability to initiate the thinking process. One reviewer of the paper presented below asked this important question, ""What is the character of the error when a diagnosis is made which is not correct? If a patient with flat feet is simply not so diagnosed, this is one type of error, but if the machine reads, 'respiratory tuberculosis inactive,' it's another."" This and many other questions properly may arise. At the same time, the device is an",4
7d5a10aebeb57d1bf7bb6585eb45ab481f964be9,Sharing Knowledge: A Functionalist Account of Assertion,"References Dreff, E. Forthcoming. Spinoza: A Philosopher of Love. Berlin: De Gruyter Press. Sharp, H. 2011. Spinoza and the Politics of Renaturalization. Chicago: University of Chicago Press. Spinoza, B. 2016. The Collected Works of Spinoza. Translated. edited by E. M. Curley. Vol. 1. Princeton: Princeton University Press Strawser, M. 2021. Spinoza and the Philosophy of Love. London, Lexington Books. Youpa, A. 2020. The Ethics of Joy: Spinoza on the Empowered Life. Oxford: Oxford University Press.",5
82adaf8804222437af2ab6d54d23f77a56631395,The challenge of crafting intelligible intelligence,"To trust the behavior of complex AI algorithms, especially in mission-critical settings, they must be made intelligible.",4
72f463e6a50bc9738a45aea57062b495331f4031,SimSensei kiosk: a virtual human interviewer for healthcare decision support,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
82ff921b0680e1c5ada19f752a2ee89b0e027cb5,mRMRe: an R package for parallelized mRMR ensemble feature selection,"MOTIVATION Feature selection is one of the main challenges in analyzing high-throughput genomic data. Minimum redundancy maximum relevance (mRMR) is a particularly fast feature selection method for finding a set of both relevant and complementary features. Here we describe the mRMRe R package, in which the mRMR technique is extended by using an ensemble approach to better explore the feature space and build more robust predictors. To deal with the computational complexity of the ensemble approach, the main functions of the package are implemented and parallelized in C using the openMP Application Programming Interface. RESULTS Our ensemble mRMR implementations outperform the classical mRMR approach in terms of prediction accuracy. They identify genes more relevant to the biological context and may lead to richer biological interpretations. The parallelized functions included in the package show significant gains in terms of run-time speed when compared with previously released packages. AVAILABILITY The R package",7
62af64ddfada1300b2953a1b01679e79e83819ef,Blockchain-based security attack resilience schemes for autonomous vehicles in industry 4.0: A systematic review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
e56dd32ea2436bdaeef7c64df29b221f013e795e,Why Interpretability in Machine Learning? An Answer Using Distributed Detection and Data Fusion Theory,"As artificial intelligence is increasingly affecting all parts of society and life, there is growing recognition that human interpretability of machine learning models is important. It is often argued that accuracy or other similar generalization performance metrics must be sacrificed in order to gain interpretability. Such arguments, however, fail to acknowledge that the overall decision-making system is composed of two entities: the learned model and a human who fuses together model outputs with his or her own information. As such, the relevant performance criteria should be for the entire system, not just for the machine learning component. In this work, we characterize the performance of such two-node tandem data fusion systems using the theory of distributed detection. In doing so, we work in the population setting and model interpretable learned models as multi-level quantizers. We prove that under our abstraction, the overall system of a human with an interpretable classifier",6
d1c91fdf066b9195a25626e903ce55765dde0387,An Explainable Artificial Intelligence System for Small-unit Tactical Behavior,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
0ef957a487251f893670421ae456a2d59e037138,Black-Box vs. White-Box: Understanding Their Advantages and Weaknesses From a Practical Point of View,"Nowadays, in the international scientific community of machine learning, there exists an enormous discussion about the use of black-box models or explainable models; especially in practical problems. On the one hand, a part of the community defends that black-box models are more accurate than explainable models in some contexts, like image preprocessing. On the other hand, there exist another part of the community alleging that explainable models are better than black-box models because they can obtain comparable results and also they can explain these results in a language close to a human expert by using patterns. In this paper, advantages and weaknesses for each approach are shown; taking into account a state-of-the-art review for both approaches, their practical applications, trends, and future challenges. This paper shows that both approaches are suitable for solving practical problems, but experts in machine learning need to understand the input data, the problem to solve,",5
0709e3eff5e28643977bc7f3e88b8f9c71e25912,Mutual Information Feature Selection (MIFS) Based Crop Yield Prediction on Corn and Soybean Crops Using Multilayer Stacked Ensemble Regression (MSER),"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
89664effe9311a20a609d3a2cb514e5ef57cb9ce,"Clinical AI: opacity, accountability, responsibility and liability","The aim of this literature review was to compose a narrative review supported by a systematic approach to critically identify and examine concerns about accountability and the allocation of responsibility and legal liability as applied to the clinician and the technologist as applied the use of opaque AI-powered systems in clinical decision making. This review questions (a) if it is permissible for a clinician to use an opaque AI system (AIS) in clinical decision making and (b) if a patient was harmed as a result of using a clinician using an AIS’s suggestion, how would responsibility and legal liability be allocated? Literature was systematically searched, retrieved, and reviewed from nine databases, which also included items from three clinical professional regulators, as well as relevant grey literature from governmental and non-governmental organisations. This literature was subjected to inclusion/exclusion criteria; those items found relevant to this review underwent data extraction. This review",5
0a1da3d352f83f7c539e621ed0ec4d292d812a10,The ethics of AI in health care: A mapping review.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
d844490ca2edb76c76e1b460b7e84875e4f21b11,Why to Buy Insurance? An Explainable Artificial Intelligence Approach,"We propose an Explainable AI model that can be employed in order to explain why a customer buys or abandons a non-life insurance coverage. The method consists in applying similarity clustering to the Shapley values that were obtained from a highly accurate XGBoost predictive classification algorithm. Our proposed method can be embedded into a technologically-based insurance service (Insurtech), allowing to understand, in real time, the factors that most contribute to customers’ decisions, thereby gaining proactive insights on their needs. We prove the validity of our model with an empirical analysis that was conducted on data regarding purchases of insurance micro-policies. Two aspects are investigated: the propensity to buy an insurance policy and the risk of churn of an existing customer. The results from the analysis reveal that customers can be effectively and quickly grouped according to a similar set of characteristics, which can predict their buying or churn behaviour well.",4
940284a49e54dca96cfed006f8ae252a11ff6157,"The threat, hype, and promise of artificial intelligence in education","The idea of building intelligent machines has been around for centuries, with a new wave of promising artificial intelligence (AI) in the twenty-first century. Artificial Intelligence in Education (AIED) is a younger phenomenon that has created hype and promises, but also been seen as a threat by critical voices. There have been rich discussions on over-optimism and hype in contemporary AI research. Less has been written about the hyped expectations on AIED and its potential to transform current education. There is huge potential for efficiency and cost reduction, but there is also aspects of quality education and the teacher role. The aim of the study is to identify potential aspects of threat, hype and promise in artificial intelligence for education. A scoping literature review was conducted to gather relevant state-of-the art research in the field of AIED. Main keywords used in the literature search were: artificial intelligence, artificial intelligence in",4
cef530e1a4b270262e1d17327711d4c59a7d99a5,A review on extreme learning machine,"Extreme learning machine (ELM) is a training algorithm for single hidden layer feedforward neural network (SLFN), which converges much faster than traditional methods and yields promising performance. In this paper, we hope to present a comprehensive review on ELM. Firstly, we will focus on the theoretical analysis including universal approximation theory and generalization. Then, the various improvements are listed, which help ELM works better in terms of stability, efficiency, and accuracy. Because of its outstanding performance, ELM has been successfully applied in many real-time learning tasks for classification, clustering, and regression. Besides, we report the applications of ELM in medical imaging: MRI, CT, and mammogram. The controversies of ELM were also discussed in this paper. We aim to report these advances and find some future perspectives.",4
7c7d0f1b8ce0608ad6ab794024e74aae739815d4,WHO Offers Guidance on Use of Artificial Intelligence in Medicine.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
917c69fa21d2579a96a06c22fc3df2c518c52b30,United Nations Educational Scientific and Cultural Organization (UNESCO),"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
89c3bd70ad33c4f8832f00ab98872b77861ee0ec,Discovering Latent Knowledge in Language Models Without Supervision,"Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms zero-shot accuracy by 4\% on average. We also find",1
2f260603c47abfe0bfc9baf48fef40733d07d0e9,Investigations on Explainable Artificial Intelligence methods for the deep learning classification of fibre layup defect in the automated composite manufacturing,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
bb40d39b7884de9babbd719636ac9d5be6b7d4f7,iPlus a User-Centered Methodology for Serious Games Design,"Standard video games are applications whose development process often follows a traditional software methodology. Serious Games (SGs) are a tool with an immensely positive impact and great success. SGs enable learning and provide entertainment and self-empowerment, which motivates students. The development of an SG consists of complex processes requiring multi-disciplinary knowledge in multiple domains, including knowing the learning domain and adding the appropriate game mechanics to foster high intrinsic motivation and positive player experience that makes the players feel like they are having fun while learning. Otherwise, the game is viewed as boring and not as a fun and engaging activity. Nevertheless, despite their potential, the application of SGs in education has been limited in terms of pedagogy. Several authors assert that this lack is because SG standards and guidelines have not been developed. There is an imbalance between experts’ contributions to education and game design specialists for the SG",5
e594f938aca2018223dec29edf55b61d4c9f6081,"Trust, Distrust and Commitment","Trust is intriguing. Trust is valued—the alleged crisis of trust is a famine not a flood—yet misplaced trust can be dangerous. Trust is needed when we lack knowledge, yet we have most trust in those we know best. Trust bestowed can be both an honour and a burden; distrust is rarely welcome. Practical reasons to trust can outstrip the evidence, yet counter-evidence can make it impossible to trust. Recent philosophical work on trust has emphasised its importance to both epistemology and ethics, asking whether reasons to trust someone must be based on reasons to think her trustworthy (e.g. Hinchman 2005, Faulkner 2007, McGeer 2008, Hieronymi 2008). But this work, and the literature it builds upon, is curiously lopsided. To understand trust, we must also understand distrust, yet distrust is usually treated as a mere afterthought, or mistakenly equated with the absence of trust. In this paper I offer an account",6
7bdacd396ae8662f6397c781c06e2d48bd87caa4,Litter on the streets - solid waste detection using VHR images,"ABSTRACT Failures in urban areas’ solid waste management lead to clandestine garbage dumping and pollution. This affects sanitation and public human hygiene, deteriorates quality of life, and contributes to deprivation. This study aimed to test a combination of machine learning, high-resolution earth observation and GIS data to detect diverse categories of residual waste on the streets, such as sacks and construction debris. We conceptualised five different classes of solid waste from image interpretation: “Sure”, “Half-sure”, “Not-sure”, “Dispersed”, and “Non-garbage”. We tested a combination of k-means-based segmentation and supervised random forest to investigate the capabilities of automatic classification of these waste classes. The model can detect the presence of solid waste on the streets and achieved an accuracy of up from 73.95%–95.76% for the class “Sure”. Moreover, a building extraction using an EfficientNet deep-learning-based semantic segmentation allowed masking the rooftops. This improved the accuracy of the classes “Sure” and “Non-garbage”. The",3
4f387e240d9428cb889ef4ccc1858ba2d39920b2,Explainable AI for Designers: A Human-Centered Perspective on Mixed-Initiative Co-Creation,"Growing interest in eXplainable Artificial Intelligence (XAI) aims to make AI and machine learning more understandable to human users. However, most existing work focuses on new algorithms, and not on usability, practical interpretability and efficacy on real users. In this vision paper, we propose a new research area of eXplainable AI for Designers (XAID), specifically for game designers. By focusing on a specific user group, their needs and tasks, we propose a human-centered approach for facilitating game designers to co-create with AI/ML techniques through XAID. We illustrate our initial XAID framework through three use cases, which require an understanding both of the innate properties of the AI techniques and users’ needs, and we identify key open challenges.",8
29f555d643915471981aaa5b07c3b94bd962329b,Human and artificial cognition,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
9534e6b18c015575f7f49d5a1252c6a854a690d7,Ethics and governance of trustworthy medical artificial intelligence,"Background The growing application of artificial intelligence (AI) in healthcare has brought technological breakthroughs to traditional diagnosis and treatment, but it is accompanied by many risks and challenges. These adverse effects are also seen as ethical issues and affect trustworthiness in medical AI and need to be managed through identification, prognosis and monitoring. Methods We adopted a multidisciplinary approach and summarized five subjects that influence the trustworthiness of medical AI: data quality, algorithmic bias, opacity, safety and security, and responsibility attribution, and discussed these factors from the perspectives of technology, law, and healthcare stakeholders and institutions. The ethical framework of ethical values-ethical principles-ethical norms is used to propose corresponding ethical governance countermeasures for trustworthy medical AI from the ethical, legal, and regulatory aspects. Results Medical data are primarily unstructured, lacking uniform and standardized annotation, and data quality will directly affect the quality of medical AI algorithm models. Algorithmic bias can",3
c952722b1261744c87bbfed09eeae4fa68486a50,Rethinking the entwinement between artificial intelligence and human learning: What capabilities do learners need for a world with AI?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
b9505b57bf41d127ab786fd0d6c0a0fae7e69f07,ChatGPT for Education and Research: A Review of Benefits and Risks,"Generative Pre-trained Transformer (ChatGPT) is an artificial intelligence (AI) tool that can quickly generate detailed responses to prompts and follow-up questions. This emerging AI tool was launched in November 2022 by an American AI research laboratory, called OpenAI, using large language models. In this article, the benefits and risks related to the use of ChatGPT in education and research are discussed. The article argues that ChatGPT has at least five main benefits, such as creating learning assessment, enhancing pedagogical practice, offering virtual personal tutoring, creating an essay or research article outline, and brainstorming ideas. However, there are risks related to academic integrity issues, unfair learning assessment, inaccurate information, and over-reliance on AI. The article offers a set of recommendations for effective use of ChatGPT for educational and research purposes.",3
dd4dc681cba9337748105482586cfff558911cb7,Readability of Online Patient Educational Materials for Coronary Artery Calcium Scans and Implications for Health Disparities,"Background Coronary artery calcium (CAC) scans can help reclassify risk and guide patient‐clinician shared treatment decisions for cardiovascular disease prevention. Patients increasingly access online patient educational materials (OPEMs) to guide medical decision‐making. The American Medical Association (AMA) recommends that OPEMs should be written below a 6th‐grade reading level. This study estimated the readability of commonly accessed OPEMs on CAC scans. Methods and Results The terms “coronary artery calcium scan,” “heart scan,” and “CAC score” were queried using an online search engine to identify the top 50 commonly accessed websites based on order of search results on December 17, 2019. Grade‐level readability was calculated using generalized estimating equations, with observations nested within readability metrics from each website. Results were compared with AMA‐recommended readability parameters. Overall grade‐level readability among all search terms was 10.9 (95% CI, 9.3–12.5). Average grade‐level readability of OPEMs for the search terms “coronary artery calcium scan,” “heart scan,”",4
7167fb2754032a4262be179dedf5607aea311c3c,Linking Trust to Trustworthiness,"Abstract Trust is valuable when placed in trustworthy agents and activities, but damaging or costly when (mis)placed in untrustworthy agents and activities. So it is puzzling that much contemporary work on trust – such as that based on polling evidence – studies generic attitudes of trust in types of agent, institution or activity in complete abstraction from any account of trustworthiness. Information about others’ generic attitudes of trust or mistrust that take no account of evidence whether those attitudes are well or ill placed can offer little or no help for those who aim to place or refuse trust well. Information about attitudes is evidently useful to those who aim to influence those who hold them, which explains why polls about attitudes are popular with political parties, advertisers and other campaigning organisations. But where we aim not to influence others, but to place and refuse trust intelligently we must link",6
9e574373ef1e8b4ded223b9e70a1c1853314020f,Can Artificial Intelligence Improve the Readability of Patient Education Materials?,"Abstract Background The recommended readability of online health education materials is at or below the sixth- to eighth-grade level. Nevertheless, more than a decade of research has demonstrated that most online education materials pertaining to orthopaedic surgery do not meet these recommendations. The repeated evidence of this limited progress underscores that unaddressed barriers exist to improving readability, such as the added time and cost associated with writing easily readable materials that cover complex topics. Freely available artificial intelligence (AI) platforms might facilitate the conversion of patient-education materials at scale, but to our knowledge, this has not been evaluated in orthopaedic surgery. Questions/purposes (1) Can a freely available AI dialogue platform rewrite orthopaedic patient education materials to reduce the required reading skill level from the high-school level to the sixth-grade level (which is approximately the median reading level in the United States)? (2) Were the converted materials accurate, and did they",3
fd4411f035e6ad587d265d01c28522f0e02206c8,AI Benchmark: Running Deep Neural Networks on Android Smartphones,"Over the last years, the computational power of mobile devices such as smartphones and tablets has grown dramatically, reaching the level of desktop computers available not long ago. While standard smartphone apps are no longer a problem for them, there is still a group of tasks that can easily challenge even high-end devices, namely running artificial intelligence algorithms. In this paper, we present a study of the current state of deep learning in the Android ecosystem and describe available frameworks, programming models and the limitations of running AI on smartphones. We give an overview of the hardware acceleration resources available on four main mobile chipset platforms: Qualcomm, HiSilicon, MediaTek and Samsung. Additionally, we present the real-world performance results of different mobile SoCs collected with AI Benchmark (http://ai-benchmark.com) that are covering all main existing hardware configurations.",3
6a2a24fa98536ca52de80697710d5a87b8f3ef97,"Video Capsule Endoscopy and Ingestible Electronics: Emerging Trends in Sensors, Circuits, Materials, Telemetry, Optics, and Rapid Reading Software","Real-time monitoring of the gastrointestinal tract in a safe and comfortable manner is valuable for the diagnosis and therapy of many diseases. Within this realm, our review captures the trends in ingestible capsule systems with a focus on hardware and software technologies used for capsule endoscopy and remote patient monitoring. We introduce the structure and functions of the gastrointestinal tract, and the FDA guidelines for ingestible wireless telemetric medical devices. We survey the advanced features incorporated in ingestible capsule systems, such as microrobotics, closed-loop feedback, physiological sensing, nerve stimulation, sampling and delivery, panoramic imaging with adaptive frame rates, and rapid reading software. Examples of experimental and commercialized capsule systems are presented with descriptions of their sensors, devices, and circuits for gastrointestinal health monitoring. We also show the recent research in biocompatible materials and batteries, edible electronics, and alternative energy sources for ingestible capsule systems. The results from clinical studies are",5
01e1ad39a01a715c94b77992a1fb9b39c97f2e48,"ARTIFICIAL INTELLIGENCE IN SUSTAINABLE ENERGY INDUSTRY: STATUS QUO, CHALLENGES, AND OPPORTUNITIES","This study focuses on the future of AI in the energy sector, examining how AI can be used to improve efficiency and sustainability in the sector. The study aims to provide a realistic baseline of AI technology that can be used to compare efforts, ambitions, new applications, and challenges around the world. We covered three main topics: (i) how AI is being used in solar and hydrogen power generation; (ii) how AI is being used in supply and demand management control; and (iii) the latest advances in AI technology. In this research we explored how AI techniques outperform traditional models in controllability, energy efficiency optimization, cyber-attack prevention, IoT, big data handling, smart grid, robotics, predictive maintenance control, and computational efficiency. Our study found that AI is becoming an important tool for a new and data-intensive energy industry, which is providing a key magic tool to increase operational performance and efficiency",2
62189e97a09f26dd24b7b4393777e88759659cf1,Leveraging computer algebra systems in calculus: a case study with SymPy,"Technology plays a pivotal role in modern university curriculum. Given the recent advances in machine learning, it is particularly important to leverage the tools provided by the latest advances in computing. In this paper, we investigate the effects of including Python-based computer algebra system SymPy in university calculus courses. The advantages of SymPy include open-source, introduction to programming, and simplicity. Critically, comparison of the grades pre and post adoption of SymPy in calculus courses indicates a statistically significant improvement. Although further studies - based on a larger cohort - about the effectiveness of open-access computer algebra system are desirable, the initial findings suggest that SymPy provides a viable alternative to commercially available computer algebra system.",3
b08d575f4d8afab06bb7e6fb89827124ed25da8c,Mapping out a research agenda for generative artificial intelligence in tertiary education,"Generative artificial intelligence (AI) has taken the world by storm. In this editorial, we outline some of the key areas of tertiary education impacted by large language models and associated applications that will require re-thinking and research to address in the short to medium term. Given how rapidly generative AI developments are currently occurring, this editorial is speculative. Although there is a long history of research on AI in education, the current situation is both unprecedented and seemingly not something that the AI in education community fully predicted. We also outline the editorial position of AJET in regards to generative AI to assist authors using tools such as ChatGPT as any part of the research or writing process. This is a rapidly evolving space. We have attempted to provide some clarity in this editorial while acknowledging that we may need to revisit some or all of what we offer here",1
6ff75ef14c71e606d76ad186a8c9515344ecc9a9,Natural Language Processing Applications for Computer-Aided Diagnosis in Oncology,"In the era of big data, text-based medical data, such as electronic health records (EHR) and electronic medical records (EMR), are growing rapidly. EHR and EMR are collected from patients to record their basic information, lab tests, vital signs, clinical notes, and reports. EHR and EMR contain the helpful information to assist oncologists in computer-aided diagnosis and decision making. However, it is time consuming for doctors to extract the valuable information they need and analyze the information from the EHR and EMR data. Recently, more and more research works have applied natural language processing (NLP) techniques, i.e., rule-based, machine learning-based, and deep learning-based techniques, on the EHR and EMR data for computer-aided diagnosis in oncology. The objective of this review is to narratively review the recent progress in the area of NLP applications for computer-aided diagnosis in oncology. Moreover, we intend to reduce the research gap between artificial intelligence (AI)",3
f07d5ae0bd63f1600392b6f3b718b78b4de655b8,Empowering educators to be AI-ready,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
6e6c03c3a971ca0d17f21bd094beaca51b514676,Identifying Ethical Considerations for Machine Learning Healthcare Applications,"Abstract Along with potential benefits to healthcare delivery, machine learning healthcare applications (ML-HCAs) raise a number of ethical concerns. Ethical evaluations of ML-HCAs will need to structure the overall problem of evaluating these technologies, especially for a diverse group of stakeholders. This paper outlines a systematic approach to identifying ML-HCA ethical concerns, starting with a conceptual model of the pipeline of the conception, development, implementation of ML-HCAs, and the parallel pipeline of evaluation and oversight tasks at each stage. Over this model, we layer key questions that raise value-based issues, along with ethical considerations identified in large part by a literature review, but also identifying some ethical considerations that have yet to receive attention. This pipeline model framework will be useful for systematic ethical appraisals of ML-HCA from development through implementation, and for interdisciplinary collaboration of diverse stakeholders that will be required to understand and subsequently manage the ethical implications",6
b4d0031594c7cfb6d9628bb12abc4de6eb048765,Ethical and legal responsibility for Artificial Intelligence,"“In civilized life, law floats in a sea of ethics”, a quote by the former Chief Justice of the United States, Earl Warren. In a democratic society, the constitution defines the country’s values, and the laws define the preferred or at least still tolerated behavior, making deviations sanctionable. As the society is in a continuous flow, also based on scientific and technical developments, law always lags behind. Until regulations can catch up, ethics has to lead society. In less democratic societies, the water gets polluted up to poisoned, ethical behavior may be against ruling law. As for the latter, Robin Hood was a thief, but for most parts of the population, a hero. The less transparent the water, the more difficult to adapt law to new developments. This includes direct corruption, but also unfaithful lobbying. This article discusses the “nature” of Artificial Intelligence, including the risks its posing, and who",5
29a32648fe0cb09980697c28176113439a81a64d,ChatGPT - Reshaping medical education and clinical management,"Artificial Intelligence is no more the talk of the fiction read in novels or seen in movies. It has been making inroads slowly and gradually in medical education and clinical management of patients apart from all other walks of life. Recently, chatbots particularly ChatGPT, were developed and trained, using a huge amount of textual data from the internet. This has made a significant impact on our approach in medical science. Though there are benefits of this new technology, a lot of caution is required for its use.",9
35d5bfd7ec723b821ac82fcd2cf4b3039c7f13d9,Exosome nanovesicles: A potential carrier for therapeutic delivery,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
906f27ffbe1508f3b3d33dee3dab2d23b69d9505,Explainable Planning,"As AI is increasingly being adopted into application solutions, the challenge of supporting interaction with humans is becoming more apparent. Partly this is to support integrated working styles, in which humans and intelligent systems cooperate in problem-solving, but also it is a necessary step in the process of building trust as humans migrate greater responsibility to such systems. The challenge is to find effective ways to communicate the foundations of AI-driven behaviour, when the algorithms that drive it are far from transparent to humans. In this paper we consider the opportunities that arise in AI planning, exploiting the modelbased representations that form a familiar and common basis for communication with users, while acknowledging the gap between planning algorithms and human problem-solving.",10
1467897d804351ce33d74b3497292fedd9710d3b,"AI-oriented Smart Power System Transient Stability: The Rationality, Applications, Challenges and Future Opportunities","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
0570e8fc8b02e7eb66e798b00726fba0592ea90f,ChatGPT listed as author on research papers: many scientists disapprove,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
7481102d1943c21194e623d08c35930088c4e521,Hallucinating symmetric protein assemblies,"Deep learning generative approaches provide an opportunity to broadly explore protein structure space beyond the sequences and structures of natural proteins. Here, we use deep network hallucination to generate a wide range of symmetric protein homo-oligomers given only a specification of the number of protomers and the protomer length. Crystal structures of seven designs are very similar to the computational models (median root mean square deviation: 0.6 angstroms), as are three cryo–electron microscopy structures of giant 10-nanometer rings with up to 1550 residues and C33 symmetry; all differ considerably from previously solved structures. Our results highlight the rich diversity of new protein structures that can be generated using deep learning and pave the way for the design of increasingly complex components for nanomachines and biomaterials. Description Deep learning takes on protein design Deep learning approaches such as Alphafold and Rosettafold have made reliable protein structure prediction broadly accessible. For the",5
ee355f8a7f35f3ea65b9fbefac63da4d5eb31db1,Social Attribution and Explanation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
62a45ab7b676f3877d41f66f6c9ddf1ec44a1c5f,GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics,"We seek to transform how new and emergent variants of pandemic-causing viruses, specifically SARS-CoV-2, are identified and classified. By adapting large language models (LLMs) for genomic data, we build genome-scale language models (GenSLMs) which can learn the evolutionary landscape of SARS-CoV-2 genomes. By pre-training on over 110 million prokaryotic gene sequences and fine-tuning a SARS-CoV-2-specific model on 1.5 million genomes, we show that GenSLMs can accurately and rapidly identify variants of concern. Thus, to our knowledge, GenSLMs represents one of the first whole-genome scale foundation models which can generalize to other prediction tasks. We demonstrate scaling of GenSLMs on GPU-based supercomputers and AI-hardware accelerators utilizing 1.63 Zettaflops in training runs with a sustained performance of 121 PFLOPS in mixed precision and peak of 850 PFLOPS. We present initial scientific insights from examining GenSLMs in tracking evolutionary dynamics of SARS-CoV-2, paving the path to realizing this on large biological data.",4
5d35119a1608582bed987df60861765245bdad8e,Interpretable Approaches to Detect Bias in Black-Box Models,"My dissertation research is grounded in the field of interpretability. I aim to develop methods to explain and interpret predictions from black-box machine learning models to help creators, as well as users, of machine learning models increase their trust and understanding of the models. In this doctoral consortium paper, I summarize my previous and current research projects in interpretability, and describe my future plans for research in this area.",7
82d9f1db6db43cb61fe4b0b26a489a2e72628675,A Test for Evaluating Performance in Human-Computer Systems,"The Turing test for comparing computer performance to that of humans is well known, but, surprisingly, there is no widely used test for comparing how much better human-computer systems perform relative to humans alone, computers alone, or other baselines. Here, we show how to perform such a test using the ratio of means as a measure of effect size. Then we demonstrate the use of this test in three ways. First, in an analysis of 79 recently published experimental results, we find that, surprisingly, over half of the studies find a decrease in performance, the mean and median ratios of performance improvement are both approximately 1 (corresponding to no improvement at all), and the maximum ratio is 1.36 (a 36% improvement). Second, we experimentally investigate whether a higher performance improvement ratio is obtained when 100 human programmers generate software using GPT-3, a massive, state-of-the-art AI system. In this case, we",3
ce3d844959ea83024e7f744b4d07160bd165b0b4,With Us or Against Us: Simulated Social Touch by Virtual Agents in a Cooperative or Competitive Setting,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
1342e7d83381608daf703757eb1716a83549edc9,Digitization and validation of a chemical synthesis literature database in the ChemPU,"Despite huge potential, automation of synthetic chemistry has only made incremental progress over the past few decades. We present an automatically executable chemical reaction database of 100 molecules representative of the range of reactions found in contemporary organic synthesis. These reactions include transition metal–catalyzed coupling reactions, heterocycle formations, functional group interconversions, and multicomponent reactions. The chemical reaction codes or χDLs for the reactions have been stored in a database for version control, validation, collaboration, and data mining. Of these syntheses, more than 50 entries from the database have been downloaded and robotically run in seven modular ChemPU’s with yields and purities comparable to those achieved by an expert chemist. We also demonstrate the automatic purification of a range of compounds using a chromatography module seamlessly coupled to the platform and programmed with the same language. Description Toward automation of common chemistry Most experiments in modern organic chemistry require prior preparation",3
1537a94da341031dafeeb303d1597c674376d6f7,Explainable Artificial Intelligence for Developing Smart Cities Solutions,"Traditional Artificial Intelligence (AI) technologies used in developing smart cities solutions, Machine Learning (ML) and recently Deep Learning (DL), rely more on utilising best representative training datasets and features engineering and less on the available domain expertise. We argue that such an approach to solution development makes the outcome of solutions less explainable, i.e., it is often not possible to explain the results of the model. There is a growing concern among policymakers in cities with this lack of explainability of AI solutions, and this is considered a major hindrance in the wider acceptability and trust in such AI-based solutions. In this work, we survey the concept of ‘explainable deep learning’ as a subset of the ‘explainable AI’ problem and propose a new solution using Semantic Web technologies, demonstrated with a smart cities flood monitoring application in the context of a European Commission-funded project. Monitoring of gullies and drainage in",2
6855557b3ae4cb70c758fa2b89d43221b33ecede,Interpretable Deep-Learning Approaches for Osteoporosis Risk Screening and Individualized Feature Analysis Using Large Population-Based Data: Model Development and Performance Evaluation,"Background Osteoporosis is one of the diseases that requires early screening and detection for its management. Common clinical tools and machine-learning (ML) models for screening osteoporosis have been developed, but they show limitations such as low accuracy. Moreover, these methods are confined to limited risk factors and lack individualized explanation. Objective The aim of this study was to develop an interpretable deep-learning (DL) model for osteoporosis risk screening with clinical features. Clinical interpretation with individual explanations of feature contributions is provided using an explainable artificial intelligence (XAI) technique. Methods We used two separate data sets: the National Health and Nutrition Examination Survey data sets from the United States (NHANES) and South Korea (KNHANES) with 8274 and 8680 respondents, respectively. The study population was classified according to the T-score of bone mineral density at the femoral neck or total femur. A DL model for osteoporosis diagnosis was trained on the data",4
ee9acac0d8798fe961b59c7b9f9941f1c7607d34,On the radar: Predicting near-future surges in skills’ hiring demand to provide early warning to educators,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
46e7a7e8adb610f76bd0bc196282b92c846fe939,REIN: A Comprehensive Benchmark Framework for Data Cleaning Methods in ML Pipelines,"Nowadays, machine learning (ML) plays a vital role in many aspects of our daily life. In essence, building well-performing ML applications requires the provision of high-quality data throughout the entire life-cycle of such applications. Nevertheless, most of the real-world tabular data suffer from different types of discrepancies, such as missing values, outliers, duplicates, pattern violation, and inconsistencies. Such discrepancies typically emerge while collecting, transferring, storing, and/or integrating the data. To deal with these discrepancies, numerous data cleaning methods have been introduced. However, the majority of such methods broadly overlook the requirements imposed by downstream ML models. As a result, the potential of utilizing these data cleaning methods in ML pipelines is predominantly unrevealed. In this work, we introduce a comprehensive benchmark, called REIN1, to thoroughly investigate the impact of data cleaning methods on various ML models. Through the benchmark, we provide answers to important research questions, e.g., where and whether",4
d0dcc9d1ed709e78059f4a29799c41b1b30a2f26,A Legal Study on the UNESCO’s ‘the Recommendation on the Ethics of Artificial Intelligence’,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
a82d3924f488d74af91ba31ff1cf80a6c07ee206,Combining Generative Artificial Intelligence (AI) and the Internet: Heading towards Evolution or Degradation?,"In the span of a few months, generative Artificial Intelligence (AI) tools that can generate realistic images or text have taken the Internet by storm, making them one of the technologies with fastest adoption ever. Some of these generative AI tools such as DALL-E, MidJourney, or ChatGPT have gained wide public notoriety. Interestingly, these tools are possible because of the massive amount of data (text and images) available on the Internet. The tools are trained on massive data sets that are scraped from Internet sites. And now, these generative AI tools are creating massive amounts of new data that are being fed into the Internet. Therefore, future versions of generative AI tools will be trained with Internet data that is a mix of original and AI-generated data. As time goes on, a mixture of original data and data generated by different versions of AI tools will populate the Internet. This",8
ce81a788d41bc8c4219db99556bee813f60d14d0,Efficient XAI Techniques: A Taxonomic Survey,"Recently, there has been a growing demand for the deployment of Explainable Artificial Intelligence (XAI) algorithms in real-world applications. However, traditional XAI methods typically suffer from a high computational complexity problem, which discourages the deployment of real-time systems to meet the time-demanding requirements of real-world scenarios. Although many approaches have been proposed to improve the efficiency of XAI methods, a comprehensive understanding of the achievements and challenges is still needed. To this end, in this paper we provide a review of efficient XAI. Specifically, we categorize existing techniques of XAI acceleration into efficient non-amortized and efficient amortized methods. The efficient non-amortized methods focus on data-centric or model-centric acceleration upon each individual instance. In contrast, amortized methods focus on learning a unified distribution of model explanations, following the predictive, generative, or reinforcement frameworks, to rapidly derive multiple model explanations. We also analyze the limitations of an efficient XAI pipeline from the",5
161e07482a298a126309a09ec93f44929722d3d2,An IoT‐based human detection system for complex industrial environment with deep learning architectures and transfer learning,"Artificial intelligence (AI), combined with the Internet of Things (IoT), plays a beneficial role in various fields, including intelligent surveillance applications. With IoT and 5G advancement, intelligent sensors, and devices in the surveillance environment collect large amounts of data in the form of videos and images. These collected data require intelligent information processing solutions, help analyze the recorded videos and images to detect and identify various objects in the scene, particularly humans. In this study, an automated human detection system is presented for a complex industrial environment, in which people are monitored/detected from a top view perspective. A top view is usually preferred because it can provide sufficient coverage and enough visibility of a scene. This study demonstrates the applications, efficiency, and effectiveness of deep learning architectures, that is, Faster Region Convolutional Neural Network (Faster R‐CNN), Single Shot MultiBox Detector (SSD), and You Only Look Once (YOLOv3), with transfer learning.",3
7ac3e09d74ca15fdafa5f730617cd65059a144f3,Weakly Supervised Anomaly Detection: A Survey,"Anomaly detection (AD) is a crucial task in machine learning with various applications, such as detecting emerging diseases, identifying financial frauds, and detecting fake news. However, obtaining complete, accurate, and precise labels for AD tasks can be expensive and challenging due to the cost and difficulties in data annotation. To address this issue, researchers have developed AD methods that can work with incomplete, inexact, and inaccurate supervision, collectively summarized as weakly supervised anomaly detection (WSAD) methods. In this study, we present the first comprehensive survey of WSAD methods by categorizing them into the above three weak supervision settings across four data modalities (i.e., tabular, graph, time-series, and image/video data). For each setting, we provide formal definitions, key algorithms, and potential future directions. To support future research, we conduct experiments on a selected setting and release the source code, along with a collection of WSAD methods and data.",3
03c9711c6a017ee2443c23cc93db1f6fa22e3652,An empirical study on how humans appreciate automated counterfactual explanations which embrace imprecise information,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
e0fa5ed16e07ce73be90fd93b98cd240f3995ee7,Federated learning for predicting histological response to neoadjuvant chemotherapy in triple-negative breast cancer,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
d3403aa9b57f69f85a61a84a83c0c5f2f284c97e,How Much More Data Do I Need? Estimating Requirements for Downstream Tasks,"Given a small training data set and a learning algorithm, how much more data is necessary to reach a target validation or test performance? This question is of critical importance in applications such as autonomous driving or medical imaging where collecting data is expensive and time-consuming. Overestimating or underestimating data requirements incurs substantial costs that could be avoided with an adequate budget. Prior work on neural scaling laws suggest that the power-law function can fit the validation performance curve and extrapolate it to larger data set sizes. We find that this does not immediately translate to the more difficult downstream task of estimating the required data set size to meet a target performance. In this work, we consider a broad class of computer vision tasks and systematically investigate a family of functions that generalize the power-law function to allow for better estimation of data requirements. Finally, we show that incorporating",1
1315975ac498ddbc5f43cc4afe1ce10c8d60d238,Somatic Mutations Drive Distinct Imaging Phenotypes in Lung Cancer.,"Tumors are characterized by somatic mutations that drive biological processes ultimately reflected in tumor phenotype. With regard to radiographic phenotypes, generally unconnected through present understanding to the presence of specific mutations, artificial intelligence methods can automatically quantify phenotypic characters by using predefined, engineered algorithms or automatic deep-learning methods, a process also known as radiomics. Here we demonstrate how imaging phenotypes can be connected to somatic mutations through an integrated analysis of independent datasets of 763 lung adenocarcinoma patients with somatic mutation testing and engineered CT image analytics. We developed radiomic signatures capable of distinguishing between tumor genotypes in a discovery cohort (n = 353) and verified them in an independent validation cohort (n = 352). All radiomic signatures significantly outperformed conventional radiographic predictors (tumor volume and maximum diameter). We found a radiomic signature related to radiographic heterogeneity that successfully discriminated between EGFR+ and EGFR- cases (AUC = 0.69). Combining this",3
572e93355389ef5fa94c7ffbb47c8570cd72ca71,A deep-learning model for transforming the style of tissue images from cryosectioned to formalin-fixed and paraffin-embedded,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
15abedb29536d50afeeec739a25358255cbda3e8,The Impact of AI on Developer Productivity: Evidence from GitHub Copilot,"Generative AI tools hold promise to increase human productivity. This paper presents results from a controlled experiment with GitHub Copilot, an AI pair programmer. Recruited software developers were asked to implement an HTTP server in JavaScript as quickly as possible. The treatment group, with access to the AI pair programmer, completed the task 55.8% faster than the control group. Observed heterogenous effects show promise for AI pair programmers to help people transition into software development careers.",8
17dec4292289bfaa1b5342a8719a58b9f88cd4ec,Conceptualizing AI literacy: An exploratory review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
35285ee3056d32f8ed5bc1fee6c3aa70afadd108,How will Language Modelers like ChatGPT Affect Occupations and Industries?,"Recent dramatic increases in AI language modeling capabilities has led to many questions about the effect of these technologies on the economy. In this paper we present a methodology to systematically assess the extent to which occupations, industries and geographies are exposed to advances in AI language modeling capabilities. We find that the top occupations exposed to language modeling include telemarketers and a variety of post-secondary teachers such as English language and literature, foreign language and literature, and history teachers. We find the top industries exposed to advances in language modeling are legal services and securities, commodities, and investments. We also find a positive correlation between wages and exposure to AI language modeling.",6
66a15e9448092ee1fff9a67e288238e399a9fc17,The Impact of Artificial Intelligence (AI) Programs on Writing Scientific Research,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
ca533a9ff755b5c2ece49b2ef72ff6bce5753949,A qualitative study,"Objective: Very little research has been conducted that examines men, sport, masculinities, and disability in the context of health. Readdressing this absence, this paper examines the health narratives told by spinal injured men and the work narratives do on, in, and for them. Methods: In-depth life history interviews and fieldwork observations with men (n=17) who sustained a spinal injury through playing sport and are now disabled were conducted. Qualitative data were analyzed using a dialogical narrative analysis. Results: Stories told about health characterized a style of embodied actions choices that anticipated a certain type of narrative, that is, an emergent narrative. The men’s narrative habitus, fashioned through the process rehabilitation, predisposed them to be interpellated to care about health. To uphold hegemonic masculinities the men also did not care too much about health. The analysis also reveals the work narratives do on, in, and for health behavior, masculine identities, resilience,",3
5ac2c3e8a473652efacb26f61329aed053bf7676,Investigating the COVID-19 vaccine discussions on Twitter through a multilayer network-based approach,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
b96812c43ea45d2cc852c01a6dc3de15d6b31e08,Outage-Limit-Approaching Channel Coding for Future Wireless Communications: Root-Protograph Low-Density Parity-Check Codes,"A block-fading (BF) channel, also known as a slow-fading channel, is a type of simple and practical channel model that can characterize the primary feature of a number of wireless-communication applications with low to moderate mobility. Although BF channels have received significant research attention in the past 20 years, designing low-complexity, outage-limit-approaching error-correction codes (ECCs) is still a challenging issue. For this reason, a novel family of protograph low-density paritycheck (LDPC) codes, called rootprotograph (RP) LDPC codes, has been conceived recently. The RP codes not only can realize linearcomplexity encoding and highspeed decoding with the help of the quasi-cyclic (QC) structure but can also achieve near-outage-limit performance in different BF scenarios. In this article, we briefly review the design guidelines of such protograph codes with the aim of inspiring further research activities in this area.",3
9aa94773f416d93dc9101ff447f21333129daa5d,"The Landscape of Artificial Intelligence in Open, Online and Distance Education: Promises and Concerns","The Landscape of Artificial Intelligence in Open, Online and Distance Education: Promises and concerns Editorial “Only the unknown frightens men. But once a man has faced the unknown, that terror becomes the known.” Antoine de Saint-Exupery, 1939.",4
16329934abcdbd46e5b0f7c201799c7d8a6d28c4,Defining the biological basis of radiomic phenotypes in lung cancer,"Medical imaging can visualize characteristics of human cancer noninvasively. Radiomics is an emerging field that translates these medical images into quantitative data to enable phenotypic profiling of tumors. While radiomics has been associated with several clinical endpoints, the complex relationships of radiomics, clinical factors, and tumor biology are largely unknown. To this end, we analyzed two independent cohorts of respectively 262 North American and 89 European patients with lung cancer, and consistently identified previously undescribed associations between radiomic imaging features, molecular pathways, and clinical factors. In particular, we found a relationship between imaging features, immune response, inflammation, and survival, which was further validated by immunohistochemical staining. Moreover, a number of imaging features showed predictive value for specific pathways; for example, intra-tumor heterogeneity features predicted activity of RNA polymerase transcription (AUC = 0.62, p=0.03) and intensity dispersion was predictive of the autodegration pathway of a ubiquitin ligase (AUC = 0.69, p<10-4).",5
115297fb487b4fc344029b3f3335494743a40109,"Microplastic sources, formation, toxicity and remediation: a review","Microplastic pollution is becoming a major issue for human health due to the recent discovery of microplastics in most ecosystems. Here, we review the sources, formation, occurrence, toxicity and remediation methods of microplastics. We distinguish ocean-based and land-based sources of microplastics. Microplastics have been found in biological samples such as faeces, sputum, saliva, blood and placenta. Cancer, intestinal, pulmonary, cardiovascular, infectious and inflammatory diseases are induced or mediated by microplastics. Microplastic exposure during pregnancy and maternal period is also discussed. Remediation methods include coagulation, membrane bioreactors, sand filtration, adsorption, photocatalytic degradation, electrocoagulation and magnetic separation. Control strategies comprise reducing plastic usage, behavioural change, and using biodegradable plastics. Global plastic production has risen dramatically over the past 70 years to reach 359 million tonnes. China is the world's top producer, contributing 17.5% to global production, while Turkey generates the most plastic waste in the Mediterranean region, at 144 tonnes per day.",3
d85d7a205dfdde6cc41f46141756d14348557218,Algorithmic fairness in artificial intelligence for medicine and healthcare,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
be3ec164145be75248950558918661e8babd32b2,Towards Explainable Shared Control using Augmented Reality,"Shared control plays a pivotal role in establishing effective human-robot interactions. Traditional control-sharing methods strive to complement a human’s capabilities at safely completing a task, and thereby rely on users forming a mental model of the expected robot behaviour. However, these methods can often bewilder or frustrate users whenever their actions do not elicit the intended system response, forming a misalignment between the respective internal models of the robot and human. To resolve this model misalignment, we introduce Explainable Shared Control as a paradigm in which assistance and information feedback are jointly considered. Augmented reality is presented as an integral component of this paradigm, by visually unveiling the robot’s inner workings to human operators. Explainable Shared Control is instantiated and tested for assistive navigation in a setup involving a robotic wheelchair and a Microsoft HoloLens with add-on eye tracking. Experimental results indicate that the introduced paradigm facilitates transparent assistance by",3
60eaae8784648ca44c1b6100760ccafad03162ee,"The Race between Man and Machine: Implications of Technology for Growth, Factor Shares, and Employment","We examine the concerns that new technologies will render labor redundant in a framework in which tasks previously performed by labor can be automated and new versions of existing tasks, in which labor has a comparative advantage, can be created. In a static version where capital is fixed and technology is exogenous, automation reduces employment and the labor share, and may even reduce wages, while the creation of new tasks has the opposite effects. Our full model endogenizes capital accumulation and the direction of research toward automation and the creation of new tasks. If the long-run rental rate of capital relative to the wage is sufficiently low, the long-run equilibrium involves automation of all tasks. Otherwise, there exists a stable balanced growth path in which the two types of innovations go hand-in-hand. Stability is a consequence of the fact that automation reduces the cost of producing using labor, and thus",9
d0d968351ecf60e10184175f9f64ef0f9a75d112,The AI Revolution in Education: Will AI Replace or Assist Teachers in Higher Education?,"This paper explores the potential of artificial intelligence (AI) in higher education, specifically its capacity to replace or assist human teachers. By reviewing relevant literature and analysing survey data from students and teachers, the study provides a comprehensive perspective on the future role of educators in the face of advancing AI technologies. Findings suggest that although some believe AI may eventually replace teachers, the majority of participants argue that human teachers possess unique qualities, such as critical thinking, creativity, and emotions, which make them irreplaceable. The study also emphasizes the importance of social-emotional competencies developed through human interactions, which AI technologies cannot currently replicate. The research proposes that teachers can effectively integrate AI to enhance teaching and learning without viewing it as a replacement. To do so, teachers need to understand how AI can work well with teachers and students while avoiding potential pitfalls, develop AI literacy, and address practical",5
8cec749bd5843bfd186b911e123afdf61f2a9754,On the moral status of social robots: considering the consciousness criterion,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
76372a4b7d4830a52fdf15e9952df2f060352a85,Deep Generative Models for Fast Photon Shower Simulation in ATLAS,"The need for large-scale production of highly accurate simulated event samples for the extensive physics programme of the ATLAS experiment at the Large Hadron Collider motivates the development of new simulation techniques. Building on the recent success of deep learning algorithms, variational autoencoders and generative adversarial networks are investigated for modelling the response of the central region of the ATLAS electromagnetic calorimeter to photons of various energies. The properties of synthesised showers are compared with showers from a full detector simulation using geant4 . Both variational autoencoders and generative adversarial networks are capable of quickly simulating electromagnetic showers with correct total energies and stochasticity, though the modelling of some shower shape distributions requires more refinement. This feasibility study demonstrates the potential of using such algorithms for ATLAS fast calorimeter simulation in the future and shows a possible way to complement current simulation techniques.",5
3dece1946ea00624cc6a671a950018bef1ae5dab,"Minimize online cheating through proctoring, consequences","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
9497fe972ef8292ed54edc722181f81583a70233,Green construction for low-carbon cities: a review,"The construction industry is a major user of non-renewable energy and contributor to emission of greenhouse gases, thus requiring to achieve net-zero carbon emissions by 2050. Indeed, construction activities account for 36% of global energy consumption and 39% of global carbon dioxide emissions. Reducing carbon emissions requires adapted government policies, carbon emission analysis and calculation models, and sustainable materials. Here, we review green construction with focus on history, carbon emissions, policies, models, life cycle assessment, and sustainable materials such as biochar, bioplastic, agricultural waste, animal wool, fly ash and self-healing concrete. Analysis of carbon emissions over the building life cycle shows that the construction phase accounts for 20–50% of total carbon emissions. The average ratio of construction phase annual emissions to operation phase emissions is 0.62. We present national policy frameworks and technology roadmaps from the United States of America, Japan, China, and the European Union, highlighting plans to achieve",4
c224bd988e89da2872dfcdce32feedeb6e91df3a,"Abstract S6-07: Double blinded validation study to assess performance of IBM artificial intelligence platform, Watson for oncology in comparison with Manipal multidisciplinary tumour board – First study of 638 breast cancer cases","Background: IBM Watson for Oncology (WFO) developed in collaboration with Memorial Sloan Kettering Cancer Centre is a cognitive computing system able to extract structured data from free text documents using natural language processing (NLP). It is a technology platform that uses NLP and machine learning to reveal insights from large amounts of unstructured data. Currently WFO provides treatment options only for breast, lung and colorectal cancers. In the present study we try to evaluate concordance of WFO treatment recommendations with Manipal multidisciplinary tumor board (MMDT),a quaternary health care centre for 638 breast cancer cases. Materials and Methods: MMDT treatment recommendation and relevant clinic-pathological data of 638 breast cancer cases both localised (514) and metastatic (124) disease which were treated in last 3 years was collected and the collected data of all the patients was entered in WFO. The treatment recommendations & the time required to enter the data and the",6
b961c79adab366b370785b82edde1a7cca320726,Using Explainable Artificial Intelligence to Improve Process Quality: Evidence from Semiconductor Manufacturing,"We develop a data-driven decision model to improve process quality in manufacturing. A challenge for traditional methods in quality management is to handle high-dimensional and nonlinear manufacturing data. We address this challenge by adapting explainable artificial intelligence to the context of quality management. Specifically, we propose the use of nonlinear modeling with Shapley additive explanations to infer how a set of production parameters and the process quality of a manufacturing system are related. Thereby, we contribute a measure of process importance based on which manufacturers can prioritize processes for quality improvement. Grounded in quality management theory, our decision model selects improvement actions that target the sources of quality variation. The decision model is validated in a real-world application at a leading manufacturer of high-power semiconductors. Seeking to improve production yield, we apply our decision model to select improvement actions for a transistor chip product. We then conduct a field experiment",3
28fc55180ac3a8117263498899c2abf1a6db53dd,Mining peripheral arterial disease cases from narrative clinical notes using natural language processing,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
96f65ecdf1d991cbfd1b3722df662ac6bd071cb2,Social robots for education: A review,"A review of social robots in education discusses expected outcomes, technical challenges, and directions for future research. Social robots can be used in education as tutors or peer learners. They have been shown to be effective at increasing cognitive and affective outcomes and have achieved outcomes similar to those of human tutoring on restricted tasks. This is largely because of their physical presence, which traditional learning technologies lack. We review the potential of social robots in education, discuss the technical challenges, and consider how the robot’s appearance and behavior affect learning outcomes.",3
2a4031393d3c7f66e4257f77630205181f0c11fe,Student engagement with automated feedback on academic writing: a study on Uyghur ethnic minority students in China,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
5c322168238098dc48bf3129675c1ef22efdf23b,Shifty Speech and Independent Thought: Epistemic Normativity in Context,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
a4317afb40537ca5052f1eceb7450e19d09d9f03,Science career aspiration and science capital in China and UK: a comparative study using PISA data,"ABSTRACT The concept of science capital has a growing influence in science education research for understanding young people’s science trajectories. Popularised in the UK, this paper aims to extend and evaluate the applicability of science capital in the context of China by drawing on PISA2015. More specifically, we make use of existing items in the PISA2015 survey as a proxy for operationalising the construct of science capital to explore the science career aspirations and attainments of 15-year-old Chinese and UK students (n = 23,998). Our findings indicate that science capital has more explanatory power for understanding UK students’ science career aspirations than for Chinese students, where science attainment seems most important. We raise the potential challenge for Chinese students to convert their science capital into scientific self-efficacy and science career aspirations as we highlight the importance of recognising cultural and national differences in operationalising science capital.",2
7130f33ebe63c2473d4c5e3cbc0d7d15e042aef8,Distributed learning: a reliable privacy-preserving strategy to change multicenter collaborations using AI,"The present scoping review aims to assess the non-inferiority of distributed learning over centrally and locally trained machine learning (ML) models in medical applications. We performed a literature search using the term “distributed learning” OR “federated learning” in the PubMed/MEDLINE and EMBASE databases. No start date limit was used, and the search was extended until July 21, 2020. We excluded articles outside the field of interest; guidelines or expert opinion, review articles and meta-analyses, editorials, letters or commentaries, and conference abstracts; articles not in the English language; and studies not using medical data. Selected studies were classified and analysed according to their aim(s). We included 26 papers aimed at predicting one or more outcomes: namely risk, diagnosis, prognosis, and treatment side effect/adverse drug reaction. Distributed learning was compared to centralized or localized training in 21/26 and 14/26 selected papers, respectively. Regardless of the aim, the type of input, the method,",4
40b736b8a628504a9463130705f8012d2e5e5560,Robust and data-efficient generalization of self-supervised machine learning for diagnostic imaging,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
4fdd9c5decd076b0f324765e1a7aa29113d008cb,Judgment and Agency,PART I: VIRTUE EPISTEMOLOGY EXTENDED AND UNIFIED PART II: A BETTER VIRTUE EPISTEMOLOGY PART III: KNOWLEDGE AND AGENCY PART IV: HISTORICAL ANTECEDENTS,5
a1e37e17015efc88bf72e7e858523b9dd65ed35c,Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
3a9dcb0e38413611301358648ffe39c7f831a632,Application of message passing neural networks for molecular property prediction.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
03dac183ea64aba831d6dfaa549677091acdfe3f,What’s new in therapeutic drug monitoring of antimicrobials?,Therapeutic drug monitoring (TDM) of plasma samples is used in many circumstances to adjust pharmaceutics to desired concentrations. It is predominantly employed for drugs with a narrow therapeutic window (to avoid both underdosing and toxic levels) and/or where large inter-and intra-individual variations of concentrations are expected (e,5
983d3fec5c35c6f40f65bf971558be1d36d2bfd7,Applicability of Internet of Things in Smart Farming,"Agriculture is critical to human life. Agriculture provides a means of subsistence for a sizable portion of the world’s population. Additionally, it provides a large number of work opportunities for inhabitants. Many farmers prefer traditional farming approaches, which result in low yields. Agriculture and related industries are vital to the economy’s long-term growth and development. The primary issues in agricultural production include decision-making, crop selection, and supporting systems for crop yield enhancement. Agriculture forecasting is influenced by natural variables such as temperature, soil fertility, water volume, water quality, season, and crop prices. Growing advancements in agricultural automation have resulted in a flood of tools and apps for rapid knowledge acquisition. Mobile devices are rapidly being used by everyone, including farmers. This paper presents a framework for smart crop tracking and monitoring. Sensors, Internet of Things cameras, mobile applications, and big data analytics are all covered. The hardware consists of an",5
f1374c60ea4548ac1674ab72c8ad1d5667fdfdaf,CRISPR/Cas9 assisted stem cell therapy in Parkinson's disease,"Since its discovery in 2012, CRISPR Cas9 has been tried as a direct treatment approach to correct the causative gene mutation and establish animal models in neurodegenerative disorders. Since no strategy developed until now could completely cure Parkinson's disease (PD), neuroscientists aspire to use gene editing technology, especially CRISPR/Cas9, to induce a permanent correction in genetic PD patients expressing mutated genes. Over the years, our understanding of stem cell biology has improved. Scientists have developed personalized cell therapy using CRISPR/Cas9 to edit embryonic and patient-derived stem cells ex-vivo . This review details the importance of CRISPR/Cas9-based stem cell therapy in Parkinson's disease in developing PD disease models and developing therapeutic strategies after elucidating the possible pathophysiological mechanisms. Graphical Abstract",5
67511d61aa96306687751f56979f15c9fadd9162,Deep echocardiography: data-efficient supervised and semi-supervised deep learning towards automated diagnosis of cardiac disease,"Deep learning and computer vision algorithms can deliver highly accurate and automated interpretation of medical imaging to augment and assist clinicians. However, medical imaging presents uniquely pertinent obstacles such as a lack of accessible data or a high-cost of annotation. To address this, we developed data-efficient deep learning classifiers for prediction tasks in cardiology. Using pipeline supervised models to focus relevant structures, we achieve an accuracy of 94.4% for 15-view still-image echocardiographic view classification and 91.2% accuracy for binary left ventricular hypertrophy classification. We then develop semi-supervised generative adversarial network models that can learn from both labeled and unlabeled data in a generalizable fashion. We achieve greater than 80% accuracy in view classification with only 4% of labeled data used in solely supervised techniques and achieve 92.3% accuracy for left ventricular hypertrophy classification. In exploring trade-offs between model type, resolution, data resources, and performance, we present a comprehensive analysis and",6
23b80b4af1e1045b6bccadcb894450988e0299ee,Towards Explainable Neural-Symbolic Visual Reasoning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
d040539321f9abd6110328eb5688227705ef1db7,"Telemedicine for healthcare: Capabilities, features, barriers, and applications","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
48d0e692070629ba3110cb119bc6cf58ba2640ef,There Is No Techno-Responsibility Gap,"In a landmark essay, Andreas Matthias claimed that current developments in autonomous, artificially intelligent (AI) systems are creating a so-called responsibility gap, which is allegedly ever-widening and stands to undermine both the moral and legal frameworks of our society. But how severe is the threat posed by emerging technologies? In fact, a great number of authors have indicated that the fear is thoroughly instilled. The most pessimistic are calling for a drastic scaling-back or complete moratorium on AI systems, while the optimists aim to show that the gap can be bridged nonetheless. Contrary to both camps, I argue against the prevailing assumption that there is a technology-based responsibility gap. I show how moral responsibility is a dynamic and flexible process, one that can effectively encompass emerging technological entities.",7
b8f436531f8faccff0b60a15371ce040e4a32784,Blockchain and AI,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
482b42554ea4d2f64d003293b16cf6404019c410,"Artificial Intelligence, the Missing Piece of Online Education?","Despite the recent explosive growth of online education, it still suffers from suboptimal learning efficacy, as evidenced by low student completion rates. This deficiency can be attributed to the lack of facetime between teachers and students, and amongst students themselves. In this article, we use the teaching and learning of economics as a case study to illustrate the application of artificial intelligence (AI) based robotic players to help engage students in online, asynchronous environments, therefore, potentially improving student learning outcomes. In particular, students could learn about competitive markets by joining a market full of automated trading robots who find every chance to arbitrage. Alternatively, students could learn to play against other humans by playing against robotic players trained to mimic human behavior, such as anticipating spiteful rejections to unfair offers in the Ultimatum Game where a proposer offers a particular way to split the pot that the responder can only",6
35409cff64e718c5a73975eaed9768ed3d27caa7,"Alexa, what do we know about conversational commerce? Insights from a systematic literature review","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
8df72c48a7ce4418c683c4dd9bb300558ac71d47,"Deep learning for healthcare: review, opportunities and challenges","Gaining knowledge and actionable insights from complex, high-dimensional and heterogeneous biomedical data remains a key challenge in transforming health care. Various types of data have been emerging in modern biomedical research, including electronic health records, imaging, -omics, sensor data and text, which are complex, heterogeneous, poorly annotated and generally unstructured. Traditional data mining and statistical learning approaches typically need to first perform feature engineering to obtain effective and more robust features from those data, and then build prediction or clustering models on top of them. There are lots of challenges on both steps in a scenario of complicated data and lacking of sufficient domain knowledge. The latest advances in deep learning technologies provide new effective paradigms to obtain end-to-end learning models from complex data. In this article, we review the recent literature on applying deep learning technologies to advance the health care domain. Based on the analyzed work, we suggest",7
2c9af30480fdd20c9c66dbf2849e045fbfe21547,Towards Active Learning Based Smart Assistant for Manufacturing,"A general approach for building a smart assistant that guides a user from a forecast generated by a machine learning model through a sequence of decision-making steps is presented. We develop a methodology to build such a system. The system is demonstrated on a demand forecasting use case in manufacturing. The methodology can be extended to several use cases in manufacturing. The system provides means for knowledge acquisition, gathering data from users. We envision active learning can be used to get data labels where labeled data is scarce.",5
478df2ddc7159853d0da9c9d6fc2211077edbe80,A survey on security and privacy of federated learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
a0b0aff4e321bcf767f325562df7cc0ae84d0bb8,Data fusion in cyber-physical-social systems: State-of-the-art and perspectives,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
c2c5c99f28b5e854746479b06b4d5a0ae52adcf0,Implementation Frameworks for Artificial Intelligence Translation Into Health Care Practice: Scoping Review,"Background Significant efforts have been made to develop artificial intelligence (AI) solutions for health care improvement. Despite the enthusiasm, health care professionals still struggle to implement AI in their daily practice. Objective This paper aims to identify the implementation frameworks used to understand the application of AI in health care practice. Methods A scoping review was conducted using the Cochrane, Evidence Based Medicine Reviews, Embase, MEDLINE, and PsycINFO databases to identify publications that reported frameworks, models, and theories concerning AI implementation in health care. This review focused on studies published in English and investigating AI implementation in health care since 2000. A total of 2541 unique publications were retrieved from the databases and screened on titles and abstracts by 2 independent reviewers. Selected articles were thematically analyzed against the Nilsen taxonomy of implementation frameworks, and the Greenhalgh framework for the nonadoption, abandonment, scale-up, spread, and sustainability (NASSS) of health care",4
f9c95ea9bcd529309c1d743f0926b5137f8ed60f,Learning inverse folding from millions of predicted structures,"We consider the problem of predicting a protein sequence from its backbone atom coordinates. Machine learning approaches to this problem to date have been limited by the number of available experimentally determined protein structures. We augment training data by nearly three orders of magnitude by predicting structures for 12M protein sequences using AlphaFold2. Trained with this additional data, a sequence-to-sequence transformer with invariant geometric input processing layers achieves 51% native sequence recovery on structurally held-out backbones with 72% recovery for buried residues, an overall improvement of almost 10 percentage points over existing methods. The model generalizes to a variety of more complex tasks including design of protein complexes, partially masked structures, binding interfaces, and multiple states.",8
05a600586b3758922ef28a4dc782d3c46ded2636,Differential Diagnosis Generators: an Evaluation of Currently Available Computer Programs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
811c64131e009de84f0d92da6cc96e824a291bd5,Artificial intelligence in online higher education: A systematic review of empirical research from 2011 to 2020,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
3409e518066038279abe7d43be851ac22990457a,An MRI-based deep learning approach for accurate detection of Alzheimer’s disease,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
1d174f0e3c391368d0f3384a144a6c7487f2a143,Big Data's Disparate Impact,"Advocates of algorithmic techniques like data mining argue that these techniques eliminate human biases from the decision-making process. But an algorithm is only as good as the data it works with. Data is frequently imperfect in ways that allow these algorithms to inherit the prejudices of prior decision makers. In other cases, data may simply reflect the widespread biases that persist in society at large. In still others, data mining can discover surprisingly useful regularities that are really just preexisting patterns of exclusion and inequality. Unthinking reliance on data mining can deny historically disadvantaged and vulnerable groups full participation in society. Worse still, because the resulting discrimination is almost always an unintentional emergent property of the algorithm’s use rather than a conscious choice by its programmers, it can be unusually hard to identify the source of the problem or to explain it to a court.This Essay examines these concerns through",7
178571a5cde984c895493e2eb6c5487449d055cf,"Data mining in clinical big data: the frequently used databases, steps, and methodological models","Many high quality studies have emerged from public databases, such as Surveillance, Epidemiology, and End Results (SEER), National Health and Nutrition Examination Survey (NHANES), The Cancer Genome Atlas (TCGA), and Medical Information Mart for Intensive Care (MIMIC); however, these data are often characterized by a high degree of dimensional heterogeneity, timeliness, scarcity, irregularity, and other characteristics, resulting in the value of these data not being fully utilized. Data-mining technology has been a frontier field in medical research, as it demonstrates excellent performance in evaluating patient risks and assisting clinical decision-making in building disease-prediction models. Therefore, data mining has unique advantages in clinical big-data research, especially in large-scale medical public databases. This article introduced the main medical public database and described the steps, tasks, and models of data mining in simple language. Additionally, we described data-mining methods along with their practical applications. The goal of this work was to aid clinical",4
85328b4a8132bf4299f8cd7f8e79e850d561c8fc,Big Data Analytics: A Survey,"Internet-based programs and communication techniques have become widely used and respected in the IT industry recently. A persistent source of ""big data,"" or data that is enormous in volume, diverse in type, and has a complicated multidimensional structure, is internet applications and communications. Today, several measures are routinely performed with no assurance that any of them will be helpful in understanding the phenomenon of interest in an era of automatic, large-scale data collection. Online transactions that involve buying, selling, or even investing are all examples of e-commerce. As a result, they generate data that has a complex structure and a high dimension. The usual data storage techniques cannot handle those enormous volumes of data. There is a lot of work being done to find ways to minimize the dimensionality of big data in order to provide analytics reports that are even more accurate and data visualizations that are more interesting.",7
733fc094e785724621c46e20db1be69f132ad9df,Comprehensive Survey of Big Data Mining Approaches in Cloud Systems,"Cloud computing, data mining, and big online data are discussed in this paper as hybridization possibilities. The method of analyzing and visualizing vast volumes of data is known as the visualization of data mining. The effect of computing conventions and algorithms on detailed storage and data communication requirements has been studied. When researching these approaches to data storage in big data, the data analytical viewpoint is often explored. These terminology and aspects have been used to address methodological development as well as problem statements. This will assist in the investigation of computational capacity as well as new knowledge in this area. The patterns of using big data were compared in many articles. In this paper, we research Big Data Mining Approaches in Cloud Systems and address cloudcompatible problems and computing techniques to promote Big Data Mining in Cloud Systems. Keywords— Big Data, Data Computing, Big Data Mining,",2
b904dcdbd7c7b33938583f2f57d05ca70e121ea9,An Efficient and Secure Big Data Storage in Cloud Environment by Using Triple Data Encryption Standard,"In recent decades, big data analysis has become the most important research topic. Hence, big data security offers Cloud application security and monitoring to host highly sensitive data to support Cloud platforms. However, the privacy and security of big data has become an emerging issue that restricts the organization to utilize Cloud services. The existing privacy preserving approaches showed several drawbacks such as a lack of data privacy and accurate data analysis, a lack of efficiency of performance, and completely rely on third party. In order to overcome such an issue, the Triple Data Encryption Standard (TDES) methodology is proposed to provide security for big data in the Cloud environment. The proposed TDES methodology provides a relatively simpler technique by increasing the sizes of keys in Data Encryption Standard (DES) to protect against attacks and defend the privacy of data. The experimental results showed that the proposed TDES method is",3
48fc9c42522184c652742255fdf31f7b9ed7ebae,Brief introduction of medical database and data mining technology in big data era,"Data mining technology can search for potentially valuable knowledge from a large amount of data, mainly divided into data preparation and data mining, and expression and analysis of results. It is a mature information processing technology and applies database technology. Database technology is a software science that researches manages, and applies databases. The data in the database are processed and analyzed by studying the underlying theory and implementation methods of the structure, storage, design, management, and application of the database. We have introduced several databases and data mining techniques to help a wide range of clinical researchers better understand and apply database technology.",2
b6b7fea1846e85ac1e3c7e3adda6e65b127d0368,"IoT, Big Data, and Artificial Intelligence in Agriculture and Food Industry","Internet of Things (IoT) results in a massive amount of streaming data, often referred to as “big data,” which brings new opportunities to monitor agricultural and food processes. Besides sensors, big data from social media is also becoming important for the food industry. In this review, we present an overview of IoT, big data, and artificial intelligence (AI), and their disruptive role in shaping the future of agri-food systems. Following an introduction to the fields of IoT, big data, and AI, we discuss the role of IoT and big data analysis in agriculture (including greenhouse monitoring, intelligent farm machines, and drone-based crop imaging), supply chain modernization, social media (for open innovation and sentiment analysis) in food industry, food quality assessment (using spectral methods and sensor fusion), and finally, food safety (using gene sequencing and blockchain-based digital traceability). A special emphasis is laid on the commercial status of applications and translational",8
80dd97954ddf3edd22d4cb21f0ac31b7ffed6bbf,Digital Twin and Big Data Towards Smart Manufacturing and Industry 4.0: 360 Degree Comparison,"With the advances in new-generation information technologies, especially big data and digital twin, smart manufacturing is becoming the focus of global manufacturing transformation and upgrading. Intelligence comes from data. Integrated analysis for the manufacturing big data is beneficial to all aspects of manufacturing. Besides, the digital twin paves a way for the cyber-physical integration of manufacturing, which is an important bottleneck to achieve smart manufacturing. In this paper, the big data and digital twin in manufacturing are reviewed, including their concept as well as their applications in product design, production planning, manufacturing, and predictive maintenance. On this basis, the similarities and differences between big data and digital twin are compared from the general and data perspectives. Since the big data and digital twin can be complementary, how they can be integrated to promote smart manufacturing are discussed.",1
8f0d7df1e34867682d0816a38ef4a9bf4a74509c,Big data quality framework: a holistic approach to continuous quality management,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",0
456c011594ecacdd24298a161787389ccbe4b88b,Big Data Service Architecture: A Survey,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
933baeec555352784848a93284c9dd0e79477759,Big Data in Smart Farming – A review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
16575f23ff879e6353a55bbfbbcc54e27606bfc5,Big data analytics: Understanding its capabilities and potential benefits for healthcare organizations,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
cc017a62c605a0749e35a1264a46d62e78fb68b7,Big Data Analytics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",14
fe44200fed05f9a7c656f2245deded8fd5f5e1e6,CatBoost for big data: an interdisciplinary review,"Gradient Boosted Decision Trees (GBDT’s) are a powerful tool for classification and regression tasks in Big Data. Researchers should be familiar with the strengths and weaknesses of current implementations of GBDT’s in order to use them effectively and make successful contributions. CatBoost is a member of the family of GBDT machine learning ensemble techniques. Since its debut in late 2018, researchers have successfully used CatBoost for machine learning studies involving Big Data. We take this opportunity to review recent research on CatBoost as it relates to Big Data, and learn best practices from studies that cast CatBoost in a positive light, as well as studies where CatBoost does not outshine other techniques, since we can learn lessons from both types of scenarios. Furthermore, as a Decision Tree based algorithm, CatBoost is well-suited to machine learning tasks involving categorical, heterogeneous data. Recent work across multiple disciplines illustrates CatBoost’s effectiveness and shortcomings",4
b34fc78de28be598e21118d7cb9d84d63374addc,Analysis of Dimensionality Reduction Techniques on Big Data,"Due to digitization, a huge volume of data is being generated across several sectors such as healthcare, production, sales, IoT devices, Web, organizations. Machine learning algorithms are used to uncover patterns among the attributes of this data. Hence, they can be used to make predictions that can be used by medical practitioners and people at managerial level to make executive decisions. Not all the attributes in the datasets generated are important for training the machine learning algorithms. Some attributes might be irrelevant and some might not affect the outcome of the prediction. Ignoring or removing these irrelevant or less important attributes reduces the burden on machine learning algorithms. In this work two of the prominent dimensionality reduction techniques, Linear Discriminant Analysis (LDA) and Principal Component Analysis (PCA) are investigated on four popular Machine Learning (ML) algorithms, Decision Tree Induction, Support Vector Machine (SVM), Naive Bayes Classifier and Random Forest Classifier",4
9198d6ab8ad1c6f1527a7d4adf06809848bf23c7,Challenges and Future Directions of Big Data and Artificial Intelligence in Education,"We discuss the new challenges and directions facing the use of big data and artificial intelligence (AI) in education research, policy-making, and industry. In recent years, applications of big data and AI in education have made significant headways. This highlights a novel trend in leading-edge educational research. The convenience and embeddedness of data collection within educational technologies, paired with computational techniques have made the analyses of big data a reality. We are moving beyond proof-of-concept demonstrations and applications of techniques, and are beginning to see substantial adoption in many areas of education. The key research trends in the domains of big data and AI are associated with assessment, individualized learning, and precision education. Model-driven data analytics approaches will grow quickly to guide the development, interpretation, and validation of the algorithms. However, conclusions from educational analytics should, of course, be applied with caution. At the education policy level, the government should",2
38f5b53b49be555430f33b8363910191a3df1d14,"A Survey on Big Data Analytics: Challenges, Open Research Issues and Tools","Abstract: A huge repository of terabytes of data is generated each day from modern information systems and digital technologies such as Internet of Things and cloud computing. Analysis of these massive data requires a lot of efforts at multiple levels to extract knowledge for decision making. Therefore, big data analysis is a current area of research and development. The basic objective of this paper is to explore the potential impact of big data challenges, open research issues, and various tools associated with it. As a result, this article provides a platform to explore big data at numerous stages. Additionally, it opens a new horizon for researchers to develop the solution, based on the challenges and open research issues.",2
4e6bba65f7636a655c778a3e54cc58e148468963,CRITICAL QUESTIONS FOR BIG DATA,"The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of analyzing genetic sequences, social media interactions, health records, phone logs, government records, and other digital traces left by people. Significant questions emerge. Will large-scale search data help us create better tools, services, and public goods? Or will it usher in a new wave of privacy incursions and invasive marketing? Will data analytics help us understand online communities and political movements? Or will it be used to track protesters and suppress speech? Will it transform how we study human communication and culture, or narrow the palette of research options and alter what ‘research’ means? Given the rise of Big Data as a socio-technical",15
1bc34cb22131554ba18f6ba9e6ede5beb42939f1,"Beyond the hype: Big data concepts, methods, and analytics","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",20
dac7344737cb824634f757aede2dd46a6eed204b,Big data analytics in healthcare: promise and potential,"To describe the promise and potential of big data analytics in healthcare. The paper describes the nascent field of big data analytics in healthcare, discusses the benefits, outlines an architectural framework and methodology, describes examples reported in the literature, briefly discusses the challenges, and offers conclusions. The paper provides a broad overview of big data analytics for healthcare researchers and practitioners. Big data analytics in healthcare is evolving into a promising field for providing insight from very large data sets and improving outcomes while reducing costs. Its potential is great; however there remain challenges to overcome.",13
8bba999de25bfb288b3f7f88e1d907aab02638b6,Big-Data Science in Porous Materials: Materials Genomics and Machine Learning,"By combining metal nodes with organic linkers we can potentially synthesize millions of possible metal–organic frameworks (MOFs). The fact that we have so many materials opens many exciting avenues but also create new challenges. We simply have too many materials to be processed using conventional, brute force, methods. In this review, we show that having so many materials allows us to use big-data methods as a powerful technique to study these materials and to discover complex correlations. The first part of the review gives an introduction to the principles of big-data science. We show how to select appropriate training sets, survey approaches that are used to represent these materials in feature space, and review different learning architectures, as well as evaluation and interpretation strategies. In the second part, we review how the different approaches of machine learning have been applied to porous materials. In particular, we discuss applications in the",4
bf5a42b53d156c0811e88e60d2a49f9fd9367cae,Big data: the management revolution.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",15
02a88547d6f6022bebc9aba6723a310cdf132f3f,Big Data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",16
78e40584f0d149bf6f98beb5561b7b83cb68e1b1,Assessing the impact of big data on firm innovation performance: Big data is not always better data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
41d4e093d5f7ed5aae1aaa9eb6c037742e4cf9b1,The use of Big Data Analytics in healthcare,"The introduction of Big Data Analytics (BDA) in healthcare will allow to use new technologies both in treatment of patients and health management. The paper aims at analyzing the possibilities of using Big Data Analytics in healthcare. The research is based on a critical analysis of the literature, as well as the presentation of selected results of direct research on the use of Big Data Analytics in medical facilities. The direct research was carried out based on research questionnaire and conducted on a sample of 217 medical facilities in Poland. Literature studies have shown that the use of Big Data Analytics can bring many benefits to medical facilities, while direct research has shown that medical facilities in Poland are moving towards data-based healthcare because they use structured and unstructured data, reach for analytics in the administrative, business and clinical area. The research positively confirmed that medical facilities are working on",3
1e4709c0b8fe3bf759cd64dc1ede695d6e5316f0,Deep learning applications and challenges in big data analytics,"Big Data Analytics and Deep Learning are two high-focus of data science. Big Data has become important as many organizations both public and private have been collecting massive amounts of domain-specific information, which can contain useful information about problems such as national intelligence, cyber security, fraud detection, marketing, and medical informatics. Companies such as Google and Microsoft are analyzing large volumes of data for business analysis and decisions, impacting existing and future technology. Deep Learning algorithms extract high-level, complex abstractions as data representations through a hierarchical learning process. Complex abstractions are learnt at a given level based on relatively simpler abstractions formulated in the preceding level in the hierarchy. A key benefit of Deep Learning is the analysis and learning of massive amounts of unsupervised data, making it a valuable tool for Big Data Analytics where raw data is largely unlabeled and un-categorized. In the present study, we explore how",11
752604994a7ca548ff2954114fc61a501d857b1c,Big data analytics and firm performance: Effects of dynamic capabilities,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",13
37b0a7a6c8fb26e32b9206847e78d521a2cd5900,A literature review on one-class classification and its potential applications in big data,"In severely imbalanced datasets, using traditional binary or multi-class classification typically leads to bias towards the class(es) with the much larger number of instances. Under such conditions, modeling and detecting instances of the minority class is very difficult. One-class classification (OCC) is an approach to detect abnormal data points compared to the instances of the known class and can serve to address issues related to severely imbalanced datasets, which are especially very common in big data. We present a detailed survey of OCC-related literature works published over the last decade, approximately. We group the different works into three categories: outlier detection, novelty detection, and deep learning and OCC. We closely examine and evaluate selected works on OCC such that a good cross section of approaches, methods, and application domains is represented in the survey. Commonly used techniques in OCC for outlier detection and for novelty detection, respectively, are discussed. We",2
a0d18dddaa995b126ad373e33767b9b881d16b2f,An Introductory Review of Deep Learning for Prediction Models With Big Data,"Deep learning models stand for a new learning paradigm in artificial intelligence (AI) and machine learning. Recent breakthrough results in image analysis and speech recognition have generated a massive interest in this field because also applications in many other domains providing big data seem possible. On a downside, the mathematical and computational methodology underlying deep learning models is very challenging, especially for interdisciplinary scientists. For this reason, we present in this paper an introductory review of deep learning approaches including Deep Feedforward Neural Networks (D-FFNN), Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs), Autoencoders (AEs), and Long Short-Term Memory (LSTM) networks. These models form the major core architectures of deep learning models currently used and should belong in any data scientist's toolbox. Importantly, those core architectural building blocks can be composed flexibly—in an almost Lego-like manner—to build new application-specific network architectures. Hence, a basic understanding of these network architectures is",3
b473e91cbe80c8b46451b49153cd5f93030480ab,Critical analysis of Big Data challenges and analytical methods,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",11
3a74bed911ccf213d9595b2b02a5b1c4ac4dcaf8,Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
94deb62af3054c49e7d80bd7eb3ed5efe990fc0b,Traffic Flow Prediction With Big Data: A Deep Learning Approach,"Accurate and timely traffic flow information is important for the successful deployment of intelligent transportation systems. Over the last few years, traffic data have been exploding, and we have truly entered the era of big data for transportation. Existing traffic flow prediction methods mainly use shallow traffic prediction models and are still unsatisfying for many real-world applications. This situation inspires us to rethink the traffic flow prediction problem based on deep architecture models with big traffic data. In this paper, a novel deep-learning-based traffic flow prediction method is proposed, which considers the spatial and temporal correlations inherently. A stacked autoencoder model is used to learn generic traffic flow features, and it is trained in a greedy layerwise fashion. To the best of our knowledge, this is the first time that a deep architecture model is applied using autoencoders as building blocks to represent traffic flow features for prediction. Moreover, experiments",11
bc6dbcaf4d2c76e618ae3f1043fd7276cbdf7f9b,"Big data in healthcare: management, analysis and future prospects","‘Big data’ is massive amounts of information that can work wonders. It has become a topic of special interest for the past two decades because of a great potential that is hidden in it. Various public and private sector industries generate, store, and analyze big data with an aim to improve the services they provide. In the healthcare industry, various sources for big data include hospital records, medical records of patients, results of medical examinations, and devices that are a part of internet of things. Biomedical research also generates a significant portion of big data relevant to public healthcare. This data requires proper management and analysis in order to derive meaningful information. Otherwise, seeking solution by analyzing big data quickly becomes comparable to finding a needle in the haystack. There are various challenges associated with each step of handling big data which can only be surpassed by using high-end computing",9
1597449a7f64b6bd24639b4deab96c8a8c184177,"Digital twin-driven product design, manufacturing and service with big data","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
91b63db746becca15090963a8990dfe2b5103799,"Big data: The next frontier for innovation, competition, and productivity","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",26
391a5f286f814d852dddcab1b2b68e5c1af6c79e,Data mining with big data,"Big Data concern large-volume, complex, growing data sets with multiple, autonomous sources. With the fast development of networking, data storage, and the data collection capacity, Big Data are now rapidly expanding in all science and engineering domains, including physical, biological and biomedical sciences. This paper presents a HACE theorem that characterizes the features of the Big Data revolution, and proposes a Big Data processing model, from the data mining perspective. This data-driven model involves demand-driven aggregation of information sources, mining and analysis, user interest modeling, and security and privacy considerations. We analyze the challenging issues in the data-driven model and also in the Big Data revolution.",6
f12930cd5f58990badc1a7c5d2749cad004cfb0e,Big data analytics for intelligent manufacturing systems: A review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
10d89b13a6309a531c35701d37d3bd76a27a3942,Big Data Storage,"This chapter provides an overview of big data storage technologies. It is the result of a survey of the current state of the art in data storage technologies in order to create a cross-sectorial technology roadmap. This chapter provides a concise overview of big data storage systems that are capable of dealing with high velocity, high volumes, and high varieties of data. It describes distributed file systems, NoSQL databases, graph databases, and NewSQL databases. The chapter investigates the challenge of storing data in a secure and privacy-preserving way. The social and economic impact of big data storage technologies is described, open research challenges highlighted, and three selected case studies are provided from the health, finance, and energy sector. Some of the key insights on big data storage are (1) in-memory databases and columnar databases typically outperform traditional relational database systems, (2) the major technical barrier to widespread up-take of big",4
56266342b01a4f2ddc28a1e8401dbbad105736a5,Big Data Analytics in Weather Forecasting: A Systematic Review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
aca6d5f3866372a4506cf15773ae298f18c3f453,A comprehensive survey of anomaly detection techniques for high dimensional big data,"Anomaly detection in high dimensional data is becoming a fundamental research problem that has various applications in the real world. However, many existing anomaly detection techniques fail to retain sufficient accuracy due to so-called “big data” characterised by high-volume, and high-velocity data generated by variety of sources. This phenomenon of having both problems together can be referred to the “curse of big dimensionality,” that affect existing techniques in terms of both performance and accuracy. To address this gap and to understand the core problem, it is necessary to identify the unique challenges brought by the anomaly detection with both high dimensionality and big data problems. Hence, this survey aims to document the state of anomaly detection in high dimensional big data by representing the unique challenges using a triangular model of vertices: the problem (big dimensionality), techniques/algorithms (anomaly detection), and tools (big data applications/frameworks). Authors’ work that fall directly into",2
f117c6f12d067bd66dad40996b3931c069daa2da,Business Intelligence and Analytics: From Big Data to Big Impact,"Business intelligence and analytics (BI&A) has emerged as an important area of study for both practitioners and researchers, reflecting the magnitude and impact of data-related problems to be solved in contemporary business organizations. This introduction to the MIS Quarterly Special Issue on Business Intelligence Research first provides a framework that identifies the evolution, applications, and emerging research areas of BI&A. BI&A 1.0, BI&A 2.0, and BI&A 3.0 are defined and described in terms of their key characteristics and capabilities. Current research in BI&A is analyzed and challenges and opportunities associated with BI&A research and education are identified. We also report a bibliometric study of critical BI&A publications, researchers, and research topics based on more than a decade of related academic and industry publications. Finally, the six articles that comprise this special issue are introduced and characterized in terms of the proposed BI&A research framework.",22
bf69c98fca9a9f6c1cde871beddbcdc668b77771,"Big Data: A Revolution That Will Transform How We Live, Work, and Think","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
4d1fdd81f033cd58f3723bfc61e7d12079647a7a,"Predicting the Future - Big Data, Machine Learning, and Clinical Medicine.","The algorithms of machine learning, which can sift through vast numbers of variables looking for combinations that reliably predict outcomes, will improve prognosis, displace much of the work of radiologists and anatomical pathologists, and improve diagnostic accuracy.",7
ccca203382e5dd198c089a0f1d7af7bef0f694e9,TBtools - an integrative toolkit developed for interactive analyses of big biological data.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
92fd5aaeacaa332a725e72647e20baec5c73b73d,Big Data Analytics in Supply Chain Management: A Systematic Literature Review and Research Directions,"Big data analytics has been successfully used for various business functions, such as accounting, marketing, supply chain, and operations. Currently, along with the recent development in machine learning and computing infrastructure, big data analytics in the supply chain are surging in importance. In light of the great interest and evolving nature of big data analytics in supply chains, this study conducts a systematic review of existing studies in big data analytics. This study presents a framework of a systematic literature review from interdisciplinary perspectives. From the organizational perspective, this study examines the theoretical foundations and research models that explain the sustainability and performances achieved through the use of big data analytics. Then, from the technical perspective, this study analyzes types of big data analytics, techniques, algorithms, and features developed for enhanced supply chain functions. Finally, this study identifies the research gap and suggests future research directions.",0
8b417c2be7a7707f372049fb1193f0d42f799562,Big Data and AI Revolution in Precision Agriculture: Survey and Challenges,"Sustainable agricultural development is a significant solution with fast population development through the use of information and communication (ICT) in precision agriculture, which produced new methods for making cultivation further productive, proficient, well-regulated while preserving the climate. Big data (machine learning, deep learning, etc.) is amongst the vital technologies of ICT employed in precision agriculture for their huge data analytical capabilities to abstract significant information and to assist agricultural practitioners to comprehend well farming practices and take precise decisions. The main goal of this article is to acquire an awareness of the Big Data latest applications in smart agriculture and be acquainted with related social and financial challenges to be concentrated on. This article features data creation methods, accessibility of technology, accessibility of devices, software tools, and data analytic methods, and appropriate applications of big data in precision agriculture. Besides, there are still a few challenges that come across the",1
4b06c7e29280b1c6bc05c9df39023b48fef02c93,Escaping the Big Data Paradigm with Compact Transformers,"With the rise of Transformers as the standard for language processing, and their advancements in computer vision, there has been a corresponding growth in parameter size and amounts of training data. Many have come to believe that because of this, transformers are not suitable for small sets of data. This trend leads to concerns such as: limited availability of data in certain scientific domains and the exclusion of those with limited resource from research in the field. In this paper, we aim to present an approach for small-scale learning by introducing Compact Transformers. We show for the first time that with the right size, convolutional tokenization, transformers can avoid overfitting and outperform state-of-the-art CNNs on small datasets. Our models are flexible in terms of model size, and can have as little as 0.28M parameters while achieving competitive results. Our best model can reach 98% accuracy when training from scratch on",4
efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea,Big Data and Machine Learning in Health Care.,"Nearly all aspects of modern life are in some way being changed by big data and machine learning. Netflix knows what movies people like to watch and Google knows what people want to know based on their search histories. Indeed, Google has recently begun to replace much of its existing non–machine learning technology with machine learning algorithms, and there is great optimism that these techniques can provide similar improvements across many sectors. It isnosurprisethenthatmedicineisawashwithclaims of revolution from the application of machine learning to big health care data. Recent examples have demonstrated that big data and machine learning can create algorithms that perform on par with human physicians.1 Though machine learning and big data may seem mysterious at first, they are in fact deeply related to traditional statistical models that are recognizable to most clinicians. It is our hope that elucidating these connections will demystify these techniques and provide a set",3
73d4accea441aae2373828a8dc2175aa2759c38f,Big Data in Finance,"Big data is revolutionizing the finance industry and has the potential to significantly shape future research in finance. This special issue contains papers following the 2019 NBER-RFS Conference on Big Data. In this introduction to the special issue, we define the “big data” phenomenon as a combination of three features: large size, high dimension, and complex structure. Using the papers in the special issue, we discuss how new research builds on these features to push the frontier on fundamental questions across areas in finance—including corporate finance, market microstructure, and asset pricing. Finally, we offer some thoughts for future research directions.",2
cbad0923db89f23febcbd6192ff4149289ff2ad9,A survey on data‐efficient algorithms in big data era,"The leading approaches in Machine Learning are notoriously data-hungry. Unfortunately, many application domains do not have access to big data because acquiring data involves a process that is expensive or time-consuming. This has triggered a serious debate in both the industrial and academic communities calling for more data-efficient models that harness the power of artificial learners while achieving good results with less training data and in particular less human supervision. In light of this debate, this work investigates the issue of algorithms’ data hungriness. First, it surveys the issue from different perspectives. Then, it presents a comprehensive review of existing data-efficient methods and systematizes them into four categories. Specifically, the survey covers solution strategies that handle data-efficiency by (i) using non-supervised algorithms that are, by nature, more data-efficient, by (ii) creating artificially more data, by (iii) transferring knowledge from rich-data domains into poor-data domains, or by (iv) altering data-hungry algorithms",2
a6fef68aa30429ee15223b6be658a4536ab19128,Finding a Needle in Haystack: Facebook's Photo Storage,"This paper describes Haystack, an object storage system optimized for Facebook's Photos application. Facebook currently stores over 260 billion images, which translates to over 20 petabytes of data. Users upload one billion new photos (∼60 terabytes) each week and Facebook serves over one million images per second at peak. Haystack provides a less expensive and higher performing solution than our previous approach, which leveraged network attached storage appliances over NFS. Our key observation is that this traditional design incurs an excessive number of disk operations because of metadata lookups. We carefully reduce this per photo metadata so that Haystack storage machines can perform all metadata lookups in main memory. This choice conserves disk operations for reading actual data and thus increases overall throughput.",4
d1208ac421cf8ff67b27d93cd19ae42b8d596f95,Deep learning with COTS HPC systems,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
020bb2ba5f3923858cd6882ba5c5a44ea8041ab6,Meta-Learning in Neural Networks: A Survey,"The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.",4
0ee9179b57c6f9f4a8ae0ad70c5f507df7d731f1,The microeconomics of personalized medicine: today's challenge and tomorrow's promise,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
f56b1e481f30b54ba10314b521abd973e9cdd0ec,Digitizing public services in Europe: putting ambition into action,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
98ec4a0080f897c7ba4b6840a7403b1eae2a55aa,"A Survey on Supply Chain Security: Application Areas, Security Threats, and Solution Architectures","The rapid improvement in the global connectivity standards has escalated the level of trade taking place among different parties. Advanced communication standards are allowing the trade of all types of commodities and services. Furthermore, the goods and services developed in a particular region are transcending boundaries to enter into foreign markets. Supply chains play an essential role in the trade of these goods. To be able to realize a connected world with no boundary restrictions in terms of goods and services, it is imperative to keep the associated supply chains transparent, secure, and trustworthy. Therefore, some fundamental changes in the current supply chain architecture are essential to achieve a secure trade environment. This article discusses the supply chain’s security-critical application areas and presents a detailed survey of the security issues in the existing supply chain architecture. Various emerging technologies, such as blockchain, machine learning (ML), and physically unclonable functions (PUFs)",4
af8d3a41a0d809081b5d1eee2a8cf14601b14be0,"Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990–2017: a systematic analysis for the Global Burden of Disease Study 2017","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
820b4d107da7b85efd53e3fb57fd981e6fb6d7f9,An improved linear kernel for complementary maximal strip recovery: Simpler and smaller,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
0b04f080f56a99c97c9bfbc3fd7317742d161014,Early Detection of Diabetic Retinopathy Using PCA-Firefly Based Deep Learning Model,"Diabetic Retinopathy is a major cause of vision loss and blindness affecting millions of people across the globe. Although there are established screening methods - fluorescein angiography and optical coherence tomography for detection of the disease but in majority of the cases, the patients remain ignorant and fail to undertake such tests at an appropriate time. The early detection of the disease plays an extremely important role in preventing vision loss which is the consequence of diabetes mellitus remaining untreated among patients for a prolonged time period. Various machine learning and deep learning approaches have been implemented on diabetic retinopathy dataset for classification and prediction of the disease but majority of them have neglected the aspect of data pre-processing and dimensionality reduction, leading to biased results. The dataset used in the present study is a diabetes retinopathy dataset collected from the UCI machine learning repository. At its inceptions, the raw",3
560fc5b5d24e92f76578216972401485d67c71cb,DAD: A Distributed Anomaly Detection system using ensemble one-class statistical learning in edge networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
55abead7a50ae20c4848d6ff14952d3669e9d409,Ensuring Supply Chain Resilience: Development and Implementation of an Assessment Tool,"In today's tightly connected global economy, traditional management practices that rely on “steady-state” conditions are challenged by chaotic external pressures and turbulent change. Just in the last few years, the world has experienced a string of catastrophic events, including a global economic meltdown, a volcanic eruption in Iceland, an oil spill in the Gulf of Mexico, a disastrous tsunami and power blackout in Japan, and political upheavals in Africa and the Middle East. Managing the risk of an uncertain future is a challenge that requires resilience—the ability to survive, adapt, and grow in the face of turbulent change. This research develops a measurement tool titled the Supply Chain Resilience Assessment and Management (SCRAM™). Data gathered from seven global manufacturing and service firms are used to validate SCRAM™, using qualitative methodology with 1,369 empirical items from focus groups reviewing 14 recent disruptions. Critical linkages are uncovered between the inherent vulnerability factors",5
063bd3b1e93a14ce47e8ec30b2e7122ac9744e6f,Quantum computing with atomic qubits and Rydberg interactions: progress and challenges,We present a review of quantum computation with neutral atom qubits. After an overview of architectural options and approaches to preparing large qubit arrays we examine Rydberg mediated gate protocols and fidelity for two- and multi-qubit interactions. Quantum simulation and Rydberg dressing are alternatives to circuit based quantum computing for exploring many body quantum dynamics. We review the properties of the dressing interaction and provide a quantitative figure of merit for the complexity of the coherent dynamics that can be accessed with dressing. We conclude with a summary of the current status and an outlook for future progress.,1
9a5d435d62fab9dab856cec78c6e42f5cfb67851,"Health big data analytics: current perspectives, challenges and potential solutions","Modern health information systems can generate several exabytes of patient data, the so called ""Health Big Data"", per year. Many health managers and experts believe that with the data, it is possible to easily discover useful knowledge to improve health policies, increase patient safety and eliminate redundancies and unnecessary costs. The objective of this paper is to discuss the characteristics of Health Big Data as well as the challenges and solutions for health Big Data Analytics (BDA) – the process of extracting knowledge from sets of Health Big Data – and to design and evaluate a pipelined framework for use as a guideline/reference in health BDA.",4
6017e81c5ede6c38b306a3df9738aeb04baa7619,Graph Convolutional Networks for Text Classification,"Text classification is an important and classical problem in natural language processing. There have been a number of studies that applied convolutional neural networks (convolution on regular grid, e.g., sequence) to classification. However, only a limited number of studies have explored the more flexible graph convolutional neural networks (convolution on non-grid, e.g., arbitrary graph) for the task. In this work, we propose to use graph convolutional networks for text classification. We build a single text graph for a corpus based on word co-occurrence and document word relations, then learn a Text Graph Convolutional Network (Text GCN) for the corpus. Our Text GCN is initialized with one-hot representation for word and document, it then jointly learns the embeddings for both words and documents, as supervised by the known class labels for documents. Our experimental results on multiple benchmark datasets demonstrate that a vanilla Text GCN without any external word embeddings or",6
8d6376c6cb7cfd6e2f9d53b0b9f091a70e0fc73a,Research on Measurement and Control System of Common Parameters of Agricultural Equipment Based on Wireless Transmission,"To resolve the limited transmission and complicated layout, the common parameter measurement and control system of agricultural equipment use virtual instrument technology and embedded technology. The research results show that the wireless transmission data of the system is accurate and reliable. The linearity errors of acquisition divestiture (AD) and frequency counting (FI) channel measurements are only 0.38% and 0.006%, respectively, and the resolution is 0.01V and 1 Hz. This performance evaluation fully meets equipment detection in agricultural use. The system is integrated with various wireless transmission platforms, intelligent agricultural equipment, and computer wireless reception and processing. These parameters can significantly improve the automation level and quality of agricultural equipment.",2
2a04610f48bb448953348c4b1087fc9c201a01f8,Market Efficiency in the Age of Big Data,"Modern investors face a high-dimensional prediction problem: thousands of observable variables are potentially relevant for forecasting. We reassess the conventional wisdom on market efficiency in light of this fact. In our model economy, which resembles a typical machine learning setting, N assets have cash flows that are a linear function of J firm characteristics, but with uncertain coefficients. Risk-neutral Bayesian investors impose shrinkage (ridge regression) or sparsity (Lasso) when they estimate the J coefficients of the model and use them to price assets. When J is comparable in size to N, returns appear cross-sectionally predictable using firm characteristics to an econometrician who analyzes data from the economy ex post. A factor zoo emerges even without p-hacking and data-mining. Standard in-sample tests of market efficiency reject the no-predictability null with high probability, despite the fact that investors optimally use the information available to them in real time. In contrast, out-of-sample tests",4
dbea809be4a59c9b6e9ac0288fc0a9adbaf56621,May the best analyst win.,"A small Australian start-up company called Kaggle is exploiting the concept of ""crowdsourcing"" in a novel way. Kaggle9s core idea is to facilitate the analysis of data by allowing outsiders to model it. To do that, the company organizes competitions in which anyone with a passion for data analysis can battle it out. The contests offered so far have ranged widely, from ranking international chess players to evaluating whether a person will respond to HIV treatments to forecasting if a researcher9s grant application will be approved. Despite often modest prizes, the competitions have so far attracted more than 3000 statisticians, computer scientists, econometrists, mathematicians, and physicists from approximately 200 universities in 100 countries, Kaggle founder Anthony Goldbloom boasts. And the wisdom of the crowds can sometimes outsmart those offering up their data. In the HIV contest, entrants significantly improved on the efforts of the research team that posed the challenge.",8
57dcf50ebb13f7480feb75fbf7b22204847be669,Leveraging big data in smart cities: A systematic review,"Recently, the notion of a smart city, which includes smart well‐being, smart transit, and smart society, has attracted much attention due to its impact on people's quality of living. Data in smart cities are characterized by variety, velocity, volume, value, and veracity that are the well‐known characteristics of big data. The fast pace expanding of IoT devices and sensors in smart cities generates a huge volume of data that can help decision‐makers and managers in city management. The aim of this article is to wholly and systematically review big data handling approaches in smart cities, in which we analyze research efforts published between 2013 and February 2021, where these techniques are categorized based on their algorithms and architectures. Further, the main ideas, evaluation techniques, tools, evaluation metrics, algorithm types, advantages, and disadvantages are explored. Additionally, essential evaluation factors are introduced in which scalability and availability by 16%, time by 15%",6
693c7b81279f4bf317d0717ca2c5b07ceac25d8a,Modeling and Forecasting the Urban Volume Using Stochastic Differential Equations,"Traffic flow prediction can be used for the management of traffic control systems and can be applied toward improving traffic light split times at intersections. In this paper, we developed a methodology for the short-term prediction of traffic flow using the stochastic differential equation (SDE). Since the current volume depends on the previous short-term volume and time, we used the Hull-White model. With the proposed method, a flexible short-term prediction of volume is suggested. It is possible to simulate traffic conditions easily and also detect incidents precisely. This method is applied in Tehran's highways, and the obtained results are compared with previous artworks. Our results offered a better fit to the traffic volume.",4
e19dbac6d2cc85d1cc55de42ae34ab17cad11b65,Machine learning identifies the dynamics and influencing factors in an auditory category learning experiment,"Human learning is one of the main topics in psychology and cognitive neuroscience. The analysis of experimental data, e.g. from category learning experiments, is a major challenge due to confounding factors related to perceptual processing, feedback value, response selection, as well as inter-individual differences in learning progress due to differing strategies or skills. We use machine learning to investigate (Q1) how participants of an auditory category-learning experiment evolve towards learning, (Q2) how participant performance saturates and (Q3) how early we can differentiate whether a participant has learned the categories or not. We found that a Gaussian Mixture Model describes well the evolution of participant performance and serves as basis for identifying influencing factors of task configuration (Q1). We found early saturation trends (Q2) and that CatBoost, an advanced classification algorithm, can separate between participants who learned the categories and those who did not, well before the end of the learning",5
69bb2581d27a810f4e64260f07cdf8c61a622665,Convolutional Neural Networks on Apache Storm,"the performance of deep learning largely depends on the size of data. One data source is real-time streaming data, produced from mobile devices, sensors or social media, etc. Streaming data is high-speed and large-scale, which needs real-time processing. However, current mainstream frameworks are mainly designed for off-line data. To suit this, we first propose a deep learning framework based on Apache Storm, which is a distributed stream processing frame, fast and fault-tolerant. Our framework implements the distributed training of CNNs. which is different from MMLSpark or TensorFlowOnSpark that is a pure Java implementation. The design of message passing and synchronization is also suitable to other MapReduce-family distributed computing platforms. To validate our work, MNIST and Cifar -10 datasets are used for evaluation and comparison with similar architectures. The results show our framework, in resource-limited environment, realizes about 10 times speedup.",4
00d681cfff7f0224ace607e515f4ed510e792df9,The Parable of Google Flu: Traps in Big Data Analysis,"Large errors in flu prediction were largely avoidable, which offers lessons for the use of big data. In February 2013, Google Flu Trends (GFT) made headlines but not for a reason that Google executives or the creators of the flu tracking system would have hoped. Nature reported that GFT was predicting more than double the proportion of doctor visits for influenza-like illness (ILI) than the Centers for Disease Control and Prevention (CDC), which bases its estimates on surveillance reports from laboratories across the United States (1, 2). This happened despite the fact that GFT was built to predict CDC reports. Given that GFT is often held up as an exemplary use of big data (3, 4), what lessons can we draw from this error?",7
8023e7b54c4fa207b32e9bad406f8224816bcb86,"Managing, Analysing, and Integrating Big Data in Medical Bioinformatics: Open Problems and Future Perspectives","The explosion of the data both in the biomedical research and in the healthcare systems demands urgent solutions. In particular, the research in omics sciences is moving from a hypothesis-driven to a data-driven approach. Healthcare is additionally always asking for a tighter integration with biomedical data in order to promote personalized medicine and to provide better treatments. Efficient analysis and interpretation of Big Data opens new avenues to explore molecular biology, new questions to ask about physiological and pathological states, and new ways to answer these open issues. Such analyses lead to better understanding of diseases and development of better and personalized diagnostics and therapeutics. However, such progresses are directly related to the availability of new solutions to deal with this huge amount of information. New paradigms are needed to store and access data, for its annotation and integration and finally for inferring knowledge and making it available to researchers.",4
46c2b5e7590bfefa78c0e71970b91c09bf3a4b0c,A Deep Multi-task Contextual Attention Framework for Multi-modal Affect Analysis,"Multi-modal affect analysis (e.g., sentiment and emotion analysis) is an interdisciplinary study and has been an emerging and prominent field in Natural Language Processing and Computer Vision. The effective fusion of multiple modalities (e.g., text, acoustic, or visual frames) is a non-trivial task, as these modalities, often, carry distinct and diverse information, and do not contribute equally. The issue further escalates when these data contain noise. In this article, we study the concept of multi-task learning for multi-modal affect analysis and explore a contextual inter-modal attention framework that aims to leverage the association among the neighboring utterances and their multi-modal information. In general, sentiments and emotions have inter-dependence on each other (e.g., anger → negative or happy → positive). In our current work, we exploit the relatedness among the participating tasks in the multi-task framework. We define three different multi-task setups, each having two tasks, i.e., sentiment 8 emotion classification,",1
c15805b9e4a2f6fd25dffbaeca324eb067a4dbfb,"Prediction of MOF performance in Vacuum-Swing Adsorption systems for post-combustion CO2 capture based on integrated molecular simulation, process optimizations, and machine learning models.","Post-combustion CO2 capture and storage (CCS) is a key technological approach to reducing greenhouse gas emissions while we transition to carbon free energy production. However, current solvent based CO2 capture processes are considered too energetically expensive for widespread deployment. Vacuum Swing Adsorption (VSA) is a low energy CCS that has potential for industrial implementation if the right sorbents can be found. Metal organic framework (MOF) materials are often promoted as sorbents for low energy CCS by highlighting select adsorption properties without a clear understanding of how they perform in real world VSA processes. In this work, atomistic simulations have been fully integrated with a detailed VSA simulator, validated at the pilot scale, to screen 1632 experimentally characterized MOFs. 482 materials were found to meet the 95% CO2 purity and 90% CO2 recovery targets (95/90-PRT) - 365 of which have parasitic energies below that of solvent based capture (~290 kWhe/MT CO2)",1
c8bb4c1498b5b9b63ef822af0623c3da663e62b7,Quality Management in Big Data,"Due to the importance of quality issues in Big Data, Big Data quality management has attracted significant research attention on how to measure, improve and manage the quality for Big Data. This special issue in the Journal of Informatics thus tends to address the quality problems in Big Data as well as promote further research for Big Data quality. Our editorial describes the state-of-the-art research challenges in the Big Data quality research, and highlights the contributions of each paper accepted in this special issue.",4
a73aedce7a56c49c20d169d3369926cd8d028152,Understanding the diversity of the metal-organic framework ecosystem,"Millions of distinct metal-organic frameworks (MOFs) can be made by combining metal nodes and organic linkers. At present, over 90,000 MOFs have been synthesized and over 500,000 predicted. This raises the question whether a new experimental or predicted structure adds new information. For MOF chemists, the chemical design space is a combination of pore geometry, metal nodes, organic linkers, and functional groups, but at present we do not have a formalism to quantify optimal coverage of chemical design space. In this work, we develop a machine learning method to quantify similarities of MOFs to analyse their chemical diversity. This diversity analysis identifies biases in the databases, and we show that such bias can lead to incorrect conclusions. The developed formalism in this study provides a simple and practical guideline to see whether new structures will have the potential for new insights, or constitute a relatively small variation of existing structures.",4
9569b51674a032b3255e874e85f508a844a17183,Graph-based semi-supervised learning: A review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
b133c73fd3ca99070a1a42d3974e01040daa2fa4,On the use of MapReduce for imbalanced big data using Random Forest,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
a3553008be341b9167e2f793fb4d440403217c4c,Supply chain recovery challenges in the wake of COVID-19 pandemic,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
5922c07787f80c2ec1dec6d4035ef6fb93aa53fb,Machine learning and in silico discovery of metal-organic frameworks: Methanol as a working fluid in adsorption-driven heat pumps and chillers,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
9e6be8ee7d816deff953cb89b27db37413d9d604,SDMSim: A manufacturing service supply–demand matching simulator under cloud environment,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
50722f62a4c28eb96f0d36c0772b7e8692a4dee4,FPGA Implementations for Data Encryption and Decryption via Concurrent and Parallel Computation: A Review,"In recent days, increasing numbers of Internet and wireless network users have helped accelerate the need for encryption mechanisms and devices to protect user data sharing across an unsecured network. Data security, integrity, and verification may be used due to these features. In internet traffic encryption, symmetrical block chips play an essential role. Data Encryption Standard (DES) and Advanced Encryption Standard (AES) ensure privacy encryption underlying data protection standards. The DES and the AES provide information security. DES and AES have the distinction of being introduced in both hardware and applications. DES and AES hardware implementation has many advantages, such as increased performance and improved safety. This paper provides an exhaustive study of the implementation by DES and AES of field programming gate arrays (FPGAs) using both DES and AES. Since FPGAs can be defined as just one mission, computers are superior to them.",2
1d1bf83f34b7b192af837cc853adda60574a389e,IQ-TREE: A Fast and Effective Stochastic Algorithm for Estimating Maximum-Likelihood Phylogenies,"Large phylogenomics data sets require fast tree inference methods, especially for maximum-likelihood (ML) phylogenies. Fast programs exist, but due to inherent heuristics to find optimal trees, it is not clear whether the best tree is found. Thus, there is need for additional approaches that employ different search strategies to find ML trees and that are at the same time as fast as currently available ML programs. We show that a combination of hill-climbing approaches and a stochastic perturbation method can be time-efficiently implemented. If we allow the same CPU time as RAxML and PhyML, then our software IQ-TREE found higher likelihoods between 62.2% and 87.1% of the studied alignments, thus efficiently exploring the tree-space. If we use the IQ-TREE stopping rule, RAxML and PhyML are faster in 75.7% and 47.1% of the DNA alignments and 42.2% and 100% of the protein alignments, respectively. However, the range of obtaining higher likelihoods",6
18ad7c9f4de611f9edd034a8fc2c1fadce4191c9,On Meaningfulness,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
9f0089d9c77605a1ad872700401bd85e34e2ba98,Competing‐risks model for predicting the prognosis of penile cancer based on the SEER database,This study performed a competing‐risks analysis using data from the SEER database on penile cancer patients with the aim of identifying more accurate prognostic factors.,5
f454f6b5f2ca9749ddf442eb5134612ef7f758c1,ResNet strikes back: An improved training procedure in timm,"The influential Residual Networks designed by He et al. remain the gold-standard architecture in numerous scientific publications. They typically serve as the default architecture in studies, or as baselines when new architectures are proposed. Yet there has been significant progress on best practices for training neural networks since the inception of the ResNet architecture in 2015. Novel optimization&data-augmentation have increased the effectiveness of the training recipes. In this paper, we re-evaluate the performance of the vanilla ResNet-50 when trained with a procedure that integrates such advances. We share competitive training settings and pre-trained models in the timm open-source library, with the hope that they will serve as better baselines for future work. For instance, with our more demanding training setting, a vanilla ResNet-50 reaches 80.4% top-1 accuracy at resolution 224x224 on ImageNet-val without extra data or distillation. We also report the performance achieved with popular models with our training procedure.",4
7c4356ec0dca6e6df0af7a882e2cd1571c8bf3dc,Data-Efficient Reinforcement Learning with Self-Predictive Representations,"While deep reinforcement learning excels at solving tasks where large amounts of data can be collected through virtually unlimited interaction with the environment, learning from limited interaction remains a key challenge. We posit that an agent can learn more efficiently if we augment reward maximization with self-supervised objectives based on structure in its visual input and sequential interaction with the environment. Our method, Self-Predictive Representations(SPR), trains an agent to predict its own latent state representations multiple steps into the future. We compute target representations for future states using an encoder which is an exponential moving average of the agent's parameters and we make predictions using a learned transition model. On its own, this future prediction objective outperforms prior methods for sample-efficient deep RL from pixels. We further improve performance by adding data augmentation to the future prediction loss, which forces the agent's representations to be consistent across multiple views of",4
507d4db5530300ef296219b56cb020ff9987c141,Big Data analytics,"In this paper, we explain the concept, characteristics & need of Big Data & different offerings available in the market to explore unstructured large data. This paper covers Big Data adoption trends, entry & exit criteria for the vendor and product selection, best practices, customer success story, benefits of Big Data analytics, summary and conclusion. Our analysis illustrates that the Big Data analytics is a fast-growing, influential practice and a key enabler for the social business. The insights gained from the user generated online contents and collaboration with customers is critical for success in the age of social media.",11
fe2bc32726726e1086dcfb34f95834d9334c2d1c,Big data analytics in logistics and supply chain management: Certain investigations for research and applications,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
3eb14a542d45abb8c294044e899629b0aebb4711,"Global burden of 369 diseases and injuries in 204 countries and territories, 1990–2019: a systematic analysis for the Global Burden of Disease Study 2019","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
8b0bda12424d4373f7e6eab5276a91cfd0cb6200,Big Data and Predictive Business Analytics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
75c203cf1aeed022ae7c15928e0f5bac7b944ca0,Towards effective offloading mechanisms in fog computing,"Fog computing is considered a formidable next-generation complement to cloud computing. Nowadays, in light of the dramatic rise in the number of IoT devices, several problems have been raised in cloud architectures. By introducing fog computing as a mediate layer between the user devices and the cloud, one can extend cloud computing's processing and storage capability. Offloading can be utilized as a mechanism that transfers computations, data, and energy consumption from the resource-limited user devices to resource-rich fog/cloud layers to achieve an optimal experience in the quality of applications and improve the system performance. This paper provides a systematic and comprehensive study to evaluate fog offloading mechanisms' current and recent works. Each selected paper's pros and cons are explored and analyzed to state and address the present potentialities and issues of offloading mechanisms in a fog environment efficiently. We classify offloading mechanisms in a fog system into four groups, including",7
6d2dc2030f5df8b38770814639c0cf99e9fa5f81,An Energy-Efficient Off-Loading Scheme for Low Latency in Collaborative Edge Computing,"Mobile terminal users applications, such as smartphones or laptops, have frequent computational task demanding but limited battery power. Edge computing is introduced to offload terminals’ tasks to meet the quality of service requirements such as low delay and energy consumption. By offloading computation tasks, edge servers can enable terminals to collaboratively run the highly demanding applications in acceptable delay requirements. However, existing schemes barely consider the characteristics of the edge server, which leads to random assignment of tasks among servers and big tasks with high computational intensity (named as “big task”) may be assigned to servers with low ability. In this paper, a task is divided into several subtasks and subtasks are offloaded according to characteristics of edge servers, such as transmission distance and central processing unit (CPU) capacity. With this multi-subtasks-to-multi-servers model, an adaptive offloading scheme based on Hungarian algorithm is proposed with low complexity. Extensive simulations are conducted",3
8566f36d7917d4bd5705e1f7dff39197e2d22817,A Manufacturing Big Data Solution for Active Preventive Maintenance,"Industry 4.0 has become more popular due to recent developments in cyber-physical systems, big data, cloud computing, and industrial wireless networks. Intelligent manufacturing has produced a revolutionary change, and evolving applications, such as product lifecycle management, are becoming a reality. In this paper, we propose and implement a manufacturing big data solution for active preventive maintenance in manufacturing environments. First, we provide the system architecture that is used for active preventive maintenance. Then, we analyze the method used for collection of manufacturing big data according to the data characteristics. Subsequently, we perform data processing in the cloud, including the cloud layer architecture, the real-time active maintenance mechanism, and the offline prediction and analysis method. Finally, we analyze a prototype platform and implement experiments to compare the traditionally used method with the proposed active preventive maintenance method. The manufacturing big data method used for active preventive maintenance has the potential to",8
bc552f33c8761b8e8704dce814334fc9b4108045,Blockchain in Agriculture Traceability Systems: A Review,"Food holds a major role in human beings’ lives and in human societies in general across the planet. The food and agriculture sector is considered to be a major employer at a worldwide level. The large number and heterogeneity of the stakeholders involved from different sectors, such as farmers, distributers, retailers, consumers, etc., renders the agricultural supply chain management as one of the most complex and challenging tasks. It is the same vast complexity of the agriproducts supply chain that limits the development of global and efficient transparency and traceability solutions. The present paper provides an overview of the application of blockchain technologies for enabling traceability in the agri-food domain. Initially, the paper presents definitions, levels of adoption, tools and advantages of traceability, accompanied with a brief overview of the functionality and advantages of blockchain technology. It then conducts an extensive literature review on the integration of blockchain into traceability",5
123d00c6a664ea6d4da57d0d89d980dd02347c79,Privacy Preserving Data Mining,Recent interest in data collection and monitoring using data mining for security and business-related applications has raised privacy. Privacy Preserving Data Mining (PPDM) techniques require data modification to disinfect them from sensitive information or to anonymize them at an uncertainty level. This study uses PPDM with adult dataset to investigate effects of K-anonymization for evaluation metrics. This study uses Artificial Bee Colony (ABC) algorithm for feature generalization and suppression where features are removed without affecting classification accuracy. Also k-anonymity is accomplished by original dataset generalization.,4
c95f9d2e505c5b4cb15511dd2de473800b2e82ad,Deep Synthetic Minority Over-Sampling Technique,"Synthetic Minority Over-sampling Technique (SMOTE) is the most popular over-sampling method. However, its random nature makes the synthesized data and even imbalanced classification results unstable. It means that in case of running SMOTE n different times, n different synthesized in-stances are obtained with n different classification results. To address this problem, we adapt the SMOTE idea in deep learning architecture. In this method, a deep neural network regression model is used to train the inputs and outputs of traditional SMOTE. Inputs of the proposed deep regression model are two randomly chosen data points which are concatenated to form a double size vector. The outputs of this model are corresponding randomly interpolated data points between two randomly chosen vectors with original dimension. The experimental results show that, Deep SMOTE can outperform traditional SMOTE in terms of precision, F1 score and Area Under Curve (AUC) in majority of test cases.",4
ef2afdce9b71657522d743178ab39fb03a394647,"Big data analytics in medical engineering and healthcare: methods, advances and challenges","Abstract Big data analytics are gaining popularity in medical engineering and healthcare use cases. Stakeholders are finding big data analytics reduce medical costs and personalise medical services for each individual patient. Big data analytics can be used in large-scale genetics studies, public health, personalised and precision medicine, new drug development, etc. The introduction of the types, sources, and features of big data in healthcare as well as the applications and benefits of big data and big data analytics in healthcare is key to understanding healthcare big data and will be discussed in this article. Major methods, platforms and tools of big data analytics in medical engineering and healthcare are also presented. Advances and technology progress of big data analytics in healthcare are introduced, which includes artificial intelligence (AI) with big data, infrastructure and cloud computing, advanced computation and data processing, privacy and cybersecurity, health economic outcomes and technology management, and",6
f599d13c6ccabe582cbec207ff8b85df76b915e7,Forecasting the power consumption of a rotor spinning machine by using an adaptive squeeze and excitation convolutional neural network with imbalanced data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
0573f03559d73040c1d32adf48af1192b160c6eb,Are firms ready to use big data analytics to create value? The role of structural and psychological readiness,"ABSTRACT In this study, we leverage Information Technology (IT) readiness literature and resource-based view (RBV) to investigate the impact of firm structural and psychological readiness on firm value creation, as mediated by big data analytics usage. The proposed research model is empirically validated using survey data from 179 senior IT managers. The findings demonstrate the importance of both structural (i.e. IT infrastructure capability, tools functionality, employee analytical capability, and bigness of data) and psychological readiness (i.e. IT proactive climate) in enhancing firm value creation through big data analytics usage. These results provide interesting theoretical and practical insights.",5
13d26cb340324445ccb0b7786910d5aeaab4e6e8,An Authenticated Key Exchange Protocol for Multi-Server Architecture in 5G Networks,"Currently, the popularity of the Internet of Things (IoT) has brought about an increase in the amount of data, so multi-server distributed cloud computing has been widely used in various applications that have brought convenience to our daily lives. At the same time, the development of the fifth generation (5G) of mobile communication technology has gradually become the main driving force for the popularization of the IoT. Because the 5G network is a heterogeneous network with multiple servers and small cells, the mutual authentication protocol under multiple servers is also applicable to the 5G network environment. However, much of the data will have serious storage and security issues during transmission. Aiming at the security issues in a multi-server (M-S) architecture, in 2018, Wu et al. proposed an authentication protocol in a distributed cloud environment. They claimed that their protocol is secure and resistant to various known types of attacks. However,",3
85eddbc784d68852fcf200edb6cf7cfde4a3aaf6,Experimentally validated machine learning frameworks for accelerated prediction of cyclic steady state and optimization of pressure swing adsorption processes,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
a4e32cd09d5bc25b0e072b4bd1055bdabafaa6bf,Googling Freedom,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
fb2f91d175b66e2224d691443877c3d144b63293,Anomaly detection of power consumption in yarn spinning using transfer learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
e29b85ab2a15c9e2a8711b66806cbfa5bf1472bb,Management and control applications in Agriculture domain via a Future Internet Business-to-Business platform,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
cf570a373a4b52a4095b1e743407176fc4582457,"Ethical Imperialism: Institutional Review Boards and the Social Sciences, 1965–2009","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
b7262a740e0726c10bcf675559ea912c28511761,IoTSE-based open database vulnerability inspection in three Baltic countries: ShoBEVODSDT sees you,"This study aims to analyze the state of the security of open data databases, i.e. being accessible from the outside of organization, representing both relational databases and NoSQL of three Baltic countries - Latvia, Lithuania, Estonia. This is done by using previously proposed tool for non-intrusive detection of vulnerable data sources called ShoBEVODSDT (Shodan- and Binary Edge-based vulnerable open data sources detection tool). ShoBEVODSDT is based on the use of Internet of Things Search Engines (IoTSE). It is found to be suitable for this study since it conducts the passive assessment, which means that its use does not harm the databases but rather checks for potentially existing bottlenecks or weaknesses which, if the attack would take place, could be exposed. It allows for both comprehensive analysis for all unprotected data sources falling into the list of predefined data sources - MySQL, PostgreSQL, MongoDB, Redis, Elasticsearch, CouchDB, Cassandra and Memcached, or",5
b581c0c41184f3640f774240b6ba9cf08497a9d2,Beyond a Technical Perspective: Understanding Big Data Capabilities in Health Care,"To date, the health care industry has paid little attention to the potential benefits to be gained from big data. While most pioneering big data studies have adopted technological perspectives, a better understanding of the strategic implications of big data is urgently needed. To address this lack, this study examines the development, architecture and component functionalities of big data, and identifies its capabilities, including traceability, the analysis of unstructured data and patterns of care, and its predictive capacity to support healthcare managers seeking to formulate more effective big-data-based strategies. Our findings will help healthcare organizations respond strategically to the challenges they face in today's highly competitive healthcare market.",2
c68dd8fd9c2cd5e6a636c641931cab34908449c5,The Innovator's Dilemma: When New Technologies Cause Great Firms to Fail,"A Wall Street Journal and Businessweek bestseller. Named by Fast Company as one of the most influential leadership books in its Leadership Hall of Fame. An innovation classic. From Steve Jobs to Jeff Bezos, Clay Christensens work continues to underpin todays most innovative leaders and organizations. The bestselling classic on disruptive innovation, by renowned author Clayton M. Christensen. His work is cited by the worlds best-known thought leaders, from Steve Jobs to Malcolm Gladwell. In this classic bestsellerone of the most influential business books of all timeinnovation expert Clayton Christensen shows how even the most outstanding companies can do everything rightyet still lose market leadership. Christensen explains why most companies miss out on new waves of innovation. No matter the industry, he says, a successful company with established products will get pushed aside unless managers know how and when to abandon traditional business practices. Offering both successes and failures from",6
8a52af5af74657d5f9c5c59d95a47ceaeed9b6d4,Gaydar: Facebook Friendships Expose Sexual Orientation,"Public information about one's coworkers, friends, family, and acquaintances, as well as one's associations with them, implicitly reveals private information. Social-networking websites, e-mail, instant messaging, telephone, and VoIP are all technologies steeped in network data—data relating one person to another. Network data shifts the locus of information control away from individuals, as the individual's traditional and absolute discretion is replaced by that of his social-network. Our research demonstrates a method for accurately predicting the sexual orientation of Facebook users by analyzing friendship associations. After analyzing 4,080 Facebook profiles from the MIT network, we determined that the percentage of a given user's friends who self-identify as gay male is strongly correlated with the sexual orientation of that user, and we developed a logistic regression classifier with strong predictive power. Although we studied Facebook friendship ties, network data is pervasive in the broader context of computer-mediated communication, raising significant privacy issues for",7
44815bffa5cfaa095032496198826765931eb6bc,Prognostic nomogram for acute pancreatitis patients: An analysis of publicly electronic healthcare records in intensive care unit,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
07d4304493c19202bb172660179734b522314b71,"Business Intelligence and Analytics Education, and Program Development: A Unique Opportunity for the Information Systems Discipline","“Big Data,” huge volumes of data in both structured and unstructured forms generated by the Internet, social media, and computerized transactions, is straining our technical capacity to manage it. More importantly, the new challenge is to develop the capability to understand and interpret the burgeoning volume of data to take advantage of the opportunities it provides in many human endeavors, ranging from science to business. Data Science, and in business schools, Business Intelligence and Analytics (BI&A) are emerging disciplines that seek to address the demands of this new era. Big Data and BI&A present unique challenges and opportunities not only for the research community, but also for Information Systems (IS) programs at business schools. In this essay, we provide a brief overview of BI&A, speculate on the role of BI&A education in business schools, present the challenges facing IS departments, and discuss the role of IS curricula and program development,",5
0157dcd6122c20b5afc359a799b2043453471f7f,Exploiting Similarities among Languages for Machine Translation,"Dictionaries and phrase tables are the basis of modern statistical machine translation systems. This paper develops a method that can automate the process of generating and extending dictionaries and phrase tables. Our method can translate missing word and phrase entries by learning language structures based on large monolingual data and mapping between languages from small bilingual data. It uses distributed representation of words and learns a linear mapping between vector spaces of languages. Despite its simplicity, our method is surprisingly effective: we can achieve almost 90% precision@5 for translation of words between English and Spanish. This method makes little assumption about the languages, so it can be used to extend and refine dictionaries and translation tables for any language pairs.",6
1c45bfad2900f553364b9f877ca31e1ab3a310a1,Big Data in product lifecycle management,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",10
0a9b4c9448b726af6ff8cc89d77fe8c6036391f6,Online active multi-field learning for efficient email spam filtering,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
3e803ab1aaa0c28fb6106f1a3b5ab42fe2655a40,A primer on partial least squares structural equation modeling (PLS-SEM),"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
35f992b1f4e6b37045bd906100fbb0f433747cc6,Can big data improve firm decision quality? The role of data quality and data diagnosticity,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
20b5a2aacb69c348bdf6b97bf66a4622ab7e9e36,Blockchain-Secured Smart Manufacturing in Industry 4.0: A Survey,"Blockchain is a new generation of secure information technology that is fueling business and industrial innovation. Many studies on key enabling technologies for resource organization and system operation of blockchain-secured smart manufacturing in Industry 4.0 had been conducted. However, the progression and promotion of these blockchain applications have been fundamentally impeded by various issues in scalability, flexibility, and cybersecurity. This survey discusses how blockchain systems can overcome potential cybersecurity barriers to achieving intelligence in Industry 4.0. In this regard, eight cybersecurity issues (CIs) are identified in manufacturing systems. Ten metrics for implementing blockchain applications in the manufacturing system are devised while surveying research in blockchain-secured smart manufacturing. This study reveals how these CIs have been studied in the literature. Based on insights obtained from this analysis, future research directions for blockchain-secured smart manufacturing are presented, which potentially guides research on urgent cybersecurity concerns for achieving intelligence in Industry 4.0.",5
658dc31f6816c51eba77bf82ca1eab4a25812deb,A comparative between hadoop mapreduce and apache Spark on HDFS,"Data is growing now in a very high speed with a large volume, Spark and MapReduce1 both provide a processing model for analyzing and managing this large data -Big Data- stored on HDFS. In this paper, we discuss a comparative between Apache Spark and Hadoop MapReduce using the machine learning algorithms, k-means and logistic regression. This comparative is done through two experiences, the first one using the same programming language java, and the second using different programming languages.",7
49ae02906ebebb0411ef24f94049bfaea3c39eae,Handbook of Research on Machine Learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
a05bf3d8f3f6934b446bbbeb9c7f192f9a7d67c0,Analysis of animal monitoring technologies in Germany from an innovation system perspective,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
72d32c986b47d6b880dad0c3f155fe23d2939038,Deep Learning of Representations: Looking Forward,"Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical results, learning algorithms and breakthrough experiments, several challenges lie ahead. This paper proposes to examine some of these challenges, centering on the questions of scaling deep learning algorithms to much larger models and datasets, reducing optimization difficulties due to ill-conditioning or local minima, designing more efficient and powerful inference and sampling procedures, and learning to disentangle the factors of variation underlying the observed data. It also proposes a few forward-looking research directions aimed at overcoming these challenges.",1
b99b2b33038e72fec702b86187bea6aab751f1d3,On the Effects of Modeling As-Manufactured Geometry: Toward Digital Twin,"A simple, nonstandardized material test specimen, which fails along one of two different likely crack paths, is considered herein. The result of deviations in geometry on the order of tenths of a millimeter, this ambiguity in crack path motivates the consideration of as-manufactured component geometry in the design, assessment, and certification of structural systems. Herein, finite element models of as-manufactured specimens are generated and subsequently analyzed to resolve the crack-path ambiguity. The consequence and benefit of such a “personalized” methodology is the prediction of a crack path for each specimen based on its as-manufactured geometry, rather than a distribution of possible specimen geometries or nominal geometry. The consideration of as-manufactured characteristics is central to the Digital Twin concept. Therefore, this work is also intended to motivate its development.",3
438c0a37e7545e836ee81c519cedf44f0702418f,Deep learning for lung cancer prognostication: A retrospective multi-cohort radiomics study,"Background Non-small-cell lung cancer (NSCLC) patients often demonstrate varying clinical courses and outcomes, even within the same tumor stage. This study explores deep learning applications in medical imaging allowing for the automated quantification of radiographic characteristics and potentially improving patient stratification. Methods and findings We performed an integrative analysis on 7 independent datasets across 5 institutions totaling 1,194 NSCLC patients (age median = 68.3 years [range 32.5–93.3], survival median = 1.7 years [range 0.0–11.7]). Using external validation in computed tomography (CT) data, we identified prognostic signatures using a 3D convolutional neural network (CNN) for patients treated with radiotherapy (n = 771, age median = 68.0 years [range 32.5–93.3], survival median = 1.3 years [range 0.0–11.7]). We then employed a transfer learning approach to achieve the same for surgery patients (n = 391, age median = 69.1 years [range 37.2–88.0], survival median = 3.1 years [range 0.0–8.8]). We found that the",6
31c186c33d96b7a3d4a77b1b6bf09a44437fa4b8,CWV-BANN-SVM ensemble learning classifier for an accurate diagnosis of breast cancer,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
43ebefae0229aa1a9d241e69b4c8fa4af66efa9a,Deformable Convolutional Networks for Efficient Mixed-Type Wafer Defect Pattern Recognition,"Defect pattern recognition (DPR) of wafer maps is critical for determining the root cause of production defects, which can provide insights for the yield improvement in wafer foundries. During wafer fabrication, several types of defects can be coupled together in a piece of wafer, it is called mixed-type defects DPR. To detect mixed-type defects is much more complicated because the combination of defects may vary a lot, from the type of defects, position, angle, number of defects, etc. Deep learning methods have been a good choice for complex pattern recognition problems. In this article, we propose a deformable convolutional network (DC-Net) for mixed-type DPR (MDPR) in which several types of defects are coupled together in a piece of wafer. A deformable convolutional unit is designed to selectively sample from mixed defects, then extract high-quality features from wafer maps. A multi-label output layer is improved with a one-hot encoding mechanism, which",4
09a740aca5510c8cd5dd5a7474d6c1dcae08eff6,An Overview of Deep Semi-Supervised Learning,"Deep neural networks demonstrated their ability to provide remarkable performances on a wide range of supervised learning tasks (e.g., image classification) when trained on extensive collections of labeled data (e.g., ImageNet). However, creating such large datasets requires a considerable amount of resources, time, and effort. Such resources may not be available in many practical cases, limiting the adoption and the application of many deep learning methods. In a search for more data-efficient deep learning methods to overcome the need for large annotated datasets, there is a rising research interest in semi-supervised learning and its applications to deep neural networks to reduce the amount of labeled data required, by either developing novel methods or adopting existing semi-supervised learning frameworks for a deep learning setting. In this paper, we provide a comprehensive overview of deep semi-supervised learning, starting with an introduction to the field, followed by a summarization of the dominant semi-supervised",4
348d4fe0ab49cba6e5b0216de51dea3753d0e2b2,An Intelligent Information Forwarder for Healthcare Big Data Systems With Distributed Wearable Sensors,"An increasing number of the elderly population wish to live an independent lifestyle, rather than rely on intrusive care programmes. A big data solution is presented using wearable sensors capable of carrying out continuous monitoring of the elderly, alerting the relevant caregivers when necessary and forwarding pertinent information to a big data system for analysis. A challenge for such a solution is the development of context-awareness through the multidimensional, dynamic and nonlinear sensor readings that have a weak correlation with observable human behaviours and health conditions. To address this challenge, a wearable sensor system with an intelligent data forwarder is discussed in this paper. The forwarder adopts a Hidden Markov Model for human behaviour recognition. Locality sensitive hashing is proposed as an efficient mechanism to learn sensor patterns. A prototype solution is implemented to monitor health conditions of dispersed users. It is shown that the intelligent forwarders can provide the",7
409ebe4c2a8eb45ce1572af381980e0d4339f3bb,Adaptive Clustering for Outlier Identification in High-Dimensional Data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
bcccf3a8499bbaac2fd809c43ceb1be96b59b926,Adversarially learned one-class novelty detection with confidence estimation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
9b1653e3b57016958d10ff8531475eb0483d156c,"Social Privacy in Networked Publics: Teens’ Attitudes, Practices, and Strategies","This paper examines how teens understand privacy in highly public networked environments like Facebook and Twitter. We describe both teens’ practices, their privacy strategies, and the structural conditions in which they are embedded, highlighting the ways in which privacy, as it plays out in everyday life, is related more to agency and the ability to control a social situation than particular properties of information. Finally, we discuss the implications of teens’ practices and strategies, revealing the importance of social norms as a regulatory force.(This paper was presented at Oxford Internet Institute’s “A Decade in Internet Time: Symposium on the Dynamics of the Internet and Society” on September 22, 2011.)",6
6c07a6e062c0e5bf6715ebd5c2ba0851e57f2112,Retracted: An enhance the data security performance using an optimal cloud network security for big data cloud framework,"Venkatesan B, Chitra S. An enhance the data security performance using an optimal cloud network security for big data cloud framework, International Journal of Communication Systems 2021, (https://doi.org/10.1002/dac.4854). The above article published online on 9 August 2021 in Wiley Online Library (wileyonlinelibrary.com), has been retracted by agreement between the Editor and John Wiley and Sons Ltd. Following publication, it has come to our attention that the people named as the Guest Editors of the Special Issue were being impersonated by a fraudulent entity and the articles were not reviewed in line with the journal's peer review standards. The Editor has determined that the articles do not meet the required scholarly standards of the journal, and therefore has taken the decision to retract the article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.",4
d145803c6d4c517b1ebad137507915e7be463099,A loosely-coupled deep reinforcement learning approach for order acceptance decision of mass-individualized printed circuit board manufacturing in industry 4.0,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
adfcbf41d0f0c0303476075401355df6aa16110c,Interdisciplinarity: Reconfigurations of the Social and Natural Sciences,"1. Interdisciplinarity: Reconfigurations of the Social and Natural Sciences by Andrew Barry and Georgina Born 2. How Disciplines Look by Simon Schaffer 3. Inter That Discipline! by Thomas Osborne 4. Fields and Fallows: A Political History of STS by Sheila Jasanoff 5. Unexpected Consequences and An Unanticipated Outcome by Marilyn Strathern and Elena Khlinovskaya Rockhill 6. Consuming Anthropology by Lucy Suchman 7. Where Natural and Social Science Meet? Reflections On An Experiment in Geographical Practice by Sarah J. Whatmore 8. Multiple Environments: Accountability, Integration and Ontology by Gisa Weszkalnys and Andrew Barry 9. Ontology and Antidisciplinarity by Andrew Pickering 10. Logics of Interdisciplinarity: The Case of Medical Humanities by Monica Greco 11. Art-Science: From Public Understanding to Public Experiment by Georgina Born and Andrew Barry",5
8deeb6091710caab295d66a1d9fa2485a83b7eac,Probabilistic topic models,Surveying a suite of algorithms that offer a solution to managing large document archives.,3
3815675396c3328d2af7344fdca3df42d2258b8a,A Bootstrap Metropolis–Hastings Algorithm for Bayesian Analysis of Big Data,"Markov chain Monte Carlo (MCMC) methods have proven to be a very powerful tool for analyzing data of complex structures. However, their computer-intensive nature, which typically require a large number of iterations and a complete scan of the full dataset for each iteration, precludes their use for big data analysis. In this article, we propose the so-called bootstrap Metropolis–Hastings (BMH) algorithm that provides a general framework for how to tame powerful MCMC methods to be used for big data analysis, that is, to replace the full data log-likelihood by a Monte Carlo average of the log-likelihoods that are calculated in parallel from multiple bootstrap samples. The BMH algorithm possesses an embarrassingly parallel structure and avoids repeated scans of the full dataset in iterations, and is thus feasible for big data problems. Compared to the popular divide-and-combine method, BMH can be generally more efficient as it can asymptotically integrate the whole",4
a29c7cccaf5fbf06d3edbe629d32a06319f98bd4,IMapC: Inner MAPping Combiner to Enhance the Performance of MapReduce in Hadoop,"Hadoop is a framework for storing and processing huge amounts of data. With HDFS, large data sets can be managed on commodity hardware. MapReduce is a programming model for processing vast amounts of data in parallel. Mapping and reducing can be performed by using the MapReduce programming framework. A very large amount of data is transferred from Mapper to Reducer without any filtering or recursion, resulting in overdrawn bandwidth. In this paper, we introduce an algorithm called Inner MAPping Combiner (IMapC) for the map phase. This algorithm in the Mapper combines the values of recurring keys. In order to test the efficiency of the algorithm, different approaches were tested. According to the test, MapReduce programs that are implemented with the Default Combiner (DC) of IMapC will be 70% more efficient than those that are implemented without one. To make computations significantly faster, this work can be combined with MapReduce.",4
a0ced57c682613e42c88a528c7b387f566152185,Single reading with computer-aided detection for screening mammography.,"BACKGROUND The sensitivity of screening mammography for the detection of small breast cancers is higher when the mammogram is read by two readers rather than by a single reader. We conducted a trial to determine whether the performance of a single reader using a computer-aided detection system would match the performance achieved by two readers. METHODS The trial was designed as an equivalence trial, with matched-pair comparisons between the cancer-detection rates achieved by single reading with computer-aided detection and those achieved by double reading. We randomly assigned 31,057 women undergoing routine screening by film mammography at three centers in England to double reading, single reading with computer-aided detection, or both double reading and single reading with computer-aided detection, at a ratio of 1:1:28. The primary outcome measures were the proportion of cancers detected according to regimen and the recall rates within the group receiving both reading regimens. RESULTS The proportion",7
971acfbf40aad7016b587993ca8a939eeb40dca8,Divining a Digital Future: Mess and Mythology in Ubiquitous Computing (review),"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
49226b2a39dacc49ec5aa3ad7523366b4d25dd27,Digging for drug facts,"With the right approach, data mining can discover unexpected side effects and drug interactions.",8
8bcc25651b62532f639fe713da9d7b67c742d562,Efficient Machine Learning for Big Data: A Review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
78421f833eebd99db716cd46340128c18cd713cd,Security Threats and Defensive Approaches in Machine Learning System Under Big Data Environment,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
96eef33dcf16e39744ec4e2ab959a82c2e95b9cf,Description of Clinical Characteristics of VAP Patients in MIMIC Database,"Background: Ventilator-associated pneumonia (VAP) is a common and serious nosocomial infection of intensive-care units (ICUs). Accurate, timely diagnosis enables early VAP patients to receive appropriate therapies and reduce the occurrence of complication. However, so far clinical datas regarding the epidemiology and mortality of VAP are still limited. Medical Information Mart for Intensive Care (MIMIC) database is a free, open and public resource about ICU research database. MIMIC database is a free, open, public database that collects information on more than 40,000 ICU patients who are predominantly white people. Therefore, the purpose of the present study is to observe and describe the clinical characteristics of VAP patients in ICU from the MIMIC database. Method: A total of 418 patients were enrolled in the study. General information, ventilator use information, microbiology information, antibiotic use information, and some nursing-related information were extracted to describe and analyze the clinical features of VAP patients. Results:",9
9d75cc322a4e06d0a3a868cb91b04219a289c12c,Machine Learning: An Applied Econometric Approach,"Machines are increasingly doing “intelligent” things. Face recognition algorithms use a large dataset of photos labeled as having a face or not to estimate a function that predicts the presence y of a face from pixels x. This similarity to econometrics raises questions: How do these new empirical tools fit with what we know? As empirical economists, how can we use them? We present a way of thinking about machine learning that gives it its own place in the econometric toolbox. Machine learning not only provides new tools, it solves a different problem. Specifically, machine learning revolves around the problem of prediction, while many economic applications revolve around parameter estimation. So applying machine learning to economics requires finding relevant tasks. Machine learning algorithms are now technically easy to use: you can download convenient packages in R or Python. This also raises the risk that the algorithms are applied naively or",11
aad7820cd6d4920e366d84cefbcf643cc053a6b2,The methodology of a multi-model project examining how facebook infrastructures social relations,"ABSTRACT It is the purpose of this paper to make explicit the methodology (the theory of the methods) by which we conducted research for an Economic and Social Research Council-funded research project on the relationship of values to value. Specifically, we wanted to study the imperative of Facebook to monetize social relationships, what happens when one of our significant forms of communication is driven by the search for profit, by the logic of capital. We therefore wanted to ‘get inside’ and understand what capital's new lines of flight, informationally driven models of economic expansion, do to social relations. Taking up the challenge to develop methods appropriate to the challenges of ‘big data', we applied four different methods to investigate the interface that is Facebook: we designed custom software tools, generated an online survey, developed data visualizations, and conducted interviews with participants to discuss their understandings of our analysis. We used",6
156510dd3d38813784f8b9cb6b380be899eec83a,The Ethical Algorithm: The Science of Socially Aware Algorithm Design,"THE ETHICAL ALGORITHM: The Science of Socially Aware Algorithm Design by Michael Kearns and Aaron Roth. New York: Oxford University Press, 2019. 232 pages. Hardcover; $24.95. ISBN: 9780190948207. *Can an algorithm be ethical? That question appears to be similar to asking if a hammer can be ethical. Isn't the ethics solely related to how the hammer is used? Using it to build a house seems ethical; using it to harm another person would be immoral. *That line of thinking would be appropriate if the algorithm were something as simple as a sorting routine. If we sort the list of names in a wedding guest book so that the thank-you cards can be sent more systematically, its use would be acceptable; sorting a list of email addresses by education level in order to target people with a scam would be immoral. *The algorithms under consideration in The Ethical Algorithm are of",5
1034bfdcdfd1ae0941bbee4660255a2130f56bd2,IT capability and organizational performance: the roles of business process agility and environmental factors,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",11
82bc4a2195f39db35f106e8e5880f16ec91ac57c,An efficient novel approach for iris recognition based on stylometric features and machine learning techniques,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
b320819c3c9d861e4c4e7663bfec9ca715dce11d,Finding the missing link for big biomedical data.,"It has been argued that big data will enable efficiencies and accountability in health care.1,2 However, to date, other industries have been far more successful at obtaining value from large-scale integration and analysis of heterogeneous data sources. What these industries have figured out is that big data becomes transformative when disparate data sets can be linked at the individual person level. In contrast, big biomedical data are scattered across institutions and intentionally isolated to protect patient privacy. Both technical and social challenges to linking these data must be addressed before big biomedical data can have their full influence on health care. It is this linkage challenge that we address in this Viewpoint.",2
4ce13dcc8e5497755bbedcea39c4b9b7e14fe64f,The internet of things,"When the Internet emerged more than two decades ago, it changed everything. But the Internet of Everything makes that pale in comparison. After two decades of networking and communication, 99% of things are still not networked. The Internet of Everything will disrupt several industries. That means new opportunities, businesses, experiences, and services, and big opportunities for people, companies, and countries. The Internet of Everything demands an intelligent network — a distributed, application-centric networking, computing and storage platform that connects things together, connects things to the Network and connects people and things to the cloud in ways that just weren't possible, or even imaginable, before.",4
528a5c6a07f3cd5dcff2d33382bbcf82cc709a71,Online Feature Selection with Streaming Features,"We propose a new online feature selection framework for applications with streaming features where the knowledge of the full feature space is unknown in advance. We define streaming features as features that flow in one by one over time whereas the number of training examples remains fixed. This is in contrast with traditional online learning methods that only deal with sequentially added observations, with little attention being paid to streaming features. The critical challenges for Online Streaming Feature Selection (OSFS) include 1) the continuous growth of feature volumes over time, 2) a large feature space, possibly of unknown or infinite size, and 3) the unavailability of the entire feature set before learning starts. In the paper, we present a novel Online Streaming Feature Selection method to select strongly relevant and nonredundant features on the fly. An efficient Fast-OSFS algorithm is proposed to improve feature selection performance. The proposed algorithms are",5
cd02e0a094953077217e2e62f3557b36a365acff,Optimizing Deeper Transformers on Small Datasets,"It is a common belief that training deep transformers from scratch requires large datasets. Consequently, for small datasets, people usually use shallow and simple additional layers on top of pre-trained models during fine-tuning. This work shows that this does not always need to be the case: with proper initialization and optimization, the benefits of very deep transformers can carry over to challenging tasks with small datasets, including Text-to-SQL semantic parsing and logical reading comprehension. In particular, we successfully train 48 layers of transformers, comprising 24 fine-tuned layers from pre-trained RoBERTa and 24 relation-aware layers trained from scratch. With fewer training steps and no task-specific pre-training, we obtain the state of the art performance on the challenging cross-domain Text-to-SQL parsing benchmark Spider. We achieve this by deriving a novel Data dependent Transformer Fixed-update initialization scheme (DT-Fixup), inspired by the prior T-Fixup work. Further error analysis shows that increasing depth can help",2
be264d4cb585847f5e0655bea8acce00faf1cec1,The role of big data analytics capabilities in greening e-procurement: A higher order PLS-SEM analysis,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
b73406d4d31c9b2b594cecf2ea8b96f75186a040,Smart Health and Wellbeing,"Healthcare informatics has drawn substantial attention in recent years. Current work on healthcare informatics is highly interdisciplinary involving methodologies from computing, engineering, information science, behavior science, management science, social science, as well as many different areas in medicine and public health. Three major tracks, (i) systems, (ii) analytics, and (iii) human factors, can be identified. The systems track focuses on healthcare system architecture, framework, design, engineering, and application; the analytics track emphasizes data/information processing, retrieval, mining, analytics, as well as knowledge discovery; the human factors track targets the understanding of users or context, interface design, and user studies of healthcare applications. In this article, we discuss some of the latest development and introduce several articles selected for this special issue. We envision that the development of computing-oriented healthcare informatics research will continue to grow rapidly. The integration of different disciplines to advance the healthcare and wellbeing of our society will",4
5d0e28c5a5cfe9820802ab6ec3c49f6927555af9,GSDS 2.0: an upgraded gene feature visualization server,"Summary: Visualizing genes’ structure and annotated features helps biologists to investigate their function and evolution intuitively. The Gene Structure Display Server (GSDS) has been widely used by more than 60 000 users since its first publication in 2007. Here, we reported the upgraded GSDS 2.0 with a newly designed interface, supports for more types of annotation features and formats, as well as an integrated visual editor for editing the generated figure. Moreover, a user-specified phylogenetic tree can be added to facilitate further evolutionary analysis. The full source code is also available for downloading. Availability and implementation: Web server and source code are freely available at http://gsds.cbi.pku.edu.cn. Contact: gaog@mail.cbi.pku.edu.cn or gsds@mail.cbi.pku.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.",2
ba46424e0da87f56dbc5838f671bce8824066171,Optimal Coverage Multi-Path Scheduling Scheme with Multiple Mobile Sinks for WSNs,"Wireless Sensor Networks (WSNs) are usually formed with many tiny sensors which are randomly deployed within sensing field for target monitoring. These sensors can transmit their monitored data to the sink in a multi-hop communication manner. However, the ‘hot spots’ problem will be caused since nodes near sink will consume more energy during forwarding. Recently, mobile sink based technology provides an alternative solution for the long-distance communication and sensor nodes only need to use single hop communication to the mobile sink during data transmission. Even though it is difficult to consider many network metrics such as sensor position, residual energy and coverage rate etc., it is still very important to schedule a reasonable moving trajectory for the mobile sink. In this paper, a novel trajectory scheduling method based on coverage rate for multiple mobile sinks (TSCR-M) is presented especially for large-scale WSNs. An improved particle swarm optimization (PSO) combined with",4
de0e0e8972479b07222b9dd978b45a5e64acf99f,Systemic perspectives on scaling agricultural innovations. A review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
21b449c01bdc488f819204869612203c1b368795,Understanding Big Data: Analytics for Enterprise Class Hadoop and Streaming Data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
5770b9257c90a99cb529576b6ceaf16f07730177,Digital image recognition based on Fractional-order-PCA-SVM coupling algorithm,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
bd20055d314fa7ffbee9d702dfd5e4fd99257c62,Measuring Corporate Culture Using Machine Learning,"We create a culture dictionary using one of the latest machine learning techniques—the word embedding model—and 209,480 earnings call transcripts. We score the five corporate cultural values of innovation, integrity, quality, respect, and teamwork for 62,664 firm-year observations over the period 2001–2018. We show that an innovative culture is broader than the usual measures of corporate innovation – R&D expenses and the number of patents. Moreover, we show that corporate culture correlates with business outcomes, including operational efficiency, risk-taking, earnings management, executive compensation design, firm value, and deal making, and that the culture-performance link is more pronounced in bad times. Finally, we present suggestive evidence that corporate culture is shaped by major corporate events, such as mergers and acquisitions.",5
745cd1c084e7d1e100a78f49befae4ede3d5baba,The social brain of language: grounding second language learning in social interaction,"For centuries, adults may have relied on pedagogies that promote rote memory for the learning of foreign languages through word associations and grammar rules. This contrasts sharply with child language learning which unfolds in socially interactive contexts. In this paper, we advocate an approach to study the social brain of language by grounding second language learning in social interaction. Evidence has accumulated from research in child language, education, and cognitive science pointing to the efficacy and significance of social learning. Work from several recent L2 studies also suggests positive brain changes along with enhanced behavioral outcomes as a result of social learning. Here we provide a blueprint for the brain network underlying social L2 learning, enabling the integration of neurocognitive bases with social cognition of second language while combining theories of language and memory with practical implications for the learning and teaching of a new language in adulthood.",4
3abb951003196e5ec2022f03cb8c29e2d1885071,Organization,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
845c58b1790ed36f41eb909608d3d103b3f5fc0a,Towards a big data framework for analyzing social media content,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
7965a3dc43107217eaabca1cbaed1011e0d09312,A Generative Adversarial Network Based Deep Learning Method for Low-Quality Defect Image Reconstruction and Recognition,"In vision-based defect recognition, deep learning (DL) is a research hotspot. However, DL is sensitive to image quality, and it is hard to collect enough high-quality defect images. The low-quality images usually lose some useful information and may mislead the DL methods into poor results. To overcome this problem, this article proposes a generative adversarial network (GAN)-based DL method for low-quality defect image recognition. A GAN is used to reconstruct the low-quality defect images, and a VGG16 network is built to recognize the reconstructed images. The experimental results under low-quality defect images show that the proposed method achieves very good performances, which has accuracies of 95.53–99.62% with different masks and noises, and they are improved greatly compared with the other methods. Furthermore, the results on PSNR, SSIM, cosine, and mutual information indicate that the quality of the reconstructed image is improved greatly, which is very helpful for defect analysis.",9
0a129ac454bb0ee0db54ff84b1b92bf5fd0c902b,NoSQL security: can my data-driven decision-making be affected from outside?,"Nowadays, there are billions interconnected devices forming Cyber-Physical Systems, Internet of Things (IoT) and Industrial Internet of Things (IIoT) ecosystems. With an increasing number of devices and systems in use, amount and the value of data, the risks of security breaches increase. One of these risks is posed by open data sources, by which are meant databases, which are not properly protected. These poorly protected databases are accessible to external actors, which poses a serious risk to the data holder and the results of data-related activities such as analysis, forecasting, monitoring, decision-making, policy development, and the whole contemporary society. This chapter aims at examining the state of the security of open data databases representing both relational databases and NoSQL, with a particular focus on a later category.",5
88658b2f29aa3ee904c4efaf1116f1f00848e995,"Clinical risk prediction with random forests for survival, longitudinal, and multivariate (RF-SLAM) data analysis","Clinical research and medical practice can be advanced through the prediction of an individual’s health state, trajectory, and responses to treatments. However, the majority of current clinical risk prediction models are based on regression approaches or machine learning algorithms that are static, rather than dynamic. To benefit from the increasing emergence of large, heterogeneous data sets, such as electronic health records (EHRs), novel tools to support improved clinical decision making through methods for individual-level risk prediction that can handle multiple variables, their interactions, and time-varying values are necessary. We introduce a novel dynamic approach to clinical risk prediction for survival, longitudinal, and multivariate (SLAM) outcomes, called random forest for SLAM data analysis (RF-SLAM). RF-SLAM is a continuous-time, random forest method for survival analysis that combines the strengths of existing statistical and machine learning methods to produce individualized Bayes estimates of piecewise-constant hazard rates. We also present a method-agnostic approach for",3
fa08b41ccdfc5d8771adfbc34c176fa237d4646c,Is Space-Time Attention All You Need for Video Understanding?,"We present a convolution-free approach to video classification built exclusively on self-attention over space and time. Our method, named""TimeSformer,""adapts the standard Transformer architecture to video by enabling spatiotemporal feature learning directly from a sequence of frame-level patches. Our experimental study compares different self-attention schemes and suggests that""divided attention,""where temporal attention and spatial attention are separately applied within each block, leads to the best video classification accuracy among the design choices considered. Despite the radically new design, TimeSformer achieves state-of-the-art results on several action recognition benchmarks, including the best reported accuracy on Kinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks, our model is faster to train, it can achieve dramatically higher test efficiency (at a small drop in accuracy), and it can also be applied to much longer video clips (over one minute long). Code and models are available at: https://github.com/facebookresearch/TimeSformer.",5
d04c8d846dfee05e310fbe689b2bbdc0b0ab8de3,An intelligent warning model for early prediction of cardiac arrest in sepsis patients,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
bbb9c3119edd9daa414fd8f2df5072587bfa3462,Apache Spark,"This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",8
2e76fa107c50485985487b03a601eb0c11894193,"Big Data: A Revolution That Will Transform How We Live, Work, and Think","Amazon Exclusive: Q&A with Kenneth Cukier and Viktor Mayer-Schonberger Q. What did it take to write Big Data? A. Kenn has written about technology and business from Europe, Asia, and the US for The Economist, and is well-connected to the data community. Viktor had researched the information economy as a professor at Harvard and now at Oxford, and his book Delete had been well received. So we thought we had a good basis to make a contribution in the area. As we wrote the book, we had to dig deep to find unheard stories about big data pioneers and interview them. We wanted Big Data to be about a big idea, but also to be full of examples and success stories -- and be engrossing to read. Q. Are you big datas cheerleaders? A. Absolutely not. We are the messengers of big data, not its evangelists. The big data age",8
a8d9b6acff2b8f2a20b082e08d09a422d59f776e,"Incidence rate and risk factors for suicide death in patients with skin malignant melanoma: a Surveillance, Epidemiology, and End Results analysis","The purpose of this study was to use the Surveillance, Epidemiology, and End Results database to identify the incidence rate and risk factors for suicide death in patients with skin malignant melanoma (MM) in the USA. We screened cases of skin MM in the SEER database. The balance of covariates between the two groups was examined by the χ2-test and Fisher’s exact test. Logistic regression was used to identify independent risk factors for committing suicide. A propensity 1: 2 matched analysis was applied to minimize the risk of bias. In total, 103 500 patients with skin MM were included in the study, of whom 623 had died of suicide. The rate of suicide death did not differ significantly between different time intervals. In logistic regression before propensity score matching, age, being divorced, separated, or widowed, receiving radiation or chemotherapy, and the elapsed time since diagnosis were independently associated with an",2
a45d5bd5b326f21148a6471ae24916b09fbb7d6e,Supply chain resilience in mindful humanitarian aid organizations: the role of big data analytics,"PurposeThe purpose of this paper is to understand the nomological network of associations between collective mindfulness and big data analytics in fostering resilient humanitarian relief supply chains.Design/methodology/approachThe authors conceptualize a research model grounded in literature and test the hypotheses using survey data collected from informants at humanitarian aid organizations in Africa and Europe.FindingsThe findings demonstrate that organizational mindfulness is key to enabling resilient humanitarian relief supply chains, as opposed to just big data analytics.Originality/valueThis is the first study to examine organizational mindfulness and big data analytics in the context of humanitarian relief supply chains.",5
9263499d59fdc184ff097b37d0b00a35927e4632,"A Survey of Fog Computing: Concepts, Applications and Issues","Despite the increasing usage of cloud computing, there are still issues unsolved due to inherent problems of cloud computing such as unreliable latency, lack of mobility support and location-awareness. Fog computing can address those problems by providing elastic resources and services to end users at the edge of network, while cloud computing are more about providing resources distributed in the core network. This survey discusses the definition of fog computing and similar concepts, introduces representative application scenarios, and identifies various aspects of issues we may encounter when designing and implementing fog computing systems. It also highlights some opportunities and challenges, as direction of potential future work, in related techniques that need to be considered in the context of fog computing.",8
7fa072fffaccb9774a51607d21be85500304924b,Smart Secure Sensing for IoT-Based Agriculture: Blockchain Perspective,"Agriculture is a vital area for the sustenance of mankind engulfing manufacturing, security, traceability, and sustainable resource management. With the resources receding expeditiously, it is of utmost significance to innovate techniques that help in the subsistence of agriculture. The growth of Internet of Things (IoT) and Blockchain technology as two rapidly emerging fields can ameliorate the state of food chain today. This paper provides a rigorous literature review to inspect the state-of-the-art development of the schemes that provide information security using blockchain technology. After identifying the core requirements in smart agriculture, a generalized blockchain-based security architecture has been proposed. A detailed cost analysis has been conducted on the studied schemes. A meticulous comparative analysis uncovered the drawbacks in existing research. Furthermore, detailed analysis of the literature has also revealed the security goals towards which the research has been directed and helped to identify new avenues for future research using artificial",5
499f63ec9ffd0e343014dcf93fa0892c07f9d6b3,Big data in the healthcare system: a synergy with artificial intelligence and blockchain technology,"Abstract In the last decades big data has facilitating and improving our daily duties in the medical research and clinical fields; the strategy to get to this point is understanding how to organize and analyze the data in order to accomplish the final goal that is improving healthcare system, in terms of cost and benefits, quality of life and outcome patient. The main objective of this review is to illustrate the state-of-art of big data in healthcare, its features and architecture. We also would like to demonstrate the different application and principal mechanisms of big data in the latest technologies known as blockchain and artificial intelligence, recognizing their benefits and limitations. Perhaps, medical education and digital anatomy are unexplored fields that might be profitable to investigate as we are proposing. The healthcare system can be revolutionized using these different technologies. Thus, we are explaining the basis of these systems focused",4
8ac0d3ecbe24d458cab199e97bbab04340d8951c,An Unequal Deep Learning Approach for 3-D Point Cloud Segmentation,"Object segmentation for 3-D point clouds plays a critical role in autonomous driving, robotic navigation, and other computer version applications. In object segmentation, all points are considered to be equal of importance in the literature. However, unequal cases exist and a segmentation boundary is mainly determined by neighbor points. To investigate point inequivalence, in this article, an unequal learning approach is proposed to integrate gene expression programming (GEP) and a deep neural network (DNN). GEP is designed to discover the inequivalent function, which measures the importance of different points according to the distances to the segmentation boundary. A cost sensitive learning method is improved to guide the DNN to obtain the loss of different points unequally with the discovered inequivalent function during model training. The experimental results reveal that point inequivalence with respect to boundary distance exists and is helpful to improve the accuracy of object segmentation.",9
5a6d393d96d9fc1e4070c374a34cf7eec1366f5f,Twitter Spam Detection: A Systematic Review,"Nowadays, with the rise of Internet access and mobile devices around the globe, more people are using social networks for collaboration and receiving real-time information. Twitter, the microblogging that is becoming a critical source of communication and news propagation, has grabbed the attention of spammers to distract users. So far, researchers have introduced various defense techniques to detect spams and combat spammer activities on Twitter. To overcome this problem, in recent years, many novel techniques have been offered by researchers, which have greatly enhanced the spam detection performance. Therefore, it raises a motivation to conduct a systematic review about different approaches of spam detection on Twitter. This review focuses on comparing the existing research techniques on Twitter spam detection systematically. Literature review analysis reveals that most of the existing methods rely on Machine Learning-based algorithms. Among these Machine Learning algorithms, the major differences are related to various feature selection methods.",5
b0395c89ce6b5837fe45de7da22cf4723c5750ab,Of Visible Race-Consciousness and Institutional Role: Equal Protection and Disparate Impact after Ricci and Inclusive Communities,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
09870e19fef123db71e95fa3b41bc242411c7334,Towards a theory of privacy in the information age,"When we think of ethical problems involving computing probably none is more paradigmatic than the issue of privacy. Given the ability of computers to manipulate information to store endlessly, to sort efficiently, and to locate effortlessly we are justifiably concerned that in a computerized society our privacy may be invaded and that information harmful to us will be revealed. Of course, we are reluctant to give up the advantages of speedy and convenient computerized information. We appreciate the easy access to computerized data when making reservations, using automatic teller machines, buying new products on the web, or investigating topics in computer data bases. Our challenge is to take advantage of computing without allowing computing to take advantage of us. When information is computerized, it is greasedto slide easily and quickly to many ports of call. This makes information retrieval quick and convenient. But legitimate concerns about privacy arise when this",2
021660297056b96ad3182eb0c3da17ebbe1f4c4f,An Oscillatory Neural Autoencoder Based on Frequency Modulation and Multiplexing,"Oscillatory phenomena are ubiquitous in the brain. Although there are oscillator-based models of brain dynamics, their universal computational properties have not been explored much unlike in the case of rate-coded and spiking neuron network models. Use of oscillator-based models is often limited to special phenomena like locomotor rhythms and oscillatory attractor-based memories. If neuronal ensembles are taken to be the basic functional units of brain dynamics, it is desirable to develop oscillator-based models that can explain a wide variety of neural phenomena. Autoencoders are a special type of feed forward networks that have been used for construction of large-scale deep networks. Although autoencoders based on rate-coded and spiking neuron networks have been proposed, there are no autoencoders based on oscillators. We propose here an oscillatory neural network model that performs the function of an autoencoder. The model is a hybrid of rate-coded neurons and neural oscillators. Input signals modulate the",5
c663bbbefed5d9a89ef8d66e56f32576cee37fe6,Neural-Network-Based Models for Short-Term Traffic Flow Forecasting Using a Hybrid Exponential Smoothing and Levenberg–Marquardt Algorithm,"This paper proposes a novel neural network (NN) training method that employs the hybrid exponential smoothing method and the Levenberg-Marquardt (LM) algorithm, which aims to improve the generalization capabilities of previously used methods for training NNs for short-term traffic flow forecasting. The approach uses exponential smoothing to preprocess traffic flow data by removing the lumpiness from collected traffic flow data, before employing a variant of the LM algorithm to train the NN weights of an NN model. This approach aids NN training, as the preprocessed traffic flow data are more smooth and continuous than the original unprocessed traffic flow data. The proposed method was evaluated by forecasting short-term traffic flow conditions on the Mitchell freeway in Western Australia. With regard to the generalization capabilities for short-term traffic flow forecasting, the NN models developed using the proposed approach outperform those that are developed based on the alternative tested algorithms, which are",7
056d86a6599429db18a31ec04d037589295e9028,The 'big data' revolution in healthcare: Accelerating value and innovation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",12
25e41aefac68b248bb781aed7ae9cac6723ee04b,"Publicising Food: Big Data, Precision Agriculture, and Co-Experimental Techniques of Addition","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
e775e649d815a02373eac840cf5e33a04ff85c95,CvT: Introducing Convolutions to Vision Transformers,"We present in this paper a new architecture, named Convolutional vision Transformer (CvT), that improves Vision Transformer (ViT) in performance and efficiency by introducing convolutions into ViT to yield the best of both de-signs. This is accomplished through two primary modifications: a hierarchy of Transformers containing a new convolutional token embedding, and a convolutional Transformer block leveraging a convolutional projection. These changes introduce desirable properties of convolutional neural networks (CNNs) to the ViT architecture (i.e. shift, scale, and distortion invariance) while maintaining the merits of Transformers (i.e. dynamic attention, global context, and better generalization). We validate CvT by conducting extensive experiments, showing that this approach achieves state-of-the-art performance over other Vision Transformers and ResNets on ImageNet-1k, with fewer parameters and lower FLOPs. In addition, performance gains are maintained when pretrained on larger datasets (e.g. ImageNet-22k) and fine-tuned to downstream tasks. Pretrained on ImageNet-22k, our CvT-W24 obtains a top-1 accuracy of",2
fccfa2f62a2d4222d1c6a8458e656609aaa0f5db,A Cooperative Co-Evolutionary Algorithm for Large-Scale Process Planning With Energy Consideration,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
114d9e30d388fa5b74797b864d092a0ee63e5b27,Complex heatmaps reveal patterns and correlations in multidimensional genomic data,"UNLABELLED Parallel heatmaps with carefully designed annotation graphics are powerful for efficient visualization of patterns and relationships among high dimensional genomic data. Here we present the ComplexHeatmap package that provides rich functionalities for customizing heatmaps, arranging multiple parallel heatmaps and including user-defined annotation graphics. We demonstrate the power of ComplexHeatmap to easily reveal patterns and correlations among multiple sources of information with four real-world datasets. AVAILABILITY AND IMPLEMENTATION The ComplexHeatmap package and documentation are freely available from the Bioconductor project: http://www.bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html CONTACT m.schlesner@dkfz.de SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.",3
a44bf845f06f743879d57dcac2271b07ae502af5,A reconstruction error-based framework for label noise detection,"Label noise is an important data quality issue that negatively impacts machine learning algorithms. For example, label noise has been shown to increase the number of instances required to train effective predictive models. It has also been shown to increase model complexity and decrease model interpretability. In addition, label noise can cause the classification results of a learner to be poor. In this paper, we detect label noise with three unsupervised learners, namely principal componentanalysis(PCA)\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\textit{principal component analysis} \hbox { (PCA)}$$\end{document}, independent componentanalysis(ICA)\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\textit{independent component analysis} \hbox { (ICA)}$$\end{document}, and autoencoders. We evaluate these three learners on a credit card fraud dataset using multiple noise levels, and then compare results to the traditional Tomek links noise filter. Our binary classification approach, which considers label noise instances as anomalies, uniquely uses reconstruction errors for noisy",5
09f8d6729197eb93095fc4370fe84ccc534a5a55,Advertising Bans and the Substitutability of Online and Offline Advertising,"The authors examine whether the growth of the Internet has reduced the effectiveness of government regulation of advertising. They combine nonexperimental variation in local regulation of offline alcohol advertising with data from field tests that randomized exposure to online advertising for 275 different online advertising campaigns to 61,580 people. The results show that people are 8% less likely to say that they will purchase an alcoholic beverage in states that have alcohol advertising bans compared with states that do not. For consumers exposed to online advertising, this gap narrows to 3%. There are similar effects for four changes in local offline alcohol advertising restrictions when advertising effectiveness is observed both before and after the change. The effect of online advertising is disproportionately high for new products and for products with low awareness in places that have bans. This suggests that online advertising could reduce the effectiveness of attempts to regulate",4
fdd1ccdea15d3000bcf66a45d64d7a243006b021,A formal definition of Big Data based on its essential features,"Purpose – The purpose of this paper is to identify and describe the most prominent research areas connected with “Big Data” and propose a thorough definition of the term. Design/methodology/approach – The authors have analysed a conspicuous corpus of industry and academia articles linked with Big Data to find commonalities among the topics they treated. The authors have also compiled a survey of existing definitions with a view of generating a more solid one that encompasses most of the work happening in the field. Findings – The main themes of Big Data are: information, technology, methods and impact. The authors propose a new definition for the term that reads as follows: “Big Data is the Information asset characterized by such a High Volume, Velocity and Variety to require specific Technology and Analytical Methods for its transformation into Value.” Practical implications – The formal definition that is proposed can enable a",7
b39ad1ae2cec0ee403f84fa26cfca0a98af9dc5f,FasParser2: a graphical platform for batch manipulation of tremendous amount of sequence data,"Summary FasParser is a graphical platform for manipulating sequences and alignments in a batch mode. It is particularly useful for biologists handling large datasets of sequences, even without an experience in programming. Here, I present an updated version 'FasParser2', featuring numerous improvements with sets of novel functions that can facilitate sequence manipulation. Its main additional features include (i) re-designed graphical interface which greatly improves its capability for batch processing, (ii) a trimming function to strip poorly-aligned regions in multiple sequence alignments, (iii) a series of functions that can identify as well as remove 'bad' sequence (either too short or too divergent sequences), (iv) an Editor tool for viewing and editing of biological sequences and (v) interfaces (with other programs) for detection of positive selection as well as primer design. Availability and implementation The compiled Windows binary is freely available at https://github.com/Sun-Yanbo/FasParser/releases.",8
1828df9ece545999069554ecf0bc77fb87b6c044,Big data-driven scheduling optimization algorithm for Cyber-Physical Systems based on a cloud platform,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
c50c789c77e097754ed41720f9a4c9bb49712758,Exploring the Path to Big Data Analytics Success in Health Care,"Like Oxygen, the world is surrounded by data today. The quantity of data that we harvest and eat up is thriving aggressively in the digitized world. Increasing use of new innovations and social media generate vast amount of data that can earn splendid information if properly analyzed. This large dataset generally known as big data, do not fit in traditional databases because of its rich size. Big Data is a collection of data that is huge in volume, yet growing exponentially with time. It is a data with so large size and complexity that none of traditional data management tools can store it or process it efficiently. Organizations need to manage and analyze big data for better decision making and outcomes. So, big data analytics is receiving a great deal of attention today. In healthcare, big data analytics has the possibility of advanced patient care and clinical decision support. In",5
e50bf4ae589d0afd8ed54ad357c0ace3acb668a6,Promises and Challenges of Big Data Computing in Health Sciences,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
ff2e999357bbcb4e9f27de17697e21e9a9b53597,A New Reinforcement Learning Based Learning Rate Scheduler for Convolutional Neural Network in Fault Classification,"Convolutional neural network (CNN) has gained increasing attention in fault classification. However, the performance of CNN is sensitive to its learning rate. Some previous works have been done to tune the learning rate, including the “trial and error” and manual search, which heavily depend on the experts’ experiences and should be conducted repeatedly on every dataset. Because of the variety of the fault data, it is time-consuming and labor intensive to use these traditional tuning methods for fault classification. To overcome this problem, in this article, we develop a novel learning rate scheduler based on the reinforcement learning (RL) for convolutional neural network (RL-CNN) in fault classification, which can schedule the learning rate efficiently and automatically. First, a new RL agent is designed to learn the policies about the learning rate adjustment during the training process. Second, a new structure of RL-CNN is developed to balance the exploration and exploitation",3
6de08c5762e6d06a7e8ee0c4baa1a0acb505720a,Research on the security technology of big data information,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
e9921aef6670dff6b3e516f4a93fcd0a201cc2a0,Multiscale fast correlation filtering tracking algorithm based on a feature fusion model,"In scenes high in visual complexity, the identification of a moving object can be affected by changes in scale and occlusion factors during the tracking process, resulting in reduced tracking accuracy. Accordingly, to address the problem of low accuracy, a multiscale fast correlation filtering tracking algorithm based on a feature fusion model is proposed in the present work with the aim of reducing the poor tracking effects caused by occlusion discrimination and scale changes in complex scenes. The object's grayscale (GRAY) feature, histogram of oriented gradient (HOG) feature, and color name (CN) feature are reduced to dimensions and fused to form a feature matrix. Moreover, a hierarchical principal component analysis (HPCA) algorithm is used to extract visually salient features and reconstruct the feature matrix under real‐time conditions, the correlation filtering position is trained, the number of dimensions is effectively reduced, and the feature fusion matrix is used to train the",3
fcfa5a4bee9780fd0433b912943db70334ff62d8,Density‐based clustering,"Clustering refers to the task of identifying groups or clusters in a data set. In density‐based clustering, a cluster is a set of data objects spread in the data space over a contiguous region of high density of objects. Density‐based clusters are separated from each other by contiguous regions of low density of objects. Data objects located in low‐density regions are typically considered noise or outliers. In this review article we discuss the statistical notion of density‐based clusters, classic algorithms for deriving a flat partitioning of density‐based clusters, methods for hierarchical density‐based clustering, and methods for semi‐supervised clustering. We conclude with some open challenges related to density‐based clustering.",5
6def0370e9733d233991d862483249e556501972,Microstructure in the Machine Age,"Understanding modern market microstructure phenomena requires large amounts of data and advanced mathematical tools. We demonstrate how machine learning can be applied to microstructural research. We find that microstructure measures continue to provide insights into the price process in current complex markets. Some microstructure features with high explanatory power exhibit low predictive power, while others with less explanatory power have more predictive power. We find that some microstructure-based measures are useful for out-of-sample prediction of various market statistics, leading to questions about market efficiency. We also show how microstructure measures can have important cross-asset effects. Our results are derived using 87 liquid futures contracts across all asset classes.",6
056368339abb62cd57a284a08a0e366c96e903e2,Apache Spark: A Big Data Processing Engine,"Big data analysis has influenced the industry market. It has a significant impact on large and varied datasets to exhibit the hidden patterns and other revelations. Apache Hadoop, Apache Flink and Apache Storm are some commonly used frameworks for big data analysis. Apache Spark is a consolidated big data analytics engine and provides absolute data parallelism. This paper scrutinizes a technical review on big data analytics using Apache Spark and how it uses in-memory computation that makes it remarkably faster as compared to other corresponding frameworks. Moreover, Spark also provides exceptional batch processing and stream processing capabilities. Furthermore, it also discuses over the multithreading and concurrency capabilities of Apache Spark. The point of convergence is architecture, hardware requirements, ecosystem, use cases, features of Apache Spark and the use of Spark in emerging technologies.",5
61cfcdf15ff3f7d888381df69d789e7dbe09052a,Big data analytics as a tool for fighting pandemics: a systematic review of literature,"Infectious and contagious diseases represent a major challenge for health systems worldwide, either in private or public sectors. More recently, with the increase in cases related to these problems, combined with the recent global pandemic of COVID-19, the need to study strategies to treat these health disturbs is even more latent. Big Data, as well as Big Data Analytics techniques, have been addressed in this context with the possibility of predicting, mapping, tracking, monitoring, and raising awareness about these epidemics and pandemics. Thus, the purpose of this study is to identify how BDA can help in cases of pandemics and epidemics. To achieve this purpose, a systematic review of literature was carried out using the methodology Methodi Ordinatio. The rigorous search resulted in a portfolio of 45 articles, retrived from scientific databases. For the collection and analysis of data, the softwares NVivo 12 and VOSviewer were used. The content analysis",4
3e63cc625b886f198dc17f5fbf353153b65d354e,Multivariate Prediction of Coronary Heart Disease in the Western Collaborative Group Study Compared to the Findings of the Framingham Study,"The Western Collaborative Group Study (WCGS) is a prospective epidemiological study of 3,154 initially well men, aged 39–59 years at intake in 1960–61, who were employed in ten participating companies in California. Clinical coronary heart disease (CHD) occurred in 257 men during a follow-up period of eight and one-half years. Coronary heart disease risk is predicted using the additive multiple logistic model with the risk factors: age, cholesterol, systolic blood pressure, hematocrit, ECG status, smoking at intake, and relative body weight. The predicted individual CHD risk levels, using the logistic results derived from the WCGS data, are highly correlated with predicted risk levels using a Framingham study (FS) equation for these same risk factors with 12-year follow-up. The observed number of CHD events in the WCGS is not significantly different from the expected number of events derived from the FS logistic equation, after correction for length of follow-up.Multiple logistic analysis",2
b9e1fed59fffb9f93921fedced533b4242b43f3a,Using Multi-inception CNN for Face Emotion Recognition,"One integral and necessary part of human behavior is emotion, which affects the way people communicate. Although human beings can recognize and interpret facial expressions, the identification of correct facial expressions continues to be a key and challenging task by computer systems. The main issues stem from the face's non-uniform design and variations in conditions such as light, facial structure, and posture. Several Convolutional Neural Network (CNN) approaches have been introduced for Face Emotion Recognition (FER), but these methods cannot completely reflect temporal variations in facial characteristics. In this study, we use the CMU face data collection of four types of emotions to provide a method for the identification of facial emotions. Four classes of distinguished emotions are happy, sad, angry, and neutral. Pixel values are fed into a Neural Network with different architecture, and the accuracy of those methods has been compared. Restricted Boltzmann machine (RBM), Deep Belief Networks",5
9d1110162ab66dbea0c839fe7798171469501c21,Big Data Analytics: Turning Big Data into Big Money,"Unique insights to implement big data analytics and reap big returns to your bottom lineFocusing on the business and financial value of big data analytics, respected technology journalist Frank J. Ohlhorst shares his insights on the newly emerging field of big data analytics in Big Data Analytics. This breakthrough book demonstrates the importance of analytics, defines the processes, highlights the tangible and intangible values and discusses how you can turn a business liability into actionable material that can be used to redefine markets, improve profits and identify new business opportunities. Reveals big data analytics as the next wave for businesses looking for competitive advantageTakes an in-depth look at the financial value of big data analyticsOffers tools and best practices for working with big dataOnce the domain of large on-line retailers such as eBay and Amazon, big data is now accessible by businesses of all sizes and across industries. From how",5
230776e4c20c0d70998289923565bc928da32125,Depression and anorexia detection in social media as a one-class classification problem,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
e53fde0e51b578767e6f4876ef7f09633fba7e7a,Who says what to whom on twitter,"We study several longstanding questions in media communications research, in the context of the microblogging service Twitter, regarding the production, flow, and consumption of information. To do so, we exploit a recently introduced feature of Twitter known as ""lists"" to distinguish between elite users - by which we mean celebrities, bloggers, and representatives of media outlets and other formal organizations - and ordinary users. Based on this classification, we find a striking concentration of attention on Twitter, in that roughly 50% of URLs consumed are generated by just 20K elite users, where the media produces the most information, but celebrities are the most followed. We also find significant homophily within categories: celebrities listen to celebrities, while bloggers listen to bloggers etc; however, bloggers in general rebroadcast more information than the other categories. Next we re-examine the classical ""two-step flow"" theory of communications, finding considerable support for it on Twitter. Third,",4
27b42af5c3684ecd30125ff61dc2eb600f8cba68,"Integrating blockchain and the internet of things in precision agriculture: Analysis, opportunities, and challenges","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
555c0d308a1c9faa089430133566bf0dd6e4613d,The Synthesizability of Molecules Proposed by Generative Models,"The discovery of functional molecules is an expensive and time-consuming process, exemplified by the rising costs of small molecule therapeutic discovery. One class of techniques of growing interest for early-stage drug discovery is de novo molecular generation and optimization, catalyzed by the development of new deep learning approaches. These techniques can suggest novel molecular structures intended to maximize a multi-objective function, e.g., suitability as a therapeutic against a particular target, without relying on brute-force exploration of a chemical space. However, the utility of these approaches is stymied by ignorance of synthesizability. To highlight the severity of this issue, we use a data-driven computer-aided synthesis planning program to quantify how often molecules proposed by state-of-the-art generative models cannot be readily synthesized. Our analysis demonstrates that there are several tasks for which these models generate unrealistic molecular structures despite performing well on popular quantitative benchmarks. Synthetic complexity heuristics can successfully bias generation",5
cdcf7cb29f37ac0546961ea8a076075b9cc1f992,Mining and summarizing customer reviews,"Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product. It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions. For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products. In this research, we aim to mine and to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we",6
d5adb6df5a7200d354bb0c3c12d4d27021eb9c4c,Heatmapper: web-enabled heat mapping for all,"Heatmapper is a freely available web server that allows users to interactively visualize their data in the form of heat maps through an easy-to-use graphical interface. Unlike existing non-commercial heat map packages, which either lack graphical interfaces or are specialized for only one or two kinds of heat maps, Heatmapper is a versatile tool that allows users to easily create a wide variety of heat maps for many different data types and applications. More specifically, Heatmapper allows users to generate, cluster and visualize: (i) expression-based heat maps from transcriptomic, proteomic and metabolomic experiments; (ii) pairwise distance maps; (iii) correlation maps; (iv) image overlay heat maps; (v) latitude and longitude heat maps and (vi) geopolitical (choropleth) heat maps. Heatmapper offers a number of simple and intuitive customization options for facile adjustments to each heat map's appearance and plotting parameters. Heatmapper also allows users to interactively explore their numeric data values by",3
deab2bb68cea5ca00ce65996313c96c30dd00ecb,Incorporating User Feedback Into One-Class Support Vector Machines for Anomaly Detection,"Machine learning and data-driven algorithms have gained a growth of interest during the past decades due to the computation capability of the computers which has increased and the quantity of data available in various domains. One possible application of machine learning is to perform unsupervised anomaly detection. Indeed, among all available data, the anomalies are supposed to be very sparse and the expert might not have the time to label all the data as nominal or not. Many solutions exist to this unsupervised problem, but are known to provide many false alarms, because some scarce nominal modes might not be included in the training dataset and thus will be detected as anomalies. To tackle this issue, we propose to present an existing iterative algorithm, which presents potential anomaly to the expert at each iteration, and compute a new boundary according to this feedback using One Class Support Vector Machine.",3
ef706e908d4fd07f3b02b68de67d058a802879ce,Dark Web: Exploring and Mining the Dark Side of the Web,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
37b71e6a43e65a9f2c9701e5079d6ad81186fd6a,Elicitation of Candidate Subspaces in High-Dimensional Data,"Anomaly detection is an important research area in data mining and has been studied intensively in recent years. The increasing number of features, non-informative noises and other irrelevant features, makes it challenging to detect anomalies in high-dimensional data. When analyzing high-dimensional data, anomalies are difficult to identify due to the sparsity caused by the curse of dimensionality. One most commonly used algorithm for reducing dimensionality is Principal Component Analysis (PCA), however, it is known to be sensitive in identifying anomalies. Furthermore, anomalies are rare and only can be found in low-dimensional subspaces. To effectively find anomalies in the high-dimensional space, we propose a technique that explores locally relevant and low-dimensional subspaces where anomalies may be possibly hidden due to the sparsity caused by the curse of dimensionality, and we call these subspaces as candidate subspaces for anomalies. In particular, the proposed technique integrates a Pearson Correlation Coefficient (PCC) and PCA,",5
4192f39023f0bf9e95053f36fe10c176b08a2bd3,Parallelization with Multiplicative Algorithms for Big Data Mining,"We propose a nontrivial strategy to parallelize a series of data mining and machine learning problems, including 1-class and 2-class support vector machines, nonnegative least square problems, and $\ell_1$ regularized regression (LASSO) problems. Our strategy fortunately leads to extremely simple multiplicative algorithms which can be straightforwardly implemented in parallel computational environments, such as Map Reduce, or CUDA. We provide rigorous analysis of the correctness and convergence of the algorithm. We demonstrate the scalability and accuracy of our algorithms in comparison with other current leading algorithms.",6
de27acae4e0cfa4833f71024c265cdfb49fbd80b,Puzzling out big data,"Big data comes in many forms. It comes as customer information and transactions contained in customer-relationship management and enterprise resourceplanning systems and HTML-based web stores. It comes as information generated by machine-to-machine applications collecting data from smart meters, manufacturing sensors, equipment logs, trading systems data and call detail records compiled by fixed and mobile telecommunications companies. Big data can come with big differences. Some say that the 'three Vs' of big data should more properly be tagged as the 'three HVs': high-volume, high-variety, high-velocity, and high-veracity. Apply those tags to the mountains of information posted on social network and blogging sites, including Facebook, Twitter and VouTube; the deluge of text contained in email and instant messages; not to mention audio and video files. It is evident then that it's not necessarily the 'big-ness' of information that presents big-data applications and services with their greatest challenge, but the variety and the",4
8e641ea510c06485f33a61ea65555cf791efad2d,Big data and its technical challenges,Exploring the inherent technical challenges in realizing the potential of Big Data.,10
2a59ed5750d4d6ed4f6be74c2757f988ef62a57e,One-Class Classification Based Bug Triage System to Assign a Newly Added Developer,"Bug triage is a software engineering problem in which a developer is assigned to a bug report. The existing methods use social network analysis, topic modeling, mining repositories, machine learning, and deep learning. Deep learning methods have shown promising results. However, these methods can not assign a newly added developer to the bug report. In this paper, we proposed a one-class SVM based method that trains a separate classifier for each developer. If a new developer is added to the project, then he or she can be considered by the triage system by training a classifier on his history. The results show an acceptable accuracy score. We believe that our preliminary study can pave the way to address this challenging problem.",3
6f4da3638ac9a87502c7a43dffc7be1bd8252a99,"Big data analytics meets social media: A systematic review of techniques, open issues, and future directions","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",11
f1a45c16fc1e3e36884646d1b50239fcedacdb7d,"Health effects of dietary risks in 195 countries, 1990–2017: a systematic analysis for the Global Burden of Disease Study 2017","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
08a327c9691e866759abee2333ba0ef7fa8257b6,Green innovation and organizational performance: The influence of big data and the moderating role of management commitment and HR practices,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
43366ceccb11d03f3e413ba4b0f49808fce7f582,Is the Road to Disparate Impact Paved With Good Intentions? -- Stuck on State of Mind in Antidiscrimination Law,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
abd1c342495432171beb7ca8fd9551ef13cbd0ff,ImageNet classification with deep convolutional neural networks,"We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called ""dropout"" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved",130
4556f3f9463166aa3e27b2bec798c0ca7316bd65,Three naive Bayes approaches for discrimination-free classification,"In this paper, we investigate how to modify the naive Bayes classifier in order to perform classification that is restricted to be independent with respect to a given sensitive attribute. Such independency restrictions occur naturally when the decision process leading to the labels in the data-set was biased; e.g., due to gender or racial discrimination. This setting is motivated by many cases in which there exist laws that disallow a decision that is partly based on discrimination. Naive application of machine learning techniques would result in huge fines for companies. We present three approaches for making the naive Bayes classifier discrimination-free: (i) modifying the probability of the decision being positive, (ii) training one model for every sensitive attribute value and balancing them, and (iii) adding a latent variable to the Bayesian model that represents the unbiased label and optimizing the model parameters for likelihood using expectation maximization. We present experiments",6
4f55d6d95090c46b65d40ca3ea027d6113a381d6,SeqKit: A Cross-Platform and Ultrafast Toolkit for FASTA/Q File Manipulation,"FASTA and FASTQ are basic and ubiquitous formats for storing nucleotide and protein sequences. Common manipulations of FASTA/Q file include converting, searching, filtering, deduplication, splitting, shuffling, and sampling. Existing tools only implement some of these manipulations, and not particularly efficiently, and some are only available for certain operating systems. Furthermore, the complicated installation process of required packages and running environments can render these programs less user friendly. This paper describes a cross-platform ultrafast comprehensive toolkit for FASTA/Q processing. SeqKit provides executable binary files for all major operating systems, including Windows, Linux, and Mac OSX, and can be directly used without any dependencies or pre-configurations. SeqKit demonstrates competitive performance in execution time and memory usage compared to similar tools. The efficiency and usability of SeqKit enable researchers to rapidly accomplish common FASTA/Q file manipulations. SeqKit is open source and available on Github at https://github.com/shenwei356/seqkit.",3
890800c3d6ebbb24c975caa7bb1b7ecc767c29aa,Risks associated with the implementation of big data analytics in sustainable supply chains,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
d382d7440042bf159509101b2b618842ffc29f9b,Big Data and its Analyzing Tools : A Perspective,"Data are generated and stored in databases at a very high speed and hence it need to be handled and analyzed properly. Nowadays industries are extensively using Hadoop and Spark to analyze the datasets. Both the frameworks are used for increasing processing speeds in computing huge complex datasets. Many researchers are comparing both of them. Now, the big questions arising are, Is Spark a substitute for Hadoop? Is hadoop going to be replaced by spark in mere future?. Spark is “built on top of” Hadoop and it extends the model to deploy more types of computations which incorporates Stream Processing and Interactive Queries. No doubt, Spark's execution speed is much faster than Hadoop, but talking in terms of fault tolerance, hadoop is slightly more fault tolerant than spark. In this article comparison of various bigdata analytics tools are done and Hadoop and Spark are discussed in detail. This article further",7
10af176ace0a857f35bbc05a9a7270d29c5e9eba,UniRule: A semi-automated rule-based system for the functional annotation of proteins,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
5653cecd3af3c70c3dbcc18af58d597b466d2bb1,New IT Driven Service-Oriented Smart Manufacturing: Framework and Characteristics,"Recently, along with the wide application of new generation information technologies (New IT) in manufacturing, many countries issued their national advanced manufacturing development strategies, such as Industrial Internet, Industry 4.0, and Made in China 2025. One common aim of these strategies is to achieve smart manufacturing, which demands the interoperation, integration, and fusion of the physical world and the cyber world of manufacturing. As well, New IT [such as Internet of Things (IoT), cloud computing, big data, mobile Internet, and cyber-physical systems (CPS)] have played pivotal roles in promoting smart manufacturing. Data generated in the physical world can be sensed and transfered to the cyber world through IoT and the Internet, and be processed and analyzed by cloud computing, big data technologies to adjust the physical world. The physical world and the cyber world of manufacturing are integrated based on CPS. On the other hand, servitization has become a prominent",4
8d2770033ebf982e6aa9b3b7e2fd3f98cfdffcba,Indoor tanning and skin cancer in Canada: A meta-analysis and attributable burden estimation.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
6213914e6340b33f90c395111b187cc93c3e3726,Restoring cortical control of functional movement in a human with quadriplegia,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
b91334db900b1c066ed5c811c9e5eea57a7e7b08,Efficient kNN classification algorithm for big data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
c09e8ff287fdf58afc5ac691c512a1b33dd799f9,Providence,"Artificial intelligence provides the opportunity to reveal important information buried in large amounts of complex data. Electronic health records (eHRs) are a source of such big data that provide a multitude of health related clinical information about patients. However, text data from eHRs, e.g., discharge summary notes, are challenging in their analysis because these notes are free-form texts and the writing formats and styles vary considerably between different records. For this reason, in this paper we study deep learning neural networks in combination with natural language processing to analyze text data from clinical discharge summaries. We provide a detail analysis of patient phenotyping, i.e., the automatic prediction of ten patient disorders, by investigating the influence of network architectures, sample sizes and information content of tokens. Importantly, for patients suffering from Chronic Pain, the disorder that is the most difficult one to classify, we find the largest performance gain for a",5
d6625fe9c842cb2ae71078c0cd26ae04061b2d64,Institutional Order Handling and Broker-Affiliated Trading Venues,"Using detailed order handling data, we find that institutional brokers who route more orders to affiliated alternative trading systems (ATSs) are associated with lower execution quality (i.e., lower fill rates and higher implementation shortfall costs). To separate clients’ preference for ATSs from brokers’ routing decisions, we confirm these results for orders where brokers have more order handling discretion, matched broker analysis that accounts for ATS usage, matched child orders that account for client intent, and based on an exogenous constraint on ATS venue choice. Our results suggest that increased transparency of order routing practices will improve execution quality.",3
54e6f9d23f16dadde1761bedcda13ca84072c04d,Obfuscation: A User's Guide for Privacy and Protest,"With Obfuscation, Finn Brunton and Helen Nissenbaum mean to start a revolution. They are calling us not to the barricades but to our computers, offering us ways to fight today's pervasive digital surveillance -- the collection of our data by governments, corporations, advertisers, and hackers. To the toolkit of privacy protecting techniques and projects, they propose adding obfuscation: the deliberate use of ambiguous, confusing, or misleading information to interfere with surveillance and data collection projects. Brunton and Nissenbaum provide tools and a rationale for evasion, noncompliance, refusal, even sabotage -- especially for average users, those of us not in a position to opt out or exert control over data about ourselves. Obfuscation will teach users to push back, software developers to keep their user data safe, and policy makers to gather data without misusing it. Brunton and Nissenbaum present a guide to the forms and formats that obfuscation has taken",1
7aa5c0ff59030a69a3db02d37750d6cd508e76ac,WIRED for Innovation: How Information Technology is Reshaping the Economy,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
98ab5cc2d8af0ddb122198acbfe50aff8a23059b,Apache Spark,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
3965a03ea866423ae5a6a043f888c916cc73ade0,A quantitative and text-based characterization of big data research,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
180e12d23e0f8e7007bca07be469fcd9522a7a8f,"Is ""Big Data"" creepy?","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
8d1031fbad647c0a69762ee524f23fe978bbaed9,Information Blocking: Is It Occurring and What Policy Strategies Can Address It?,"Policy Points: Congress has expressed concern about electronic health record (EHR) vendors and health care providers knowingly interfering with the electronic exchange of patient health information. These “information blocking” practices would privately benefit vendors and providers but limit the societal quality and efficiency benefits from EHR adoption. We found that information blocking is reported to frequently occur among EHR vendors as well as hospitals and health systems, and that it is perceived to be motivated by opportunities for revenue gain. Because information blocking is largely legal today, the most effective policy response likely involves a combination of direct enforcement and the altering of market conditions that promote information blocking. Context Congress has raised concerns about providers and electronic health record (EHR) vendors knowingly engaging in business practices that interfere with electronic health information exchange (HIE). Such “information blocking” is presumed to occur because providers and vendors reap financial benefits, but",1
9fe91ae98e6119dd6e0efad3c5b5f2f654bf0107,Privacy-Preserving Public Auditing for Secure Cloud Storage,"Using cloud storage, users can remotely store their data and enjoy the on-demand high-quality applications and services from a shared pool of configurable computing resources, without the burden of local data storage and maintenance. However, the fact that users no longer have physical possession of the outsourced data makes the data integrity protection in cloud computing a formidable task, especially for users with constrained computing resources. Moreover, users should be able to just use the cloud storage as if it is local, without worrying about the need to verify its integrity. Thus, enabling public auditability for cloud storage is of critical importance so that users can resort to a third-party auditor (TPA) to check the integrity of outsourced data and be worry free. To securely introduce an effective TPA, the auditing process should bring in no new vulnerabilities toward user data privacy, and introduce no additional online burden to user.",5
109f6c2ea18058cca7b9cc734b30dea6dd64cac0,Supervised Weighting-Online Learning Algorithm for Short-Term Traffic Flow Prediction,"Prediction of short-term traffic flow has become one of the major research fields in intelligent transportation systems. Accurately estimated traffic flow forecasts are important for operating effective and proactive traffic management systems in the context of dynamic traffic assignment. For predicting short-term traffic flows, recent traffic information is clearly a more significant indicator of the near-future traffic flow. In other words, the relative significance depending on the time difference between traffic flow data should be considered. Although there have been several research works for short-term traffic flow predictions, they are offline methods. This paper presents a novel prediction model, called online learning weighted support-vector regression (OLWSVR), for short-term traffic flow predictions. The OLWSVR model is compared with several well-known prediction models, including artificial neural network models, locally weighted regression, conventional support-vector regression, and online learning support-vector regression. The results show that the performance of the proposed model is superior to",8
28f09e7b8d6d9acac916773a7d1443ad92e00ba4,Meta-Transfer Learning for Code-Switched Speech Recognition,"An increasing number of people in the world today speak a mixed-language as a result of being multilingual. However, building a speech recognition system for code-switching remains difficult due to the availability of limited resources and the expense and significant effort required to collect mixed-language data. We therefore propose a new learning method, meta-transfer learning, to transfer learn on a code-switched speech recognition system in a low-resource setting by judiciously extracting information from high-resource monolingual datasets. Our model learns to recognize individual languages, and transfer them so as to better recognize mixed-language speech by conditioning the optimization on the code-switching data. Based on experimental results, our model outperforms existing baselines on speech recognition and language modeling tasks, and is faster to converge.",5
dba235fb6f66500bec0c2142f112edbba9fbe9f8,Big data platforms: in the lens of selection and evaluation approach,"ABSTRACT The manifestation of big data has brought about firms’ intense desires for analytical value creation besides crucial challenges to handle data processing. Unlocking the potentials of big data analytics depends on devising and setting up platforms through the big data value chain. Achieving these appropriate platforms is indispensable and necessitates a selection and evaluation method. To that end, in this research, a new fuzzy superiority and inferiority ranking approach for selecting and evaluating big data platforms has been investigated; and introduced. In the proposed approach, both functional and non-functional criteria for the big data platform were gathered and customized. For demonstrating the applicability of the method, a numerical example provided; and the suggested approach was used in a company case that had been encountered with this platform acquisition problem. Simplifying assessment and selection of the big data platform, and feasible procedure are the main values of the offered approach.",3
547df0f649d5b8fcb64ac06611e5bbe7b14518f7,Challenges of Big Data Analysis.,"Big Data bring new opportunities to modern society and challenges to data scientists. On one hand, Big Data hold great promises for discovering subtle population patterns and heterogeneities that are not possible with small-scale data. On the other hand, the massive sample size and high dimensionality of Big Data introduce unique computational and statistical challenges, including scalability and storage bottleneck, noise accumulation, spurious correlation, incidental endogeneity, and measurement errors. These challenges are distinguished and require new computational and statistical paradigm. This article gives overviews on the salient features of Big Data and how these features impact on paradigm change on statistical and computational methods as well as computing architectures. We also provide various new perspectives on the Big Data analysis and computation. In particular, we emphasize on the viability of the sparsest solution in high-confidence set and point out that exogeneous assumptions in most statistical methods for Big Data can",9
b6988c2580c8e6a445b560c489d7b07bf992a66b,Big Data Pre-Processing: Closing the Data Quality Enforcement Loop,"In the Big Data Era, data is the core for any governmental, institutional, and private organization. Efforts were geared towards extracting highly valuable insights that cannot happen if data is of poor quality. Therefore, data quality (DQ) is considered as a key element in Big data processing phase. In this stage, low quality data is not penetrated to the Big Data value chain. This paper, addresses the data quality rules discovery (DQR) after the evaluation of quality and prior to Big Data pre-processing. We propose a DQR discovery model to enhance and accurately target the pre-processing activities based on quality requirements. We defined, a set of pre-processing activities associated with data quality dimensions (DQD's) to automatize the DQR generation process. Rules optimization are applied on validated rules to avoid multi-passes pre-processing activities and eliminates duplicate rules. Conducted experiments showed an increased quality scores after applying the discovered and optimized DQR's",6
b7b915d508987b73b61eccd2b237e7ed099a2d29,Maxout Networks,"We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.",15
04db5a786dc27e1d80c41f55b32e76083da910ae,Load balancing mechanisms in fog computing: A systematic review,"Recently, fog computing has been introduced as a modern distributed paradigm and complement to cloud computing to provide services. Fog system extends storing and computing to the edge of the network, which can solve the problem about service computing of the delay-sensitive applications remarkably besides enabling the location awareness and mobility support. Load balancing is an important aspect of fog networks that avoids a situation with some under-loaded or overloaded fog nodes. Quality of Service (QoS) parameters such as resource utilization, throughput, cost, response time, performance, and energy consumption can be improved with load balancing. In recent years, some researches in load balancing techniques in fog networks have been carried out, but there is no systematic review to consolidate these studies. This article reviews the load-balancing mechanisms systematically in fog computing in four classifications, including approximate, exact, fundamental, and hybrid methods (published between 2013 and August 2020). Also, this article",5
9eb24c4543826539412e9d2a90399cc2a888b553,"Healthcare Analysis in Smart Big Data Analytics: Reviews, Challenges and Recommendations","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
fae92216e02f9985aa235ebe51ec1cb00b578a6e,"Big Data in Neonatal Health Care: Big Reach, Big Reward?","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
c8487e05c5a8a4099f814420df5b41eccc60275e,Saving Disparate Impact,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
9d7b65e15382e009a9be8297a628737a66327ea1,Secure online payment through facial recognition and proxy detection with the help of TripleDES encryption,"Abstract Nowadays, there is a tremendous increase in the use of online secure payment systems. Even roadside shops all over India and other countries have access to online payment which made each and every person to go cash-free. But there is one important issue we need to consider which is the security during online transactions. There are several new techniques that are being developed nowadays but each has its own pros and cons. In order to enhance the security during online transaction, we have introduced a two-way authentication system which increases the security during online transaction. This system includes facial and proxy detection before entering the UPI pin. The algorithm used in this paper, will further improve the security and efficiency of facial recognition since it embeds 128 feature points of the user’s face thereby increasing the accuracy of the system. While the data is being transmitted for verification, we",6
804b7301d0b6837a8eff365b6ea1ee070820aab3,Broken Promises of Privacy: Responding to the Surprising Failure of Anonymization,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
aba0082174688e93ea8548575abfa4fd60d6aab5,Big Data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
61e5b76518397d6251ad31b977de045ef1b8fb6a,Towards Understanding Transfer Learning Algorithms Using Meta Transfer Features,"Transfer learning, which aims to reuse knowledge in different domains, has achieved great success in many scenarios via minimizing domain discrepancy and enhancing feature discriminability. However, there are seldom practical determination methods for measuring the transferability among domains. In this paper, we bring forward a novel meta-transfer feature method (MetaTrans) for this problem. MetaTrans is used to train a model to predict performance improvement ratio from historical transfer learning experiences, and can consider both the Transferability between tasks and the Discriminability emphasized on targets. We apply this method to both shallow and deep transfer learning algorithms, providing a detail explanation for the success of specific transfer learning algorithms. From experimental studies, we find that different transfer learning algorithms have varying dominant factor deciding their success, so we propose a multi-task learning framework which can learn both common and specific experience from historical transfer learning results. The empirical investigations reveal that",5
9bc9f67ed2093e6ee134ac3629cca741276b61ce,The impact of supply chain analytics on operational performance: a resource-based view,"This study seeks to better understand the role of supply chain analytics (SCA) on supply chain planning satisfaction and operational performance. We define the architecture of SCA as the integration of three sets of resources, data management resources (DMR), IT-enabled planning resources and performance management resources (PMR), from the perspective of a resource-based view. Based on the data collected from 537 manufacturing plants, we test hypotheses exploring the relationships among these resources, supply chain planning satisfaction, and operational performance. Our analysis supports that DMR should be considered a key building block of manufacturers’ business analytics initiatives for supply chains. The value of data is transmitted to outcome values through increasing supply chain planning and performance capabilities. Additionally, the deployment of advanced IT-enabled planning resources occurs after acquisition of DMR. Manufacturers with sophisticated planning technologies are likely to take advantage of data-driven processes and quality control practices. DMR are found to",6
2984ab83ade26639c3a82d29628d0d9e4abbebb0,Incorporating Convolution Designs into Visual Transformers,"Motivated by the success of Transformers in natural language processing (NLP) tasks, there emerge some attempts (e.g., ViT and DeiT) to apply Transformers to the vision domain. However, pure Transformer architectures often require a large amount of training data or extra supervision to obtain comparable performance with convolutional neural networks (CNNs). To overcome these limitations, we analyze the potential drawbacks when directly borrowing Transformer architectures from NLP. Then we propose a new Convolution-enhanced image Transformer (CeiT) which combines the advantages of CNNs in extracting low-level features, strengthening locality, and the advantages of Transformers in establishing long-range dependencies. Three modifications are made to the original Transformer: 1) instead of the straightforward tokenization from raw input images, we design an Image-to-Tokens (I2T) module that extracts patches from generated low-level features; 2) the feed-froward network in each encoder block is replaced with a Locally-enhanced Feed-Forward (LeFF) layer that promotes the correlation among neighboring",2
2f7ceb6dc9d8405151e55691e043619cbbe2886c,Big Data’s End Run around Anonymity and Consent,"Introduction Big data promises to deliver analytic insights that will add to the stock of scientific and social scientific knowledge, significantly improve decision making in both the public and private sector, and greatly enhance individual self-knowledge and understanding. They have already led to entirely new classes of goods and services, many of which have been embraced enthusiastically by institutions and individuals alike. And yet, where these data commit to record details about human behavior, they have been perceived as a threat to fundamental values, including everything from autonomy, to fairness, justice, due process, property, solidarity, and, perhaps most of all, privacy. Given this apparent conflict, some have taken to calling for outright prohibitions on various big data practices, while others have found good reason to finally throw caution (and privacy) to the wind in the belief that big data will more than compensate for its potential costs. Still others, of",6
6baa279953fa1c34826ed7f2d67ba5a7c611fc0b,Complexity and Algorithms for Superposed Data Uploading Problem in Networks With Smart Devices,"As a successful application of edge computing in the industrial production environment, prolonging the smart devices’ (SDs’) battery lifetime has become an important issue. In some special practical applications, the uploaded data from SDs to vehicle base stations (VBSs) or servers can be merged between SDs with a fixed size, which is called superposed data. In this article, we consider the superposed data uploading problem in a decentralized device-to-device communication system. The task of the problem is to minimize the total energy consumption of uploading data. We reduce it into a combinatorial optimization problem from the graph theory perspective. For VBSs or servers with infinite capacities, we propose an optimal algorithm with polynomial running time. When VBSs or servers have limited capacities, the problem is NP-hard even in very special cases. For this NP-hard problem, we give two heuristic algorithms and the corresponding numerical simulation results.",1
32a6b93248fb72fd791f934a029ac8426fbdd516,Research on Defensive Strategy of Real-Time Price Attack Based on Multiperson Zero-Determinant,"The smart grid solves the growing load demand of electrical customers through two-way real-time communication of electricity supply and demand sides and home energy management system (HEMS). However, these technical features also bring network security risks to the real-time price signal of the smart grid. The real-time price attack (RTPA) can maliciously raise the real-time price in smart meter, resulting in an increase in electrical customers load demand, causing the extensive damage to the power transmission lines due to overload. In this paper, we based on the behavioral relationship between load demand of electrical customers and real-time price of electricity suppliers (ES), defined the game relationship between RTPA, ES, and electrical customers, established a price elasticity of electricity demand (PEED) model, and proposed a defensive strategy of real-time price attack based on multiperson zero-determinant strategy (MPZDS). The experimental results show that the combination of MPZDS to some extent cut the",3
f8e2cd820ce83be745b764c66557ae6a986a2bcc,Intelligent workflow scheduling for Big Data applications in IoT cloud computing environments,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
df41eeb72d797ce3abdf30bed09a3a0b432bacb2,What we talk about when we talk about (big) data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
a462dfbc2e4583479080741ec9e4c71396d04394,Computational Intelligence in Power Engineering,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
8251a58c62dcdbc5f2e4aa9d9944638c21be0020,"HortiCube: A Platform for Transparent, Trusted Data Sharing in the Food Supply Chain","Food supply chains consist of many links and operate on a global scale with many stakeholders involved from farm to fork. Each stakeholder maintains data about food products that they handle, but this data is not transparently available to all other stakeholders in the chain due to various reasons. Trust and reciprocity for data sharing is limited and there is insufficient clarity in data ownership and possible legal consequences. However, various stakeholders could benefit from making data available across the supply chain. Food producers are very interested in consumer demands and trends. Growers also want to guide their supply based on the potential demand for specific food products in the near future. In addition, there are various other data sources that contain interesting data for these same stakeholders, such as import/export transactions, production (forecast) data, parcel crop information, local weather predictions and social media streams. To make all stakeholders in",5
6b88333518c780a60a39732b1f020cb1cbd09260,Prediction Policy Problems.,"Most empirical policy work focuses on causal inference. We argue an important class of policy problems does not require causal inference but instead requires predictive inference. Solving these ""prediction policy problems"" requires more than simple regression techniques, since these are tuned to generating unbiased estimates of coefficients rather than minimizing prediction error. We argue that new developments in the field of ""machine learning"" are particularly useful for addressing these prediction problems. We use an example from health policy to illustrate the large potential social welfare gains from improved prediction.",3
36a30c0507c3b1b7944288589ee6e92f3851c16c,Solving a Higgs optimization problem with quantum annealing for machine learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
010f65dd2fa979892a8229db825954871652fb8f,Defining Data Science by a Data-Driven Quantification of the Community,"Data science is a new academic field that has received much attention in recent years. One reason for this is that our increasingly digitalized society generates more and more data in all areas of our lives and science and we are desperately seeking for solutions to deal with this problem. In this paper, we investigate the academic roots of data science. We are using data of scientists and their citations from Google Scholar, who have an interest in data science, to perform a quantitative analysis of the data science community. Furthermore, for decomposing the data science community into its major defining factors corresponding to the most important research fields, we introduce a statistical regression model that is fully automatic and robust with respect to a subsampling of the data. This statistical model allows us to define the ‘importance’ of a field as its predictive abilities. Overall, our method provides an",4
7fa92483671d21ac56a1112f0a1ebff8a0b14e1f,Semantic preservation of standardized healthcare documents in big data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
30daec40b05b1ec9afbc97d53e0d1279f5128eaa,Cultivars to face climate change effects on crops and weeds: a review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
e5bd499e31c3b1493e21416fc9d6f8a1ce8c98ed,An Online Change-Point-Based Model for Traffic Parameter Prediction,"This paper develops a method for predicting traffic parameters under abrupt changes based on change point models. Traffic parameters such as speed, flow, and density are subject to shifts because of weather, accidents, driving characteristics, etc. An intuitive approach of employing the hidden Markov model (HMM) and the expectation-maximization (EM) algorithm as change point models at these shifts and accordingly adapting the autoregressive-integrated-moving-average (ARIMA) forecasting model is formulated. The model is fitted and tested using publicly available 1993 I-880 loop data. It is compared with basic and mean updating forecasting models. Detailed numerical experiments are given on several days of data to show the impact of using change point models for adaptive forecasting models.",4
18841e624f4fddd4282e37ad2b29384fa9bc0be6,Big data platforms: What's next?,"Three computer scientists from UC Irvine address the question ""What's next for big data?"" by summarizing the current state of the big data platform space and then describing ASTERIX, their next-generation big data management system.",4
39731f9ff7b8e00b098b9cd4b9e57389c60f3eaf,Application of Big Data Technology for COVID-19 Prevention and Control in China: Lessons and Recommendations,"Background In the prevention and control of infectious diseases, previous research on the application of big data technology has mainly focused on the early warning and early monitoring of infectious diseases. Although the application of big data technology for COVID-19 warning and monitoring remain important tasks, prevention of the disease’s rapid spread and reduction of its impact on society are currently the most pressing challenges for the application of big data technology during the COVID-19 pandemic. After the outbreak of COVID-19 in Wuhan, the Chinese government and nongovernmental organizations actively used big data technology to prevent, contain, and control the spread of COVID-19. Objective The aim of this study is to discuss the application of big data technology to prevent, contain, and control COVID-19 in China; draw lessons; and make recommendations. Methods We discuss the data collection methods and key data information that existed in China before the outbreak of",3
106fce09c874f1e2a6a4e0cff273cf78260363f9,Coupling Damage-Sensing Particles to the Digitial Twin Concept,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
a9a84242cf78a9b277fce869f8bbfa7bfacfbc38,Big Data: Issues and Challenges Moving Forward,"Big data refers to data volumes in the range of exabytes (1018) and beyond. Such volumes exceed the capacity of current on-line storage systems and processing systems. Data, information, and knowledge are being created and collected at a rate that is rapidly approaching the exabyte/year range. But, its creation and aggregation are accelerating and will approach the zettabyte/year range within a few years. Volume is only one aspect of big data; other attributes are variety, velocity, value, and complexity. Storage and data transport are technology issues, which seem to be solvable in the near-term, but represent longterm challenges that require research and new paradigms. We analyze the issues and challenges as we begin a collaborative research program into methodologies for big data analysis and design.",4
44f1c3aa7090c39fc80a9b490cc63e6921136220,A data-driven robust optimization method for the assembly job-shop scheduling problem under uncertainty,"ABSTRACT This paper studies the production scheduling problem in an assembly manufacturing system with uncertain processing time and random machine breakdown. The objectives of minimizing makespan and the performance deviation of the actual schedule from the baseline schedule are simultaneously considered. Specifically, a boosting radial basis function network constructed using the data generated by Monte Carlo method, is used as the surrogate model to approximate the performance deviation. After that, a modified master-apprentice evolutionary algorithm (MAE) is developed for robust scheduling. In the design of MAE, we employ an extended adjacency matrix of subassemblies to cope with the sequential constraints of operations in AJSSP. Based on this, effective neighbourhood structures and distance metric of solutions are designed for tabu search and path relinking operators to generate feasible schedules. To evaluate the effectiveness of the proposed method, a series of computational experiments are conducted. The results indicate that, compared with several",2
09e72c1ddaa2f5b26f6c3a04583005bddaa030c7,How ‘Big Data’ Can Make Big Impact: Findings from a Systematic Review and a Longitudinal Case Study,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",17
0023318fc6f4533280d1277314a24fbe851b6bdb,A Primer on Partial Least Squares Structural Equation Modeling (PLS-SEM),"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
e26236a85d42e0c530a592b105b125e245b9e176,Puzzling out big data [Information Technology Analytics],"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
815fe9fb59eb556e47200d1fbb0fc18475df9e45,Performance of CatBoost and XGBoost in Medicare Fraud Detection,"Due to the size of the data involved, performance is an important consideration in the task of detecting fraudulent Medicare insurance claims. We evaluate CatBoost and XGBoost on the task of Medicare fraud detection, and report performance in terms of running time and Area Under the Receiver Operating Characteristic Curve (AUC). We show that adding a categorical feature for XGBoost and CatBoost improves performance in terms of AUC, and that CatBoost’s performance is higher in a statistically significant sense. Moreover, we conduct experiments to find the optimal number of decision trees to use for XGBoost and CatBoost in the task of Medicare fraud detection. This is an important contribution because the number of trees in the ensemble governs overall resource consumption of a Gradient Boosted Decision Tree implementation. We find that with a purely numerical dataset, CatBoost and XGBoost yield nearly equivalent performance in terms of AUC, and XGBoost has",2
56f9cc0508e8c46b667538a35ea7679d19314950,CheXtransfer: performance and parameter efficiency of ImageNet models for chest X-Ray interpretation,"Deep learning methods for chest X-ray interpretation typically rely on pretrained models developed for ImageNet. This paradigm assumes that better ImageNet architectures perform better on chest X-ray tasks and that ImageNet-pretrained weights provide a performance boost over random initialization. In this work, we compare the transfer performance and parameter efficiency of 16 popular convolutional architectures on a large chest X-ray dataset (CheXpert) to investigate these assumptions. First, we find no relationship between ImageNet performance and CheXpert performance for both models without pretraining and models with pretraining. Second, we find that, for models without pretraining, the choice of model family influences performance more than size within a family for medical imaging tasks. Third, we observe that ImageNet pretraining yields a statistically significant boost in performance across architectures, with a higher boost for smaller architectures. Fourth, we examine whether ImageNet architectures are unnecessarily large for CheXpert by truncating final blocks from pretrained",2
c48e0bd0f36c25ab83befbc7b7da369b75fd25f5,Big Data-Survey,"Big data is the term for any gathering of information sets, so expensive and complex, that it gets to be hard to process for utilizing customary information handling applications. The difficulties incorporate investigation, catch, duration, inquiry, sharing, stockpiling, Exchange, perception, and protection infringement. To reduce spot business patterns, anticipate diseases, conflict etc., we require bigger data sets when compared with the smaller data sets. Enormous information is hard to work with utilizing most social database administration frameworks and desktop measurements and perception bundles, needing rather enormously parallel programming running on tens, hundreds, or even a large number of servers. In this paper there was an observation on Hadoop architecture, different tools used for big data and its security issues.",9
6c92e3ccc96fdee71d680d0bf0276e00fc01b413,A Simple and Effective Approach for Digitization of the CTG Signals from CTG Traces,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
469460d71ede47dc1082a3123e39f84dc33ba2cc,Big data classification: problems and challenges in network intrusion prediction with machine learning,"This paper focuses on the specific problem of Big Data classification of network intrusion traffic. It discusses the system challenges presented by the Big Data problems associated with network intrusion prediction. The prediction of a possible intrusion attack in a network requires continuous collection of traffic data and learning of their characteristics on the fly. The continuous collection of traffic data by the network leads to Big Data problems that are caused by the volume, variety and velocity properties of Big Data. The learning of the network characteristics require machine learning techniques that capture global knowledge of the traffic patterns. The Big Data properties will lead to significant system challenges to implement machine learning frameworks. This paper discusses the problems and challenges in handling Big Data classification using geometric representation-learning techniques and the modern Big Data networking technologies. In particular this paper discusses the issues related to combining supervised learning",4
e5478d9ad72788d8b75060f814ad31dccb790cdf,Computationally Efficient Analysis of SMA Sensory Particles Embedded in Complex Aerostructures Using a Substructure Approach,"The Digital Twin concept represents an innovative method to monitor and predict the performance of an aircraft’s various subsystems. By creating ultra-realistic multi-physical computational models associated with each unique aircraft and combining them with known flight histories, operators could benefit from a real-time understanding of the vehicle’s current capabilities. One important facet of the Digital Twin program is the detection and monitoring of structural damage. Recently, a method to detect fatigue cracks using the transformation response of shape memory alloy (SMA) particles embedded in the aircraft structure has been proposed. By detecting changes in the mechanical and/or electromagnetic responses of embedded particles, operators could detect the onset of fatigue cracks in the vicinity of these particles. In this work, the development of a finite element model of an aircraft wing containing embedded SMA particles in key regions will be discussed. In particular, this model will feature a technique known as",3
2a6a79ef4de1b986b71fc59c012c69d199a76d61,Single Reading with Computer-Aided Detection for Screening Mammography,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
29b053c336af2189e3d050fd8c23f81e2fd2a8d3,Big data reduction framework for value creation in sustainable enterprises,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
bfc1c08ba71294ce5de5e131561cfa7594d64a0f,Private traits and attributes are predictable from digital records of human behavior,"We show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender. The analysis presented is based on a dataset of over 58,000 volunteers who provided their Facebook Likes, detailed demographic profiles, and the results of several psychometric tests. The proposed model uses dimensionality reduction for preprocessing the Likes data, which are then entered into logistic/linear regression to predict individual psychodemographic profiles from Likes. The model correctly discriminates between homosexual and heterosexual men in 88% of cases, African Americans and Caucasian Americans in 95% of cases, and between Democrat and Republican in 85% of cases. For the personality trait “Openness,” prediction accuracy is close to the test–retest accuracy of a standard personality test. We give",2
88500d702a79a1d4e2200b5a9138415c4255cd80,An Automated Machine Learning architecture for the accelerated prediction of Metal-Organic Frameworks performance in energy and environmental applications,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
6a4260f10b5af738f1f46a7dac1c707e1e39445c,How to Address the Data Quality Issues in Regression Models: A Guided Process for Data Cleaning,"Today, data availability has gone from scarce to superabundant. Technologies like IoT, trends in social media and the capabilities of smart-phones are producing and digitizing lots of data that was previously unavailable. This massive increase of data creates opportunities to gain new business models, but also demands new techniques and methods of data quality in knowledge discovery, especially when the data comes from different sources (e.g., sensors, social networks, cameras, etc.). The data quality process of the data set proposes conclusions about the information they contain. This is increasingly done with the aid of data cleaning approaches. Therefore, guaranteeing a high data quality is considered as the primary goal of the data scientist. In this paper, we propose a process for data cleaning in regression models (DC-RM). The proposed data cleaning process is evaluated through a real datasets coming from the UCI Repository of Machine Learning Databases. With the aim",3
2b6e67582e078eec249f9acdaec936ab4427d6ea,Process Mining: Overview and Opportunities,"Over the last decade, process mining emerged as a new research field that focuses on the analysis of processes using event data. Classical data mining techniques such as classification, clustering, regression, association rule learning, and sequence/episode mining do not focus on business process models and are often only used to analyze a specific step in the overall process. Process mining focuses on end-to-end processes and is possible because of the growing availability of event data and new process discovery and conformance checking techniques. Process models are used for analysis (e.g., simulation and verification) and enactment by BPM/WFM systems. Previously, process models were typically made by hand without using event data. However, activities executed by people, machines, and software leave trails in so-called event logs. Process mining techniques use such logs to discover, analyze, and improve business processes. Recently, the Task Force on Process Mining released the Process Mining Manifesto. This",4
5bacfea96066f8a5e295c159625713b8c72d91bf,Managing ‘Big Data’,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
16e0361afc68b2c71cab43b21abf482da69b33d0,Shroud: ensuring private access to large-scale data in the data center,"Recent events have shown online service providers the perils of possessing private information about users. Encrypting data mitigates but does not eliminate this threat: the pattern of data accesses still reveals information. Thus, we present Shroud, a general storage system that hides data access patterns from the servers running it, protecting user privacy. Shroud functions as a virtual disk with a new privacy guarantee: the user can look up a block without revealing the block's address. Such a virtual disk can be used for many purposes, including map lookup, microblog search, and social networking.Shroud aggressively targets hiding accesses among hundreds of terabytes of data. We achieve our goals by adapting oblivious RAM algorithms to enable large-scale parallelization. Specifically, we show, via new techniques such as oblivious aggregation, how to securely use many inexpensive secure coprocessors acting in parallel to improve request latency. Our evaluation combines large-scale emulation with an implementation",7
21db69e57a81a20ce75beb2b29a93812eb14baee,Rapid Detection of Mobilized Colistin Resistance using a Nucleic Acid Based Lab-on-a-Chip Diagnostic System,"The increasing prevalence of antimicrobial resistance is a serious threat to global public health. One of the most concerning trends is the rapid spread of Carbapenemase-Producing Organisms (CPO), where colistin has become the last-resort antibiotic treatment. The emergence of colistin resistance, including the spread of mobilized colistin resistance ( mcr ) genes, raises the possibility of untreatable bacterial infections and motivates the development of improved diagnostics for the detection of colistin-resistant organisms. This work demonstrates a rapid response for detecting the most recently reported mcr gene, mcr −9, using a portable and affordable lab-on-a-chip (LoC) platform, offering a promising alternative to conventional laboratory-based instruments such as real-time PCR (qPCR). The platform combines semiconductor technology, for non-optical real-time DNA sensing, with a smartphone application for data acquisition, visualization and cloud connectivity. This technology is enabled by using loop-mediated isothermal amplification (LAMP) as the chemistry for targeted DNA detection, by virtue of",1
64d2fe89ba7f105cb96796742f4dcbf4e56bd2ca,"The World’s Technological Capacity to Store, Communicate, and Compute Information","An inventory of the world’s technological capacity from 1986 to 2007 reveals the evolution from analog to digital technologies. We estimated the world’s technological capacity to store, communicate, and compute information, tracking 60 analog and digital technologies during the period from 1986 to 2007. In 2007, humankind was able to store 2.9 × 1020 optimally compressed bytes, communicate almost 2 × 1021 bytes, and carry out 6.4 × 1018 instructions per second on general-purpose computers. General-purpose computing capacity grew at an annual rate of 58%. The world’s capacity for bidirectional telecommunication grew at 28% per year, closely followed by the increase in globally stored information (23%). Humankind’s capacity for unidirectional information diffusion through broadcasting channels has experienced comparatively modest annual growth (6%). Telecommunication has been dominated by digital technologies since 1990 (99.9% in digital format in 2007), and the majority of our technological memory has been in digital format since",11
23cfa973c3e131ed578ad2503c5e0559bbb83f10,Cloud-based Data-intensive Framework towards fault diagnosis in large-scale petrochemical plants,"Industrial Wireless Sensor Networks (IWSNs) are expected to offer promising monitoring solutions to meet the demands of monitoring applications for fault diagnosis in large-scale petrochemical plants, however, involves heterogeneity and Big Data problems due to large amounts of sensor data with high volume and velocity. Cloud Computing is an outstanding approach which provides a flexible platform to support the addressing of such heterogeneous and data-intensive problems with massive computing, storage, and data-based services. In this paper, we propose a Cloud-based Data-intensive Framework (CDF) for on-line equipment fault diagnosis system that facilitates the integration and processing of mass sensor data generated from Industrial Sensing Ecosystem (ISE). ISE enables data collection of interest with topic-specific industrial monitoring systems. Moreover, this approach contributes the establishment of on-line fault diagnosis monitoring system with sensor streaming computing and storage paradigms based on Hadoop as a key to the complex problems. Finally, we present a practical",2
8fd7db9116e165584b0a240a05b7dae4fd3e82b2,Labeling Examples That Matter: Relevance-Based Active Learning with Gaussian Processes,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
bdca6d573cf0b2eb86ea495ae9aaffc7bf418ca7,Growth and Renewal in the United States: Retooling America's Economic Engine,"New research by the McKinsey Global Institute (MGI) examines the growth challenge facing the United States and explores how U.S. business and government can contribute to the economy's renewal by reinvigorating their drive toward higher productivity. As baby boomers retire and the female participation rate plateaus, the U.S. economy will receive significantly less lift from increases in the labor force and will have to rely increasingly on productivity gains to fuel growth. The report finds that the United States needs a 34% acceleration in productivity growth if it is to match the GDP growth rates of the past 20 years and that this is possible. Three-quarters of the necessary productivity growth acceleration can come from the efforts of private-sector companies operating within the current regulatory and business environment. Even the best-performing companies and sectors still have headroom to boost productivity by emulating the best practice of others and tapping into",4
361391a1f47e7817deea9f8f40146a766d821690,The data deluge,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
c1787db25af5614f41e56938aa594f2dbb1dca07,The Unreasonable Effectiveness of Data,"At Brown University, there is excitement of having access to the Brown Corpus, containing one million English words. Since then, we have seen several notable corpora that are about 100 times larger, and in 2006, Google released a trillion-word corpus with frequency counts for all sequences up to five words long. In some ways this corpus is a step backwards from the Brown Corpus: it's taken from unfiltered Web pages and thus contains incomplete sentences, spelling errors, grammatical errors, and all sorts of other errors. It's not annotated with carefully hand-corrected part-of-speech tags. But the fact that it's a million times larger than the Brown Corpus outweighs these drawbacks. A trillion-word corpus - along with other Web-derived corpora of millions, billions, or trillions of links, videos, images, tables, and user interactions - captures even very rare aspects of human behavior. So, this corpus could serve as the basis of a",6
9c1b9598f82f9ed7d75ef1a9e627496759aa2387,"Data Science, Predictive Analytics, and Big Data: A Revolution that Will Transform Supply Chain Design and Management","We illuminate the myriad of opportunities for research where supply chain management intersects with data science, predictive analytics, and big data, collectively referred to as DPB. We show that these terms are not only becoming popular but are also relevant to supply chain research and education. Data science requires both domain knowledge and a broad set of quantitative skills, but there is a dearth of literature on the topic and many questions. We call for research on skills that are needed by SCM data scientists and discuss how such skills and domain knowledge affect the effectiveness of a SCM data scientist. Such knowledge is crucial to developing future supply chain leaders. We propose definitions of data science and predictive analytics as applied to supply chain management. We examine possible applications of DPB in practice and provide examples of research questions from these applications, as well as examples of research questions",10
3469d924818d1167b3ba5ba850f03c2ccb50638f,"Maternal mortality ratios in 2852 Chinese counties, 1996–2015, and achievement of Millennium Development Goal 5 in China: a subnational analysis of the Global Burden of Disease Study 2016","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
77f7ec30897e3b03fd3316cd23c61c3b85c775e8,The role of big data analytics capabilities in bolstering supply chain resilience and firm performance: a dynamic capability view,"PurposeBig data analytics capability (BDAC) can affect firm performance in several ways. The purpose of this paper is to understand how BDA capabilities affect firm performance through supply chain resilience in the presence of the risk management culture.Design/methodology/approachThe study adopted a cross-sectional approach to collect survey-based responses to examine the hypotheses. 167 responses were collected and analyzed using partial least squares in SmartPLS3. The respondents were generally senior IT executives with education and experience in data and business analytics.FindingsThe results show that BDA capabilities increase supply chain resilience as a mediator by enhancing innovative capabilities and information quality, ultimately leading to improved firm performance. In addition, the relationship between supply chain resilience and firm performance is influenced by risk management culture as a moderator.Originality/valueThe present study contributes to the relevant literature by demonstrating the mediating role of supply chain resilience between the BDA capabilities relationship and firm performance. In this",5
479fd6434e62711a0e091c7c2c7216ca3bacdd5a,Distributed Primal-Dual Optimization for Online Multi-Task Learning,"Conventional online multi-task learning algorithms suffer from two critical limitations: 1) Heavy communication caused by delivering high velocity of sequential data to a central machine; 2) Expensive runtime complexity for building task relatedness. To address these issues, in this paper we consider a setting where multiple tasks are geographically located in different places, where one task can synchronize data with others to leverage knowledge of related tasks. Specifically, we propose an adaptive primal-dual algorithm, which not only captures task-specific noise in adversarial learning but also carries out a projection-free update with runtime efficiency. Moreover, our model is well-suited to decentralized periodic-connected tasks as it allows the energy-starved or bandwidth-constraint tasks to postpone the update. Theoretical results demonstrate the convergence guarantee of our distributed algorithm with an optimal regret. Empirical results confirm that the proposed model is highly effective on various real-world datasets.",4
73eef4ee714123753b0bb2e63567b1eeef263535,Leveraging Financial Social Media Data for Corporate Fraud Detection,"Abstract Corporate fraud can lead to significant financial losses and cause immeasurable damage to investor confidence and the overall economy. Detection of such frauds is a time-consuming and challenging task. Traditionally, researchers have been relying on financial data and/or textual content from financial statements to detect corporate fraud. Guided by systemic functional linguistics (SFL) theory, we propose an analytic framework that taps into unstructured data from financial social media platforms to assess the risk of corporate fraud. We assemble a unique data set including 64 fraudulent firms and a matched sample of 64 nonfraudulent firms, as well as the social media data prior to the firm’s alleged fraud violation in Accounting and Auditing Enforcement Releases (AAERs). Our framework automatically extracts signals such as sentiment features, emotion features, topic features, lexical features, and social network features, which are then fed into machine learning classifiers for fraud detection. We evaluate and compare",3
9278112571f5424ee1f05726b6432354cba00ab8,A CLSTM-TMN for marketing intention detection,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
029088ac7288fd455df8e5469952154552f86a2a,Ensure Inclusive and Equitable Quality Education and Promote Lifelong Learning Opportunities for All,"Coeducation has its origins in feminist pedagogy and involves the equivalence principle replacing that of equality. Thus, it is not about educating girls as if they were children, or teaching women to be like men but giving children a world view that counts women as citizens. Values, attitudes, curricula and practices have a comprehensive gender approach, eliminating androcentric visions and replacing them with intercultural panorama that include, among other aspects, the views of women, who represent half of the population.",2
f1945a113ffd733f809d1b0cba56f37ffaf3eb00,"Dragnet Nation: A Quest for Privacy, Security, and Freedom in a World of Relentless Surveillance","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
72cf27dcd51d690887dbf3028ad2c2a700019921,Identify glomeruli in human kidney tissue images using a deep learning approach,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
86e060423a76e6e6658d6c0cec44e0f5538bf2c5,Implementing Anti-discrimination Policies in Statistical Profiling Models,"How should statistical models used for assigning prices or eligibility be implemented when there is concern about discrimination? In many settings, factors such as race, gender, and age are prohibited. However, the use of variables that correlate with these omitted characteristics (e.g., zip codes, credit scores) is often contentious. We provide a framework to address these issues and propose a method that can eliminate proxy effects while maintaining predictive accuracy relative to an approach that restricts the use of contentious variables outright. We illustrate the value of our proposed method using data from the Worker Profiling and Reemployment Services system. (JEL C53, J15, J65, J71)",2
d6d74d8fd12e4ca748ef6054276c03abfa7df4c1,An Overview of Health Analytics,"Objectives: We examine the emerging health analytics field by describing the different health analytics and providing examples of various applications. Methods: The paper discusses different definitions of health analytics, describes the four stages of health analytics, its architectural framework, development methodology, and examples in public health. Results: The paper provides a broad overview of health analytics for researchers and practitioners. Conclusions: Health analytics is rapidly emerging as a key and distinct application of health information technology. The key objective of health analytics is to gain insight for making informed healthcare decisions.",3
c847e7a0430a475caf7173cafb02cab9367779b8,Robust Intelligent Malware Detection Using Deep Learning,"Security breaches due to attacks by malicious software (malware) continue to escalate posing a major security concern in this digital age. With many computer users, corporations, and governments affected due to an exponential growth in malware attacks, malware detection continues to be a hot research topic. Current malware detection solutions that adopt the static and dynamic analysis of malware signatures and behavior patterns are time consuming and have proven to be ineffective in identifying unknown malwares in real-time. Recent malwares use polymorphic, metamorphic, and other evasive techniques to change the malware behaviors quickly and to generate a large number of new malwares. Such new malwares are predominantly variants of existing malwares, and machine learning algorithms (MLAs) are being employed recently to conduct an effective malware analysis. However, such approaches are time consuming as they require extensive feature engineering, feature learning, and feature representation. By using the advanced MLAs such as",6
8534a31fde1d1b26a52f84ab94a30fe14213e2b0,A cost-effective approach to improving performance of big genomic data analyses in clouds,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
140c4b0e6c84914b171d55d5818702341f68b9c4,Incorporating risk measures in closed-loop supply chain network design,"This paper considers a location-allocation problem in a closed-loop supply chain (CLSC) with two extensions: first, demand and prices of new and return products are regarded as non-deterministic parameters and second, the objective function is developed from expected profit to three types of mean-risk ones. Indeed, design and planning an integrated CLSC in real-world volatile markets is an important and necessary issue. Further, risk-neutral approaches, which are considered expected values, are not efficient for such uncertain conditions. Hence, this paper, copes with the design and planning problem of a CLSC in a two-stage stochastic structure. Besides, risk criteria are considered through using three types of popular and well-behaved risk measures: mean absolute deviation, value at risk and conditional value at risk (CVaR). Consequently, three types of mean-risk models are developed as objective functions and decision-making procedures are undertaken based on the expected values and risk adversity criteria. Finally, performances of",5
0ac065b6199e67d01c48f3f399014cb39bc3f8ef,Big Data and virtualization for manufacturing cyber-physical systems: A survey of the current status and future outlook,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
c828fe9ea20eb96dd296813ea814092849401f6d,Familial Hypocalciuric Hypercalcemia in Pregnancy: Diagnostic Pitfalls,"Familial hypocalciuric hypercalcemia (FHH) is a group of autosomal dominant disorders caused by dysfunction of the calcium sensing receptor (CaSR) and its downstream signaling proteins, leading to generally asymptomatic hypercalcemia. During pregnancy, distinguishing FHH from primary hyperparathyroidism (PHPT) is important, as the latter is associated with adverse outcomes and can be treated surgically during pregnancy, whereas the former is benign. This case report highlights the difficulties in diagnosing FHH during pregnancy. A 32‐year‐old woman was found to have asymptomatic hypercalcemia at 14‐weeks’ gestation. Investigations showed a corrected calcium (cCa) of 2.61 mmol/L (2.10 to 2.60), ionized Ca (iCa) of 1.40 mmol/L (1.15 to 1.28), 25OHD of 33 nmol/L (75 to 250), and PTH of 9.5 pmol/L (1.5 to 7.0). The patient was treated with 2000 IU cholecalciferol daily with normalization of 25OHD. The urine calcium / creatinine clearance ratio (CCCR) was 0.0071, and neck US did not visualize a parathyroid",5
508b42aafed6fcd25fef98aae063d9e193e018ea,Will quantum computers be the end of public key encryption?,"ABSTRACT The emergence of practical quantum computers poses a significant threat to the most popular public key cryptographic schemes in current use. While we know that the well-understood algorithms for factoring large composites and solving the discrete logarithm problem run at best in superpolynomial time on conventional computers, new, less well understood algorithms run in polynomial time on certain quantum computer architectures. Many appear to be heralding this next step in computing as ‘the end of public key encryption’. We argue that this is not the case and that there are many fields of mathematics that can be used for creating ‘quantum resistant’ cryptographic schemes. We present a high-level review of the threat posed by quantum computers, using RSA and Shor’s algorithm as an example but we explain why we feel that the range of quantum algorithms that pose a threat to public key encryption schemes is likely to be",4
a24d373bd33788640e95c117ebd5d78c88e8ce92,An IoT-Oriented Data Storage Framework in Cloud Computing Platform,"The Internet of Things (IoT) has provided a promising opportunity to build powerful industrial systems and applications by leveraging the growing ubiquity of Radio Frequency IDentification (RFID) and wireless sensors devices. Benefiting from RFID and sensor network technology, common physical objects can be connected, and are able to be monitored and managed by a single system. Such a network brings a series of challenges for data storage and processing in a cloud platform. IoT data can be generated quite rapidly, the volume of data can be huge and the types of data can be various. In order to address these potential problems, this paper proposes a data storage framework not only enabling efficient storing of massive IoT data, but also integrating both structured and unstructured data. This data storage framework is able to combine and extend multiple databases and Hadoop to store and manage diverse types of data collected by",3
ed9e3636c024b24b9d0a9c8c9a553a34ca635d36,Big data and business intelligence for management accountants,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
b3d8dffb73bc93de239998548386c84177caa2ad,Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks,"Abstract: Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural network that operates directly on the image pixels. We employ the DistBelief implementation of deep neural networks in order to train large, distributed neural networks on high quality images. We find that the performance of this approach increases with the depth of the convolutional network, with the best performance occurring in the deepest architecture we trained, with eleven hidden layers. We evaluate this approach on the publicly available SVHN dataset and achieve over $96\%$ accuracy in recognizing complete street numbers.",6
f039cd42598ed533333b4434c43c5309f6fda2b2,Birch,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
5d55ce7fa18583b81ec853b521c4ea07a30c0876,Cloud Dynamic Scheduling for Multimedia Data Encryption Using Tabu Search Algorithm,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
5b36280f6ecd8787facf4147b42a3271fed67b18,Big data and Spark: Comparison with Hadoop,"Now a days, data is generating by different industries on a daily basis which amount growing from terabyte to petabyte. To handle this large amount of data, big data technology is great revolution and has impacted the trends of the applied science. For the analysis of the large amount of data, Hadoop MapReduce technology is used in parallel multiple nodes. The numerous amount of data and information is stored through HDFS, Map and Reduce are two main functions of the MapReduce. There are many loop holes in MapReduce so for fast queries and real time data stream, Spark is introduced. The base of the Spark is DAG and RDD approaches. The main purpose of this research is to make comparison between the basic features of Hadoop and Spark on which basis their performance will be evaluate.",4
0bc6977f2c260eb279a7e6feab34910434de210d,Cost Minimization for Big Data Processing in Geo-Distributed Data Centres,"Demand on big data is being increasing day by day and also increasing heavy burden on computation, storage and communication in data centres, which lead to considerable expenditure to data centre providers. So, cost minimization became an issue for the upcoming big data. One of the main feature of big data is coupling of data and computation as computation task. This can be done only when that corresponding is available for computation. Three tasks like data placement, task assignment and data movement influence the expense of data centres. In this paper we study how to minimize cost through joint optimization of these above three factors for big data service in geo distributes data centres. Here we propose 2-D Markov chain to describe time to complete a particular task with consideration of data transmission and computation to derive average task completion time in closed time. In addition, we here model the",5
aca43cc3f55ed43a9ce5a0eb7df30b4a8f54b623,Big data approach for sentiment analysis of twitter data using Hadoop framework and deep learning,"Sentiment analysis acquired a great area of attention in the microblogging websites and analysis of sentiment is a practice of categorization and identification of opinions that are articulated as speech, text, database sources and tweets to detect if opinion is negative, positive or neutral. The challenge lies in determining sentiment from the tweets due to the unique characteristics of Twitter data. This paper presents an approach for sentiment analysis by adapting a Hadoop framework and deep learning classifier. The Hadoop cluster is used for the distribution of data for extracting the features. Then, the significant features are extracted using the twitter data. The deep learning classifier, namely deep recurrent neural network classifier is used assign a real-valued review to each input twitter data thus, classifying the input data into two classes, such as positive review and negative review. The analysis of the performance is done using metrics like, classification accuracy,",2
dbe077f8521ecbe0a1477d6148c726d4f053d9c9,Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet,"Transformers, which are popular for language modeling, have been explored for solving vision tasks recently, e.g., the Vision Transformer (ViT) for image classification. The ViT model splits each image into a sequence of tokens with fixed length and then applies multiple Transformer layers to model their global relation for classification. However, ViT achieves inferior performance to CNNs when trained from scratch on a midsize dataset like ImageNet. We find it is because: 1) the simple tokenization of input images fails to model the important local structure such as edges and lines among neighboring pixels, leading to low training sample efficiency; 2) the redundant attention backbone design of ViT leads to limited feature richness for fixed computation budgets and limited training samples. To overcome such limitations, we propose a new Tokens-To-Token Vision Transformer (T2T-VTT), which incorporates 1) a layer-wise Tokens-to-Token (T2T) transformation to progressively structurize the image to tokens by recursively",9
0fadf229f741212a01f658dcd6370fa9bc8893a0,Unified Ontology Implementation of Cloud Computing for Distributed Systems,"The ability to provide massive data storage, applications, platforms plus many other services leads to make the number of clouds services providers been increased. Providing different types of services and resources by various providers implies to get a high level of complexity. This complexity leads to face many challenges related to security, reliability, discovery, service selection, and interoperability. In this review, we focus on the use of many technologies and methods for utilizing the semantic web and ontology in cloud computing and distributed system as a solution for these challenges. Cloud computing does not have an own search engine to satisfy the needs of the providers of the cloud service. Using ontology enhances the cloud computing self-motivated via an intelligent framework of SaaS and consolidating the security by providing resources access control. The use RDF and OWL semantic technologies in the modeling of a multi-agent system are very effective in",6
8636dec409eaddd4ff9c389381465470ef120052,Automatic Cardiotocography Diagnostic System Based on Hilbert Transform and Adaptive Threshold Technique,"The visual analysis of cardiotocographic examinations is a very subjective process. The accurate detection and segmentation of the fetal heart rate (FHR) features and their correlation with the uterine contractions in time allow a better diagnostic and the possibility of anticipation of many problems related to fetal distress. This paper presents a computerized diagnostic aid system based on digital signal processing techniques to detect and segment changes in the FHR and the uterine tone signals automatically. After a pre-processing phase, the FHR baseline detection is calculated. An auxiliary signal called detection line is proposed to support the detection and segmentation processes. Then, the Hilbert transform is used with an adaptive threshold for identifying fiducial points on the fetal and maternal signals. For an antepartum (before labor) database, the positive predictivity value (PPV) is 96.80% for the FHR decelerations, and 96.18% for the FHR accelerations. For an intrapartum (during labor) database,",3
0bfbb24fd7b39ae118e1e37cdde191f323ebe6d1,Large-Scale Free Energy Calculations on a Computational Metal–Organic Frameworks Database: Toward Synthetic Likelihood Predictions,"Metal-organic frameworks (MOFs) have captivated the research community due to a modular crystal structure that is tailorable for many applications. However, with millions of possible MOFs to be considered, it is challenging to identify the ideal MOF for the application of choice. Although computational screening of MOF databases has provided a fast way to evaluate MOF properties, validation experiments on predicted “exceptional” MOFs are not common due to uncertainties on the synthetic likelihood of computationally constructed MOFs, hence hindering material discovery. Aiming to leverage the perspective provided by large datasets, here we created and screened a topologically diverse database of 8,500 MOFs to interrogate whether thermodynamic stability metrics such as free energy could be used to generally predict the synthetic likelihood of computationally constructed MOFs. To this end, we first evaluated the suitability of two methods and three force fields to calculate free energies in MOFs at large scale, settling",4
1b117efcc4e13c8d87833e02c32fd5c4de751c67,A Cognitive Adopted Framework for IoT Big-Data Management and Knowledge Discovery Prospective,"In future IoT big-data management and knowledge discovery for large scale industrial automation application, the importance of industrial internet is increasing day by day. Several diversified technologies such as IoT (Internet of Things), computational intelligence, machine type communication, big-data, and sensor technology can be incorporated together to improve the data management and knowledge discovery efficiency of large scale automation applications. So in this work, we need to propose a Cognitive Oriented IoT Big-data Framework (COIB-framework) along with implementation architecture, IoT big-data layering architecture, and data organization and knowledge exploration subsystem for effective data management and knowledge discovery that is well-suited with the large scale industrial automation applications. The discussion and analysis show that the proposed framework and architectures create a reasonable solution in implementing IoT big-data based smart industrial applications.",3
f71c25642f53c52823aeef5d215993470991cf82,Deep learning for class-generic object detection,"We investigate the use of deep neural networks for the novel task of class generic object detection. We show that neural networks originally designed for image recognition can be trained to detect objects within images, regardless of their class, including objects for which no bounding box labels have been provided. In addition, we show that bounding box labels yield a 1% performance increase on the ImageNet recognition challenge.",8
cd8c9fca3eb140aa3250fdc41084ef3f3db51821,To FinTech and Beyond,"FinTech is about the introduction of new technologies into the financial sector, and it is now revolutionizing the financial industry. In 2017, when the academic finance community was not actively researching FinTech, the editorial team of the Review of Financial Studies launched a competition to develop research proposals focused on this topic. This special issue is the result. In this introductory article, we describe the recent FinTech phenomenon and the novel editorial protocol employed for this special issue following the Registered Reports format. We discuss what we learned from the submitted proposals about the field of FinTech and which ones we selected to be completed and ultimately come out in this special issue. We also provide several observations to help guide future research in the emerging area of FinTech.",4
3b217403302f9cb9d9685404c7646de7bc0db428,"Data-intensive applications, challenges, techniques and technologies: A survey on Big Data","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",19
1a342afefe4f0506a8ee678f19bfac93cbd7fb87,"A Competing Risk Analysis Study of Prognosis in Patients with Esophageal Carcinoma 2006–2015 Using Data from the Surveillance, Epidemiology, and End Results (SEER) Database","Background Competing risk analysis determines the probability of survival and considers competing events. This retrospective study aimed to undertake a competing risk analysis of prognosis in patients with esophageal carcinoma between 2006–2015 using data from the Surveillance, Epidemiology, and End Results (SEER) database. Material/Methods Clinicopathological, demographic, and survival data were analyzed for patients with esophageal carcinoma registered in the SEER database between 2006–2015. The competing risk model calculated the cumulative incidence function (CIF) of events of interest and prognosis. The Cox proportional-hazards model and the cause-specific hazard function (CS) were used to generalize the hazard function for competing risks. The Fine-Gray model was used for multivariate analysis. More accurate prognostic factors were analyzed by comparing the hazard ratio (HR) values between groups. Results There were 14,695 patients identified with esophageal carcinoma, 9,621 died from esophageal carcinoma, and 1,251 patients died from other causes. The cumulative incidence of events of interest",4
610b302950a19acef1c45456111dcd495f638c18,ConViT: improving vision transformers with soft convolutional inductive biases,"Convolutional architectures have proven to be extremely successful for vision tasks. Their hard inductive biases enable sample-efficient learning, but come at the cost of a potentially lower performance ceiling. Vision transformers rely on more flexible self-attention layers, and have recently outperformed CNNs for image classification. However, they require costly pre-training on large external datasets or distillation from pre-trained convolutional networks. In this paper, we ask the following question: is it possible to combine the strengths of these two architectures while avoiding their respective limitations? To this end, we introduce gated positional self-attention (GPSA), a form of positional self-attention which can be equipped with a ‘soft’ convolutional inductive bias. We initialize the GPSA layers to mimic the locality of convolutional layers, then give each attention head the freedom to escape locality by adjusting a gating parameter regulating the attention paid to position versus content information. The resulting convolutional-like ViT architecture, ConViT,",2
05a34a3f9d7ccd3a3247d41533b3c17028663f9a,A State of Art Survey for Concurrent Computation and Clustering of Parallel Computing for Distributed Systems,"In this paper, several works has been presented related to the clustering parallel computing for distributed system. The trend of the paper is to focus on the strength points of previous works in this field towards enhancing performance of the distributed systems. This concentration conducted via presenting several techniques where each of them has the weak and strong features. The most challenging points for all techniques vary from increasing the performance of the system to time responding to overcome overhead running of the system. For more specific addressing concurrent computation besides parallel computing classifications for distributed systems, this paper depended comprehensive features study and comparison between SYNC and ASYNC Modes.",3
2cef702e6cd1ada90c6ee7311825ee978b81526a,The Filter Bubble: What the Internet Is Hiding from You,"none Copyright Information: All rights reserved unless otherwise indicated. Contact the author or original publisher for any necessary permissions. eScholarship is not the copyright owner for deposited works. Learn more at http://www.escholarship.org/help_copyright.html#reuse The Filter Bubble: What the Internet is Hiding from You by Eli Pariser. New York: Penguin Press, 2011. 294 pp. ISBN: 978-0-670-92038-9 “We’re not evil. We try really hard not to be evil. But if we wanted to, man, could we ever.” An unnamed Google engineer, interviewed in The Filter Bubble. In 1991, Mark Weiser wrote, “the most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it... The constant background presence of these products...does not require active attention...It [becomes] difficult to imagine modern life otherwise” (p. 94). Weiser, a Xerox PARC researcher, would witness the personal computing revolution from an epicenter of technological innovation. Though Weiser’s",7
3508b5e9b7fee02a5f2c628340fb9aa69b9f40c2,Improving Organizational Performance Through the Use of Big Data,"ABSTRACT The number of firms that plan to invest in big data usage has been reduced as many of them are still trying to understand the necessary conditions needed to improve their performance through the processing and use of big data. In this study, we leverage the resource-based view to investigate the role of tools sophistication, big data utilization, and employee analytical skills in improving organizational performance. The research model is validated empirically from 140 senior IT professionals using survey data. The findings show that when firms process big data, organizational performance is at its highest when firms use sophisticated tools, while this is not the case when firms do not process big data. Furthermore, findings show that, interestingly, at the lower levels of employee analytical skills, there is no significant impact of big data utilization on organizational performance, suggesting important implications for theory and for the guidance of business",6
3127190433230b3dc1abd0680bb58dced4bcd90e,Large Scale Distributed Deep Networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",21
23f2343d3406ea250e0cc929aa9104c462251470,A control model for object virtualization in supply chain management,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
0b8001f143f94353f4b41ec68276c24df4175d7d,Research challenges of big data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
d2c059e953a2881e98631dfafd581e61d992834f,Transferable and Extensible Machine Learning-Derived Atomic Charges for Modeling Hybrid Nanoporous Materials,Nanoporous materials have attracted significant interest as an emerging platform for adsorption-related applications. The high-throughput computational screening became a standard technique to acce...,5
22d6d9c1b7ac2738b51d93be45ac8f753f81867c,Stacked Autoencoders for Unsupervised Feature Learning and Multiple Organ Detection in a Pilot Study Using 4D Patient Data,"Medical image analysis remains a challenging application area for artificial intelligence. When applying machine learning, obtaining ground-truth labels for supervised learning is more difficult than in many more common applications of machine learning. This is especially so for datasets with abnormalities, as tissue types and the shapes of the organs in these datasets differ widely. However, organ detection in such an abnormal dataset may have many promising potential real-world applications, such as automatic diagnosis, automated radiotherapy planning, and medical image retrieval, where new multimodal medical images provide more information about the imaged tissues for diagnosis. Here, we test the application of deep learning methods to organ identification in magnetic resonance medical images, with visual and temporal hierarchical features learned to categorize object classes from an unlabeled multimodal DCE-MRI dataset so that only a weakly supervised training is required for a classifier. A probabilistic patch-based method was employed for multiple organ",5
5bed7d79f3937694647f5ce30796df053ef54be7,Points of view: Sets and intersections,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
7abb451f13c899cfea0c0a8a3061c2ddea5c4bd1,The changing privacy landscape in the era of big data,"Mol Syst Biol. 8: 612 Thirty years ago, it was relatively easy to protect one's privacy and remain anonymous. Few computerized systems existed to store our personal information, the internet was so primitive that most were not even aware it existed, and only a few thousand individuals were privileged enough to own a handheld cellular phone. Fast forward to our current day and life—everything has changed. Rapid electronic transactions among individuals and between individuals and entire communities occur on an unprecedented scale, our life stream is continuously digitized and archived—GPS positioning information, cell phone calls, text messages, credit card purchases, e‐mails, online social network chatter and even our electronic medical records (Figure 1). In fact, today the marketing department of your neighborhood Target can know before you that your own daughter is pregnant, given changes in purchase patterns (Duhigg, 2012). Long gone are the days of anonymity and privacy. Figure",3
9c42f726882b0ab4539afd34b546ae710aa1ceb0,Techniques and applications for sentiment analysis,The main applications and challenges of one of the hottest research areas in computer science.,5
00396270ed338ff24d612ad1530b8eb2ba194f06,Strength in Numbers: How Does Data-Driven Decisionmaking Affect Firm Performance?,"We examine whether firms that emphasize decision making based on data and business analytics (“data driven decision making” or DDD) show higher performance. Using detailed survey data on the business practices and information technology investments of 179 large publicly traded firms, we find that firms that adopt DDD have output and productivity that is 5-6% higher than what would be expected given their other investments and information technology usage. Furthermore, the relationship between DDD and performance also appears in other performance measures such as asset utilization, return on equity and market value. Using instrumental variables methods, we find evidence that the effect of DDD on the productivity do not appear to be due to reverse causality. Our results provide some of the first large scale data on the direct connection between data-driven decision making and firm performance.",4
595cb1395e5e4bfc9a879c90378bd7bcd697d4b8,Smart Brushing for Parallel Coordinates,"The Parallel Coordinates plot is a popular tool for the visualization of high-dimensional data. One of the main challenges when using parallel coordinates is occlusion and overplotting resulting from large data sets. Brushing is a popular approach to address these challenges. Since its conception, limited improvements have been made to brushing both in the form of visual design and functional interaction. We present a set of novel, smart brushing techniques that enhance the standard interactive brushing of a parallel coordinates plot. We introduce two new interaction concepts: Higher-order, sketch-based brushing, and smart, data-driven brushing. Higher-order brushes support interactive, flexible, n-dimensional pattern searches involving an arbitrary number of dimensions. Smart, data-driven brushing provides interactive, real-time guidance to the user during the brushing process based on derived meta-data. In addition, we implement a selection of novel enhancements and user options that complement the two techniques as well as enhance the exploration and",2
39c11c2e7aa513751520c9d9712e71d9549c90a1,Artificial Intelligence in the Agri-Food System: Rethinking Sustainable Business Models in the COVID-19 Scenario,"The aim of the paper is to investigate the artificial intelligence (AI) function in agri-food industry, as well as the role of stakeholders in its supply chain. Above all, from the beginning of the new millennium, scholars and practitioners have paid an increasing attention to artificial intelligence (AI) technologies in operational processes management and challenges for new business models, in a sustainable and socially responsible perspective. Thus, the stakeholders can assume a proactive or marginal role in the value creation for business, according to their own environmental awareness. These issues appear still “open” in some industries, such as the agri-food system, where the adoption of new technologies requires rethinking and redesigning the whole business model. Methodologically, we brought forward an in-depth review of the literature about major articles in this field. Especially, the study has been conducted following two phases: firstly, we extracted from scientific databases (Web of Science, Scopus,",4
c814d3840ea1e80572a4ccf648152fc6560d8de1,Comparing biological information contained in mRNA and non-coding RNAs for classification of lung cancer patients,"Deciphering the meaning of the human DNA is an outstanding goal which would revolutionize medicine and our way for treating diseases. In recent years, non-coding RNAs have attracted much attention and shown to be functional in part. Yet the importance of these RNAs especially for higher biological functions remains under investigation. In this paper, we analyze RNA-seq data, including non-coding and protein coding RNAs, from lung adenocarcinoma patients, a histologic subtype of non-small-cell lung cancer, with deep learning neural networks and other state-of-the-art classification methods. The purpose of our paper is three-fold. First, we compare the classification performance of different versions of deep belief networks with SVMs, decision trees and random forests. Second, we compare the classification capabilities of protein coding and non-coding RNAs. Third, we study the influence of feature selection on the classification performance. As a result, we find that deep belief networks perform at least competitively to",6
63fbb97022470c59252040b72581fd164b96a0bf,Does data analytics use improve firm decision making quality? The role of knowledge sharing and data analytics competency,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
62ce35108ef0a816ba1929223f511c976079a300,k-Anonymity: A Model for Protecting Privacy,"Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k- anonymity unless accompanying policies are respected. The k-anonymity protection model is important because",10
de3b22bff59655a4dd79deb93f9dccbd7dff4118,Association Testing of Previously Reported Variants in a Large Case-Control Meta-analysis of Diabetic Nephropathy,"We formed the GEnetics of Nephropathy–an International Effort (GENIE) consortium to examine previously reported genetic associations with diabetic nephropathy (DN) in type 1 diabetes. GENIE consists of 6,366 similarly ascertained participants of European ancestry with type 1 diabetes, with and without DN, from the All Ireland-Warren 3-Genetics of Kidneys in Diabetes U.K. and Republic of Ireland (U.K.-R.O.I.) collection and the Finnish Diabetic Nephropathy Study (FinnDiane), combined with reanalyzed data from the Genetics of Kidneys in Diabetes U.S. Study (U.S. GoKinD). We found little evidence for the association of the EPO promoter polymorphism, rs161740, with the combined phenotype of proliferative retinopathy and end-stage renal disease in U.K.-R.O.I. (odds ratio [OR] 1.14, P = 0.19) or FinnDiane (OR 1.06, P = 0.60). However, a fixed-effects meta-analysis that included the previously reported cohorts retained a genome-wide significant association with that phenotype (OR 1.31, P = 2 × 10−9). An expanded investigation of the",2
1be2b20d5ad1c4602a7ceb972ae705c5c82ab591,Wired for Innovation: How Information Technology Is Reshaping the Economy,"A wave of business innovation is driving the productivity resurgence in the U.S. economy. In Wired for Innovation, Erik Brynjolfsson and Adam Saunders describe how information technology directly or indirectly created this productivity explosion, reversing decades of slow growth. They argue that the companies with the highest level of returns to their technology investment are doing more than just buying technology; they are inventing new forms of organizational capital to become digital organizations. These innovations include a cluster of organizational and business-process changes, including broader sharing of information, decentralized decision-making, linking pay and promotions to performance, pruning of non-core products and processes, and greater investments in training and education. Brynjolfsson and Saunders go on to examine the real sources of value in the emerging information economy, including intangible inputs and outputs that have defied traditional metrics. For instance, intangible organizational capital is not directly observable on a balance sheet yet",3
05b5a32d2f3795a9f73a841db985aea2441ed562,Predicting online shopping behaviour from clickstream data using deep learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
f3c79f628a7a83840a200ad47aaadfb4a2531a35,Reference architecture design for farm management information systems: a multi-case study approach,"One of the key elements of precision agriculture is the farm management information system (FMIS) that is responsible for data management, analytics and subsequent decision support. Various FMISs have been developed to support the management of farm businesses. A key artefact in the development of FMISs is the software architecture that defines the gross level structure of the system. The software architecture is important for understanding the system, analysing the design decisions and guiding the further development of the system based on the architecture. To assist in the design of the FMIS architecture, several reference architectures have been provided in the literature. Unfortunately, in practice, it is less trivial to derive the application architecture from these reference architectures. Two underlying reasons for this were identified. First of all, it appears that the proposed reference architectures do not specifically focus on FMIS but have a rather broad scope of the agricultural",3
048760760e5f522e84562bb24a90ead2355669ea,One-Class based learning for Hybrid Spectrum Sensing in Cognitive Radio,"The main aim of the Spectrum Sensing (SS) in a Cognitive Radio system is to distinguish between the binary hypotheses H0: Primary User (PU) is absent and H1: PU is active. In this paper, Machine Learning (ML)-based hybrid Spectrum Sensing (SS) scheme is proposed. The scattering of the Test Statistics (TSs) of two detectors is used in the learning and prediction phases. As the SS decision is binary, the proposed scheme requires the learning of only the boundaries of H0-class in order to make a decision on the PU status: active or idle. Thus, a set of data generated under H0 hypothesis is used to train the detection system. Accordingly, unlike the existing ML-based schemes of the literature, no PU statistical parameters are required. In order to discriminate between H0-class and elsewhere, we used a one-class classification approach that is inspired by the Isolation Forest algorithm. Extensive simulations are done",4
cad44703024c5b44fd8d9625cfb66f5c68edbf3b,Supply chain analytics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
b656558175947d339acfba31813aed4c4684ca86,A survey of big data management: Taxonomy and state-of-the-art,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
eb8655151cc0cf1ff58aa58aef690f52027c6613,Estimation of Locally Relevant Subspace in High-dimensional Data,"High-dimensional data is becoming more and more available due to the advent of big data and IoT. Having more dimensions makes data analysis cumbersome increasing the sparsity of data points due to the problem called “curse of dimensionality“. To address this problem, global dimensionality reduction techniques are used; however, these techniques are ineffective in revealing hidden outliers from the high-dimensional space. This is due to the behaviour of outliers being hidden in the subspace where they belong; hence, a locally relevant subspace is needed to reveal the hidden outliers. In this paper, we present a technique that identifies a locally relevant subspace and associated low-dimensional subspaces by deriving a final correlation score. To verify the effectiveness of the technique in determining the generalised locally relevant subspace, we evaluate the results with a benchmark data set. Our comparative analysis shows that the technique derived the locally relevant subspace that consists of",3
67ea3cb20608797f5e8798a183ca45a6d345e146,‘Datafication’: making sense of (big) data in a complex world,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",11
78dcbbaf53b95e84e3b6c1f245514342e650cce0,"Analytics at Work: Smarter Decisions, Better Results","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
9a71b600cd1505aed6b0951c2917a888c2666e06,"Big Data, Bigger Outcomes","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
91e611c3e8705002438fb4439733e47ddec85b5d,fastai: A Layered API for Deep Learning,"fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two",4
c58716b6b1c8a8594dffbfa01084c9ec50fc4885,Predictive Analytics Techniques Using Big Data for Healthcare Databases,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
b340d619f34df9258d983b41eceba05d9eb052ee,The role of positive and negative valence factors on the impact of bigness of data on big data analytics usage,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
cc137d03d4451effe4ebdd5ef5847578a459edb4,Crop Yield Prediction through Proximal Sensing and Machine Learning Algorithms,"Proximal sensing techniques can potentially survey soil and crop variables responsible for variations in crop yield. The full potential of these precision agriculture technologies may be exploited in combination with innovative methods of data processing such as machine learning (ML) algorithms for the extraction of useful information responsible for controlling crop yield. Four ML algorithms, namely linear regression (LR), elastic net (EN), k-nearest neighbor (k-NN), and support vector regression (SVR), were used to predict potato (Solanum tuberosum) tuber yield from data of soil and crop properties collected through proximal sensing. Six fields in Atlantic Canada including three fields in Prince Edward Island (PE) and three fields in New Brunswick (NB) were sampled, over two (2017 and 2018) growing seasons, for soil electrical conductivity, soil moisture content, soil slope, normalized-difference vegetative index (NDVI), and soil chemistry. Data were collected from 39–40 30 × 30 m2 locations in each field, four times",3
49051605a56a9c82a2401f96c3471312d00552d9,A Novel PCA-Firefly Based XGBoost Classification Model for Intrusion Detection in Networks Using GPU,"The enormous popularity of the internet across all spheres of human life has introduced various risks of malicious attacks in the network. The activities performed over the network could be effortlessly proliferated, which has led to the emergence of intrusion detection systems. The patterns of the attacks are also dynamic, which necessitates efficient classification and prediction of cyber attacks. In this paper we propose a hybrid principal component analysis (PCA)-firefly based machine learning model to classify intrusion detection system (IDS) datasets. The dataset used in the study is collected from Kaggle. The model first performs One-Hot encoding for the transformation of the IDS datasets. The hybrid PCA-firefly algorithm is then used for dimensionality reduction. The XGBoost algorithm is implemented on the reduced dataset for classification. A comprehensive evaluation of the model is conducted with the state of the art machine learning approaches to justify the superiority of our proposed approach.",4
16165b1e5f91eb27b0104c9d87d8940f7d8e2a7b,It's Complicated: The Social Lives of Networked Teens,"When I was a senior in high school, I joined America Online, which was, for many of my generation, our first real taste of the Internet. I often chatted with friends through instant messenger, but I also spent many late nights exploring the topic-specific chat rooms talking with people who shared similar interests. Most importantly, I used AOL to locate and introduce myself to current and fellow incoming students at my future college, gaining both friends and valuable information before I ever stepped foot on campus. Even though my introduction to mediated social interactions occurred more than a decade before the interviews highlighted in danah boyd’s new book, It’s Complicated: The Social Lives of Networked Teens, I found myself easily identifying with the perspectives and experiences these teens shared as they navigated identity, privacy, and relationships via technology. In many ways, not much has changed: Teens today face many of",1
c70490db33fc0de7878a4457c1f369d8ebc52075,A hybrid unsupervised clustering-based anomaly detection method,"In recent years, machine learning-based cyber intrusion detection methods have gained increasing popularity. The number and complexity of new attacks continue to rise; therefore, effective and intelligent solutions are necessary. Unsupervised machine learning techniques are particularly appealing to intrusion detection systems since they can detect known and unknown types of attacks as well as zero-day attacks. In the current paper, we present an unsupervised anomaly detection method, which combines Sub-Space Clustering (SSC) and One Class Support Vector Machine (OCSVM) to detect attacks without any prior knowledge. The proposed approach is evaluated using the well-known NSL-KDD dataset. The experimental results demonstrate that our method performs better than some of the existing techniques.",4
d05d86db86a4ac0d95e6dcd951b42a9651939793,Deep Learning Approach for Intelligent Intrusion Detection System,"Machine learning techniques are being widely used to develop an intrusion detection system (IDS) for detecting and classifying cyberattacks at the network-level and the host-level in a timely and automatic manner. However, many challenges arise since malicious attacks are continually changing and are occurring in very large volumes requiring a scalable solution. There are different malware datasets available publicly for further research by cyber security community. However, no existing study has shown the detailed analysis of the performance of various machine learning algorithms on various publicly available datasets. Due to the dynamic nature of malware with continuously changing attacking methods, the malware datasets available publicly are to be updated systematically and benchmarked. In this paper, a deep neural network (DNN), a type of deep learning model, is explored to develop a flexible and effective IDS to detect and classify unforeseen and unpredictable cyberattacks. The continuous change in network behavior and",7
2533dcb5642df1aa80176912de81207e62f9a397,Predictive Analytics for Readmission of Patients with Congestive Heart Failure,"Mitigating preventable readmissions, where patients are readmitted for the same primary diagnosis within 30 days, poses a significant challenge to the delivery of high-quality healthcare. Toward this end, we develop a novel, predictive analytics model, termed as the beta geometric Erlang-2 BG/EG hurdle model, which predicts the propensity, frequency, and timing of readmissions of patients diagnosed with congestive heart failure CHF. This unified model enables us to answer three key questions related to the use of predictive analytics methods for patient readmissions: whether a readmission will occur, how often readmissions will occur, and when a readmission will occur. We test our model using a unique data set that tracks patient demographic, clinical, and administrative data across 67 hospitals in North Texas over a four-year period. We show that our model provides superior predictive performance compared to extant models such as the logit, BG/NBD hurdle, and EG hurdle models. Our model",7
befe585e679c7fdf2f9df84b87fcbdc289bb14b2,Fog Computing Approaches in Smart Cities: A State-of-the-Art Review,"These days, the development of smart cities, specifically in location-aware, latency-sensitive, and security-crucial applications (such as emergency fire events, patient health monitoring, or real-time manufacturing) heavily depends on a more advance computing paradigms that can address these requirements. In this regard, fog computing, a robust cloud computing complement, plays a preponderant role by virtue of locating closer to the end-devices. Nonetheless, utilized approaches in smart cities are frequently cloud-based, which causes not only the security and time-sensitive services to suffer but also its flexibility and reliability to be restricted. So as to obviate the limitations of cloud and other related computing paradigms such as edge computing, this paper proposes a systematic literature review (SLR) for the state-of-the-art fog-based approaches in smart cities. Furthermore, according to the content of the reviewed researches, a taxonomy is proposed, falls into three classes, including service-based, resource-based, and application-based. This SLR also investigates the evaluation",4
97ecd97a364dc8cd00c740d8e6acce5c5ed064dc,Opinion mining about a product by analyzing public tweets in Twitter,"In this paper we have explained the detailed work done in developing a system which can be used for the purpose of opinion analysis of a product or a service. The system readily processes the tweets by pulling data from tweeter posts, preprocessing it and connecting to Alchemy API by REST call method. and showing the result graphically. We have given the analysis for the product Samsung Galaxy Our proposed system access the public tweets by API and filters them for Samsung Galaxy. The analysis is being carried out as to classify the sentiment as positive, negative or neutral.",2
505b2f4f5364ec43657c13932b334b6f1f3fc7a8,Investigating the Value of Sociomaterialism in Conceptualizing IT Capability of a Firm,"Sociomateriality (or sociomaterialism) allows us to approach the information technology (IT) capability research from an angle that has been rarely visited by information systems scholars. While relevant studies presume that humans and materials are distinct and largely independent, sociomateriality emphasizes agency that represents the relational, emergent, and shifting capacity realized through the association of actors (both humans and materials). The objective of this paper is to explore the value of conducting IT capability research through the theoretical lens of sociomaterialism. For this, we expand the imbrication metaphor introduced in an early study to explain the formation and advancement of a firm's IT capability from the sociomaterial perspective. Then, the key building blocks of IT capability of an organization are conceptualized based on the combination of existing studies and the expanded imbrication metaphor. Lastly, the effectiveness of formulating IT capability as a third-order construct that substantiates the entanglement concept of sociomaterialism",3
d459aaa782a6553783f80c2c4301f7fea1f30680,Multiphysics Stimulated Simulation Digital Twin Methods for Fleet Management,"The objectives of fleet management are typically readiness, availability, and reduced risk and cost. Of course, data management is essential to handle multiple data streams from many platforms. But the heart of successful, proactive fleet management is the science and engineering behind the interpretive analysis used for each ""tail number."" That is the focus of the present paper. Science and engineering have generally focused on detecting discrete events, especially early in life, then on deciding when a certain ""collection"" of those events warrants corrective action (e.g., maintenance). This approach has two serious shortcomings for composite material components. First, composite structures rarely fail from damage initiation; they generally fail from damage accumulation and interaction. Second, the limits on performance (e.g., stiffness, strength, and life) are determined by emergent behavior defined by interactive degradation events (from ""the bottom"") and by the assembly of extrinsic factors including manufacturing, geometry and morphology, load history,",5
be78a87bbfc30a540b477087089d106ce2b394f1,Integration of Cloud computing and Internet of Things: A survey,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
0b9476177e70d281d4a52aa60809b6a15d2a7523,PF-Net: Point Fractal Network for 3D Point Cloud Completion,"In this paper, we propose a Point Fractal Network (PF-Net), a novel learning-based approach for precise and high-fidelity point cloud completion. Unlike existing point cloud completion networks, which generate the overall shape of the point cloud from the incomplete point cloud and always change existing points and encounter noise and geometrical loss, PF-Net preserves the spatial arrangements of the incomplete point cloud and can figure out the detailed geometrical structure of the missing region(s) in the prediction. To succeed at this task, PF-Net estimates the missing point cloud hierarchically by utilizing a feature-points-based multi-scale generating network. Further, we add up multi-stage completion loss and adversarial loss to generate more realistic missing region(s). The adversarial loss can better tackle multiple modes in the prediction. Our experiments demonstrate the effectiveness of our method for several challenging point cloud completion tasks.",2
05a2f1fe94ac485d9adf9a5bce131b66c56b47c4,Cloud Programming Simplified: A Berkeley View on Serverless Computing,"Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.",3
51871d01c26acb651c81adaf073c32c3d9ec0f0b,Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge,"The computation for today's intelligent personal assistants such as Apple Siri, Google Now, and Microsoft Cortana, is performed in the cloud. This cloud-only approach requires significant amounts of data to be sent to the cloud over the wireless network and puts significant computational pressure on the datacenter. However, as the computational resources in mobile devices become more powerful and energy efficient, questions arise as to whether this cloud-only processing is desirable moving forward, and what are the implications of pushing some or all of this compute to the mobile devices on the edge. In this paper, we examine the status quo approach of cloud-only processing and investigate computation partitioning strategies that effectively leverage both the cycles in the cloud and on the mobile device to achieve low latency, low energy consumption, and high datacenter throughput for this class of intelligent applications. Our study uses 8 intelligent applications spanning computer vision,",3
1f7190fc294246f83f1f331cc51e3264851d0d36,Above the Clouds: A Berkeley View of Cloud Computing,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",22
e50db41ef56a0c33832ac35b269e4b1139903dcb,Cloud RAN for Mobile Networks—A Technology Overview,"Cloud Radio Access Network (C-RAN) is a novel mobile network architecture which can address a number of challenges the operators face while trying to support growing end-user's needs. The main idea behind C-RAN is to pool the Baseband Units (BBUs) from multiple base stations into centralized BBU Pool for statistical multiplexing gain, while shifting the burden to the high-speed wireline transmission of In-phase and Quadrature (IQ) data. C-RAN enables energy efficient network operation and possible cost savings on baseband resources. Furthermore, it improves network capacity by performing load balancing and cooperative processing of signals originating from several base stations. This paper surveys the state-of-the-art literature on C-RAN. It can serve as a starting point for anyone willing to understand C-RAN architecture and advance the research on C-RAN.",5
adeb6bf8919b9b6b458486499b936f649ae31c2b,IoT-Cloud-Based Smart Healthcare Monitoring System for Heart Disease Prediction via Deep Learning,"The Internet of Things confers seamless connectivity between people and objects, and its confluence with the Cloud improves our lives. Predictive analytics in the medical domain can help turn a reactive healthcare strategy into a proactive one, with advanced artificial intelligence and machine learning approaches permeating the healthcare industry. As the subfield of ML, deep learning possesses the transformative potential for accurately analysing vast data at exceptional speeds, eliciting intelligent insights, and efficiently solving intricate issues. The accurate and timely prediction of diseases is crucial in ensuring preventive care alongside early intervention for people at risk. With the widespread adoption of electronic clinical records, creating prediction models with enhanced accuracy is key to harnessing recurrent neural network variants of deep learning possessing the ability to manage sequential time-series data. The proposed system acquires data from IoT devices, and the electronic clinical data stored on the cloud pertaining to patient history",2
805f2ab1c5c6035744d647744af58a1359df12c1,What Is Cloud Computing?,"Cloud computing is a distributed environment for multiple organizations to use remotely and get high scalability, reliability on anytime, anywhere, and pay-as-you-go concepts. An organization has to create data centres to store, manage, and process the information to achieve benefits from data and make decisions. Cloud gives organizations a successful approach that leads to profit without maintaining the cost of data centres and technical staff to manage the services. Cloud has different types of architectures, types of clouds, and cost packages for using the cloud. These services can be scaled up or down when required by an organization. Cloud has unbeatable future because IT world is acquiring it and giving a boost to their businesses. Many cloud providers are using it and the remaining are moving to cloud. Cloud computing also gives birth to edge computing, fog computing, and many more zero downtime solutions.",3
8fc928bb430d3f72ac876ca156042ad1860acacd,"Article in Press Future Generation Computer Systems ( ) – Future Generation Computer Systems Cloud Computing and Emerging It Platforms: Vision, Hype, and Reality for Delivering Computing as the 5th Utility","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
80da612e1831b8c11539180871843cff6dfaac90,PoinTr: Diverse Point Cloud Completion with Geometry-Aware Transformers,"Point clouds captured in real-world applications are of-ten incomplete due to the limited sensor resolution, single viewpoint, and occlusion. Therefore, recovering the complete point clouds from partial ones becomes an indispensable task in many practical applications. In this paper, we present a new method that reformulates point cloud completion as a set-to-set translation problem and design a new model, called PoinTr that adopts a transformer encoder-decoder architecture for point cloud completion. By rep-resenting the point cloud as a set of unordered groups of points with position embeddings, we convert the point cloud to a sequence of point proxies and employ the transformers for point cloud generation. To facilitate transformers to better leverage the inductive bias about 3D geometric structures of point clouds, we further devise a geometry-aware block that models the local geometric relationships explicitly. The migration of transformers enables our model to better learn structural knowledge and preserve detailed",5
1bb466a643ef08434fbb6527cfc3d891d2932f8f,Cloud Computing - The Business Perspective,"If cloud computing (CC) is to achieve its potential, there needs to be a clear understanding of the various issues involved, both from the perspectives of the providers and the consumers of the technology. There is an equally urgent need for understanding the business-related issues surrounding CC. We interviewed several industry executives who are either involved as developers or are evaluating CC as an enterprise user. We identify the strengths, weaknesses, opportunities and threats for the industry. We also identify the various issues that will affect the different stakeholders of CC. We issue a set of recommendations for the practitioners who will provide and manage this technology. For IS researchers, we outline the different areas of research that need attention so that we are in a position to advise the industry in the years to come. Finally, we outline some of the key issues facing governmental agencies who will be",5
80f5ee8578ee76e2c17824f211762ffec7e029d4,VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection,"Accurate detection of objects in 3D point clouds is a central problem in many applications, such as autonomous navigation, housekeeping robots, and augmented/virtual reality. To interface a highly sparse LiDAR point cloud with a region proposal network (RPN), most existing efforts have focused on hand-crafted feature representations, for example, a bird's eye view projection. In this work, we remove the need of manual feature engineering for 3D point clouds and propose VoxelNet, a generic 3D detection network that unifies feature extraction and bounding box prediction into a single stage, end-to-end trainable deep network. Specifically, VoxelNet divides a point cloud into equally spaced 3D voxels and transforms a group of points within each voxel into a unified feature representation through the newly introduced voxel feature encoding (VFE) layer. In this way, the point cloud is encoded as a descriptive volumetric representation, which is then connected to a RPN to generate detections.",21
731304583d2e40bf6ee030e3cd81f767713f999a,CloneCloud: elastic execution between mobile device and cloud,"Mobile applications are becoming increasingly ubiquitous and provide ever richer functionality on mobile devices. At the same time, such devices often enjoy strong connectivity with more powerful machines ranging from laptops and desktops to commercial clouds. This paper presents the design and implementation of CloneCloud, a system that automatically transforms mobile applications to benefit from the cloud. The system is a flexible application partitioner and execution runtime that enables unmodified mobile applications running in an application-level virtual machine to seamlessly off-load part of their execution from mobile devices onto device clones operating in a computational cloud. CloneCloud uses a combination of static analysis and dynamic profiling to partition applications automatically at a fine granularity while optimizing execution time and energy use for a target computation and communication environment. At runtime, the application partitioning is effected by migrating a thread from the mobile device at a chosen point to the clone",15
59e258b91748c8b44dac3572ac75845ee52cb649,"Oceanic phytoplankton, atmospheric sulphur, cloud albedo and climate","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
fcc0eb6ff52827a121673280ea34f870d0c93b54,3D is here: Point Cloud Library (PCL),"With the advent of new, low-cost 3D sensing hardware such as the Kinect, and continued efforts in advanced point cloud processing, 3D perception gains more and more importance in robotics, as well as other fields. In this paper we present one of our most recent initiatives in the areas of point cloud perception: PCL (Point Cloud Library - http://pointclouds.org). PCL presents an advanced and extensive approach to the subject of 3D perception, and it's meant to provide support for all the common 3D building blocks that applications need. The library contains state-of-the art algorithms for: filtering, feature estimation, surface reconstruction, registration, model fitting and segmentation. PCL is supported by an international community of robotics and perception researchers. We provide a brief walkthrough of PCL including its algorithmic capabilities and implementation strategies.",10
572a5aa00f0569887469ffb7554699c21156ba0b,FoldingNet: Point Cloud Auto-Encoder via Deep Grid Deformation,"Recent deep networks that directly handle points in a point set, e.g., PointNet, have been state-of-the-art for supervised learning tasks on point clouds such as classification and segmentation. In this work, a novel end-to-end deep auto-encoder is proposed to address unsupervised learning challenges on point clouds. On the encoder side, a graph-based enhancement is enforced to promote local structures on top of PointNet. Then, a novel folding-based decoder deforms a canonical 2D grid onto the underlying 3D object surface of a point cloud, achieving low reconstruction errors even for objects with delicate structures. The proposed decoder only uses about 7% parameters of a decoder with fully-connected neural networks, yet leads to a more discriminative representation that achieves higher linear SVM classification accuracy than the benchmark. In addition, the proposed decoder structure is shown, in theory, to be a generic architecture that is able to reconstruct an arbitrary point cloud from",30
e69fa2ec8a83fd256f7e5843dc31c125d90360dd,PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition,"Unlike its image based counterpart, point cloud based retrieval for place recognition has remained as an unexplored and unsolved problem. This is largely due to the difficulty in extracting local feature descriptors from a point cloud that can subsequently be encoded into a global descriptor for the retrieval task. In this paper, we propose the PointNetVLAD where we leverage on the recent success of deep networks to solve point cloud based retrieval for place recognition. Specifically, our PointNetVLAD is a combination/modification of the existing PointNet and NetVLAD, which allows end-to-end training and inference to extract the global descriptor from a given 3D point cloud. Furthermore, we propose the ""lazy triplet and quadruplet"" loss functions that can achieve more discriminative and generalizable global descriptors to tackle the retrieval task. We create benchmark datasets for point cloud based retrieval for place recognition, and the experimental results on these datasets show the feasibility",1
7a2e527b6d51071a54aac7a8bdb56ca735a1f78b,Large-Scale Point Cloud Semantic Segmentation with Superpoint Graphs,"We propose a novel deep learning-based framework to tackle the challenge of semantic segmentation of large-scale point clouds of millions of points. We argue that the organization of 3D point clouds can be efficiently captured by a structure called superpoint graph (SPG), derived from a partition of the scanned scene into geometrically homogeneous elements. SPGs offer a compact yet rich representation of contextual relationships between object parts, which is then exploited by a graph convolutional network. Our framework sets a new state of the art for segmenting outdoor LiDAR scans (+11.9 and +8.8 mIoU points for both Semantic3D test sets), as well as indoor scans (+12.4 mIoU points for the S3DIS dataset).",16
6da3d71dc601fd9cd6b4e84bc947de5474c5873b,"A survey of mobile cloud computing: architecture, applications, and approaches","Together with an explosive growth of the mobile applications and emerging of cloud computing concept, mobile cloud computing (MCC) has been introduced to be a potential technology for mobile services. MCC integrates the cloud computing into the mobile environment and overcomes obstacles related to the performance (e.g., battery life, storage, and bandwidth), environment (e.g., heterogeneity, scalability, and availability), and security (e.g., reliability and privacy) discussed in mobile computing. This paper gives a survey of MCC, which helps general readers have an overview of the MCC including the definition, architecture, and applications. The issues, existing solutions, and approaches are presented. In addition, the future research directions of MCC are discussed. Copyright © 2011 John Wiley & Sons, Ltd.",6
487b787e6ca2368aff7941c86e39941db83c5087,The NIST Definition of Cloud Computing,"Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model promotes availability and is composed of five essential characteristics, three service models, and four deployment models.",13
afb1acd9cb0caa50b9b9170e3cd63fa4a6f65478,Client-Edge-Cloud Hierarchical Federated Learning,"Federated Learning is a collaborative machine learning framework to train a deep learning model without accessing clients’ private data. Previous works assume one central parameter server either at the cloud or at the edge. The cloud server can access more data but with excessive communication overhead and long latency, while the edge server enjoys more efficient communications with the clients. To combine their advantages, we propose a client-edge-cloud hierarchical Federated Learning system, supported with a HierFAVG algorithm that allows multiple edge servers to perform partial model aggregation. In this way, the model can be trained faster and better communication-computation trade-offs can be achieved. Convergence analysis is provided for HierFAVG and the effects of key parameters are also investigated, which lead to qualitative design guidelines. Empirical experiments verify the analysis and demonstrate the benefits of this hierarchical architecture in different data distribution scenarios. Particularly, it is shown that by introducing the",3
ff50b46b4e1cc0fd9beb832fc3468785b635a824,PCT: Point cloud transformer,"The irregular domain and lack of ordering make it challenging to design deep neural networks for point cloud processing. This paper presents a novel framework named Point Cloud Transformer (PCT) for point cloud learning. PCT is based on Transformer, which achieves huge success in natural language processing and displays great potential in image processing. It is inherently permutation invariant for processing a sequence of points, making it well-suited for point cloud learning. To better capture local context within the point cloud, we enhance input embedding with the support of farthest point sampling and nearest neighbor search. Extensive experiments demonstrate that the PCT achieves the state-of-the-art performance on shape classification, part segmentation, semantic segmentation, and normal estimation tasks.",6
a022334521d88eb0181e76f01b53ce42e7dcc302,An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud & Edge Systems,"Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds or thousands of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and cloud utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present DeathStarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail",3
b6cf10713451191de8f0d30211f85a1080249a74,TopNet: Structural Point Cloud Decoder,"3D point cloud generation is of great use for 3D scene modeling and understanding. Real-world 3D object point clouds can be properly described by a collection of low-level and high-level structures such as surfaces, geometric primitives, semantic parts,etc. In fact, there exist many different representations of a 3D object point cloud as a set of point groups. Existing frameworks for point cloud genera-ion either do not consider structure in their proposed solutions, or assume and enforce a specific structure/topology,e.g. a collection of manifolds or surfaces, for the generated point cloud of a 3D object. In this work, we pro-pose a novel decoder that generates a structured point cloud without assuming any specific structure or topology on the underlying point set. Our decoder is softly constrained to generate a point cloud following a hierarchical rooted tree structure. We show that given enough capacity and allowing for redundancies, the proposed decoder is",11
3b98a87a3d4c6935b29380c4070a6c637306df64,Bulk Parameterization of the Snow Field in a Cloud Model,"Abstract A two-dimensional, time-dependent cloud model has been used to simulate a moderate intensity thunderstorm for the High Plains region. Six forms of water substance (water vapor, cloud water, cloud ice, rain, snow and hail, i.e., graupel) are simulated. The model utilizes the “bulk water” microphysical parameterization technique to represent the precipitation fields which are all assumed to follow exponential size distribution functions. Autoconversion concepts are used to parameterize the collision-coalescence and collision-aggregation processes. Accretion processes involving the various forms of liquid and solid hydrometeors are simulated in this model. The transformation of cloud ice to snow through autoconversion (aggregation) and Bergeron process and subsequent accretional growth or aggregation to form hail are simulated. Hail is also produced by various contact mechanisms and via probabilistic freezing of raindrops. Evaporation (sublimation) is considered for all precipitation particles outsi...",0
f48d322244c906b45792b28206df7cfb23495004,Escape from Cells: Deep Kd-Networks for the Recognition of 3D Point Cloud Models,"We present a new deep learning architecture (called Kdnetwork) that is designed for 3D model recognition tasks and works with unstructured point clouds. The new architecture performs multiplicative transformations and shares parameters of these transformations according to the subdivisions of the point clouds imposed onto them by kdtrees. Unlike the currently dominant convolutional architectures that usually require rasterization on uniform twodimensional or three-dimensional grids, Kd-networks do not rely on such grids in any way and therefore avoid poor scaling behavior. In a series of experiments with popular shape recognition benchmarks, Kd-networks demonstrate competitive performance in a number of shape recognition tasks such as shape classification, shape retrieval and shape part segmentation.",39
4f940cfbfa70c67ecb026478a8607fa7ec376220,Computation Offloading and Resource Allocation For Cloud Assisted Mobile Edge Computing in Vehicular Networks,"Computation offloading services provide required computing resources for vehicles with computation-intensive tasks. Past computation offloading research mainly focused on mobile edge computing (MEC) or cloud computing, separately. This paper presents a collaborative approach based on MEC and cloud computing that offloads services to automobiles in vehicular networks. A cloud-MEC collaborative computation offloading problem is formulated through jointly optimizing computation offloading decision and computation resource allocation. Since the problem is non-convex and NP-hard, we propose a collaborative computation offloading and resource allocation optimization (CCORAO) scheme, and design a distributed computation offloading and resource allocation algorithm for CCORAO scheme that achieves the optimal solution. The simulation results show that the proposed algorithm can effectively improve the system utility and computation time, especially for the scenario where the MEC servers fail to meet demands due to insufficient computation resources.",2
c32fd8ea1b3f2df410410fb18d569dede102c53a,Diffusion Probabilistic Models for 3D Point Cloud Generation,"We present a probabilistic model for point cloud generation, which is fundamental for various 3D vision tasks such as shape completion, upsampling, synthesis and data augmentation. Inspired by the diffusion process in non-equilibrium thermodynamics, we view points in point clouds as particles in a thermodynamic system in contact with a heat bath, which diffuse from the original distribution to a noise distribution. Point cloud generation thus amounts to learning the reverse diffusion process that transforms the noise distribution to the distribution of a desired shape. Specifically, we propose to model the reverse diffusion process for point clouds as a Markov chain conditioned on certain shape latent. We derive the variational bound in closed form for training and provide implementations of the model. Experimental results demonstrate that our model achieves competitive performance in point cloud generation and auto-encoding. The code is available at https://github.com/luost26/diffusion-point-cloud.",4
7ef08f1fa127af817cdfd9d3bd00bdf60e32143b,Cloud computing: state-of-the-art and research challenges,"Cloud computing has recently emerged as a new paradigm for hosting and delivering services over the Internet. Cloud computing is attractive to business owners as it eliminates the requirement for users to plan ahead for provisioning, and allows enterprises to start from the small and increase resources only when there is a rise in service demand. However, despite the fact that cloud computing offers huge opportunities to the IT industry, the development of cloud computing technology is currently at its infancy, with many issues still to be addressed. In this paper, we present a survey of cloud computing, highlighting its key concepts, architectural principles, state-of-the-art implementation as well as research challenges. The aim of this paper is to provide a better understanding of the design challenges of cloud computing and identify important research directions in this increasingly important area.",7
2b9b4a646c5b86b0fbf0e18cd3bd0f52e06fa980,A break in the clouds: towards a cloud definition,"This paper discusses the concept of Cloud Computing to achieve a complete definition of what a Cloud is, using the main characteristics typically associated with this paradigm in the literature. More than 20 definitions have been studied allowing for the extraction of a consensus definition as well as a minimum definition containing the essential characteristics. This paper pays much attention to the Grid paradigm, as it is often confused with Cloud technologies. We also describe the relationships and distinctions between the Grid and Cloud approaches.",10
af2ad9cad35e99a9076b37176b92398a487e057d,Collaborative Cloud and Edge Computing for Latency Minimization,"By performing data processing at the network edge, mobile edge computing can effectively overcome the deficiencies of network congestion and long latency in cloud computing systems. To improve edge cloud efficiency with limited communication and computation capacities, we investigate the collaboration between cloud computing and edge computing, where the tasks of mobile devices can be partially processed at the edge node and at the cloud server. First, a joint communication and computation resource allocation problem is formulated to minimize the weighted-sum latency of all mobile devices. Then, the closed-form optimal task splitting strategy is derived as a function of the normalized backhaul communication capacity and the normalized cloud computation capacity. Some interesting and useful insights for the optimal task splitting strategy are also highlighted by analyzing four special scenarios. Based on this, we further transform the original joint communication and computation resource allocation problem into an equivalent convex optimization problem",5
49b0b43e57dc8efe3a92f06ddcb5a7f39da4790d,SO-Net: Self-Organizing Network for Point Cloud Analysis,"This paper presents SO-Net, a permutation invariant architecture for deep learning with orderless point clouds. The SO-Net models the spatial distribution of point cloud by building a Self-Organizing Map (SOM). Based on the SOM, SO-Net performs hierarchical feature extraction on individual points and SOM nodes, and ultimately represents the input point cloud by a single feature vector. The receptive field of the network can be systematically adjusted by conducting point-to-node k nearest neighbor search. In recognition tasks such as point cloud reconstruction, classification, object part segmentation and shape retrieval, our proposed network demonstrates performance that is similar with or better than state-of-the-art approaches. In addition, the training speed is significantly faster than existing point cloud recognition networks because of the parallelizability and simplicity of the proposed architecture. Our code is available at the project website.1",25
b2fdee22aa02477292b858fbafcb418932732bce,Cloud computing,"As with any new trend in the IT world, enterprises must figure out the benefits and risks of cloud computing and the best way to use this technology. The buzz around cloud computing has reached a fever pitch. Some believe it is a disruptive trend representing the next stage in the evolution of the internet. Others believe it is hype, as it uses long established computing technologies. One thing is clear: The industry needs an objective, straightforward conversation about how this new computing paradigm will impact organizations, how it can be used with existing technologies, and the potential pitfalls of proprietary technologies that can lead to lock-in and limited choice. This document is intended to initiate a conversation that will bring together the emerging cloud computing community (both cloud users and cloud vendors) around a core set of principles. We believe that these core principles are rooted in the belief",13
7545dd6921d1c4f59b2cabe2994726506fa527e1,"Aerosols, Cloud Microphysics, and Fractional Cloudiness",Increases in aerosol concentrations over the oceans may increase the amount of low-level cloudiness through a reduction in drizzle—a process that regulates the liquid-water content and the energetics of shallow marine clouds. The resulting increase in the global albedo would be in addition to the increase due to enhancement in reflectivity associated with a decrease in droplet size and would contribute to a cooling of the earth's surface.,2
3d7df210adf70f30f952739553201994b92e5630,PointWeb: Enhancing Local Neighborhood Features for Point Cloud Processing,"This paper presents PointWeb, a new approach to extract contextual features from local neighborhood in a point cloud. Unlike previous work, we densely connect each point with every other in a local neighborhood, aiming to specify feature of each point based on the local region characteristics for better representing the region. A novel module, namely Adaptive Feature Adjustment (AFA) module, is presented to find the interaction between points. For each local region, an impact map carrying element-wise impact between point pairs is applied to the feature difference map. Each feature is then pulled or pushed by other features in the same region according to the adaptively learned impact indicators. The adjusted features are well encoded with region information, and thus benefit the point cloud recognition tasks, such as point cloud segmentation and classification. Experimental results show that our model outperforms the state-of-the-arts on both semantic segmentation and shape classification datasets.",7
f0db5b28dae48d4e56a2238297f987a38d54036e,"A survey on security challenges in cloud computing: issues, threats, and solutions","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
c50a7f1850d1770fe728b8e42200e463ca669896,Cloud Computing and Grid Computing 360-Degree Compared,"Cloud computing has become another buzzword after Web 2.0. However, there are dozens of different definitions for cloud computing and there seems to be no consensus on what a cloud is. On the other hand, cloud computing is not a completely new concept; it has intricate connection to the relatively new but thirteen-year established grid computing paradigm, and other relevant technologies such as utility computing, cluster computing, and distributed systems in general. This paper strives to compare and contrast cloud computing with grid computing from various angles and give insights into the essential characteristics of both.",5
b2b0c31d036941cb557be4afb7101dc1b72f17cb,Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data,"Deep learning techniques for point cloud data have demonstrated great potentials in solving classical problems in 3D computer vision such as 3D object classification and segmentation. Several recent 3D object classification methods have reported state-of-the-art performance on CAD model datasets such as ModelNet40 with high accuracy (~92\%). Despite such impressive results, in this paper, we argue that object classification is still a challenging task when objects are framed with real-world settings. To prove this, we introduce ScanObjectNN, a new real-world point cloud object dataset based on scanned indoor scene data. From our comprehensive benchmark, we show that our dataset poses great challenges to existing point cloud classification techniques as objects from real-world scans are often cluttered with background and/or are partial due to occlusions. We identify three key open problems for point cloud object classification, and propose new point cloud classification neural networks that achieve state-of-the-art performance on classifying objects",6
22cc76c6d9b25facb2874bbcbbbfe781a4d85bcd,Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud,"In this paper, we propose a graph neural network to detect objects from a LiDAR point cloud. Towards this end, we encode the point cloud efficiently in a fixed radius near-neighbors graph. We design a graph neural network, named Point-GNN, to predict the category and shape of the object that each vertex in the graph belongs to. In Point-GNN, we propose an auto-registration mechanism to reduce translation variance, and also design a box merging and scoring operation to combine detections from multiple vertices accurately. Our experiments on the KITTI benchmark show the proposed approach achieves leading accuracy using the point cloud alone and can even surpass fusion-based algorithms. Our results demonstrate the potential of using the graph neural network as a new approach for 3D object detection. The code is available at https://github.com/WeijingShi/Point-GNN.",3
30a82a63a339c1e69aac36b23900544fe9ec97bb,CloudSim: a toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms,"Cloud computing is a recent advancement wherein IT infrastructure and applications are provided as ‘services’ to end‐users under a usage‐based payment model. It can leverage virtualized services even on the fly based on requirements (workload patterns and QoS) varying with time. The application services hosted under Cloud computing model have complex provisioning, composition, configuration, and deployment requirements. Evaluating the performance of Cloud provisioning policies, application workload models, and resources performance models in a repeatable manner under varying system and user configurations and requirements is difficult to achieve. To overcome this challenge, we propose CloudSim: an extensible simulation toolkit that enables modeling and simulation of Cloud computing systems and application provisioning environments. The CloudSim toolkit supports both system and behavior modeling of Cloud system components such as data centers, virtual machines (VMs) and resource provisioning policies. It implements generic application provisioning techniques that can be extended with ease and limited effort.",7
0d46406058396f66fca4a248b897956159dfabcb,PointFlow: 3D Point Cloud Generation With Continuous Normalizing Flows,"As 3D point clouds become the representation of choice for multiple vision and graphics applications, the ability to synthesize or reconstruct high-resolution, high-fidelity point clouds becomes crucial. Despite the recent success of deep learning models in discriminative tasks of point clouds, generating point clouds remains challenging. This paper proposes a principled probabilistic framework to generate 3D point clouds by modeling them as a distribution of distributions. Specifically, we learn a two-level hierarchy of distributions where the first level is the distribution of shapes and the second level is the distribution of points given a shape. This formulation allows us to both sample shapes and sample an arbitrary number of points from a shape. Our generative model, named PointFlow, learns each level of the distribution with a continuous normalizing flow. The invertibility of normalizing flows enables the computation of the likelihood during training and allows us to train our model in",12
1a620e05f545f9e729e4e30adb035452af40e0dc,A Survey on End-Edge-Cloud Orchestrated Network Computing Paradigms,"Sending data to the cloud for analysis was a prominent trend during the past decades, driving cloud computing as a dominant computing paradigm. However, the dramatically increasing number of devices and data traffic in the Internet-of-Things (IoT) era are posing significant burdens on the capacity-limited Internet and uncontrollable service delay. It becomes difficult to meet the delay-sensitive and context-aware service requirements of IoT applications by using cloud computing alone. Facing these challenges, computing paradigms are shifting from the centralized cloud computing to distributed edge computing. Several new computing paradigms, including Transparent Computing, Mobile Edge Computing, Fog Computing, and Cloudlet, have emerged to leverage the distributed resources at network edge to provide timely and context-aware services. By integrating end devices, edge servers, and cloud, they form a hierarchical IoT architecture, i.e., End-Edge-Cloud orchestrated architecture to improve the performance of IoT systems. This article presents a comprehensive survey of these emerging computing",4
0d88252e3a8777618d680fbb7fe64f8c1bdd1483,Efficient Multi-User Computation Offloading for Mobile-Edge Cloud Computing,"Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper, we first study the multi-user computation offloading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution, and hence adopt a game theoretic approach for achieving efficient computation offloading in a distributed manner. We formulate the distributed computation offloading decision making problem among mobile device users as a multi-user computation offloading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the finite improvement property. We then design a distributed computation offloading algorithm that can achieve a Nash equilibrium, derive the upper bound of the convergence time, and quantify its efficiency ratio over the centralized optimal solutions in",16
20f846fc514c4b2ef83a2e0764dce29f4ea8a925,"IoT and Cloud Computing Issues, Challenges and Opportunities: A Review","With the exponential growth of the Industrial Internet of Things (IIoT), multiple outlets are constantly producing a vast volume of data. It is unwise to locally store all the raw data in the IIoT devices since the energy and storage spaces of the end devices are strictly constrained. self-organization and short-range Internet of Things (IoT) networking also support outsourced data and cloud computing, independent of the distinctive resource constraint properties. For the remainder of the findings, there is a sequence of unfamiliar safeguards for IoT and cloud integration problems. The delivery of cloud computing is highly efficient, storage is becoming more and more current, and some groups are now altering their data from in house records Cloud Computing Vendors' hubs. Intensive IoT applications for workloads and data are subject to challenges while utilizing cloud computing tools. In this report, we research IoT and cloud computing and address cloud-compatible problems and",4
477a1de90ba8f22e4f4068ff8d6233afe74db936,GRNet: Gridding Residual Network for Dense Point Cloud Completion,"Estimating the complete 3D point cloud from an incomplete one is a key problem in many vision and robotics applications. Mainstream methods (e.g., PCN and TopNet) use Multi-layer Perceptrons (MLPs) to directly process point clouds, which may cause the loss of details because the structural and context of point clouds are not fully considered. To solve this problem, we introduce 3D grids as intermediate representations to regularize unordered point clouds. We therefore propose a novel Gridding Residual Network (GRNet) for point cloud completion. In particular, we devise two novel differentiable layers, named Gridding and Gridding Reverse, to convert between point clouds and 3D grids without losing structural information. We also present the differentiable Cubic Feature Sampling layer to extract features of neighboring points, which preserves context information. In addition, we design a new loss function, namely Gridding Loss, to calculate the L1 distance between the 3D grids of the predicted",7
c69859fd9ee74e5287c5dbf22ee7e82663fe8bdd,Benchmarking cloud serving systems with YCSB,"While the use of MapReduce systems (such as Hadoop) for large scale data analysis has been widely recognized and studied, we have recently seen an explosion in the number of systems developed for cloud data serving. These newer systems address ""cloud OLTP"" applications, though they typically do not support ACID transactions. Examples of systems proposed for cloud serving use include BigTable, PNUTS, Cassandra, HBase, Azure, CouchDB, SimpleDB, Voldemort, and many others. Further, they are being applied to a diverse range of applications that differ considerably from traditional (e.g., TPC-C like) serving workloads. The number of emerging cloud serving systems and the wide range of proposed applications, coupled with a lack of apples-to-apples performance comparisons, makes it difficult to understand the tradeoffs between systems and the workloads for which they are suited. We present the ""Yahoo! Cloud Serving Benchmark"" (YCSB) framework, with the goal of facilitating performance comparisons of the new",5
49403326211c20b3c1ac7f6b6ac2471a11af8f07,A Survey on Internet of Things and Cloud Computing for Healthcare,"The fast development of the Internet of Things (IoT) technology in recent years has supported connections of numerous smart things along with sensors and established seamless data exchange between them, so it leads to a stringy requirement for data analysis and data storage platform such as cloud computing and fog computing. Healthcare is one of the application domains in IoT that draws enormous interest from industry, the research community, and the public sector. The development of IoT and cloud computing is improving patient safety, staff satisfaction, and operational efficiency in the medical industry. This survey is conducted to analyze the latest IoT components, applications, and market trends of IoT in healthcare, as well as study current development in IoT and cloud computing-based healthcare applications since 2015. We also consider how promising technologies such as cloud computing, ambient assisted living, big data, and wearables are being applied in the healthcare industry",5
dd2819016c6bf244c39b3e6707b60389bbdbcd21,Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point Modeling,"We present Point-BERT, a new paradigm for learning Transformers to generalize the concept of BERT [8] to 3D point cloud. Inspired by BERT, we devise a Masked Point Modeling (MPM) task to pre-train point cloud Transformers. Specifically, we first divide a point cloud into several local point patches, and a point cloud Tokenizer with a discrete Variational AutoEncoder (dVAE) is designed to generate discrete point tokens containing meaningful local information. Then, we randomly mask out some patches of input point clouds and feed them into the backbone Transformers. The pre-training objective is to recover the original point tokens at the masked locations under the supervision of point tokens obtained by the Tokenizer. Extensive experiments demonstrate that the proposed BERT-style pre-training strategy significantly improves the performance of standard point cloud Transformers. Equipped with our pre-training strategy, we show that a pure Transformer architecture attains 93.8% accuracy on ModelNet40 and 83.1% accuracy",2
7ce6eca495909de2ffa0b6d9c16993757208764e,PointRCNN: 3D Object Proposal Generation and Detection From Point Cloud,"In this paper, we propose PointRCNN for 3D object detection from raw point cloud. The whole framework is composed of two stages: stage-1 for the bottom-up 3D proposal generation and stage-2 for refining proposals in the canonical coordinates to obtain the final detection results. Instead of generating proposals from RGB image or projecting point cloud to bird's view or voxels as previous methods do, our stage-1 sub-network directly generates a small number of high-quality 3D proposals from point cloud in a bottom-up manner via segmenting the point cloud of the whole scene into foreground points and background. The stage-2 sub-network transforms the pooled points of each proposal to canonical coordinates to learn better local spatial features, which is combined with global semantic features of each point learned in stage-1 for accurate box refinement and confidence prediction. Extensive experiments on the 3D detection benchmark of KITTI dataset show that our proposed",11
5deef74e922df23a636a3fd4e33c119247de8d30,A view of cloud computing,Clearing the clouds away from the true potential and obstacles posed by this computing capability.,7
1284ed4bf6a043ecf8cebca09e4811f1e3b83b65,Federated Optimization in Heterogeneous Networks,"Federated Learning is a distributed learning paradigm with two key challenges that differentiate it from traditional distributed optimization: (1) significant variability in terms of the systems characteristics on each device in the network (systems heterogeneity), and (2) non-identically distributed data across the network (statistical heterogeneity). In this work, we introduce a framework, FedProx, to tackle heterogeneity in federated networks. FedProx can be viewed as a generalization and re-parametrization of FedAvg, the current state-of-the-art method for federated learning. While this re-parameterization makes only minor modifications to the method itself, these modifications have important ramifications both in theory and in practice. Theoretically, we provide convergence guarantees for our framework when learning over data from non-identical distributions (statistical heterogeneity), and while adhering to device-level systems constraints by allowing each participating device to perform a variable amount of work (systems heterogeneity). Practically, we demonstrate that FedProx allows for more robust convergence than FedAvg across",7
ab33e9ced1913a2dd687e5e8f7af9efc9a8673d9,Hermes: Latency Optimal Task Assignment for Resource-constrained Mobile Computing,"With mobile devices increasingly able to connect to cloud servers from anywhere, resource-constrained devices can potentially perform offloading of computational tasks to either save local resource usage or improve performance. It is of interest to find optimal assignments of tasks to local and remote devices that can take into account the application-specific profile, availability of computational resources, and link connectivity, and find a balance between energy consumption costs of mobile devices and latency for delay-sensitive applications. We formulate an NP-hard problem to minimize the application latency while meeting prescribed resource utilization constraints. Different from most of existing works that either rely on the integer programming solver, or on heuristics that offer no theoretical performance guarantees, we propose Hermes, a novel fully polynomial time approximation scheme (FPTAS). We identify for a subset of problem instances, where the application task graphs can be described as serial trees, Hermes provides a solution with",2
d2bcea9743f2ea056d90db968cc020932d7bad24,Cost-Aware Virtual USB Drive: Providing Cost-Effective Block I/O Management Commercial Cloud Storage for Mobile Devices,"This paper addresses difficulties in mapping blocks onto cloud storage and proposes a novel cost-aware log-structured block I/O management over one of the commercial cloud storage, Amazon S3. The proposed scheme is imbedded in the virtual USB drive architecture that replaces the NAND flash of the USB memory with the capacity-free network storage. The key of the proposed scheme is to perform onto the cloud storage log-structured writes with the optimal number of data blocks that adaptively changes with I/O characteristics (the number of I/O operations and storage size) and cloud storage pricing policy. The proposed scheme also efficiently manages associate metadata by using well-organized data structures and layouts both in the memory and on the cloud storage. Performance analysis shows that the proposed scheme can reduce the total I/O costs significantly up to 54%, as compared with a simple one-to-one mapping scheme.",1
fe6901f657ea8457cf30a5360916f2f14de58870,vManage: loosely coupled platform and virtualization management in data centers,"Management is an important challenge for future enterprises. Previous work has addressed platform management (e.g., power and thermal management) separately from virtualization management (e.g., virtual machine (VM) provisioning, application performance). Coordinating the actions taken by these different management layers is important and beneficial, for reasons of performance, stability, and efficiency. Such coordination, in addition to working well with existing multi-vendor solutions, also needs to be extensible to support future new management solutions potentially operating on different sensors and actuators. In response to these requirements, this paper proposes vManage, a solution to loosely couple platform and virtualization management and facilitate coordination between them in data centers. Our solution is comprised of registry and proxy mechanisms that provide unified monitoring and actuation across platform and virtualization domains, and coordinators that provide policy execution for better VM placement and runtime management, including a formal approach to ensure system stability from inefficient management actions.",7
e1799aaf23c12af6932dc0ef3dfb1638f01413d1,Dynamic Graph CNN for Learning on Point Clouds,"Point clouds provide a flexible geometric representation suitable for countless applications in computer graphics; they also comprise the raw output of most 3D data acquisition devices. While hand-designed features on point clouds have long been proposed in graphics and vision, however, the recent overwhelming success of convolutional neural networks (CNNs) for image analysis suggests the value of adapting insight from CNN to the point cloud world. Point clouds inherently lack topological information, so designing a model to recover topology can enrich the representation power of point clouds. To this end, we propose a new neural network module dubbed EdgeConv suitable for CNN-based high-level tasks on point clouds, including classification and segmentation. EdgeConv acts on graphs dynamically computed in each layer of the network. It is differentiable and can be plugged into existing architectures. Compared to existing modules operating in extrinsic space or treating each point independently, EdgeConv has several appealing",49
10c6eddfff30567d8b06475422a60920f3c84857,PointCNN,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",15
e6ec919e8ec35ea1b6d7bebda034dad47af803eb,Comparative accuracy of selected multiple scattering approximations,"Abstract Computational results have been obtained for the plane albedo, total transmission and fractional absorption of plane-parallel atmospheres composed of cloud droplets. These computations, which were obtained using the doubling method, are compared with comparable results obtained using selected radiative transfer approximations. Both the relative and absolute accuracies of asymptotic theory for thick layers and delta-Eddington, Meador–Weaver and Coakley–Chýlek approximations are compared as a function of optical thickness, solar zenith angle and single scattering albedo. Asymptotic theory is found to be accurate to within 5% for all optical thickness greater than about 6. On the other hand, the Coakley–Chýlek approximation is accurate to within 5% for thin atmospheres having optical thickness less than about 0.2 for most values of the solar zenith angle. Though the accuracies of delta-Eddington and Meador-Weaver approximations are less easily summarized it can generally be concluded that the delta-...",2
e2e0e226f1f74ff65c0de3e5ad565bcd8b9710da,Adaptive Federated Learning in Resource Constrained Edge Computing Systems,"Emerging technologies and applications including Internet of Things, social networking, and crowd-sourcing generate large amounts of data at the network edge. Machine learning models are often built from the collected data, to enable the detection, classification, and prediction of future events. Due to bandwidth, storage, and privacy concerns, it is often impractical to send all the data to a centralized location. In this paper, we consider the problem of learning model parameters from data distributed across multiple edge nodes, without sending raw data to a centralized place. Our focus is on a generic class of machine learning models that are trained using gradient-descent-based approaches. We analyze the convergence bound of distributed gradient descent from a theoretical point of view, based on which we propose a control algorithm that determines the best tradeoff between local update and global parameter aggregation to minimize the loss function under a given resource budget. The",5
b6112124ff22b6f7e9a23b862a5d9a8f1f1ff742,Discrete Point Flow Networks for Efficient Point Cloud Generation,"Generative models have proven effective at modeling 3D shapes and their statistical variations. In this paper we investigate their application to point clouds, a 3D shape representation widely used in computer vision for which, however, only few generative models have yet been proposed. We introduce a latent variable model that builds on normalizing flows with affine coupling layers to generate 3D point clouds of an arbitrary size given a latent shape representation. To evaluate its benefits for shape modeling we apply this model for generation, autoencoding, and single-view shape reconstruction tasks. We improve over recent GAN-based models in terms of most metrics that assess generation and autoencoding. Compared to recent work based on continuous flows, our model offers a significant speedup in both training and inference times for similar or better performance. For single-view shape reconstruction we also obtain results on par with state-of-the-art voxel, point cloud, and mesh-based methods.",3
ad11826f21ebff84a86d93920e8770d202d8ff55,Future global warming from atmospheric trace gases,"Human activity this century has increased the concentrations of atmospheric trace gases, which in turn has elevated global surface temperatures by blocking the escape of thermal infrared radiation. Natural climate variations are masking this temperature increase, but further additions of trace gases during the next 65 years could double or even quadruple the present effects, causing the global average temperature to rise by at least 1 °C and possibly by more than 5 °C. If the rise continues into the twenty-second century, the global average temperature may reach higher values than have occurred in the past 10 million years.",2
8c31e0862a7f26fd1a4a52045ffcf24b8b82292e,Multi-Task Multi-Sensor Fusion for 3D Object Detection,"In this paper we propose to exploit multiple related tasks for accurate multi-sensor 3D object detection. Towards this goal we present an end-to-end learnable architecture that reasons about 2D and 3D object detection as well as ground estimation and depth completion. Our experiments show that all these tasks are complementary and help the network learn better representations by fusing information at various levels. Importantly, our approach leads the KITTI benchmark on 2D, 3D and bird's eye view object detection, while being real-time.",4
960dcf1b4585fde8c3a6c6e6bf34cef6b5596d0c,CloudAnalyst: A CloudSim-Based Visual Modeller for Analysing Cloud Computing Environments and Applications,"Advances in Cloud computing opens up many new possibilities for Internet applications developers. Previously, a main concern of Internet applications developers was deployment and hosting of applications, because it required acquisition of a server with a fixed capacity able to handle the expected application peak demand and the installation and maintenance of the whole software infrastructure of the platform supporting the application. Furthermore, server was underutilized because peak traffic happens only at specific times. With the advent of the Cloud, deployment and hosting became cheaper and easier with the use of pay-peruse flexible elastic infrastructure services offered by Cloud providers. Because several Cloud providers are available, each one offering different pricing models and located in different geographic regions, a new concern of application developers is selecting providers and data center locations for applications. However, there is a lack of tools that enable developers to evaluate requirements of large-scale Cloud applications",4
449fe9af9de799d075556e62f82bf0dff3faac99,Photo-oxidation of dimethylsulphide in aqueous solution,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
8faaa20dc9af4defa14735d85e19e2651bc537cd,Massively Distributed Systems : From Grids and P2P to Clouds,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
e6b052f798b245c05fc73faf1673c8cf24bc6411,Multiplexing gains achieved in pools of baseband computation units in 4G cellular networks,"The tremendous increase of mobile user traffic load within the last few years forces us to efficiently use the wireless network and processing resources. Cloud computing and virtualization techniques offer an exciting opportunity to considerably reduce operation costs and provide flexible and dynamic systems. In this paper we present a simulation study for a cloud base station, which concentrates baseband processing functions of multiple radio sites. There we focus on the multiplexing-gains induced from user load and traffic heterogeneity. Our simulation results show that the data traffic influences the variance of the compute resource utilization, which in consequence leads to significant multiplexing gains if multiple sectors are aggregated into one single cloud base station. In addition, the spatial user distribution has a high impact on the compute resource load. These findings should be taken into account for the assessment of multiplexing gains in real networks.",2
7947033f776b926458ae3c99cfe6d76f00319d7f,PointWise: An Unsupervised Point-wise Feature Learning Network,"We present a novel approach to learning a point-wise, meaningful embedding for point-clouds in an unsupervised manner, through the use of neural-networks. The domain of point-cloud processing via neural-networks is rapidly evolving, with novel architectures and applications frequently emerging. Within this field of research, the availability and plethora of unlabeled point-clouds as well as their possible applications make finding ways of characterizing this type of data appealing. Though significant advancement was achieved in the realm of unsupervised learning, its adaptation to the point-cloud representation is not trivial. Previous research focuses on the embedding of entire point-clouds representing an object in a meaningful manner. We present a deep learning framework to learn point-wise description from a set of shapes without supervision. Our approach leverages self-supervision to define a relevant loss function to learn rich per-point features. We train a neural-network with objectives based on context derived directly from the raw data,",3
39c34713fe6503c3782cabbdf72ebeb7fc9bcafa,VoxSegNet: Volumetric CNNs for Semantic Part Segmentation of 3D Shapes,"Volumetric representation has been widely used for 3D deep learning in shape analysis due to its generalization ability and regular data format. However, for fine-grained tasks like part segmentation, volumetric data has not been widely adopted compared to other representations. Aiming at delivering an effective volumetric method for 3D shape part segmentation, this paper proposes a novel volumetric convolutional neural network. Our method can extract discriminative features encoding detailed information from voxelized 3D data under limited resolution. To this purpose, a spatial dense extraction (SDE) module is designed to preserve spatial resolution during feature extraction procedure, alleviating the loss of details caused by sub-sampling operations such as max pooling. An attention feature aggregation (AFA) module is also introduced to adaptively select informative features from different abstraction levels, leading to segmentation with both semantic consistency and high accuracy of details. Experimental results demonstrate that promising results can be achieved by using",7
cdc8ecdb79c24b44b3fc5296a18d937a68faf2a6,A Logic Programming Approach to Scientific Workflow Provenance Querying,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
21392a527c80839067c0c814763f6b320ee6665e,Amdahl's law for tail latency,"Queueing theoretic models can guide design trade-offs in systems targeting tail latency, not just average performance.",3
7961709c5b5e3289476f574a99b457756901102b,Treadmill: Attributing the Source of Tail Latency through Precise Load Testing and Statistical Inference,"Managing tail latency of requests has become one of the primary challenges for large-scale Internet services. Data centers are quickly evolving and service operators frequently desire to make changes to the deployed software and production hardware configurations. Such changes demand a confident understanding of the impact on one's service, in particular its effect on tail latency (e.g., 95th-or 99th-percentile response latency of the service). Evaluating the impact on the tail is challenging because of its inherent variability. Existing tools and methodologies for measuring these effects suffer from a number of deficiencies including poor load tester design, statistically inaccurate aggregation, and improper attribution of effects. As shown in the paper, these pitfalls can often result in misleading conclusions. In this paper, we develop a methodology for statistically rigorous performance evaluation and performance factor attribution for server workloads. First, we find that careful design of the server load tester can ensure high",8
baa5277988d41c72b9e57abaa6337e5069488cd2,"3D visual perception for self-driving cars using a multi-camera system: Calibration, mapping, localization, and obstacle detection","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
1cc4baab05896e91fd911b847dc2ac892adeb38e,Joint Channel Access and Sampling Rate Control in Energy Harvesting Cognitive Radio Sensor Networks,"In this paper, we investigate the network utility maximization problem in energy harvesting cognitive radio sensor networks (CRSNs). Different from traditional sensor networks, sensor nodes in CRSNs are embedded cognitive radio modules, enabling them to dynamically access the licensed channels. Since the dynamic channel access is critical to guarantee the network capacity for CRSNs, existing solutions without considering the dynamic channel access cannot be directly applied into CRSNs. To this end, we aim at maximizing the network utility by jointly controlling the sampling rates and channel access of sensor nodes, under the energy consumption, channel capacity and interference constraints. With the consideration of fluctuated energy harvesting rates and channel switching costs, we formulate the network utility maximization as a mix-integer non-linear programming problem and solve it in an efficient and decoupled way by means of dual decomposition. A joint channel access and sampling rate control scheme, named JASC, is then",3
cfa1b66cc49e5c0b1e630614d0b12347351cab24,Flexible and Efficient Authenticated Key Agreement Scheme for BANs Based on Physiological Features,"In Body Area Networks (BANs), bio-sensors can collect personal health information and cooperate with each other to provide intelligent health care services for medical users. Since personal health information is highly privacy-sensitive, the flourish of BANs still faces critical security challenges, especially secure communication between bio-sensors. In this paper, we propose a flexible and efficient authenticated key agreement scheme (PBAKA) to provide secure communication for BANs. Specifically, we employ a control unit (e.g., smart phone) to launch authentication based on physiological features collected from BANs, and integrate bilinear pairings to negotiate session keys for bio-sensors. Since physiological features can be collected from various kinds of bio-sensors in real time, PBAKA is flexible for adding new bio-sensors without pre-distributed keys. Meanwhile, PBAKA is computationally efficient by offloading authentication burden from resource-limited bio-sensors to the control unit. Security analysis demonstrates that PBAKA is provably secure under the decisional bilinear Diffie-Hellman assumption. Extensive",7
79cfb51a51fc093f66aac8e858afe2e14d4a1f20,Focal Loss for Dense Object Detection,"The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we",17
5cfc112c932e38df95a0ba35009688735d1a386b,Federated Learning with Non-IID Data,"Federated learning enables resource-constrained edge compute devices, such as mobile phones and IoT devices, to learn a shared model for prediction, while keeping the training data local. This decentralized approach to train models provides privacy, security, regulatory and economic benefits. In this work, we focus on the statistical challenge of federated learning when local data is non-IID. We first show that the accuracy of federated learning reduces significantly, by up to 55% for neural networks trained for highly skewed non-IID data, where each client device trains only on a single class of data. We further show that this accuracy reduction can be explained by the weight divergence, which can be quantified by the earth mover's distance (EMD) between the distribution over classes on each device and the population distribution. As a solution, we propose a strategy to improve training on non-IID data by creating a small subset of data which",9
5d9b36e296e6f61177c2f1739a6ca8c553303c09,Semantic3D.net: A new Large-scale Point Cloud Classification Benchmark,"This paper presents a new 3D point cloud classification benchmark data set with over four billion manually labelled points, meant as input for data-hungry (deep) learning methods. We also discuss first submissions to the benchmark that use deep convolutional neural networks (CNNs) as a work horse, which already show remarkable performance improvements over state-of-the-art. CNNs have become the de-facto standard for many tasks in computer vision and machine learning like semantic segmentation or object detection in images, but have no yet led to a true breakthrough for 3D point cloud labelling tasks due to lack of training data. With the massive data set presented in this paper, we aim at closing this data gap to help unleash the full potential of deep learning methods for 3D labelling tasks. Our this http URL data set consists of dense point clouds acquired with static terrestrial laser scanners. It contains 8 semantic classes",9
36d28725fa8a876e2657988790489c95d7de0a2e,AWS Certified Solutions Architect Study Guide,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
9360dd86a3f6d395b2f2cbc59af45c752e71757f,Retrieve,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
54807a6395a41c1ab14655e8b56de864de113849,Research Perspectives,"This chapter offers some research perspectives. In the realm of empirics, it discusses a twofold level of observation and examines the description of forms as a point of departure. It also looks at the observation of social norms. Next, this chapter turns to norms beyond functional differentiation and autonomy. Here, it considers Luhmann's model of the pure norm. It comments on the inevitable hybrid character of social norms as well. In addition to these remarks, the chapter turns toward the challenge of historicism and the project of a comparison of theories, after which it discusses two perspectives on normativity succeeding—over-normativization and under-normativization.",6
962dc29fdc3fbdc5930a10aba114050b82fe5a3e,End-to-End Object Detection with Transformers,"We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster RCNN baseline on the challenging COCO object detection dataset. Moreover, DETR",13
ce6922002a9ce0750bfbeeb1cc763affecbbc519,Cloud Centric Authentication for Wearable Healthcare Monitoring System,"Security and privacy are the major concerns in cloud computing as users have limited access on the stored data at the remote locations managed by different service providers. These become more challenging especially for the data generated from the wearable devices as it is highly sensitive and heterogeneous in nature. Most of the existing techniques reported in the literature are having high computation and communication costs and are vulnerable to various known attacks, which reduce their importance for applicability in real-world environment. Hence, in this paper, we propose a new cloud based user authentication scheme for secure authentication of medical data. After successful mutual authentication between a user and wearable sensor node, both establish a secret session key that is used for future secure communications. The extensively-used Real-Or-Random (ROR) model based formal security analysis and the broadly-accepted Automated Validation of Internet Security Protocols and Applications (AVISPA) tool based formal security",4
c40b394ff3c657fd58d10dbbfbeabb24c869d96b,Justlookup: One Millisecond Deep Feature Extraction for Point Clouds By Lookup Tables,"Deep models are capable of fitting complex high dimensional functions while usually yielding large computation load. There is no way to speed up the inference process by classical lookup tables due to the high-dimensional input and limited memory size. Recently, a novel architecture (PointNet) for point clouds has demonstrated that it is possible to obtain a complicated deep function from a set of 3-variable functions. In this paper, we exploit this property and apply a lookup table to encode these 3-variable functions. This method ensures that the inference time is only determined by the memory access no matter how complicated the deep function is. We conduct extensive experiments on ModelNet and ShapeNet datasets and demonstrate that we can complete the inference process in 1.5 ms on an Intel i7-8700 CPU (single core mode), 32× speedup over the PointNet architecture without any performance degradation.",4
88087bd6b61eeb44148041ab4d1939b65f89e73b,C-Store: A Column-oriented DBMS,"This paper presents the design of a read-optimized relational DBMS that contrasts sharply with most current systems, which are write-optimized. Among the many differences in its design are: storage of data by column rather than by row, careful coding and packing of objects into storage including main memory during query processing, storing an overlapping collection of column-oriented projections, rather than the current fare of tables and indexes, a non-traditional implementation of transactions which includes high availability and snapshot isolation for read-only transactions, and the extensive use of bitmap indexes to complement B-tree structures.We present preliminary performance data on a subset of TPC-H and show that the system we are building, C-Store, is substantially faster than popular commercial products. Hence, the architecture looks very encouraging.",7
7fd2213b834a5e745deecc0ee375e5be05fd1b2f,"Swift: Fast, Reliable, Loosely Coupled Parallel Computation","We present Swift, a system that combines a novel scripting language called SwiftScript with a powerful runtime system based on CoG Karajan, Falkon, and Globus to allow for the concise specification, and reliable and efficient execution, of large loosely coupled computations. Swift adopts and adapts ideas first explored in the GriPhyN virtual data system, improving on that system in many regards. We describe the SwiftScript language and its use of XDTM to describe the logical structure of complex file system structures. We also present the Swift runtime system and its use of CoG Karajan, Falkon, and Globus services to dispatch and manage the execution of many tasks in parallel and grid environments. We describe application experiences and performance experiments that quantify the cost of Swift operations.",11
286802537ac6ec028e6e4ce68d2daa3c3870c7e3,An assessment of the impact of pollution on global cloud albedo,"Increased pollution leads to increasing particulate concentrations. Since some particles nucleatedrop formation, clouds will contain, with increasing pollution, more drops per unit volume, andhence will tend to be optically thicker and more reflecting. An opposite effect is also present, inthat increasing absorption also attends increasing pollution. Measurements suggest that theformer (brightening) effect is the dominant one for global climate and that the climatic effect isquite comparable to that of increased carbon dioxide, and acts in the opposite direction. DOI: 10.1111/j.1600-0889.1984.tb00254.x",8
21184368e608cccd68e3d602a090aa603c24b8e6,The Case for Mobile Edge-Clouds,"Current mobile applications treat the end-user device as a ""thin client,"" with all of the heavy computations being offloaded to an infrastructure cloud. However, the computational capabilities of mobile devices are constantly improving, and it is worthwhile considering whether an edge-cloud that consists purely of mobile devices (operating effectively as ""thick clients"") can perform as well as, or even better than, an infrastructure cloud. In this paper, we study the trade-offs between offloading computation to an infrastructure cloud versus retaining the computation within a mobile edge-cloud. To this end, we develop and run two classes of applications on both types of clouds, and we analyze the performance of the two clouds in terms of the time taken to run the application, along with the total amount of battery power consumed in both cases. Our results indicate that there are indeed classes of applications where an edge-cloud can outperform an infrastructure",4
03bce1b255a6cb57c7c9a544c87e34c8f926a255,Beef Up the Edge: Spectrum-Aware Placement of Edge Computing Services for the Internet of Things,"In this paper, we introduce a network entity called point of connection (PoC), which is equipped with customized powerful communication, computing, and storage (CCS) capabilities, and design a data transportation network (DART) of interconnected PoCs to facilitate the provision of Internet of Things (IoT) services. By exploiting the powerful CCS capabilities of PoCs, DART brings both communication and computing services much closer to end devices so that resource-constrained IoT devices could have access to the desired communication and computing services. To achieve the design goals of DART, we further study the spectrum-aware placement of edge computing services. We formulate the service placement as a stochastic mixed-integer optimization problem and propose an enhanced coarse-grained fixing procedure to facilitate efficient solution finding. Through extensive simulations, we demonstrate the effectiveness of the resulting spectrum-aware service placement strategies and the proposed solution approach.",2
11d86034218c1a2e16102f480159079b318f0391,Heart Disease Prediction Based on the Embedded Feature Selection Method and Deep Neural Network,"In recent decades, heart disease threatens people's health seriously because of its prevalence and high risk of death. Therefore, predicting heart disease through some simple physical indicators obtained from the regular physical examination at an early stage has become a valuable subject. Clinically, it is essential to be sensitive to these indicators related to heart disease to make predictions and provide a reliable basis for further diagnosis. However, the large amount of data makes manual analysis and prediction taxing and arduous. Our research aims to predict heart disease both accurately and quickly through various indicators of the body. In this paper, a novel heart disease prediction model is given. We propose a heart disease prediction algorithm that combines the embedded feature selection method and deep neural networks. This embedded feature selection method is based on the LinearSVC algorithm, using the L1 norm as a penalty item to choose a subset",3
b23eaeecd80106e27b965df898731edb49f201f2,Meteorology: Clouds and climate regulation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
f56bf3c025b29a758a4a9fac93f0a4f2e80fb6f9,Effect of Ship-Stack Effluents on Cloud Reflectivity,Under stable meteorological conditions the effect of ship-stack exhaust on overlying clouds was detected in daytime satellite images as an enhancement in cloud reflectivity at 3.7 micrometers. The exhaust is a source of cloud-condensation nuclei that increases the number of cloud droplets while reducing droplet size. This reduction in droplet size causes the reflectivity at 3.7 micrometers to be greater than the levels for nearby noncontaminated clouds of similar physical characteristics. The increase in droplet number causes the reflectivity at 0.63 micrometer to be significantly higher for the contaminated clouds despite the likelihood that the exhaust is a source of particles that absorb at visible wavelengths. The effect of aerosols on cloud reflectivity is expected to have a larger influence on the earth's albedo than that due to the direct scattering and absorption of sunlight by the aerosols alone.,5
ba46ae9b310e5c2a3f31fedc308ffcf4ebd6ab06,PowerChop: Identifying and Managing Non-critical Units in Hybrid Processor Architectures,"On-core microarchitectural structures consume significant portions of a processor's power budget. However, depending on application characteristics, those structures do not always provide (much) performance benefit. While timeout-based power gating techniques have been leveraged for underutilized cores and inactive functional units, these techniques have not directly translated to high-activity units such as vector processing units, complex branch predictors, and caches. The performance benefit provided by these units does not necessarily correspond with unit activity, but instead is a function of application characteristics. This work introduces PowerChop, a novel technique that leverages the unique capabilities of HW/SW co-designed hybrid processors to enact unit-level power management at the application phase level. PowerChop adds two small additional hardware units to facilitate phase identification and triggering different power states, enabling the software layer to cheaply track, predict and take advantage of varying unit criticality across application phases by powering gating units that are not needed",1
3c91a5fb88790f1c68ba9a2a0b4762c01a7d9c59,A novel analysis-prediction approach for geometrically nonlinear problems using group method of data handling,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
50edd67cb5b95e33c589aae8d26ee4385efd691b,A structured regularization framework for spatially smoothing semantic labelings of 3D point clouds,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
a78bc54068384d9ea6f07db89a1ce902ef56c2c6,VideoFlow: A Flow-Based Generative Model for Video,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
fe33ba23625e0039b6bddf69a63f43dfe22928b1,"BCube: a high performance, server-centric network architecture for modular data centers","This paper presents BCube, a new network architecture specifically designed for shipping-container based, modular data centers. At the core of the BCube architecture is its server-centric network structure, where servers with multiple network ports connect to multiple layers of COTS (commodity off-the-shelf) mini-switches. Servers act as not only end hosts, but also relay nodes for each other. BCube supports various bandwidth-intensive applications by speeding-up one-to-one, one-to-several, and one-to-all traffic patterns, and by providing high network capacity for all-to-all traffic. BCube exhibits graceful performance degradation as the server and/or switch failure rate increases. This property is of special importance for shipping-container data centers, since once the container is sealed and operational, it becomes very difficult to repair or replace its components. Our implementation experiences show that BCube can be seamlessly integrated with the TCP/IP protocol stack and BCube packet forwarding can be efficiently implemented in both hardware and software. Experiments in",8
0c28623a7c77b804068a5c0b29543f10c669da75,Linear Road: A Stream Data Management Benchmark,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
6400c36efdb8a66b401b6aef26c057227266fddd,PointCNN: Convolution On X-Transformed Points,"We present a simple and general framework for feature learning from point clouds. The key to the success of CNNs is the convolution operator that is capable of leveraging spatially-local correlation in data represented densely in grids (e.g. images). However, point clouds are irregular and unordered, thus directly convolving kernels against features associated with the points, will result in desertion of shape information and variance to point ordering. To address these problems, we propose to learn an $\mathcal{X}$-transformation from the input points, to simultaneously promote two causes. The first is the weighting of the input features associated with the points, and the second is the permutation of the points into a latent and potentially canonical order. Element-wise product and sum operations of the typical convolution operator are subsequently applied on the $\mathcal{X}$-transformed features. The proposed method is a generalization of typical CNNs to feature learning from point clouds, thus we",29
1254306ab0e1c8e179d9f31b4b9ea0cef7398bd8,Learning to Drive from Simulation without Real World Labels,"Simulation can be a powerful tool for under-standing machine learning systems and designing methods to solve real-world problems. Training and evaluating methods purely in simulation is often “doomed to succeed” at the desired task in a simulated environment, but the resulting models are incapable of operation in the real world. Here we present and evaluate a method for transferring a vision-based lane following driving policy from simulation to operation on a rural road without any real-world labels. Our approach leverages recent advances in image-to-image translation to achieve domain transfer while jointly learning a single-camera control policy from simulation control labels. We assess the driving performance of this method using both open-loop regression metrics, and closed-loop performance operating an autonomous vehicle on rural and urban roads.",3
325f4787a40c14518529a64332b801e6f53b22d7,"Market-Oriented Cloud Computing: Vision, Hype, and Reality for Delivering IT Services as Computing Utilities",This keynote paper: presents a 21st century vision of computing; identifies various computing paradigms promising to deliver the vision of computing utilities; defines Cloud computing and provides the architecture for creating market-oriented Clouds by leveraging technologies such as VMs; provides thoughts on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain SLA-oriented resource allocation; presents some representative Cloud platforms especially those developed in industries along with our current work towards realising market-oriented resource allocation of Clouds by leveraging the 3rd generation Aneka enterprise Grid technology; reveals our early thoughts on interconnecting Clouds for dynamically creating an atmospheric computing environment along with pointers to future community research; and concludes with the need for convergence of competing IT paradigms for delivering our 21st century vision.,8
511ff60d4aa5ab2660552f02ee85692425912b46,OctNet: Learning Deep 3D Representations at High Resolutions,"We present OctNet, a representation for deep learning with sparse 3D data. In contrast to existing models, our representation enables 3D convolutional networks which are both deep and high resolution. Towards this goal, we exploit the sparsity in the input data to hierarchically partition the space using a set of unbalanced octrees where each leaf node stores a pooled feature representation. This allows to focus memory allocation and computation to the relevant dense regions and enables deeper networks without compromising resolution. We demonstrate the utility of our OctNet representation by analyzing the impact of resolution on several 3D tasks including 3D object classification, orientation estimation and point cloud labeling.",41
484518021086915a0424b031c8d1db276b947391,External integrity verification for outsourced big data in cloud and IoT: A big picture,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
29fc18a43103814b0aec8800a5759057c333aad1,A Predictive Analysis of Heart Rates Using Machine Learning Techniques,"Heart disease, caused by low heart rate, is one of the most significant causes of mortality in the world today. Therefore, it is critical to monitor heart health by identifying the deviation in the heart rate very early, which makes it easier to detect and manage the heart’s function irregularities at a very early stage. The fast-growing use of advanced technology such as the Internet of Things (IoT), wearable monitoring systems and artificial intelligence (AI) in the healthcare systems has continued to play a vital role in the analysis of huge amounts of health-based data for early and accurate disease detection and diagnosis for personalized treatment and prognosis evaluation. It is then important to analyze the effectiveness of using data analytics and machine learning to monitor and predict heart rates using wearable device (accelerometer)-generated data. Hence, in this study, we explored a number of powerful data-driven models including the autoregressive",2
9ebdd272db2596f4f4bee741d6399363b2b6559f,SPLATNet: Sparse Lattice Networks for Point Cloud Processing,"We present a network architecture for processing point clouds that directly operates on a collection of points represented as a sparse set of samples in a high-dimensional lattice. NaÃ¯vely applying convolutions on this lattice scales poorly, both in terms of memory and computational cost, as the size of the lattice increases. Instead, our network uses sparse bilateral convolutional layers as building blocks. These layers maintain efficiency by using indexing structures to apply convolutions only on occupied parts of the lattice, and allow flexible specifications of the lattice structure enabling hierarchical and spatially-aware feature learning, as well as joint 2D-3D reasoning. Both point-based and image-based representations can be easily incorporated in a network with such layers and the resulting model can be trained in an end-to-end manner. We present results on 3D segmentation tasks where our approach outperforms existing state-of-the-art techniques.",24
0b7d3b78e23479c7b1e366ef81088aab8b5731f3,Unsupervised Multi-Task Feature Learning on Point Clouds,"We introduce an unsupervised multi-task model to jointly learn point and shape features on point clouds. We define three unsupervised tasks including clustering, reconstruction, and self-supervised classification to train a multi-scale graph-based encoder. We evaluate our model on shape classification and segmentation benchmarks. The results suggest that it outperforms prior state-of-the-art unsupervised models: In the ModelNet40 classification task, it achieves an accuracy of 89.1% and in ShapeNet segmentation task, it achieves an mIoU of 68.2 and accuracy of 88.6%.",5
d049d63ba6fa4c57cdb7334cbc3108fa3add8bb0,Cloud Computing Virtualization of Resources Allocation for Distributed Systems,"Cloud computing is a new technology which managed by a third party “cloud provider” to provide the clients with services anywhere, at any time, and under various circumstances. In order to provide clients with cloud resources and satisfy their needs, cloud computing employs virtualization and resource provisioning techniques. The process of providing clients with shared virtualized resources (hardware, software, and platform) is a big challenge for the cloud provider because of over-provision and under-provision problems. Therefore, this paper highlighted some proposed approaches and scheduling algorithms applied for resource allocation within cloud computing through virtualization in the datacenter. The paper also aims to explore the role of virtualization in providing resources effectively based on clients’ requirements. The results of these approaches showed that each proposed approach and scheduling algorithm has an obvious role in utilizing the shared resources of the cloud data center. The paper also explored that virtualization technique has",4
e1d09bdb7fc19eacc5230156733f2e92b99df825,Using Socio-Spatial Context in Mobile Cloud Process Offloading for Energy Conservation in Wireless Devices,"Abstract The high proliferation of on-line gaming along with the high demands of availability of network resources, created the need for the development of Cloudified services that will augment computation capabilities of mobile devices. To this end, this work elaborates on the design, the development and the comparative evaluation with other similar models, as well as with real-time comparisons through emulators, of a process-offloading scheme that is based on a mobile opportunistic cloud computing approach. According to the proposed approach, each mobile device with access to interactive -delay sensitive- multimedia content (i.e. online gaming with processing power requirements) exploits several network-centric parameters, by using Nano-Mobile Data Centers for an interactive, collaborative and real-time manipulation of the available resources. The communication and the social context is used by the mobile nodes with other communication related parameters, towards achieving the efficient execution of the offloading process in order to support adequate quality",2
170e2f4778f975768aaa5e888349fc0cb23d576f,Point Cloud GAN,"Generative Adversarial Networks (GAN) can achieve promising performance on learning complex data distributions on different types of data. In this paper, we first show a straightforward extension of existing GAN algorithm is not applicable to point clouds, because the constraint required for discriminators is undefined for set data. We propose a two fold modification to GAN algorithm for learning to generate point clouds (PC-GAN). First, we combine ideas from hierarchical Bayesian modeling and implicit generative models by learning a hierarchical and interpretable sampling process. A key component of our method is that we train a posterior inference network for the hidden variables. Second, instead of using only state-of-the-art Wasserstein GAN objective, we propose a sandwiching objective, which results in a tighter Wasserstein distance estimate than the commonly used dual form. Thereby, PC-GAN defines a generic framework that can incorporate many existing GAN algorithms. We validate our claims on ModelNet40 benchmark",9
8674494bd7a076286b905912d26d47f7501c4046,PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space,"Few prior works study deep learning on point sets. PointNet by Qi et al. is a pioneer in this direction. However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability to complex scenes. In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set. By exploiting metric space distances, our network is able to learn local features with increasing contextual scales. With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. Experiments show that our network called PointNet++ is able to learn deep point set features efficiently and robustly. In particular, results significantly better than state-of-the-art",80
ff605ade239aa90caea65ef3f2447c8736a794b7,Federated Learning over Wireless Networks: Optimization Model Design and Analysis,"There is an increasing interest in a new machine learning technique called Federated Learning, in which the model training is distributed over mobile user equipments (UEs), and each UE contributes to the learning model by independently computing the gradient based on its local training data. Federated Learning has several benefits of data privacy and potentially a large amount of UE participants with modern powerful processors and low-delay mobile-edge networks. While most of the existing work focused on designing learning algorithms with provable convergence time, other issues such as uncertainty of wireless channels and UEs with heterogeneous power constraints and local data size, are under-explored. These issues especially affect to various trade-offs: (i) between computation and communication latencies determined by learning accuracy level, and thus (ii) between the Federated Learning time and UE energy consumption. We fill this gap by formulating a Federated Learning over wireless network as an optimization problem",4
975b229e10f8b2d0ce6371850b4e2d02f4c46386,Outlook for research on subtropical marine stratiform clouds,"A detailed description of the goals and methodology of the First International Satellite Cloud Cover Project Regional Experiment (FIRE) is presented. The purpose of the experiment is to develop physical models and parameterizations of fractional cloud cover over the Pacific Basin. In order to determine fractional cloud cover parameters, satellite observations by radar and lidar instruments will be combined with in situ measurements of the cloud-capped marine boundary layer. A description of a candidate experiment for the program is presented, and some general problems connected with the statistical characterization of satellite imagery are discussed.",2
497591fed66f38f1cc00f160858d229d3e810ff2,An iterative double auction for mobile data offloading,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
5eb4a5ac7faa2fc75e1739b45c511ba3fab5bb56,Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling,"Unlike on images, semantic learning on 3D point clouds using a deep network is challenging due to the naturally unordered data structure. Among existing works, PointNet has achieved promising results by directly learning on point sets. However, it does not take full advantage of a point's local neighborhood that contains fine-grained structural information which turns out to be helpful towards better semantic learning. In this regard, we present two new operations to improve PointNet with a more efficient exploitation of local structures. The first one focuses on local 3D geometric structures. In analogy to a convolution kernel for images, we define a point-set kernel as a set of learnable 3D points that jointly respond to a set of neighboring data points according to their geometric affinities measured by kernel correlation, adapted from a similar technique for point cloud registration. The second one exploits local high-dimensional feature structures by recursive feature",15
378c7910e78066e251312c703c9b5959de942150,Technology Adoption,"Welcome to the 21st century, where paradigms are shifting, roles are reversing, and changes in workflow influence—perhaps even dictate—new patterns of thought. If that sounds new age to you, then you might be onto something, because this is a new age, and new rules apply. We can no longer succeed by sitting atop a power hierarchy and bending others to our will; instead, we must step into the flow of others' work. This applies to every field, including biomedical engineering, where every inventor has a story about groundbreaking technology that never reached its target market. To what extent does changing our mindset for the 21st century influence the success of a device? To answer this question, we need to know the following: when useful technology, invented by the greatest minds in science, fails, what went wrong? And more importantly, when it succeeded—both from a medical and financial point of view—what",2
d2c56eb76bdef1ad25fe635ddbf022e12cad37dd,Emergence of the Academic Computing Clouds,"Computational grids are very large-scale aggregates of communication and computation resources enabling new types of applications and bringing several benefits of economy-of-scale. The first computational grids were established in academic environments during the previous decade, and today are making inroads into the realm of corporate and enterprise computing. Very recently, we observe the emergence of cloud computing as a new potential super structure for corporate, enterprise and academic computing. While cloud computing shares the same original vision of grid computing articulated in the 1990s by Foster, Kesselman and others, there are significant differences. In this paper, we first briefly outline the architecture, technologies and standards of computational grids. We then point at some of notable examples of academic use of grids and sketch the future of research in grids. In the third section, we draw some architectural lines of cloud computing, hint at the design and technology choices and indicate",4
f58b8245e0604354b03654535f9543907edbb8b3,Limitations of Load Balancing Mechanisms for N-Tier Systems in the Presence of Millibottlenecks,"The scalability of n-tier systems relies on effective load balancing to distribute load among the servers of the same tier. We found that load balancing mechanisms (and some policies) in servers used in typical n-tier systems (e.g., Apache and Tomcat) have issues of instability when very long response time (VLRT) requests appear due to millibottlenecks, very short bottlenecks that last only tens to hundreds of milliseconds. Experiments with standard n-tier benchmarks show that during millibottlenecks, some load balancing policy/mechanism combinations make the mistake of sending new requests to the node(s) suffering from millibottlenecks, instead of the idle nodes as load balancers are supposed to do. Several of these mistakes are due to the implicit assumptions made by load balancing policies and mechanisms on the stability of system state. Our study shows that appropriate remedies at policy and mechanism levels can avoid these mistakes during millibottlenecks and remove the VLRT requests,",2
5be337b3715e619075c2855900707b42f9f61c28,3D2SeqViews: Aggregating Sequential Views for 3D Global Feature Learning by CNN With Hierarchical Attention Aggregation,"Learning 3D global features by aggregating multiple views is important. Pooling is widely used to aggregate views in deep learning models. However, pooling disregards a lot of content information within views and the spatial relationship among the views, which limits the discriminability of learned features. To resolve this issue, 3D to Sequential Views (3D2SeqViews) is proposed to more effectively aggregate the sequential views using convolutional neural networks with a novel hierarchical attention aggregation. Specifically, the content information within each view is first encoded. Then, the encoded view content information and the sequential spatiality among the views are simultaneously aggregated by the hierarchical attention aggregation, where view-level attention and class-level attention are proposed to hierarchically weight sequential views and shape classes. View-level attention is learned to indicate how much attention is paid to each view by each shape class, which subsequently weights sequential views through a novel recursive view integration. Recursive",3
4fbb1530b79432d1783017fd393c096eaebc809f,Semantic Segmentation of 3D Point Clouds Based on High Precision Range Search Network,"Semantic segmentation for 3D point clouds plays a critical role in the construction of 3D models. Due to the sparse and disordered natures of the point clouds, semantic segmentation of such unstructured data yields technical challenges. A recently proposed deep neural network, PointNet, delivers attractive semantic segmentation performance, but it only exploits the global features of point clouds without incorporating any local features, limiting its ability to recognize fine-grained patterns. For that, this paper proposes a deeper hierarchical structure called the high precision range search (HPRS) network, which can learn local features with increasing contextual scales. We develop an adaptive ball query algorithm that designs a comprehensive set of grouping strategies. It can gather detailed local feature points in comparison to the common ball query algorithm, especially when there are not enough feature points within the ball range. Furthermore, compared to the sole use of either the max pooling or",5
c258394cf93a70f815dbfe863deb18082cfa799c,Thermal time shifting: Leveraging phase change materials to reduce cooling costs in warehouse-scale computers,"Datacenters, or warehouse scale computers, are rapidly increasing in size and power consumption. However, this growth comes at the cost of an increasing thermal load that must be removed to prevent overheating and server failure. In this paper, we propose to use phase changing materials (PCM) to shape the thermal load of a datacenter, absorbing and releasing heat when it is advantageous to do so. We present and validate a methodology to study the impact of PCM on a datacenter, and evaluate two important opportunities for cost savings. We find that in a datacenter with full cooling system subscription, PCM can reduce the necessary cooling system size by up to 12% without impacting peak throughput, or increase the number of servers by up to 14.6% without increasing the cooling load. In a thermally constrained setting, PCM can increase peak throughput up to 69% while delaying the onset of thermal limits",5
a305840586d9e158bc7da5ecbf3ec3a1bb0deb90,Cloud Spanner,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
d22a270ec055216580164b4f297089845065ff23,GWCNN: A Metric Alignment Layer for Deep Shape Analysis,"Deep neural networks provide a promising tool for incorporating semantic information in geometry processing applications. Unlike image and video processing, however, geometry processing requires handling unstructured geometric data, and thus data representation becomes an important challenge in this framework. Existing approaches tackle this challenge by converting point clouds, meshes, or polygon soups into regular representations using, e.g., multi‐view images, volumetric grids or planar parameterizations. In each of these cases, geometric data representation is treated as a fixed pre‐process that is largely disconnected from the machine learning tool. In contrast, we propose to optimize for the geometric representation during the network learning process using a novel metric alignment layer. Our approach maps unstructured geometric data to a regular domain by minimizing the metric distortion of the map using the regularized Gromov–Wasserstein objective. This objective is parameterized by the metric of the target domain and is differentiable; thus, it can be easily",5
7723385449eca845cd7d4dee7f5ce17ad8f92e65,A Volunteer-Supported Fog Computing Environment for Delay-Sensitive IoT Applications,"Fog computing (FC) has emerged as a complementary solution to the centralized cloud infrastructure. An FC node is available in closer proximity to users and extends cloud services to the edge of the network in a highly distributed manner. However, with an increase in streaming and delay-sensitive Internet-of-Things (IoT) applications, FC also needs to address the issue of higher latency while forwarding compute-intensive jobs to remote cloud data centers. Hence, there is a need to investigate the use of computational resources at the edge of the network. Volunteer computing (VC) offers a reduction in the cost of maintaining high-performance computing by making use of user-owned underutilized or idle resources, e.g., laptops and desktop computers closer to fog devices. We propose volunteer-supported FC (VSFC), as a computing paradigm, that explores the interplay of these two distributed computing domains to help minimize inherent communication delays of cloud computing, energy consumption, and network",1
41d08fb733f3e50ac183490f84d6377dffccf350,A Point Set Generation Network for 3D Object Reconstruction from a Single Image,"Generation of 3D data by deep neural network has been attracting increasing attention in the research community. The majority of extant works resort to regular representations such as volumetric grids or collection of images, however, these representations obscure the natural invariance of 3D shapes under geometric transformations, and also suffer from a number of other issues. In this paper we address the problem of 3D reconstruction from a single image, generating a straight-forward form of output &#x2013; point cloud coordinates. Along with this problem arises a unique and interesting issue, that the groundtruth shape for an input image may be ambiguous. Driven by this unorthordox output form and the inherent ambiguity in groundtruth, we design architecture, loss function and learning paradigm that are novel and effective. Our final solution is a conditional shape sampler, capable of predicting multiple plausible 3D point clouds from an input image. In experiments not only",43
ac7072f8446cafabfade74e274ca4b2a90587e61,PointSIFT: A SIFT-like Network Module for 3D Point Cloud Semantic Segmentation,"Recently, 3D understanding research sheds light on extracting features from point cloud directly, which requires effective shape pattern description of point clouds. Inspired by the outstanding 2D shape descriptor SIFT, we design a module called PointSIFT that encodes information of different orientations and is adaptive to scale of shape. Specifically, an orientation-encoding unit is designed to describe eight crucial orientations, and multi-scale representation is achieved by stacking several orientation-encoding units. PointSIFT module can be integrated into various PointNet-based architecture to improve the representation ability. Extensive experiments show our PointSIFT-based framework outperforms state-of-the-art method on standard benchmark datasets. The code and trained model will be published accompanied by this paper.",15
5125a16039cabc6320c908a4764f32596e018ad3,SECOND: Sparsely Embedded Convolutional Detection,"LiDAR-based or RGB-D-based object detection is used in numerous applications, ranging from autonomous driving to robot vision. Voxel-based 3D convolutional networks have been used for some time to enhance the retention of information when processing point cloud LiDAR data. However, problems remain, including a slow inference speed and low orientation estimation performance. We therefore investigate an improved sparse convolution method for such networks, which significantly increases the speed of both training and inference. We also introduce a new form of angle loss regression to improve the orientation estimation performance and a new data augmentation approach that can enhance the convergence speed and performance. The proposed network produces state-of-the-art results on the KITTI 3D object detection benchmarks while maintaining a fast inference speed.",11
d821767b7c7315c69daa39fbb0f4a44426bfaf41,Monocular 3D Object Detection for Autonomous Driving,"The goal of this paper is to perform 3D object detection from a single monocular image in the domain of autonomous driving. Our method first aims to generate a set of candidate class-specific object proposals, which are then run through a standard CNN pipeline to obtain high-quality object detections. The focus of this paper is on proposal generation. In particular, we propose an energy minimization approach that places object candidates in 3D using the fact that objects should be on the ground-plane. We then score each candidate box projected to the image plane via several intuitive potentials encoding semantic segmentation, contextual information, size and location priors and typical object shape. Our experimental evaluation demonstrates that our object proposal generation approach significantly outperforms all monocular approaches, and achieves the best detection performance on the challenging KITTI benchmark, among published monocular competitors.",13
a58715797b61588cbd020b9a98292a98f8483420,Relation-Shape Convolutional Neural Network for Point Cloud Analysis,"Point cloud analysis is very challenging, as the shape implied in irregular points is difficult to capture. In this paper, we propose RS-CNN, namely, Relation-Shape Convolutional Neural Network, which extends regular grid CNN to irregular configuration for point cloud analysis. The key to RS-CNN is learning from relation, i.e., the geometric topology constraint among points. Specifically, the convolutional weight for local point set is forced to learn a high-level relation expression from predefined geometric priors, between a sampled point from this point set and the others. In this way, an inductive local representation with explicit reasoning about the spatial layout of points can be obtained, which leads to much shape awareness and robustness. With this convolution as a basic operator, RS-CNN, a hierarchical architecture can be developed to achieve contextual shape-aware learning for point cloud analysis. Extensive experiments on challenging benchmarks across three tasks verify RS-CNN achieves the state of",11
b04c9e851ae605592d693aa65f0d753b8af08feb,Baymax: QoS Awareness and Increased Utilization for Non-Preemptive Accelerators in Warehouse Scale Computers,"Modern warehouse-scale computers (WSCs) are being outfitted with accelerators to provide the significant compute required by emerging intelligent personal assistant (IPA) workloads such as voice recognition, image classification, and natural language processing. It is well known that the diurnal user access pattern of user-facing services provides a strong incentive to co-locate applications for better accelerator utilization and efficiency, and prior work has focused on enabling co-location on multicore processors. However, interference when co-locating applications on non-preemptive accelerators is fundamentally different than contention on multi-core CPUs and introduces a new set of challenges to reduce QoS violation. To address this open problem, we first identify the underlying causes for QoS violation in accelerator-outfitted servers. Our experiments show that queuing delay for the compute resources and PCI-e bandwidth contention for data transfer are the main two factors that contribute to the long tails of user-facing applications. We then present Baymax, a runtime",5
04ee2f5afb0883803f31397aa32ec62a5691d94c,"On-Board Object Detection: Multicue, Multimodal, and Multiview Random Forest of Local Experts","Despite recent significant advances, object detection continues to be an extremely challenging problem in real scenarios. In order to develop a detector that successfully operates under these conditions, it becomes critical to leverage upon multiple cues, multiple imaging modalities, and a strong multiview (MV) classifier that accounts for different object views and poses. In this paper, we provide an extensive evaluation that gives insight into how each of these aspects (multicue, multimodality, and strong MV classifier) affect accuracy both individually and when integrated together. In the multimodality component, we explore the fusion of RGB and depth maps obtained by high-definition light detection and ranging, a type of modality that is starting to receive increasing attention. As our analysis reveals, although all the aforementioned aspects significantly help in improving the accuracy, the fusion of visible spectrum and depth information allows to boost the accuracy by a much larger margin. The resulting",5
7040c149b797506426177d23d5ab52d402fa0fd7,A Generalization of Convolutional Neural Networks to Graph-Structured Data,"This paper introduces a generalization of Convolutional Neural Networks (CNNs) from low-dimensional grid data, such as images, to graph-structured data. We propose a novel spatial convolution utilizing a random walk to uncover the relations within the input, analogous to the way the standard convolution uses the spatial neighborhood of a pixel on the grid. The convolution has an intuitive interpretation, is efficient and scalable and can also be used on data with varying graph structure. Furthermore, this generalization can be applied to many standard regression or classification problems, by learning the the underlying graph. We empirically demonstrate the performance of the proposed CNN on MNIST, and challenge the state-of-the-art on Merck molecular activity data set.",7
eae1b4df7a8524a14f2c32a27e7038a8ab2b6091,Service-Oriented Architecture for VIEW: A Visual Scientific Workflow Management System,"Scientific workflows have recently emerged as a new paradigm for scientists to formalize and structure complex and distributed scientific processes to enable and accelerate many scientific discoveries. In contrast to business workflows, which are typically control flow oriented, scientific workflows tend to be dataflow oriented, introducing a new set of requirements for system development. These requirements demand a new architectural design for scientific workflow management systems (SWFMSs). Although several SWFMSs have been developed that provide much experience for future research and development, a study from an architectural perspective is still missing. The main contributions of this paper are: (i) based on a comprehensive survey of the literature and identification of key requirements for SWFMSs, we propose the first reference architecture for SWFMSs, (ii) in compliance with the reference architecture, we further propose a service-oriented architecture for VIEW (a VIsual sciEntificWorkflow management system), (iii) we implement VIEW to validate the feasibility",2
6d7154e0a966b0e5e4b3a8d528e82e96ad0f11cd,Secure and Optimized Load Balancing for Multitier IoT and Edge-Cloud Computing Systems,"Mobile-edge computing (MEC) has emerged as a new computing paradigm with great potential to alleviate resource limitations attributed to mobile device users (MDUs) by offloading intensive computations to ubiquitous MEC server. However, most of the current offloading policies allow MDUs to transmit their tasks to the same connected small base stations (sBSs), which invariably increases latency and limits performance gain due to overload. Moreover, the security issue mitigating sensitive communication of information is not adequately addressed. Therefore, in this study, in addition to proposing a joint load balancing and computation offloading (CO) technique for MEC systems, we introduce a new security layer to circumvent potential security issues. First, a load balancing algorithm for efficient redistribution of MDUs among sBSs is proposed. In addition, a new advanced encryption standard (AES) cryptographic technique suffused with electrocardiogram (ECG) signal-based encryption and decryption key is presented as a security layer to safeguard the vulnerability",2
c6c779ee3b702a22d8704fad98f748c34b1cdcb1,An evolutionary game for joint wireless and cloud resource allocation in mobile edge computing,"This paper mainly focuses on developing a joint cloud and wireless resource allocation algorithm based on evolutionary game (JRA-EG) considering mobile terminals' energy consumption and time delay as well as monetary cost in mobile edge computing environment. The mobile terminals (MTs) in different service areas form different populations. In addition, the competition among populations of MTs in different service areas is to share the limited amount of bandwidth and computation resources in the accessible service providers (SPs). We analyse the stability property of the evolutionary game model and obtain the evolutionary equilibrium (EE). EE is acquired by replicator dynamics approach. Simulation results show that our JRA-EG algorithm can converge to the EE rapidly. Compared with the existing algorithms, the algorithms can save more energy and have less time delay when input data size becomes larger.",6
06f3e42c28fe87156c8be5188ff38fe9845df769,Interpolated Convolutional Networks for 3D Point Cloud Understanding,"Point cloud is an important type of 3D representation. However, directly applying convolutions on point clouds is challenging due to the sparse, irregular and unordered data structure. In this paper, we propose a novel Interpolated Convolution operation, InterpConv, to tackle the point cloud feature learning and understanding problem. The key idea is to utilize a set of discrete kernel weights and interpolate point features to neighboring kernel-weight coordinates by an interpolation function for convolution. A normalization term is introduced to handle neighborhoods of different sparsity levels. Our InterpConv is shown to be permutation and sparsity invariant, and can directly handle irregular inputs. We further design Interpolated Convolutional Neural Networks (InterpCNNs) based on InterpConv layers to handle point cloud recognition tasks including shape classification, object part segmentation and indoor scene semantic parsing. Experiments show that the networks can capture both fine-grained local structures and global shape context information effectively. The proposed",3
11e4e71b13860045fa9abff5ea227463d0e7562b,Modeling and simulation of scalable Cloud computing environments and the CloudSim toolkit: Challenges and opportunities,"Cloud computing aims to power the next generation data centers and enables application service providers to lease data center capabilities for deploying applications depending on user QoS (Quality of Service) requirements. Cloud applications have different composition, configuration, and deployment requirements. Quantifying the performance of resource allocation policies and application scheduling algorithms at finer details in Cloud computing environments for different application and service models under varying load, energy performance (power consumption, heat dissipation), and system size is a challenging problem to tackle. To simplify this process, in this paper we propose CloudSim: an extensible simulation toolkit that enables modelling and simulation of Cloud computing environments. The CloudSim toolkit supports modelling and creation of one or more virtual machines (VMs) on a simulated node of a Data Center, jobs, and their mapping to suitable VMs. It also allows simulation of multiple Data Centers to enable a study on federation and associated",7
131660f9f10a831968f2fafa0985f1b5eeb0b337,SEGCloud: Semantic Segmentation of 3D Point Clouds,"3D semantic scene labeling is fundamental to agents operating in the real world. In particular, labeling raw 3D point sets from sensors provides fine-grained semantics. Recent works leverage the capabilities of Neural Networks (NNs), but are limited to coarse voxel predictions and do not explicitly enforce global consistency. We present SEGCloud, an end-to-end framework to obtain 3D point-level segmentation that combines the advantages of NNs, trilinear interpolation(TI) and fully connected Conditional Random Fields (FC-CRF). Coarse voxel predictions from a 3D Fully Convolutional NN are transferred back to the raw 3D points via trilinear interpolation. Then the FC-CRF enforces global consistency and provides fine-grained semantics on the points. We implement the latter as a differentiable Recurrent NN to allow joint optimization. We evaluate the framework on two indoor and two outdoor 3D datasets (NYU V2, S3DIS, KITTI, this http URL), and show performance comparable or superior to the state-of-the-art on all",15
bbe630072113109bc035ee7d81c09d861a466119,Continuous shape shifting: Enabling loop co-optimization via near-free dynamic code rewriting,"The class of optimizations characterized by manipulating a loop's interaction space for improved cache locality and reuse (i.e, cache tiling/blocking/strip mine and interchange) are static optimizations requiring a priori information about the microarchitectural and runtime environment of an application binary. However, particularly in datacenter environments, deployed applications face numerous dynamic environments over their lifetimes. As a result, this class of optimizations can result in sub-optimal performance due to the inability to flexibly adapt iteration spaces as cache conditions change at runtime. This paper introduces continuous shape shifiting, a compilation approach that removes the risks of cache tiling optimizations by dynamically rewriting (and reshaping) deployed, running application code. To realize continuous shape shifting, we present ShapeShifter, a framework for continuous monitoring of co-running applications and their runtime environments to reshape loop iteration spaces and pinpoint near-optimal loop tile configurations. Upon identifying a need for reshaping, a new tiling approach is quickly",1
8352e3ba20cb0fd48e2514bc1948e68108943e39,SOCK: Rapid Task Provisioning with Serverless-Optimized Containers,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
dbab629417c033f85eee334765c1253f47fb113c,Poster: Benchmarking Microservice Systems for Software Engineering Research,"Despite the prevalence and importance of microservices in industry, there exists limited research on microservices, partly due to lacking a benchmark system that reflects the characteristics of industrial microservice systems. To fill this gap, we conduct a review of literature and open source systems to identify the gap between existing benchmark systems and industrial microservice systems. Based on the results of the gap analysis, we then develop and release a medium-size benchmark system of microservice architecture.",2
e9675f461418a9c591486e5d4cecd4b42addfd75,Learning Gradient Fields for Shape Generation,"In this work, we propose a novel technique to generate shapes from point cloud data. A point cloud can be viewed as samples from a distribution of 3D points whose density is concentrated near the surface of the shape. Point cloud generation thus amounts to moving randomly sampled points to high-density areas. We generate point clouds by performing stochastic gradient ascent on an unnormalized probability density, thereby moving sampled points toward the high-likelihood regions. Our model directly predicts the gradient of the log density field and can be trained with a simple objective adapted from score-based generative models. We show that our method can reach state-of-the-art performance for point cloud auto-encoding and generation, while also allowing for extraction of a high-quality implicit surface. Code is available at this https URL.",2
b52db9e41e15f76bdcfbe674abe0314af545c430,The Rise of “Big Data” on Cloud Computing,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
9f51b01697729e046632d9575968524eaef00920,Improving the Scalability of Data Center Networks with Traffic-aware Virtual Machine Placement,"The scalability of modern data centers has become a practical concern and has attracted significant attention in recent years. In contrast to existing solutions that require changes in the network architecture and the routing protocols, this paper proposes using traffic-aware virtual machine (VM) placement to improve the network scalability. By optimizing the placement of VMs on host machines, traffic patterns among VMs can be better aligned with the communication distance between them, e.g. VMs with large mutual bandwidth usage are assigned to host machines in close proximity. We formulate the VM placement as an optimization problem and prove its hardness. We design a two-tier approximate algorithm that efficiently solves the VM placement problem for very large problem sizes. Given the significant difference in the traffic patterns seen in current data centers and the structural differences of the recently proposed data center architectures, we further conduct a comparative analysis on the",4
ead956ecdcedf5c015b91203046910c71f6c4685,Storing and Querying Scientific Workflow Provenance Metadata Using an RDBMS,"Provenance management has become increasingly important to support scientific discovery reproducibility, result interpretation, and problem diagnosis in scientific workflow environments. This paper proposes an approach to provenance management that seamlessly integrates the interoperability, extensibility, and reasoning advantages of semantic Web technologies with the storage and querying power of an RDBMS. Specifically, we propose: i) two schema mapping algorithms to map an arbitrary OWL provenance ontology to a relational database schema that is optimized for common provenance queries; ii) two efficient data mapping algorithms to map provenance RDF metadata to relational data according to the generated relational database schema, and iii) a schema-independent SPARQL-to-SQL translation algorithm that is optimized on-the-fly by using the type information of an instance available from the input provenance ontology and the statistics of the sizes of the tables in the database. Experimental results are presented to show that our algorithms are efficient and scalable.",8
810c5e5cd7f83edbd141a6e89981e116b0de405f,"Serverless Computing: One Step Forward, Two Steps Back","Serverless computing offers the potential to program the cloud in an autoscaling, pay-as-you go manner. In this paper we address critical gaps in first-generation serverless computing, which place its autoscaling potential at odds with dominant trends in modern computing: notably data-centric and distributed computing, but also open source and custom hardware. Put together, these gaps make current serverless offerings a bad fit for cloud innovation and particularly bad for data systems innovation. In addition to pinpointing some of the main shortfalls of current serverless architectures, we raise a set of challenges we believe must be met to unlock the radical potential that the cloud---with its exabytes of storage and millions of cores---should offer to innovative developers.",6
30d148d21c20c1682bfbea5ffa41d83c8abdc64c,Representation Learning and Adversarial Generation of 3D Point Clouds,"Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep autoencoder network for point clouds, which outperforms the state of the art in 3D recognition tasks. We also design GAN architectures to generate novel point-clouds. Importantly, we show that by training the GAN in the latent space learned by the autoencoder, we greatly boost the GAN's data-generating capacity, creating significantly more diverse and realistic geometries, with far simpler architectures. The expressive power of our learned embedding, obtained without human supervision, enables basic shape editing applications via simple algebraic manipulations, such as semantic part editing and shape interpolation.",5
bba345002eb750b93b2d06d7955b2ca78c49493b,A commodity market algorithm for pricing substitutable Grid resources,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
221b4a76383bca2738de607624609db332e816c1,3DmFV: Three-Dimensional Point Cloud Classification in Real-Time Using Convolutional Neural Networks,"Modern robotic systems are often equipped with a direct three-dimensional (3-D) data acquisition device, e.g., LiDAR, which provides a rich 3-D point cloud representation of the surroundings. This representation is commonly used for obstacle avoidance and mapping. Here, we propose a new approach for using point clouds for another critical robotic capability, semantic understanding of the environment (i.e., object classification). Convolutional neural networks (CNNs), that perform extremely well for object classification in 2-D images, are not easily extendible to 3-D point clouds analysis. It is not straightforward due to point clouds’ irregular format and a varying number of points. The common solution of transforming the point cloud data into a 3-D voxel grid needs to address severe accuracy versus memory size tradeoffs. In this letter, we propose a novel, intuitively interpretable, 3-D point cloud representation called 3-D modified Fisher vectors. Our representation is hybrid as it combines a coarse discrete",4
288062000d7bd7825533693d557de2ca8628dc56,Mobile Edge Computing,"Mobile edge computing is a promising paradigm that brings computing resources to mobile users at the network edge, allowing computing-intensive and delay-sensitive applications to be quickly processed by edge servers to satisfy the requirements of mobile users. In this chapter, we first introduce a hierarchical architecture of mobile edge computing that consists of a cloud plane, an edge plane, and a user plane. We then introduce three typical computation offloading decisions. Finally, we review state-of-the-art works on computation offloading and present the use case of joint computation offloading.",4
d916830788be8306ee896cb246615c5b217439a4,Meltdown: Reading Kernel Memory from User Space,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
01a836d8cde31545fa37acb43d3398aa9e2f040f,Future directions for providing better IoT infrastructure,"Internet of Things (IoT) supports a connection between objects and humans, enabling the ubiquitous computing in our daily lives. Future research directions in IoT infrastructure should consider real-time communication and scalability to provide a better experience to the users. We justify this sentence by developing an IoT micro-benchmark, which was evaluated over a real IoT middleware. Considering the observed gaps, this article describes the ideas on redesigning the IoT infrastructure, not imposing any modifications in the users' source code. The modeling combines cloud virtualization and elasticity, service decomposition and multithreading programming. The scientific contribution of the article consists of both a novel IoT infrastructure and the algorithms to control the functioning and scalability of each component.",6
38ffe43d59e6db4edc108606a56ae9b76abaa7b5,MCDNN: An Execution Framework for Deep Neural Networks on Resource-Constrained Devices,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
8961213b7bf4ecb0e15d00f4374603a1c310abca,An Edge-Computing Based Architecture for Mobile Augmented Reality,"In order to mitigate the long processing delay and high energy consumption of mobile augmented reality (AR) applications, mobile edge computing (MEC) has been recently proposed and is envisioned as a promising means to deliver better Quality of Experience (QoE) for AR consumers. In this article, we first present a comprehensive AR overview, including the indispensable components of general AR applications, fashionable AR devices, and several existing techniques for overcoming the thorny latency and energy consumption problems. Then we propose a novel hierarchical computation architecture by inserting an edge layer between the conventional user layer and cloud layer. Based on the proposed architecture, we further develop an innovative operation mechanism to improve the performance of mobile AR applications. Three key technologies are also discussed to further assist the proposed AR architecture. Simulation results are finally provided to verify that our proposals can significantly improve latency and energy performance as compared",6
e415b20462b51e31890411586dee4043d189f937,Wishbone: Profile-based Partitioning for Sensornet Applications,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
cd3a4d7f6f12775c4218fe268f9f1c2636e45346,Toward green and soft: a 5G perspective,"As the deployment and commercial operation of 4G systems are speeding up, technologists worldwide have begun searching for next generation wireless solutions to meet the anticipated demands in the 2020 era given the explosive growth of mobile Internet. This article presents our perspective of the 5G technologies with two major themes: green and soft. By rethinking the Shannon theorem and traditional cell-centric design, network capacity can be significantly increased while network power consumption is decreased. The feasibility of the combination of green and soft is investigated through five interconnected areas of research: energy efficiency and spectral efficiency co-design, no more cells, rethinking signaling/control, invisible base stations, and full duplex radio.",2
195b80fbd7541e8c5cf5cb7341efc93a24c7aa12,Mobileflow: Toward software-defined mobile networks,"Mobile carrier networks follow an architecture where network elements and their interfaces are defined in detail through standardization, but provide limited ways to develop new network features once deployed. In recent years we have witnessed rapid growth in over-the-top mobile applications and a 10-fold increase in subscriber traffic while ground-breaking network innovation took a back seat. We argue that carrier networks can benefit from advances in computer science and pertinent technology trends by incorporating a new way of thinking in their current toolbox. This article introduces a blueprint for implementing current as well as future network architectures based on a software-defined networking approach. Our architecture enables operators to capitalize on a flow-based forwarding model and fosters a rich environment for innovation inside the mobile network. In this article, we validate this concept in our wireless network research laboratory, demonstrate the programmability and flexibility of the architecture, and provide implementation and",4
f1489d11c418afddf135ac75a0c037a368c9edc3,Energy-Efficient Decision Making for Mobile Cloud Offloading,"Mobile cloud offloading migrates heavy computation from mobile devices to remote cloud resources or nearby cloudlets. It is a promising method to alleviate the struggle between resource-constrained mobile devices and resource-hungry mobile applications. Caused by frequently changing location mobile users often see dynamically changing network conditions which have a great impact on the perceived application performance. Therefore, making high-quality offloading decisions at run time is difficult in mobile environments. To balance the energy-delay tradeoff based on different offloading-decision criteria (e.g., minimum response time or energy consumption), an energy-efficient offloading-decision algorithm based on Lyapunov optimization is proposed. The algorithm determines when to run the application locally, when to forward it directly for remote execution to a cloud infrastructure and when to delegate it via a nearby cloudlet to the cloud. The algorithm is able to minimize the average energy consumption on the mobile device while ensuring that the average response time",3
3bb322718d64a34b91b29c8230c5978de5d7fb7a,PointPillars: Fast Encoders for Object Detection From Point Clouds,"Object detection in point clouds is an important aspect of many robotics applications such as autonomous driving. In this paper, we consider the problem of encoding a point cloud into a format appropriate for a downstream detection pipeline. Recent literature suggests two types of encoders; fixed encoders tend to be fast but sacrifice accuracy, while encoders that are learned from data are more accurate, but slower. In this work, we propose PointPillars, a novel encoder which utilizes PointNets to learn a representation of point clouds organized in vertical columns (pillars). While the encoded features can be used with any standard 2D convolutional detection architecture, we further propose a lean downstream network. Extensive experimentation shows that PointPillars outperforms previous encoders with respect to both speed and accuracy by a large margin. Despite only using lidar, our full detection pipeline significantly outperforms the state of the art, even among fusion methods, with",10
f01fc309b315b86c9ca66d01bae7699ba474bcea,PortLand: a scalable fault-tolerant layer 2 data center network fabric,"This paper considers the requirements for a scalable, easily manageable, fault-tolerant, and efficient data center network fabric. Trends in multi-core processors, end-host virtualization, and commodities of scale are pointing to future single-site data centers with millions of virtual end points. Existing layer 2 and layer 3 network protocols face some combination of limitations in such a setting: lack of scalability, difficult management, inflexible communication, or limited support for virtual machine migration. To some extent, these limitations may be inherent for Ethernet/IP style protocols when trying to support arbitrary topologies. We observe that data center networks are often managed as a single logical network fabric with a known baseline topology and growth model. We leverage this observation in the design and implementation of PortLand, a scalable, fault tolerant layer 2 routing and forwarding protocol for data center environments. Through our implementation and evaluation, we show that PortLand holds promise for supporting",5
4c21828885997dc52083fd8414253feb5589e261,The Bayou Architecture: Support for Data Sharing Among Mobile Users,"The Bayou System is a platform of replicated, highly-available, variable-consistency, mobile databases on which to build collaborative applications. This paper presents the preliminary system architecture along with the design goals that influenced it. We take a fresh, bottom-up and critical look at the requirements of mobile computing applications and carefully pull together both new and existing techniques into an overall architecture that meets these requirements. Our emphasis is on supporting application-specific conflict detection and resolution and on providing application controlled inconsistency.",7
2bcfce1e68e9adb5f1547307e66a7b23c16d319a,PIXOR: Real-time 3D Object Detection from Point Clouds,"We address the problem of real-time 3D object detection from point clouds in the context of autonomous driving. Speed is critical as detection is a necessary component for safety. Existing approaches are, however, expensive in computation due to high dimensionality of point clouds. We utilize the 3D data more efficiently by representing the scene from the Bird's Eye View (BEV), and propose PIXOR, a proposal-free, single-stage detector that outputs oriented 3D object estimates decoded from pixel-wise neural network predictions. The input representation, network architecture, and model optimization are specially designed to balance high accuracy and real-time efficiency. We validate PIXOR on two datasets: the KITTI BEV object detection benchmark, and a large-scale 3D vehicle detection benchmark. In both datasets we show that the proposed detector surpasses other state-of-the-art methods notably in terms of Average Precision (AP), while still runs at 10 FPS.",11
008d479b6d7818fd334f9bf0c7d30ac5ecd0e6b6,Optimizing small cell deployment by the use of C-RANs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
27b17ffd47b071ffc7a0e0adb1d623afbff3408c,Trustworthy Sensing for Public Safety in Cloud-Centric Internet of Things,"The Internet of Things (IoT) paradigm stands for virtually interconnected objects that are identifiable and equipped with sensing, computing, and communication capabilities. Implementation of services and applications over the IoT architecture can take benefit of the cloud computing concept. Sensing-as-a-Service (S2 aaS) is a cloud-inspired service model which enables access to the IoT. In this paper, we present a framework where IoT can enhance public safety by crowd management via sensing services that are provided by smart phones equipped with various types of sensors. In order to ensure trustworthiness in the presented framework, we propose a reputation-based (S2 aaS) scheme, namely, Trustworthy Sensing for Crowd Management (TSCM) for front-end access to the IoT. TSCM collects sensing data based on a cloud model and an auction procedure which selects mobile devices for particular sensing tasks and determines the payments to the users of the mobile devices that provide data. Performance evaluation",5
db33c408174eef1e40661e8279afbbbf6db2352c,Self-Supervised Learning with Swin Transformers,"We are witnessing a modeling shift from CNN to Transformers in computer vision. In this work, we present a self-supervised learning approach called MoBY, with Vision Transformers as its backbone architecture. The approach basically has no new inventions, which is combined from MoCo v2 and BYOL and tuned to achieve reasonably high accuracy on ImageNet-1K linear evaluation: 72.8% and 75.0% top-1 accuracy using DeiT-S and Swin-T, respectively, by 300-epoch training. The performance is slightly better than recent works of MoCo v3 and DINO which adopt DeiT as the backbone, but with much lighter tricks. More importantly, the general-purpose Swin Transformer backbone enables us to also evaluate the learnt representations on downstream tasks such as object detection and semantic segmentation, in contrast to a few recent approaches built on ViT/DeiT which only report linear evaluation results on ImageNet-1K due to ViT/DeiT not tamed for these dense prediction tasks. We hope our",5
c41a89d744afcdc91cc7b9f05d2abb438ed200c1,Detail Preserved Point Cloud Completion via Separated Feature Aggregation,"Point cloud shape completion is a challenging problem in 3D vision and robotics. Existing learning-based frameworks leverage encoder-decoder architectures to recover the complete shape from a highly encoded global feature vector. Though the global feature can approximately represent the overall shape of 3D objects, it would lead to the loss of shape details during the completion process. In this work, instead of using a global feature to recover the whole complete surface, we explore the functionality of multi-level features and aggregate different features to represent the known part and the missing part separately. We propose two different feature aggregation strategies, named global \& local feature aggregation(GLFA) and residual feature aggregation(RFA), to express the two kinds of features and reconstruct coordinates from their combination. In addition, we also design a refinement component to prevent the generated point cloud from non-uniform distribution and outliers. Extensive experiments have been conducted on the ShapeNet",6
65ca5c3ee6c86729f0d887ccf44b6fc31a601236,Open Cirrus: A Global Cloud Computing Testbed,"Open Cirrus is a cloud computing testbed that, unlike existing alternatives, federates distributed data centers. It aims to spur innovation in systems and applications research and catalyze development of an open source service stack for the cloud.",4
385b36574754d2e68c2cf90d1886895aead194a9,"Offloading in HetNet: A Coordination of Interference Mitigation, User Association, and Resource Allocation","The use of heterogeneous small cell-based networks to offload the traffic of existing cellular systems has recently attracted significant attention. One main challenge is solving the joint problems of interference mitigation, user association, and resource allocation. These problems are formulated as an optimization which is then analyzed using two different approaches: Markov approximation and log-linear learning. However, finding the optimal solutions of both approaches requires complete information of the whole network which is not scalable with the network size. Thus, an approach based on a Markov approximation with a novel Markov chain design and transition probabilities is proposed. This approach enables the Markov chain to converge to the bounded near optimal distribution without complete information. In the game-theoretic approach, the payoff-based log-linear learning is used, and it converges in probability to a mixed-strategy $\epsilon$ -Nash equilibrium. Based on the principles of these two approaches, a highly randomized self-organizing algorithm is",6
21248bcc81539e7cd1ef83b3b184768603f6f247,Hybrid Task Cascade for Instance Segmentation,"Cascade is a classic yet powerful architecture that has boosted performance on various tasks. However, how to introduce cascade to instance segmentation remains an open question. A simple combination of Cascade R-CNN and Mask R-CNN only brings limited gain. In exploring a more effective approach, we find that the key to a successful instance segmentation cascade is to fully leverage the reciprocal relationship between detection and segmentation. In this work, we propose a new framework, Hybrid Task Cascade (HTC), which differs in two important aspects: (1) instead of performing cascaded refinement on these two tasks separately, it interweaves them for a joint multi-stage processing; (2) it adopts a fully convolutional branch to provide spatial context, which can help distinguishing hard foreground from cluttered background. Overall, this framework can learn more discriminative features progressively while integrating complementary features together in each stage. Without bells and whistles, a single HTC obtains 38.4%",6
85d9aff092d860aebf8ea5aa255b06de25a1930e,Deep Continuous Fusion for Multi-sensor 3D Object Detection,"In this paper, we propose a novel 3D object detector that can exploit both LIDAR as well as cameras to perform very accurate localization. Towards this goal, we design an end-to-end learnable architecture that exploits continuous convolutions to fuse image and LIDAR feature maps at different levels of resolution. Our proposed continuous fusion layer encode both discrete-state image features as well as continuous geometric information. This enables us to design a novel, reliable and efficient end-to-end learnable 3D object detector based on multiple sensors. Our experimental evaluation on both KITTI as well as a large scale 3D object detection benchmark shows significant improvements over the state of the art.",11
940dd2fa074ad97d5e8efa7e867b1f4460cfb8d5,Fast Point Feature Histograms (FPFH) for 3D registration,"In our recent work [1], [2], we proposed Point Feature Histograms (PFH) as robust multi-dimensional features which describe the local geometry around a point p for 3D point cloud datasets. In this paper, we modify their mathematical expressions and perform a rigorous analysis on their robustness and complexity for the problem of 3D registration for overlapping point cloud views. More concretely, we present several optimizations that reduce their computation times drastically by either caching previously computed values or by revising their theoretical formulations. The latter results in a new type of local features, called Fast Point Feature Histograms (FPFH), which retain most of the discriminative power of the PFH. Moreover, we propose an algorithm for the online computation of FPFH features for realtime applications. To validate our results we demonstrate their efficiency for 3D registration and propose a new sample consensus based method for bringing two datasets into the convergence",14
52afbe99de04878a5ac73a4adad4b1cedae8a6ce,Multiresolution Tree Networks for 3D Point Cloud Processing,"We present multiresolution tree-structured networks to process point clouds for 3D shape understanding and generation tasks. Our network represents a 3D shape as a set of locality-preserving 1D ordered list of points at multiple resolutions. This allows efficient feed-forward processing through 1D convolutions, coarse-to-fine analysis through a multi-grid architecture, and it leads to faster convergence and small memory footprint during training. The proposed tree-structured encoders can be used to classify shapes and outperform existing point-based architectures on shape classification benchmarks, while tree-structured decoders can be used for generating point clouds directly and they outperform existing approaches for image-to-shape inference tasks learned using the ShapeNet dataset. Our model also allows unsupervised learning of point-cloud based shapes by using a variational autoencoder, leading to higher-quality generated shapes.",18
bbb606d78d379262c85c4615cb5d9c191cd2e3bf,Peeking Behind the Curtains of Serverless Platforms,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
5c126ae3421f05768d8edd97ecd44b1364e2c99a,Denoising Diffusion Probabilistic Models,"We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at this https URL",7
da09eaa1412aaf0a62622f01f50e2e801a3b4c52,Vote3Deep: Fast object detection in 3D point clouds using efficient convolutional neural networks,"This paper proposes a computationally efficient approach to detecting objects natively in 3D point clouds using convolutional neural networks (CNNs). In particular, this is achieved by leveraging a feature-centric voting scheme to implement novel convolutional layers which explicitly exploit the sparsity encountered in the input. To this end, we examine the trade-off between accuracy and speed for different architectures and additionally propose to use an L1 penalty on the filter activations to further encourage sparsity in the intermediate representations. To the best of our knowledge, this is the first work to propose sparse convolutional layers and L1 regularisation for efficient large-scale processing of 3D data. We demonstrate the efficacy of our approach on the KITTI object detection benchmark and show that VoteSDeep models with as few as three layers outperform the previous state of the art in both laser and laser-vision based approaches by margins of up to 40% while",15
be43f293cf389d2f1dd81c835d9e78c5b09ee4aa,Cutting Corners: Workbench Automation for Server Benchmarking,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
29c05c8a2f24ddf9572019b396801ad9bb21e884,3D Point Capsule Networks,"In this paper, we propose 3D point-capsule networks, an auto-encoder designed to process sparse 3D point clouds while preserving spatial arrangements of the input data. 3D capsule networks arise as a direct consequence of our unified formulation of the common 3D auto-encoders. The dynamic routing scheme and the peculiar 2D latent space deployed by our capsule networks bring in improvements for several common point cloud-related tasks, such as object classification, object reconstruction and part segmentation as substantiated by our extensive evaluations. Moreover, it enables new applications such as part interpolation and replacement.",5
b256e7155dd1a27ed9233aa4b47fd6334f5f243b,Tangent Convolutions for Dense Prediction in 3D,"We present an approach to semantic scene analysis using deep convolutional networks. Our approach is based on tangent convolutions - a new construction for convolutional networks on 3D data. In contrast to volumetric approaches, our method operates directly on surface geometry. Crucially, the construction is applicable to unstructured point clouds and other noisy real-world data. We show that tangent convolutions can be evaluated efficiently on large-scale point clouds with millions of points. Using tangent convolutions, we design a deep fully-convolutional network for semantic segmentation of 3D point clouds, and apply it to challenging real-world datasets of indoor and outdoor 3D environments. Experimental results show that the presented approach outperforms other recent deep network constructions in detailed analysis of large 3D scenes.",13
2c2d7daabd764f981950b71230e3ac96a0d21984,Monte Carlo convolution for learning on non-uniformly sampled point clouds,"Deep learning systems extensively use convolution operations to process input data. Though convolution is clearly defined for structured data such as 2D images or 3D volumes, this is not true for other data types such as sparse point clouds. Previous techniques have developed approximations to convolutions for restricted conditions. Unfortunately, their applicability is limited and cannot be used for general point clouds. We propose an efficient and effective method to learn convolutions for non-uniformly sampled point clouds, as they are obtained with modern acquisition techniques. Learning is enabled by four key novelties: first, representing the convolution kernel itself as a multilayer perceptron; second, phrasing convolution as a Monte Carlo integration problem, third, using this notion to combine information from multiple samplings at different levels; and fourth using Poisson disk sampling as a scalable means of hierarchical point cloud learning. The key idea across all these contributions is to guarantee adequate",10
b72b6fae30561a7e29392e04e82ed1ad7bce8e78,Federated Learning for Mobile Keyboard Prediction,"We train a recurrent neural network language model using a distributed, on-device learning framework called federated learning for the purpose of next-word prediction in a virtual keyboard for smartphones. Server-based training using stochastic gradient descent is compared with training on client devices using the Federated Averaging algorithm. The federated algorithm, which enables training on a higher-quality dataset for this use case, is shown to achieve better prediction recall. This work demonstrates the feasibility and benefit of training language models on client devices without exporting sensitive user data to servers. The federated learning environment gives users greater control over the use of their data and simplifies the task of incorporating privacy by default with distributed training and aggregation across a population of client devices.",7
4f37468a95ccc62debb9e5a4cb0d73489ca61190,Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography,"A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing",6
d8ba2965be9cc93439c5bb52961b504c39f16e80,RL-GAN-Net: A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion,"We present RL-GAN-Net, where a reinforcement learning (RL) agent provides fast and robust control of a generative adversarial network (GAN). Our framework is applied to point cloud shape completion that converts noisy, partial point cloud data into a high-fidelity completed shape by controlling the GAN. While a GAN is unstable and hard to train, we circumvent the problem by (1) training the GAN on the latent space representation whose dimension is reduced compared to the raw point cloud input and (2) using an RL agent to find the correct input to the GAN to generate the latent space representation of the shape that best fits the current input of incomplete point cloud. The suggested pipeline robustly completes point cloud with large missing regions. To the best of our knowledge, this is the first attempt to train an RL agent to control the GAN, which effectively learns the highly nonlinear mapping",8
b59581b31f74c34a6168e131e941f427f921b40f,Competitive pricing of information goods: Subscription pricing versus pay-per-use,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
b7dfca646ac61ec85c8e015828a05c77f2d7d22f,Self-Supervised Pretraining of 3D Features on any Point-Cloud,"Pretraining on large labeled datasets is a prerequisite to achieve good performance in many computer vision tasks like image recognition, video understanding etc. However, pretraining is not widely used for 3D recognition tasks where state-of-the-art methods train models from scratch. A primary reason is the lack of large annotated datasets because 3D data labelling is time-consuming. Recent work shows that self-supervised learning is useful to pretrain models in 3D but requires multi-view data and point correspondences. We present a simple self-supervised pretraining method that can work with single-view depth scans acquired by varied sensors, without 3D registration and point correspondences. We pretrain standard point cloud and voxel based model architectures, and show that joint pretraining further improves performance. We evaluate our models on 9 benchmarks for object detection, semantic segmentation, and object classification, where they achieve state-of-the-art results. Most notably, we set a new state-of-the-art for object detection on ScanNet",4
eff74406f7b18d20aec40db7a97ee16bbadd3df2,Learning Shape Priors for Single-View 3D Completion and Reconstruction,"The problem of single-view 3D shape completion or reconstruction is challenging, because among the many possible shapes that explain an observation, most are implausible and do not correspond to natural objects. Recent research in the field has tackled this problem by exploiting the expressiveness of deep convolutional networks. In fact, there is another level of ambiguity that is often overlooked: among plausible shapes, there are still multiple shapes that fit the 2D image equally well; i.e., the ground truth shape is non-deterministic given a single-view input. Existing fully supervised approaches fail to address this issue, and often produce blurry mean shapes with smooth surfaces but no fine details. In this paper, we propose ShapeHD, pushing the limit of single-view shape completion and reconstruction by integrating deep generative models with adversarially learned shape priors. The learned priors serve as a regularizer, penalizing the model only if its output is unrealistic, not",6
220d47d9b2872f0f0c33084fb4425424d91fa0ac,Waveglow: A Flow-based Generative Network for Speech Synthesis,"In this paper we propose WaveGlow: a flow-based network capable of generating high quality speech from mel-spectrograms. WaveGlow combines insights from Glow [1] and WaveNet [2] in order to provide fast, efficient and high-quality audio synthesis, without the need for auto-regression. WaveGlow is implemented using only a single network, trained using only a single cost function: maximizing the likelihood of the training data, which makes the training procedure simple and stable. Our PyTorch implementation produces audio samples at a rate of more than 500 kHz on an NVIDIA V100 GPU. Mean Opinion Scores show that it delivers audio quality as good as the best publicly available WaveNet implementation. All code will be made publicly available online [3].",5
63b059cdad77906ff381515b3cfac21757e5e64c,Deep Ordinal Regression Network for Monocular Depth Estimation,"Monocular depth estimation, which plays a crucial role in understanding 3D scene geometry, is an ill-posed problem. Recent methods have gained significant improvement by exploring image-level information and hierarchical features from deep convolutional neural networks (DCNNs). These methods model depth estimation as a regression problem and train the regression networks by minimizing mean squared error, which suffers from slow convergence and unsatisfactory local solutions. Besides, existing depth estimation networks employ repeated spatial pooling operations, resulting in undesirable low-resolution feature maps. To obtain high-resolution depth maps, skip-connections or multilayer deconvolution networks are required, which complicates network training and consumes much more computations. To eliminate or at least largely reduce these problems, we introduce a spacing-increasing discretization (SID) strategy to discretize depth and recast depth network learning as an ordinal regression problem. By training the network using an ordinary regression loss, our method achieves much higher accuracy and faster convergence in synch.",5
147ab7ec4c77bd9941dd6b4bbf3a039a6676cc10,Cloud Computing Characteristics and Services A Brief Review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
c843a944a58396ebea23078bda7e304bde81607c,A Hybrid Semantic Point Cloud Classification-Segmentation Framework Based on Geometric Features and Semantic Rules,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
9ab434ca694f2727293f3d82bd48782cecd4f577,Joint Resource Allocation for Latency-Sensitive Services Over Mobile Edge Computing Networks With Caching,"Mobile edge computing (MEC) has risen as a promising paradigm to provide high quality of experience via relocating the cloud server in close proximity to smart mobile devices (SMDs). In MEC networks, the MEC server with computation capability and storage resource can jointly execute the latency-sensitive offloading tasks and cache the contents requested by SMDs. In order to minimize the total latency consumption of the computation tasks, we jointly consider computation offloading, content caching, and resource allocation as an integrated model, which is formulated as a mixed integer nonlinear programming (MINLP) problem. We design an asymmetric search tree and improve the branch and bound method to obtain a set of accurate decisions and resource allocation strategies. Furthermore, we introduce the auxiliary variables to reformulate the proposed model and apply the modified generalized benders decomposition method to solve the MINLP problem in polynomial computation complexity time. Simulation results demonstrate the superiority",3
4a843c7b126efb9e7bf654799c82a0cfadd463bf,A Novel Blockchain-Based Healthcare System Design and Performance Benchmarking on a Multi-Hosted Testbed,"As a result of the proliferation of digital and network technologies in all facets of modern society, including the healthcare systems, the widespread adoption of Electronic Healthcare Records (EHRs) has become the norm. At the same time, Blockchain has been widely accepted as a potent solution for addressing security issues in any untrusted, distributed, decentralized application and has thus seen a slew of works on Blockchain-enabled EHRs. However, most such prototypes ignore the performance aspects of proposed designs. In this paper, a prototype for a Blockchain-based EHR has been presented that employs smart contracts with Hyperledger Fabric 2.0, which also provides a unified performance analysis with Hyperledger Caliper 0.4.2. The additional contribution of this paper lies in the use of a multi-hosted testbed for the performance analysis in addition to far more realistic Gossip-based traffic scenario analysis with Tcpdump tools. Moreover, the prototype is tested for performance with superior transaction",4
40b36071bd553b9fda2ea26c6d4e057f37c0e7e7,PointASNL: Robust Point Clouds Processing Using Nonlocal Neural Networks With Adaptive Sampling,"Raw point clouds data inevitably contains outliers or noise through acquisition from 3D sensors or reconstruction algorithms. In this paper, we present a novel end-to-end network for robust point clouds processing, named PointASNL, which can deal with point clouds with noise effectively. The key component in our approach is the adaptive sampling (AS) module. It first re-weights the neighbors around the initial sampled points from farthest point sampling (FPS), and then adaptively adjusts the sampled points beyond the entire point cloud. Our AS module can not only benefit the feature learning of point clouds, but also ease the biased effect of outliers. To further capture the neighbor and long-range dependencies of the sampled point, we proposed a local-nonlocal (L-NL) module inspired by the nonlocal operation. Such L-NL module enables the learning process insensitive to noise. Extensive experiments verify the robustness and superiority of our approach in point clouds processing tasks",6
32a69681c103807704f71b838454c7924ceec5ce,Libra R-CNN: Towards Balanced Learning for Object Detection,"Compared with model architectures, the training process, which is also crucial to the success of detectors, has received relatively less attention in object detection. In this work, we carefully revisit the standard training practice of detectors, and find that the detection performance is often limited by the imbalance during the training process, which generally consists in three levels - sample level, feature level, and objective level. To mitigate the adverse effects caused thereby, we propose Libra R-CNN, a simple but effective framework towards balanced learning for object detection. It integrates three novel components: IoU-balanced sampling, balanced feature pyramid, and balanced L1 loss, respectively for reducing the imbalance at sample, feature, and objective level. Benefitted from the overall balanced design, Libra R-CNN significantly improves the detection performance. Without bells and whistles, it achieves 2.5 points and 2.0 points higher Average Precision (AP) than FPN Faster R-CNN and RetinaNet respectively on MSCOCO.",4
a2273a00c023fdc6636463ea7ad505f08252487a,Machine Learning-Based Heart Disease Diagnosis: A Systematic Literature Review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
9423aeaad6655d701a5ae56ebc18d224cb5a80bb,Point Encoder GAN: A deep learning model for 3D point cloud inpainting,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
840e804bb5ed1944e494959c2980a90bea0675c4,A Papier-Mache Approach to Learning 3D Surface Generation,"We introduce a method for learning to generate the surface of 3D shapes. Our approach represents a 3D shape as a collection of parametric surface elements and, in contrast to methods generating voxel grids or point clouds, naturally infers a surface representation of the shape. Beyond its novelty, our new shape generation framework, AtlasNet, comes with significant advantages, such as improved precision and generalization capabilities, and the possibility to generate a shape of arbitrary resolution without memory issues. We demonstrate these benefits and compare to strong baselines on the ShapeNet benchmark for two applications: (i) autoencoding shapes, and (ii) single-view reconstruction from a still image. We also provide results showing its potential for other applications, such as morphing, parametrization, super-resolution, matching, and co-segmentation.",20
a022efe4016f804f007afd3a1976bed3b1136df3,Optimal Joint Scheduling and Cloud Offloading for Mobile Applications,"Cloud offloading is an indispensable solution to supporting computationally demanding applications on resource constrained mobile devices. In this paper, we introduce the concept of wireless aware joint scheduling and computation offloading (JSCO) for multi-component applications, where an optimal decision is made on which components need to be offloaded as well as the scheduling order of these components. The JSCO approach allows for more degrees of freedom in the solution by moving away from a compiler pre-determined scheduling order for the components towards a more wireless aware scheduling order. For some component dependency graph structures, the proposed algorithm can shorten execution times by parallel processing appropriate components in the mobile and cloud. We define a net utility that trades-off the energy saved by the mobile, subject to constraints on the communication delay, overall application execution time, and component precedence ordering. The linear optimization problem is solved using real data measurements obtained",6
99b898b4b2bc0c12375cec07f34b0e0d71ef6116,Computing in the Clouds.,"• I wrote this article without the aid of word processing software loaded on my computer. • I used several computers in several locations to write this article without using a flashdrive to move the file. • I shared this article with the editors of L&L without attaching it to an e-mail. • I saved my electronic draft in a place where I will have access to the content, even if my laptop is lost, the external hard drive where I keep my backups fails, and the new version of Microsoft Office refuses to open my file format. • And I am doing all of these things at no cost.",11
4ebf5a9c35f40d3343a2376d0b75d8d7a3126d8d,3D Graph Neural Networks for RGBD Semantic Segmentation,"RGBD semantic segmentation requires joint reasoning about 2D appearance and 3D geometric information. In this paper we propose a 3D graph neural network (3DGNN) that builds a k-nearest neighbor graph on top of 3D point cloud. Each node in the graph corresponds to a set of points and is associated with a hidden representation vector initialized with an appearance feature extracted by a unary CNN from 2D images. Relying on recurrent functions, every node dynamically updates its hidden representation based on the current status and incoming messages from its neighbors. This propagation model is unrolled for a certain number of time steps and the final per-node representation is used for predicting the semantic class of each pixel. We use back-propagation through time to train the model. Extensive experiments on NYUD2 and SUN-RGBD datasets demonstrate the effectiveness of our approach.",12
69fc2fa7bffa570b127f7a55ede90f99082e2e84,Decentralized Computation Offloading Game for Mobile Cloud Computing,"Mobile cloud computing is envisioned as a promising approach to augment computation capabilities of mobile devices for emerging resource-hungry mobile applications. In this paper, we propose a game theoretic approach for achieving efficient computation offloading for mobile cloud computing. We formulate the decentralized computation offloading decision making problem among mobile device users as a decentralized computation offloading game. We analyze the structural property of the game and show that the game always admits a Nash equilibrium. We then design a decentralized computation offloading mechanism that can achieve a Nash equilibrium of the game and quantify its efficiency ratio over the centralized optimal solution. Numerical results demonstrate that the proposed mechanism can achieve efficient computation offloading performance and scale well as the system size increases.",9
fbca4a0caef1032d8643154b54d8148ca2230e2e,"Towards a smart city based on cloud of things, a survey on the smart city vision and paradigms","Smart city represents one of the most promising, prominent and challenging Internet of Things (IoT) applications [1]. In the last few years, indeed, the smart city concept has played an important role in academic and industry fields, with the development and deployment of various middleware platforms and IoT‐based infrastructures. However, this expansion has followed distinct approaches creating, therefore, a fragmented scenario, in which different IoT ecosystems are not able to communicate between them. To fill this gap, there is a need to re‐visit the smart city IoT semantic and to offer a global common approach. To this purpose, this paper browses the semantic annotation of the sensors in Cloud, and innovative services can be implemented and considered by bridging Cloud of Things (CoT) and IoT. Things like semantic will be considered to perform the aggregation of heterogeneous resources by defining the CoT paradigm. We survey the smart city vision, providing",6
e8b6b9f2d2bf0cf05630cf7076a065023540ccdc,PointGMM: A Neural GMM Network for Point Clouds,"Point clouds are a popular representation for 3D shapes. However, they encode a particular sampling without accounting for shape priors or non-local information. We advocate for the use of a hierarchical Gaussian mixture model (hGMM), which is a compact, adaptive and lightweight representation that probabilistically defines the underlying 3D surface. We present PointGMM, a neural network that learns to generate hGMMs which are characteristic of the shape class, and also coincide with the input point cloud. PointGMM is trained over a collection of shapes to learn a class-specific prior. The hierarchical representation has two main advantages: (i) coarse-to-fine learning, which avoids converging to poor local-minima; and (ii) (an unsupervised) consistent partitioning of the input shape. We show that as a generative model, PointGMM learns a meaningful latent space which enables generating consistent interpolations between existing shapes, as well as synthesizing novel shapes. We also present a novel framework for rigid",4
c4b30751fa0e2d9fd1fca925e8e47180a15a3865,Deep Cascade Generation on Point Sets,"This paper proposes a deep cascade network to generate 3D geometry of an object on a point cloud, consisting of a set of permutation-insensitive points. Such a surface representation is easy to learn from, but inhibits exploiting rich low-dimensional topological manifolds of the object shape due to lack of geometric connectivity. For benefiting from its simple structure yet utilizing rich neighborhood information across points, this paper proposes a two-stage cascade model on point sets. Specifically, our method adopts the state-of-the-art point set autoencoder to generate a sparsely coarse shape first, and then locally refines it by encoding neighborhood connectivity on a graph representation. An ensemble of sparse refined surface is designed to alleviate the suffering from local minima caused by modeling complex geometric manifolds. Moreover, our model develops a dynamically-weighted loss function for jointly penalizing the generation output of cascade levels at different training stages in a coarse-to-fine manner. Comparative",3
2da949736e79a612adc1d92b91b67d88ed2764f8,Recent Advances on IoT-Assisted Wearable Sensor Systems for Healthcare Monitoring,"IoT has played an essential role in many industries over the last few decades. Recent advancements in the healthcare industry have made it possible to make healthcare accessible to more people and improve their overall health. The next step in healthcare is to integrate it with IoT-assisted wearable sensor systems seamlessly. This review rigorously discusses the various IoT architectures, different methods of data processing, transfer, and computing paradigms. It compiles various communication technologies and the devices commonly used in IoT-assisted wearable sensor systems and deals with its various applications in healthcare and their advantages to the world. A comparative analysis of all the wearable technology in healthcare is also discussed with tabulation of various research and technology. This review also analyses all the problems commonly faced in IoT-assisted wearable sensor systems and the specific issues that need to be tackled to optimize these systems in healthcare and describes the various",6
e08f17fe8ac8781d83470af79b7045097217b725,Hierarchical Fog-Cloud Computing for IoT Systems: A Computation Offloading Game,"Fog computing, which provides low-latency computing services at the network edge, is an enabler for the emerging Internet of Things (IoT) systems. In this paper, we study the allocation of fog computing resources to the IoT users in a hierarchical computing paradigm including fog and remote cloud computing services. We formulate a computation offloading game to model the competition between IoT users and allocate the limited processing power of fog nodes efficiently. Each user aims to maximize its own quality of experience (QoE), which reflects its satisfaction of using computing services in terms of the reduction in computation energy and delay. Utilizing a potential game approach, we prove the existence of a pure Nash equilibrium (NE) and provide an upper bound for the price of anarchy. Since the time complexity to reach the equilibrium increases exponentially in the number of users, we further propose a near-optimal resource allocation mechanism and",10
f968de5288193d0e01fc0e651700f02835d0816a,Heating rates in tropical anvils,"Abstract The interaction of infrared and solar radiation with tropical cirrus anvils is addressed. Optical properties of the anvils are inferred from satellite observations and from high-altitude aircraft measurements. An infrared multiple-scattering model is used to compute heating rates in tropical anvils. Layer-average heating rates in 2 km thick anvils were found to be on the order of 20 to 30°K day−1. The difference between heating rates at cloud bottom and cloud top ranges from 30 to 200°K day−1, leading to convective instability in the anvil. The calculations are most sensitive to the assumed ice water content, but also are affected by the vertical distribution of ice water content and by the anvil thickness. Solar heating in anvils is shown to be less important than infrared hearing but not negligible The dynamical implications of the computed heating rates are also explored and we conclude that the heating may have important",9
a0d4b0fd59c2bfba02b79309d9c62ca64ee6d457,PL-SVO: Semi-direct Monocular Visual Odometry by combining points and line segments,"Most approaches to visual odometry estimates the camera motion based on point features, consequently, their performance deteriorates in low-textured scenes where it is difficult to find a reliable set of them. This paper extends a popular semi-direct approach to monocular visual odometry known as SVO [1] to work with line segments, hence obtaining a more robust system capable of dealing with both textured and structured environments. The proposed odometry system allows for the fast tracking of line segments since it eliminates the necessity of continuously extracting and matching features between subsequent frames. The method, of course, has a higher computational burden than the original SVO, but it still runs with frequencies of 60Hz on a personal computer while performing robustly in a wider variety of scenarios.",4
13513bb13ff668f7d7cf341d2a8712dea6455674,Energy-efficient computation offloading and resource allocation in fog computing for Internet of Everything,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
af7dbac37354f8b86013732469aff0480c857f04,Quality of Service (QoS)-driven resource provisioning for large-scale graph processing in cloud computing environments: Graph Processing-as-a-Service (GPaaS),"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
4f41b1d7e44f5832167891c709239690db345755,Ensem-HAR: An Ensemble Deep Learning Model for Smartphone Sensor-Based Human Activity Recognition for Measurement of Elderly Health Monitoring,"Biomedical images contain a huge number of sensor measurements that can provide disease characteristics. Computer-assisted analysis of such parameters aids in the early detection of disease, and as a result aids medical professionals in quickly selecting appropriate medications. Human Activity Recognition, abbreviated as ‘HAR’, is the prediction of common human measurements, which consist of movements such as walking, running, drinking, cooking, etc. It is extremely advantageous for services in the sphere of medical care, such as fitness trackers, senior care, and archiving patient information for future use. The two types of data that can be fed to the HAR system as input are, first, video sequences or images of human activities, and second, time-series data of physical movements during different activities recorded through sensors such as accelerometers, gyroscopes, etc., that are present in smart gadgets. In this paper, we have decided to work with time-series kind of data as the",2
9cfe79734c25c80aa210847320298d3618445e20,Joint allocation of computation and communication resources in multiuser mobile cloud computing,"Mobile cloud computing is offering a very powerful storage and computational facility to enhance the capabilities of resource-constrained mobile handsets. However, full exploitation of the cloud computing capabilities can be achieved only if the allocation of radio and computational capabilities is performed jointly. In this paper, we propose a method to jointly optimize the transmit power, the number of bits per symbol and the CPU cycles assigned to each application in order to minimize the power consumption at the mobile side, under an average latency constraint dictated by the application requirements. We consider the case of a set of mobile handsets served by a single cloud and we show that the optimization leads to a one-to-one relationship between the transmit power and the percentage of CPU cycles assigned to each user. Based on our optimization, we propose then a computation scheduling technique and verify the stability of the computations queue.",4
2a33d0939cb4f9200d401a453146bb120ee3b403,Recurrent Slice Networks for 3D Segmentation of Point Clouds,"Point clouds are an efficient data format for 3D data. However, existing 3D segmentation methods for point clouds either do not model local dependencies [21] or require added computations [14, 23]. This work presents a novel 3D segmentation framework, RSNet1, to efficiently model local structures in point clouds. The key component of the RSNet is a lightweight local dependency module. It is a combination of a novel slice pooling layer, Recurrent Neural Network (RNN) layers, and a slice unpooling layer. The slice pooling layer is designed to project features of unordered points onto an ordered sequence of feature vectors so that traditional end-to-end learning algorithms (RNNs) can be applied. The performance of RSNet is validated by comprehensive experiments on the S3DIS[1], ScanNet[3], and ShapeNet [34] datasets. In its simplest form, RSNets surpass all previous state-of-the-art methods on these benchmarks. And comparisons against previous state-of-the-art methods [21, 23] demonstrate the efficiency",16
e0b380e71c4541b2ecc2c8b94a3f2b0035330891,Greening the internet with nano data centers,"Motivated by increased concern over energy consumption in modern data centers, we propose a new, distributed computing platform called Nano Data Centers (NaDa). NaDa uses ISP-controlled home gateways to provide computing and storage services and adopts a managed peer-to-peer model to form a distributed data center infrastructure. To evaluate the potential for energy savings in NaDa platform we pick Video-on-Demand (VoD) services. We develop an energy consumption model for VoD in traditional and in NaDa data centers and evaluate this model using a large set of empirical VoD access data. We find that even under the most pessimistic scenarios, NaDa saves at least 20% to 30% of the energy compared to traditional data centers. These savings stem from energy-preserving properties inherent to NaDa such as the reuse of already committed baseline power on underutilized gateways, the avoidance of cooling costs, and the reduction of network energy consumption as a result",3
2519e985fb4339207d2d0aa83240d5fe4f056332,Simplifying cyber foraging for mobile devices,"Cyber foraging is the transient and opportunistic use of compute servers bymobile devices. The short market life of such devices makes rapid modification of applications for remote execution an important problem. We describe a solution that combines a ""little language"" for cyber foraging with an adaptive runtime system. We report results from a user study showing that even novice developers are able to successfully modify large, unfamiliar applications in just a few hours. We also show that the quality of novice-modified and expert-modified applications are comparable in most cases.",3
f6871be408813171daa2521061658aeaa4708bba,Green and Sustainable Cloud of Things: Enabling Collaborative Edge Computing,"The proliferation of IoTs beside the emergence of various cloud services push the horizon of edge computing. By offering cloud capabilities at the network edge closer to mobile devices, edge computing is a promising paradigm to resolve several vital challenges in IoTs, such as bandwidth saturation, energy constraints, low latency transmission, and data security and privacy. To provide a comprehensive understanding of edge computing supported by the integration of IoTs and cloud computing, that is, CoTs, this article first discusses some distinct research directions in CoTs with respect to edge computing. Given the significance of energy efficiency and sustainability of edge deployment in CoTs, we put forward a green and sustainable virtual network embedding framework for cooperative edge computing in wireless-optical broadband access networks. Specifically, we leverage a reliability function to confirm the number of backup edge devices, and embed virtual networks onto the suitable edge devices in CoTs. Finally,",2
a84906dbd4d6640f918d0b6ed2a7313dda0d55f1,Panoptic Feature Pyramid Networks,"The recently introduced panoptic segmentation task has renewed our community's interest in unifying the tasks of instance segmentation (for thing classes) and semantic segmentation (for stuff classes). However, current state-of-the-art methods for this joint task use separate and dissimilar networks for instance and semantic segmentation, without performing any shared computation. In this work, we aim to unify these methods at the architectural level, designing a single network for both tasks. Our approach is to endow Mask R-CNN, a popular instance segmentation method, with a semantic segmentation branch using a shared Feature Pyramid Network (FPN) backbone. Surprisingly, this simple baseline not only remains effective for instance segmentation, but also yields a lightweight, top-performing method for semantic segmentation. In this work, we perform a detailed study of this minimally extended version of Mask R-CNN with FPN, which we refer to as Panoptic FPN, and show it is a robust and accurate baseline",4
6cd872c23456bb3629655957890561d1a4742f02,The ocean's response to a CO2-induced warming,"The climate response to a large increase in atmospheric CO2 was investigated in a numerical experiment with a coupled ocean-atmosphere model. The study is focused on one aspect of the experiment, the predicted response of the ocean to the warming episode. A fourfold increase in atmospheric CO2 causes a warming sufficiently intense to produce a partial collapse of the thermohaline circulation of the ocean. Surprisingly, the wind-driven circulation of the ocean is maintained without appreciable change. The global hydrological cycle intensifies without a major shift of the pattern of net precipitation over the model ocean. In the warming episode the downward pathways for heat, which include diffusion and Ekman pumping, remain open. The partial collapse of the thermohaline circulation closes the normal upward pathways associated with abyssal upwelling and high-latitude convection. As a result the thermocline is able to sequester almost twice as much heat than would be predicted from",3
e6b9fc7aa2996e7afc91c7f223460f9ded85e2da,Client Selection for Federated Learning with Heterogeneous Resources in Mobile Edge,"We envision a mobile edge computing (MEC) framework for machine learning (ML) technologies, which leverages distributed client data and computation resources for training high-performance ML models while preserving client privacy. Toward this future goal, this work aims to extend Federated Learning (FL), a decentralized learning framework that enables privacy-preserving training of models, to work with heterogeneous clients in a practical cellular network. The FL protocol iteratively asks random clients to download a trainable model from a server, update it with own data, and upload the updated model to the server, while asking the server to aggregate multiple client updates to further improve the model. While clients in this protocol are free from disclosing own private data, the overall training process can become inefficient when some clients are with limited computational resources (i.e., requiring longer update time) or under poor wireless channel conditions (longer upload time). Our new FL protocol, which",7
c5a3d27f2e3404137cf0d5295763b15c663f6369,Towards autonomic workload provisioning for enterprise Grids and clouds,"This paper explores autonomic approaches for optimizing provisioning for heterogeneous workloads on enterprise Grids and clouds. Specifically, this paper presents a decentralized, robust online clustering approach that addresses the distributed nature of these environments, and can be used to detect patterns and trends, and use this information to optimize provisioning of virtual (VM) resources. It then presents a model-based approach for estimating application service time using long-term application performance monitoring, to provide feedback about the appropriateness of requested resources as well as the system's ability to meet QoS constraints and SLAs. Specifically for high-performance computing workloads, the use of a quadratic response surface model (QRSM) is justified with respect to traditional models, demonstrating the need for application-specific modeling. The proposed approaches are evaluated using a real computing center workload trace and the results demonstrate both their effectiveness and cost-efficiency.",6
bf2793fc09176f8bf23b3a2b3c6b32185e8a8329,Multi-level Fusion Based 3D Object Detection from Monocular Images,"In this paper, we present an end-to-end multi-level fusion based framework for 3D object detection from a single monocular image. The whole network is composed of two parts: one for 2D region proposal generation and another for simultaneously predictions of objects' 2D locations, orientations, dimensions, and 3D locations. With the help of a stand-alone module to estimate the disparity and compute the 3D point cloud, we introduce the multi-level fusion scheme. First, we encode the disparity information with a front view feature representation and fuse it with the RGB image to enhance the input. Second, features extracted from the original input and the point cloud are combined to boost the object detection. For 3D localization, we introduce an extra stream to predict the location information from point cloud directly and add it to the aforementioned location prediction. The proposed algorithm can directly output both 2D and 3D object detection results",4
0b93657965e506dfbd56fbc1c1d4b9666b1d01c8,KLEE: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
c92c70dbfc2907350a2c547d6126da783aa5e1b6,Patch-Based Progressive 3D Point Set Upsampling,"We present a detail-driven deep neural network for point set upsampling. A high-resolution point set is essential for point-based rendering and surface reconstruction. Inspired by the recent success of neural image super-resolution techniques, we progressively train a cascade of patch-based upsampling networks on different levels of detail end-to-end. We propose a series of architectural design contributions that lead to a substantial performance boost. The effect of each technical contribution is demonstrated in an ablation study. Qualitative and quantitative experiments show that our method significantly outperforms the state-of-the-art learning-based and optimazation-based approaches, both in terms of handling low-resolution inputs and revealing high-fidelity details.",8
f0daa4b6f33751ff85fb36cd0583c6769a53e0ec,PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving Paths,"The task of point cloud completion aims to predict the missing part for an incomplete 3D shape. A widely used strategy is to generate a complete point cloud from the incomplete one. However, the unordered nature of point clouds will degrade the generation of high-quality 3D shapes, as the detailed topology and structure of discrete points are hard to be captured by the generative process only using a latent code. In this paper, we address the above problem by reconsidering the completion task from a new perspective, where we formulate the prediction as a point cloud deformation process. Specifically, we design a novel neural network, named PMP-Net, to mimic the behavior of an earth mover. It moves move each point of the incomplete input to complete the point cloud, where the total distance of point moving paths (PMP) should be shortest. Therefore, PMP-Net predicts a unique point moving path for",1
d33949030c7be933ee83768e4dfa1ed387cdc12b,Point2Sequence: Learning the Shape Representation of 3D Point Clouds with an Attention-based Sequence to Sequence Network,"Exploring contextual information in the local region is important for shape understanding and analysis. Existing studies often employ hand-crafted or explicit ways to encode contextual information of local regions. However, it is hard to capture fine-grained contextual information in hand-crafted or explicit manners, such as the correlation between different areas in a local region, which limits the discriminative ability of learned features. To resolve this issue, we propose a novel deep learning model for 3D point clouds, named Point2Sequence, to learn 3D shape features by capturing fine-grained contextual information in a novel implicit way. Point2Sequence employs a novel sequence learning model for point clouds to capture the correlations by aggregating multi-scale areas of each local region with attention. Specifically, Point2Sequence first learns the feature of each area scale in a local region. Then, it captures the correlation between area scales in the process of aggregating all area scales using a",10
1fe1033a508caa43dea180f4faa135c57d931752,Plasticine: A reconfigurable architecture for parallel patterns,"Reconfigurable architectures have gained popularity in recent years as they allow the design of energy-efficient accelerators. Fine-grain fabrics (e.g. FPGAs) have traditionally suffered from performance and power inefficiencies due to bit-level reconfigurable abstractions. Both fine-grain and coarse-grain architectures (e.g. CGRAs) traditionally require low level programming and suffer from long compilation times. We address both challenges with Plasticine, a new spatially reconfigurable architecture designed to efficiently execute applications composed of parallel patterns. Parallel patterns have emerged from recent research on parallel programming as powerful, high-level abstractions that can elegantly capture data locality, memory access patterns, and parallelism across a wide range of dense and sparse applications. We motivate Plasticine by first observing key application characteristics captured by parallel patterns that are amenable to hardware acceleration, such as hierarchical parallelism, data locality, memory access patterns, and control flow. Based on these observations, we architect Plasticine as a collection of Pattern Compute Units",3
e0c6abdbdecf04ffac65c440da77fb9d66bb474c,XLNet: Generalized Autoregressive Pretraining for Language Understanding,"With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.",13
18865de480ed9da8d67015f68458ce03cdbae40e,VL2: a scalable and flexible data center network,"To be agile and cost effective, data centers should allow dynamic resource allocation across large server pools. In particular, the data center network should enable any server to be assigned to any service. To meet these goals, we present VL2, a practical network architecture that scales to support huge data centers with uniform high capacity between servers, performance isolation between services, and Ethernet layer-2 semantics. VL2 uses (1) flat addressing to allow service instances to be placed anywhere in the network, (2) Valiant Load Balancing to spread traffic uniformly across network paths, and (3) end-system based address resolution to scale to large server pools, without introducing complexity to the network control plane. VL2's design is driven by detailed measurements of traffic and fault data from a large operational cloud service provider. VL2's implementation leverages proven network technologies, already available at low cost in high-speed hardware implementations, to build a scalable",8
c7d7d579d94b7fc67c75b68361e01ba8f59b1d40,Intelligent services for Big Data science,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
7775c0a95922a42730e9411af9096894e39603c5,Smart water consumption measurement system for houses using IoT and cloud computing,"Presently, in several parts of the world, water consumption is not measured or visualized in real time, in addition, water leaks are not detected in time and with high precision, generating unnecessary waste of water. That is why this article presents the implementation of a smart water measurement consumption system under an architecture design, with high decoupling and integration of various technologies, which allows real-time visualizing the consumptions, in addition, a leak detection algorithm is proposed based on rules, historical context, and user location that manages to cover 10 possible water consumption scenarios between normal and anomalous consumption. The system allows data to be collected by a smart meter, which is preprocessed by a local server (Gateway) and sent to the Cloud from time to time to be analyzed by the leak detection algorithm and, simultaneously, be viewed on a web interface. The results show that the algorithm has 100%",2
d74ed94c7a83298a4b4f0e1c70200126e464cc05,"1 year, 1000 km: The Oxford RobotCar dataset","We present a challenging new dataset for autonomous driving: the Oxford RobotCar Dataset. Over the period of May 2014 to December 2015 we traversed a route through central Oxford twice a week on average using the Oxford RobotCar platform, an autonomous Nissan LEAF. This resulted in over 1000 km of recorded driving with almost 20 million images collected from 6 cameras mounted to the vehicle, along with LIDAR, GPS and INS ground truth. Data was collected in all weather conditions, including heavy rain, night, direct sunlight and snow. Road and building works over the period of a year significantly changed sections of the route from the beginning to the end of data collection. By frequently traversing the same route over the period of a year we enable research investigating long-term localization and mapping for autonomous vehicles in real-world, dynamic urban environments. The full dataset is available for download at: http://robotcar-dataset.robots.ox.ac.uk",3
bf87d03bb650f4f6e0fddde0e6ffa57858c92893,Technically speaking: The cloud is the computer,"Discusses the terms that define the direction of computers, the Internet, and networking, and how we access information.",4
fc780c6681dd2734deb572746a8b1a828ef08f95,Scheduling Internet of Things requests to minimize latency in hybrid Fog-Cloud​ computing,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
33998aff64ce51df8dee45989cdca4b6b1329ec4,Graph Attention Networks,"We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).",104
96cf663aaf3d3da7d1485be4fcfa89e42a7cf85e,Collaborative Energy and Information Transfer in Green Wireless Sensor Networks for Smart Cities,"Smart city is able to make the city source and infrastructure more efficiently utilized, which improves the quality of life for citizens. In this framework, wireless sensor networks (WSNs) play an important role to collect, process, and analyze the corresponding information. However, the massive deployment of WSNs consumes a significant energy consumption, which has raised the growing demand for green WSNs for smart cities. Exploiting the recent advance in collaborative energy and information transfer to power the WSNs and transmit the data has been considered a promising approach to realize the green WSNs for smart cities. We propose an architecture design of the green WSNs for smart cities, by exploiting the collaborative energy and information transfer protocol, and illustrate the challenging issues in this design. To achieve a green system design, the sensor nodes in WSNs harvest the energy simultaneously with the information decoding (ID) from the received radio frequency",3
2c8c82a03d8fffff8b66cf5e0972d46fd38fa665,AN HRM SYSTEM FOR SMALL AND MEDIUM ENTERPRISES (SME)S BASED ON CLOUD COMPUTING TECHNOLOGY,"Technology has changed our life and the way we work; however, technology has affected several methods of working in Small and Medium Enterprises (SME)s. Human Resource (HR) is one of the core components in businesses, and nowadays most businesses are using technology for daily basis tasks. However, it still is not used all over the world. In Kurdistan Region-Iraq (KRI), most of the SMEs still use the old way of working and follow the paper-based method for their daily basis tasks. According to a survey, more than seventy percent of SMEs in Kurdistan are not using software to manage human resource management tasks. However, some big companies are using HRMS; but even then, there is a lack of use of Cloud Technology. In this study, a model of the Enterprise Human Resource Management System (EHRMS) is proposed and implemented to solve the HR problems in this area using Cloud Technology.",3
a9afcb2f2759b572a1d2a2db42410fd5a8ce2223,Joint Communication and Computation Resource Allocation for Cloud-Edge Collaborative System,"In this paper, we investigate the latency minimization resource allocation problem in a hierarchical cloud-edge coexistence system by optimally splitting tasks for partial cloud computing and partial edge computing. A joint communication and computation resource allocation problem is first formulated and the structural characteristics are further analyzed. Next, by defining two novel parameters: the normalized backhaul communication capacity and the normalized cloud computation capacity, an optimal task splitting strategy is developed. With the help of these definitions, the joint communication and computation resource allocation policy can be devised in closed-form. Finally, numerical results demonstrate that the proposed collaborative cloud-edge computing scheme performs better than some baseline schemes in terms of minimizing the end-to-end latency of mobile devices.",4
31abcf70a3a118269d4b5707a7f06b0ef8cdaab9,"Cloud computing and emerging IT platforms: Vision, hype, and reality for delivering computing as the 5th utility","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
a456265138c088a894301c0433dae938705a9bec,Deep Sets,"In this paper, we study the problem of designing objective functions for machine learning problems defined on finite \emph{sets}. In contrast to traditional objective functions defined for machine learning problems operating on finite dimensional vectors, the new objective functions we propose are operating on finite sets and are invariant to permutations. Such problems are widespread, ranging from estimation of population statistics \citep{poczos13aistats}, via anomaly detection in piezometer data of embankment dams \citep{Jung15Exploration}, to cosmology \citep{Ntampaka16Dynamical,Ravanbakhsh16ICML1}. Our main theorem characterizes the permutation invariant objective functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We demonstrate the applicability of our method on population statistic estimation, point",32
4cdcf2ae5e1fafebd9b3613247a7b1962584da34,Volumetric and Multi-view CNNs for Object Classification on 3D Data,"3D shape models are becoming widely available and easier to capture, making available 3D information crucial for progress in object classification. Current state-of-theart methods rely on CNNs to address this problem. Recently, we witness two types of CNNs being developed: CNNs based upon volumetric representations versus CNNs based upon multi-view representations. Empirical results from these two types of CNNs exhibit a large gap, indicating that existing volumetric CNN architectures and approaches are unable to fully exploit the power of 3D representations. In this paper, we aim to improve both volumetric CNNs and multi-view CNNs according to extensive analysis of existing approaches. To this end, we introduce two distinct network architectures of volumetric CNNs. In addition, we examine multi-view CNNs, where we introduce multiresolution filtering in 3D. Overall, we are able to outperform current state-of-the-art methods for both volumetric CNNs and multi-view CNNs. We provide extensive experiments designed to evaluate underlying",55
7227b0cd926af25c95a71513ddddc11ac9e71a7f,Rate coefficient for the reaction between NO3 radicals and dimethyl sulphide,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
c802ceb7a9ff904220c48ee44ae9b671be6d6379,On the Convergence of FedAvg on Non-IID Data,"Federated learning enables a large amount of edge computing devices to jointly learn a model without data sharing. As a leading algorithm in this setting, Federated Averaging (\texttt{FedAvg}) runs Stochastic Gradient Descent (SGD) in parallel on a small subset of the total devices and averages the sequences only once in a while. Despite its simplicity, it lacks theoretical guarantees under realistic settings. In this paper, we analyze the convergence of \texttt{FedAvg} on non-iid data and establish a convergence rate of $\mathcal{O}(\frac{1}{T})$ for strongly convex and smooth problems, where $T$ is the number of SGDs. Importantly, our bound demonstrates a trade-off between communication-efficiency and convergence rate. As user devices may be disconnected from the server, we relax the assumption of full device participation to partial device participation and study different averaging schemes; low device participation rate can be achieved without severely slowing down the learning. Our results indicate that heterogeneity of",2
247ede1aa594d5fc849a5465553d8b58b1aec6d7,Azure Accelerated Networking: SmartNICs in the Public Cloud,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
b3159fd22e19e24d7cde9d37b3e482b832d4fa58,Learning Representations and Generative Models for 3D Point Clouds,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",31
42b1cb0030e174ba4395d987df77cfa6d112d221,Joint 2D-3D-Semantic Data for Indoor Scene Understanding,"We present a dataset of large-scale indoor spaces that provides a variety of mutually registered modalities from 2D, 2.5D and 3D domains, with instance-level semantic and geometric annotations. The dataset covers over 6,000m2 and contains over 70,000 RGB images, along with the corresponding depths, surface normals, semantic annotations, global XYZ images (all in forms of both regular and 360{\deg} equirectangular images) as well as camera information. It also includes registered raw and semantically annotated 3D meshes and point clouds. The dataset enables development of joint and cross-modal learning models and potentially unsupervised approaches utilizing the regularities present in large-scale indoor spaces. The dataset is available here: this http URL",8
e5a54fc0e00369180d336687470b0dd6a1d19aa7,Nebulas: Using Distributed Voluntary Resources to Build Clouds,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
57f1e3397004ea0ce2877e07f0cbbfbb3045de41,Serving DNNs in Real Time at Datacenter Scale with Project Brainwave,"To meet the computational demands required of deep learning, cloud operators are turning toward specialized hardware for improved efficiency and performance. Project Brainwave, Microsofts principal infrastructure for AI serving in real time, accelerates deep neural network (DNN) inferencing in major services such as Bings intelligent search features and Azure. Exploiting distributed model parallelism and pinning over low-latency hardware microservices, Project Brainwave serves state-of-the-art, pre-trained DNN models with high efficiencies at low batch sizes. A high-performance, precision-adaptable FPGA soft processor is at the heart of the system, achieving up to 39.5 teraflops (Tflops) of effective performance at Batch 1 on a state-of-the-art Intel Stratix 10 FPGA.",4
897035ae01cb6dde31f6e881c15a9470c36c5bfd,View Inter-Prediction GAN: Unsupervised Representation Learning for 3D Shapes by Learning Global Shape Memories to Support Local View Predictions,"In this paper, we present a novel unsupervised representation learning approach for 3D shapes, which is an important research challenge as it avoids the manual effort required for collecting supervised data. Our method trains an RNNbased neural network architecture to solve multiple view inter-prediction tasks for each shape. Given several nearby views of a shape, we define view inter-prediction as the task of predicting the center view between the input views, and reconstructing the input views in a low-level feature space. The key idea of our approach is to implement the shape representation as a shape-specific global memory that is shared between all local view inter-predictions for each shape. Intuitively, this memory enables the system to aggregate information that is useful to better solve the view inter-prediction tasks for each shape, and to leverage the memory as a viewindependent shape representation. Our approach obtains the best results using a combination",4
22c141b489e6e189f5996537b0a908fc10f90de7,Adaptive and Fault-Tolerant Data Processing in Healthcare IoT Based on Fog Computing,"In recent years, healthcare IoT have been helpful in mitigating pressures of hospital and medical resources caused by aging population to a large extent. As a safety-critical system, the rapid response from the health care system is extremely important. To fulfill the low latency requirement, fog computing is a competitive solution by deploying healthcare IoT devices on the edge of clouds. However, these fog devices generate huge amount of sensor data. Designing a specific framework for fog devices to ensure reliable data transmission and rapid data processing becomes a topic of utmost significance. In this paper, a Reduced Variable Neighborhood Search (RVNS)-based sEnsor Data Processing Framework (REDPF) is proposed to enhance reliability of data transmission and processing speed. Functionalities of REDPF include fault-tolerant data transmission, self-adaptive filtering and data-load-reduction processing. Specifically, a reliable transmission mechanism, managed by a self-adaptive filter, will recollect lost or inaccurate data automatically. Then, a new",3
e71aca83459cd6f3000f098b6ea152d19fdd8ca8,An IoT-Based Framework for Health Monitoring Systems: A Case Study Approach,"A software framework is a reusable design that requires various software components to function almost out of the box. To specify a framework, the creator must specify the different components that form the framework and how to instantiate them. Also, the communication interfaces between these various components must be defined. In this article, the authors propose such a framework based on the internet of things (IoT) for developing applications for handling emergencies of some kind. This article demonstrates the usage of the framework by explaining various applications such as tracking the status of autistic students, analytics on medical records to detect and mitigate chronic heart diseases in the Indian demographic, prediction of Parkinson's disease, determining the type of disease that corresponds to the dermatology field, and health monitoring and management using internet of things (IoT) sensing.",4
6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4,Learning Transferable Visual Models From Natural Language Supervision,"State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many",12
d8c59d536058abeae21cccb323e9642e3918b1be,FusionNet: 3D Object Classification Using Multiple Data Representations,"High-quality 3D object recognition is an important component of many vision and robotics systems. We tackle the object recognition problem using two data representations, to achieve leading results on the Princeton ModelNet challenge. The two representations: 1. Volumetric representation: the 3D object is discretized spatially as binary voxels - $1$ if the voxel is occupied and $0$ otherwise. 2. Pixel representation: the 3D object is represented as a set of projected 2D pixel images. Current leading submissions to the ModelNet Challenge use Convolutional Neural Networks (CNNs) on pixel representations. However, we diverge from this trend and additionally, use Volumetric CNNs to bridge the gap between the efficiency of the above two representations. We combine both representations and exploit them to learn new features, which yield a significantly better classifier than using either of the representations in isolation. To do this, we introduce new Volumetric CNN (V-CNN) architectures.",15
41edd975efbbc5af28971bc2669d9a1ae6ee8ace,PCN: Point Completion Network,"Shape completion, the problem of estimating the complete geometry of objects from partial observations, lies at the core of many vision and robotics applications. In this work, we propose Point Completion Network (PCN), a novel learning-based approach for shape completion. Unlike existing shape completion methods, PCN directly operates on raw point clouds without any structural assumption (e.g. symmetry) or annotation (e.g. semantic class) about the underlying shape. It features a decoder design that enables the generation of fine-grained completions while maintaining a small number of parameters. Our experiments show that PCN produces dense, complete point clouds with realistic structures in the missing regions on inputs with various levels of incompleteness and noise, including cars from LiDAR scans in the KITTI dataset.",14
b5007972c6f5a2294f83357c73e12664dd7c85b3,CayleyNets: Graph Convolutional Neural Networks With Complex Rational Spectral Filters,"The rise of graph-structured data such as social networks, regulatory networks, citation graphs, and functional brain networks, in combination with resounding success of deep learning in various applications, has brought the interest in generalizing deep learning models to non-Euclidean domains. In this paper, we introduce a new spectral domain convolutional architecture for deep learning on graphs. The core ingredient of our model is a new class of parametric rational complex functions (Cayley polynomials) allowing to efficiently compute spectral filters on graphs that specialize on frequency bands of interest. Our model generates rich spectral filters that are localized in space, scales linearly with the size of the input data for sparsely connected graphs, and can handle different constructions of Laplacian operators. Extensive experimental results show the superior performance of our approach, in comparison to other spectral domain convolutional architectures, on spectral image classification, community detection, vertex classification, and matrix completion tasks.",13
b1393e3b598b623d301ede5648ed9189ae346eab,Market-Oriented Grid and Utility Computing,"The first single-source reference covering the state of the art in grid and utility computing economy research This book presents the first integrated, single-source reference on market-oriented grid and utility computing. Divided into four main partsand with contributions from a panel of experts in the fieldit systematically and carefully explores: Foundationspresents the fundamental concepts of market-oriented computing and the issues and challenges in allocating resources in a decentralized computing environment. Business modelscovers business models for service providers and brokers supporting different types of distributed applications, as well as business rules-based models for managing virtual organizations and accounting operations and services in grid computing environments. Policies and agreementsintroduces policies, agreements, and specifications for the negotiation and establishment of contracts between providers and consumers. It also covers different approaches for resource allocation based on service-level agreements (SLAs) and management of risks associated with SLA violations. Resource allocation and scheduling mechanismscovers economic models,",2
beafabdbd7df228bbdd2a3bb5a463d5869b84983,Trustworthy and personalized computing on public kiosks,"Many people desire ubiquitous access to their personal computing environments. We present a system in which a user leverages a personal mobile device to establish trust in a public computing device, or kiosk, prior to resuming her environment on the kiosk. We have designed a protocol by which the mobile device determines the identity and integrity of all software loaded on the kiosk, in order to inform the user whether the kiosk is trustworthy. Our system exploits emerging hardware security technologies, namely the Trusted Platform Module and new support in x86 processors for establishing a dynamic root of trust. We have demonstrated the viability of our approach by implementing and evaluating our system on commodity hardware. Through a brief survey, we found that respondents are generally willing to endure a delay in exchange for an increased assurance of data privacy, and that the delay incurred by our unoptimized prototype is",6
68b07bb990ee6c7fce28ea56c9a7808f607f0eac,The Google file system,"We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across",13
1923472cacb63e80cec937fd2c8e8d9631266a6a,AWS Certified Solutions Architect Study Guide: Associate SAA-C01 Exam,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
dbdcabd0444ad50b68ee09e30f39b66e9068f5d2,DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification,"Attention is sparse in vision transformers. We observe the final prediction in vision transformers is only based on a subset of most informative tokens, which is sufficient for accurate image recognition. Based on this observation, we propose a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, we devise a lightweight prediction module to estimate the importance score of each token given the current features. The module is added to different layers to prune redundant tokens hierarchically. To optimize the prediction module in an end-to-end manner, we propose an attention masking strategy to differentiably prune a token by blocking its interactions with other tokens. Benefiting from the nature of self-attention, the unstructured sparse tokens are still hardware friendly, which makes our framework easy to achieve actual speed-up. By hierarchically pruning 66% of the input tokens, our method greatly reduces 31%~37% FLOPs and improves",4
af9bbea473e72fcbef487f3205e3f252a5ac8a3a,The Reservoir model and architecture for open federated cloud computing,"The emerging cloud-computing paradigm is rapidly gaining momentum as an alternative to traditional IT (information technology). However, contemporary cloud-computing offerings are primarily targeted for Web 2.0-style applications. Only recently have they begun to address the requirements of enterprise solutions, such as support for infrastructure service-level agreements. To address the challenges and deficiencies in the current state of the art, we propose a modular, extensible cloud architecture with intrinsic support for business service management and the federation of clouds. The goal is to facilitate an open, service-based online economy in which resources and services are transparently provisioned and managed across clouds on an ondemand basis at competitive costs with high-quality service. The Reservoir project is motivated by the vision of implementing an architecture that would enable providers of cloud infrastructure to dynamically partner with each other to create a seemingly infinite pool of IT resources while fully preserving their individual autonomy",2
d46d5e90bdf8f5294b3b4baec401bf81f75fcf69,Fog computing-based intelligent healthcare system for the detection and prevention of mosquito-borne diseases,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
35934b00e734319b95905ad39e5b69514ac30886,A Negotiation Mechanism for Advance Resource Reservations Using the Alternate Offers Protocol,"Service level agreements (SLAs) between grid users and providers have been proposed as mechanisms for ensuring that the users' quality of service (QoS) requirements are met, and that the provider is able to realise utility from its infrastructure. This paper presents a bilateral protocol for SLA negotiation using the alternate offers mechanism wherein a party is able to respond to an offer by modifying some of its terms to generate a counter offer. We apply this protocol to the negotiation between a resource broker and a provider for advance reservation of compute nodes, and implement and evaluate it on a real grid system.",7
ca19cea3e170cf2b84fe601b3ae4e1ff3f0df4fe,SPNet: Deep 3D Object Classification and Retrieval using Stereographic Projection,"We propose an efficient Stereographic Projection Neural Network (SPNet) for learning representations of 3D objects. We first transform a 3D input volume into a 2D planar image using stereographic projection. We then present a shallow 2D convolutional neural network (CNN) to estimate the object category followed by view ensemble, which combines the responses from multiple views of the object to further enhance the predictions. Specifically, the proposed approach consists of four stages: (1) Stereographic projection of a 3D object, (2) view-specific feature learning, (3) view selection and (4) view ensemble. The proposed approach performs comparably to the state-of-the-art methods while having substantially lower GPU memory as well as network parameters. Despite its lightness, the experiments on 3D object classification and shape retrievals demonstrate the high performance of the proposed method.",3
51eecf3bc2a6d807ac1ef56834869810ea353dbd,Selfish Decentralized Computation Offloading for Mobile Cloud Computing in Dense Wireless Networks,"Offloading computation to a mobile cloud is a promising solution to augment the computation capabilities of mobile devices. In this paper, we consider selfish mobile devices in a dense wireless network, in which individual mobile devices can offload computations through multiple access points or through the base station to a mobile cloud so as to minimize their computation costs. We provide a game theoretical analysis of the problem, prove the existence of pure strategy Nash equilibria, and provide an efficient decentralized algorithm for computing an equilibrium. For the case when the cloud computing resources scale with the number of mobile devices, we show that all improvement paths are finite. Furthermore, we provide an upper bound on the price of anarchy of the game, which serves as an upper bound on the approximation ratio of the proposed decentralized algorithms. We use simulations to evaluate the time complexity of computing Nash equilibria",5
fb9b8ad445fb4afd172606007be165f728b646c1,Platform-as-a-Service Architecture for Real-Time Quality of Service Management in Clouds,"Cloud computing offers the potential to dramatically reduce the cost of software services through the commoditization of information technology assets and on-demand usage patterns. However, the complexity of determining resource provision policies for applications in such complex environments introduces significant inefficiencies and has driven the emergence of a new class of infrastructure called Platform-as-a-Service (PaaS). In this paper, we present a novel PaaS architecture being developed in the EU IST IRMOS project targeting real-time Quality of Service (QoS) guarantees for online interactive multimedia applications. The architecture considers the full service lifecycle including service engineering, service level agreement design, provisioning and monitoring. QoS parameters at both application and infrastructure levels are given specific attention as the basis for provisioning policies in the context of temporal constraints. The generic applicability of the architecture is being verified and validated through implemented scenarios from three important application sectors (film post-production, virtual augmented reality for",3
e62ab6416643e49245f997b203f97e072e053016,"Hey, you, get off of my cloud: exploring information leakage in third-party compute clouds","Third-party cloud computing represents the promise of outsourcing as applied to computation. Services, such as Microsoft's Azure and Amazon's EC2, allow users to instantiate virtual machines (VMs) on demand and thus purchase precisely the capacity they require when they require it. In turn, the use of virtualization allows third-party cloud providers to maximize the utilization of their sunk capital costs by multiplexing many customer VMs across a shared physical infrastructure. However, in this paper, we show that this approach can also introduce new vulnerabilities. Using the Amazon EC2 service as a case study, we show that it is possible to map the internal cloud infrastructure, identify where a particular target VM is likely to reside, and then instantiate new VMs until one is placed co-resident with the target. We explore how such placement can then be used to mount cross-VM side-channel attacks to extract information from a target VM on",6
8ca14e5107ab49aea72e884b033ea6fb13c1e547,PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention,"Generating 3D point clouds is challenging yet highly desired. This work presents a novel autoregressive model, PointGrow, which can generate diverse and realistic point cloud samples from scratch or conditioned on semantic contexts. This model operates recurrently, with each point sampled according to a conditional distribution given its previously-generated points, allowing inter-point correlations to be well-exploited and 3D shape generative processes to be better interpreted. Since point cloud object shapes are typically encoded by long-range dependencies, we augment our model with dedicated self-attention modules to capture such relations. Extensive evaluations show that PointGrow achieves satisfying performance on both unconditional and conditional point cloud generation tasks, with respect to realism and diversity. Several important applications, such as unsupervised feature learning and shape arithmetic operations, are also demonstrated.",8
a3967f1a6f2bc027c18538f3c3fc3cdc09c5d298,A new golden age for computer architecture,"Innovations like domain-specific hardware, enhanced security, open instruction sets, and agile chip development will lead the way.",5
e0eecfcd233bb0c32ec21fec18bcd7c66885eb3e,VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation,"Generative models that can model and predict sequences of future events can, in principle, learn to capture complex real-world phenomena, such as physical interactions. However, a central challenge in video prediction is that the future is highly uncertain: a sequence of past observations of events can imply many possible futures. Although a number of recent works have studied probabilistic models that can represent uncertain futures, such models are either extremely expensive computationally as in the case of pixel-level autoregressive models, or do not directly optimize the likelihood of the data. To our knowledge, our work is the first to propose multi-frame video prediction with normalizing flows, which allows for direct optimization of the data likelihood, and produces high-quality stochastic predictions. We describe an approach for modeling the latent space dynamics, and demonstrate that flow-based generative models offer a viable and competitive approach to generative modelling of video.",3
b8b11e8152fa900ab34aabb30f9542ffe7d4c453,Joint Computation Partitioning and Resource Allocation for Latency Sensitive Applications in Mobile Edge Clouds,"The proliferation of mobile devices and ubiquitous access of the wireless network enables many new mobile applications such as augmented reality, mobile gaming and so on. As the applications are latency sensitive, researchers propose to offload the complex computations of these applications to the nearby mobile edge cloud, in order to reduce the latency. Existing works mostly consider the problem of partitioning the computations between the mobile device and the traditional cloud that has abundant resources. The proposed approaches can not be applied in the context of mobile edge cloud, because both the resources in the mobile edge cloud and the wireless access bandwidth to the edge cloud are constrained. In this paper, we study joint computation partitioning and resource allocation problem for latency sensitive applications in mobile edge clouds. The problem is novel in that we combine the computation partitioning and the two-dimensional resource allocations in both the computation",4
fe3e55e6b6db8c127e5931e089b74982fd307964,Self-Supervised Learning on 3D Point Clouds by Learning Discrete Generative Models,"While recent pre-training tasks on 2D images have proven very successful for transfer learning, pre-training for 3D data remains challenging. In this work, we introduce a general method for 3D self-supervised representation learning that 1) remains agnostic to the underlying neural network architecture, and 2) specifically leverages the geometric nature of 3D point cloud data. The proposed task softly segments 3D points into a discrete number of geometric partitions. A self-supervised loss is formed under the interpretation that these soft partitions implicitly parameterize a latent Gaussian Mixture Model (GMM), and that this generative model establishes a data likelihood function. Our pretext task can therefore be viewed in terms of an encoder-decoder paradigm that squeezes learned representations through an implicitly defined parametric discrete generative model bottleneck. We show that any existing neural network architecture designed for supervised point cloud segmentation can be repurposed for the proposed unsupervised pretext task. By maximizing",3
18b89ae68d587b5150fbf2e933bcbc1c3404bee9,A comparison of approaches to large-scale data analysis,"There is currently considerable enthusiasm around the MapReduce (MR) paradigm for large-scale data analysis [17]. Although the basic control flow of this framework has existed in parallel SQL database management systems (DBMS) for over 20 years, some have called MR a dramatically new computing model [8, 17]. In this paper, we describe and compare both paradigms. Furthermore, we evaluate both kinds of systems in terms of performance and development complexity. To this end, we define a benchmark consisting of a collection of tasks that we have run on an open source version of MR as well as on two parallel DBMSs. For each task, we measure each system's performance for various degrees of parallelism on a cluster of 100 nodes. Our results reveal some interesting trade-offs. Although the process to load data into and tune the execution of parallel DBMSs took much longer than the MR system, the observed performance",5
c7abade5be44b822475401008549271daa2f2009,3D Point Cloud Generative Adversarial Network Based on Tree Structured Graph Convolutions,"In this paper, we propose a novel generative adversarial network (GAN) for 3D point clouds generation, which is called tree-GAN. To achieve state-of-the-art performance for multi-class 3D point cloud generation, a tree-structured graph convolution network (TreeGCN) is introduced as a generator for tree-GAN. Because TreeGCN performs graph convolutions within a tree, it can use ancestor information to boost the representation power for features. To evaluate GANs for 3D point clouds accurately, we develop a novel evaluation metric called Fr\'echet point cloud distance (FPD). Experimental results demonstrate that the proposed tree-GAN outperforms state-of-the-art GANs in terms of both conventional metrics and FPD, and can generate point clouds for different semantic parts without prior knowledge.",6
7d6f39f24e9b0a15f3690dae5a00baf8a88180e7,Study on the Development of Mobile Learning Promoted by Cloud Computing,"Cloud computing which is regarded as the next revolution of science and technology is the development of distributed processing, parallel computing and grid computing. It is an Internet-based super computing model and is promoting the rapid development of mobile learning for its unique superiority as well. The paper summarizes the characteristics and models of traditional mobile learning, analyzes the features of cloud computing and clarifies the superiority of development of the mobile learning model in the cloud computing environment.",6
7bad536dc7b108cd476db0dc26ed325e101b0263,"An Energy-Saving Algorithm With Joint User Association, Clustering, and On/Off Strategies in Dense Heterogeneous Networks","Green networks, which is put forward for the environmental and economic benefits, has received much attention recently because of the vast energy cost in wireless cellular networks. To reduce the energy consumption and simultaneously guarantee the service performance of the dense heterogeneous networks, this paper proposes an energy-saving algorithm with joint user association, clustering, and ON/OFF strategies. First, for the user association subproblem, an optimal association policy, which is related to load balancing and energy efficiency, is designed for the new arriving user equipment (UE) and re-associated UE. Second, based on the locations and load of the base stations (BSs), the clustering subproblem is modeled as an integer linear programming, and the near-optimal clustering results are obtained by using the semi-definite programming. Finally, an intra-cluster ON/OFF strategy for the switching ON/OFF subproblem is designed in which the chosen BSs to be switched OFF are decided by their load effect to",2
f8e1b3bcee316203b4aa843efd5f581bc16849dc,The Visualization Toolkit: An Object-Oriented Approach to 3-D Graphics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
45e65b8edff09d97c2a329699105eed8db430f3a,Fog Computing for 5G Tactile Industrial Internet of Things: QoE-Aware Resource Allocation Model,"Fifth generation mobile communication networks are currently being deployed, thus making Tactile Internet possible. Tactile Internet is the future advancement of the current Internet of Things (IoT) vision wherein haptics, or touch and senses, can be communicated from one geographical place to another, enabling near real-time control and navigation of remote objects. Tactile Internet will have its use cases in several application domains, with the industrial sector being among the most prominent ones. With the Industrial Internet of Things (IIoT), Tactile Internet will be used in healthcare, manufacturing, mining, education, autonomous driving, etc. The acceptable delay in most of these tactile applications will be under one millisecond. Since Tactile Internet communicates haptics and gives visual feedback, quality of service (QoS) becomes an important issue. Similarly, user's satisfaction on the service quality [often measured as quality of experience (QoE)] becomes equally important. To reap the true potential of Tactile Internet, sophisticated",4
36c15f27f9406fbdc1165ee37b5744ee73935cec,Large-Scale Location Recognition and the Geometric Burstiness Problem,"Visual location recognition is the task of determining the place depicted in a query image from a given database of geo-tagged images. Location recognition is often cast as an image retrieval problem and recent research has almost exclusively focused on improving the chance that a relevant database image is ranked high enough after retrieval. The implicit assumption is that the number of inliers found by spatial verification can be used to distinguish between a related and an unrelated database photo with high precision. In this paper, we show that this assumption does not hold for large datasets due to the appearance of geometric bursts, i.e., sets of visual elements appearing in similar geometric configurations in unrelated database photos. We propose algorithms for detecting and handling geometric bursts. Although conceptually simple, using the proposed weighting schemes dramatically improves the recall that can be achieved when high precision is required compared to",4
43df18622279d0107d5cf020f917d61b56bfeacc,Sirius: An Open End-to-End Voice and Vision Personal Assistant and Its Implications for Future Warehouse Scale Computers,"As user demand scales for intelligent personal assistants (IPAs) such as Apple's Siri, Google's Google Now, and Microsoft's Cortana, we are approaching the computational limits of current datacenter architectures. It is an open question how future server architectures should evolve to enable this emerging class of applications, and the lack of an open-source IPA workload is an obstacle in addressing this question. In this paper, we present the design of Sirius, an open end-to-end IPA web-service application that accepts queries in the form of voice and images, and responds with natural language. We then use this workload to investigate the implications of four points in the design space of future accelerator-based server architectures spanning traditional CPUs, GPUs, manycore throughput co-processors, and FPGAs. To investigate future server designs for Sirius, we decompose Sirius into a suite of 7 benchmarks (Sirius Suite) comprising the computationally intensive bottlenecks of Sirius. We port Sirius",11
0742fa40bf9be455fc6338e3a40ed6f0113d4a61,OpenFlow: enabling innovation in campus networks,"This whitepaper proposes OpenFlow: a way for researchers to run experimental protocols in the networks they use every day. OpenFlow is based on an Ethernet switch, with an internal flow-table, and a standardized interface to add and remove flow entries. Our goal is to encourage networking vendors to add OpenFlow to their switch products for deployment in college campus backbones and wiring closets. We believe that OpenFlow is a pragmatic compromise: on one hand, it allows researchers to run experiments on heterogeneous switches in a uniform way at line-rate and with high port-density; while on the other hand, vendors do not need to expose the internal workings of their switches. In addition to allowing researchers to evaluate their ideas in real-world traffic settings, OpenFlow could serve as a useful campus component in proposed large-scale testbeds like GENI. Two buildings at Stanford University will soon run OpenFlow networks, using commercial Ethernet",4
484882d338cde1e07701f4a2208e3752b72f717f,Cloud transcoding for mobile video content delivery,This study analyzes a use case where computer clouds are used in the transcoding of media content and points to their advantages in a low cost media distribution solution such as HTTP Live.,2
6321d8fd548a925d2b625a6710a6ff18f95e1cb4,μ Suite: A Benchmark Suite for Microservices,"Modern On-Line Data Intensive (OLDI) applications have evolved from monolithic systems to instead comprise numerous, distributed microservices interacting via Remote Procedure Calls (RPCs). Microservices face single-digit millisecond RPC latency goals (implying sub-ms medians)—much tighter than their monolithic ancestors that must meet $\ge 100$ ms latency targets. Sub-ms-scale OS/network overheads that were once insignificant for such monoliths can now come to dominate in the sub-ms-scale microservice regime. It is therefore vital to characterize the influence of OS- and network-based effects on microservices. Unfortunately, widely-used academic data center benchmark suites are unsuitable to aid this characterization as they (1) use monolithic rather than microservice architectures, and (2) largely have request service times $\ge 100$ ms. In this paper, we investigate how OS and network overheads impact microservice median and tail latency by developing a complete suite of microservices called $ \mu$ Suite that we use to facilitate our study. $ \mu$ Suite",3
d68fb3a66b4e64abffa22d32e98378b82f601cc7,Multi-view Harmonized Bilinear Network for 3D Object Recognition,"View-based methods have achieved considerable success in 3D object recognition tasks. Different from existing view-based methods pooling the view-wise features, we tackle this problem from the perspective of patches-to-patches similarity measurement. By exploiting the relationship between polynomial kernel and bilinear pooling, we obtain an effective 3D object representation by aggregating local convolutional features through bilinear pooling. Meanwhile, we harmonize different components inherited in the bilinear feature to obtain a more discriminative representation. To achieve an end-to-end trainable framework, we incorporate the harmonized bilinear pooling as a layer of a network, constituting the proposed Multi-view Harmonized Bilinear Network (MHBN). Systematic experiments conducted on two public benchmark datasets demonstrate the efficacy of the proposed methods in 3D object recognition.",4
f8282ea7df17d32b7fd39ca94d02194ec2c83c5f,Managing Revenue in Grids,"The distributed usage of computing resources over a large-scale network allows users to receive and offer resources on demand. The on demand paradigm leads to dynamic and unpredictable usage of resources, since every user in the network will try to maximize his utility by selfish behavior. The customer's behavior can be actuated by pricing policies to lower demand at peak time. Revenue Management as a relatively new economic paradigm provides various tools to optimally allocate capacity and increase revenue. We provide a framework how the matured concepts of Revenue Management can be deployed to Grid Computing. We analyze whether the Grid Computing domain has notable differences from the airline industry or other common areas for Revenue Management like restaurant, hotel or car rental industries. Hence, we outline tools and methods known from Revenue Management and how they can be applied to Grid Computing.",3
83dfbc785b4fa750a5efe4cadd1e6018094e0a39,Communications of the ACM,"Communications of the ACM (CACM for short, not the best sounding acronym around) is the ACM’s flagship magazine. Started in 1957, CACM is handy for keeping up to date on current research being carried out across all topics of computer science and realworld applications. CACM has had an illustrious past with many influential pieces of work and debates started within its pages. These include Hoare’s presentation of the Quicksort algorithm; Rivest, Shamir and Adleman’s description of the first publickey cryptosystem RSA; and Dijkstra’s famous letter against the use of GOTO. In addition to the print edition, which is released monthly, there is a fantastic website (http://cacm.acm. org/) that showcases not only the most recent edition but all previous CACM articles as well, readable online as well as downloadable as a PDF. In addition, the website lets you browse for articles by subject, a handy feature if you want to focus",1
aa98c7819826f262ef3f48c0d7dd349dd510ebdb,Cassandra: a structured storage system on a P2P network,"Cassandra is a distributed storage system for managing structured data that is designed to scale to a very large size across many commodity servers, with no single point of failure. Reliability at massive scale is a very big challenge. Outages in the service can have significant negative impact. Hence Cassandra aims to run on top of an infrastructure of hundreds of nodes (possibly spread across different datacenters). At this scale, small and large components fail continuously; the way Cassandra manages the persistent state in the face of these failures drives the reliability and scalability of the software systems relying on this service. Cassandra has achieved several goals -- scalability, high performance, high availability and applicability. In many ways Cassandra resembles a database and shares many design and implementation strategies with databases. Cassandra does not support a full relational data model; instead, it provides clients with a simple data model that",2
a64db2fe34dbe9594cc868d8d108801f1e4a9f3d,Android Open Source Projectを対象としたパッチレビュー活動の調査,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
10da56ca968d4e862d9071246790e930660438d4,InterCloud: Utility-Oriented Federation of Cloud Computing Environments for Scaling of Application Services,"Cloud computing providers have setup several data centers at different geographical locations over the Internet in order to optimally serve needs of their customers around the world However, existing systems do not support mechanisms and policies for dynamically coordinating load distribution among different Cloud-based data centers in order to determine optimal location for hosting application services to achieve reasonable QoS levels Further, the Cloud computing providers are unable to predict geographic distribution of users consuming their services, hence the load coordination must happen automatically, and distribution of services must change in response to changes in the load To counter this problem, we advocate creation of federated Cloud computing environment (InterCloud) that facilitates just-in-time, opportunistic, and scalable provisioning of application services, consistently achieving QoS targets under variable workload, resource and network conditions The overall goal is to create a computing environment that supports dynamic expansion or contraction of capabilities (VMs, services,",4
de4754d75c5d2179f348c58a1108be9c1cbdf4a1,Fog Computing Based Face Identification and Resolution Scheme in Internet of Things,"The identification and resolution technology are the prerequisite for realizing identity consistency of physical–cyber space mapping in the Internet of Things (IoT). Face, as a distinctive noncoded and unstructured identifier, has especial advantages in identification applications. With the increase of face identification based applications, the requirements for computation, communication, and storage capability are becoming higher and higher. To solve this problem, we propose a fog computing based face identification and resolution scheme. Face identifier is first generated by the identification system model to identify an individual. Then, a fog computing based resolution framework is proposed to efficiently resolve the individual's identity. Some computing overhead is offloaded from a cloud to network edge devices in order to improve processing efficiency and reduce network transmission. Finally, a prototype system based on local binary patterns (LBP) identifier is implemented to evaluate the scheme. Experimental results show that this scheme can effectively save bandwidth",8
d19356ce442d9c04625b3a253f370feaf00ea6a0,GS3D: An Efficient 3D Object Detection Framework for Autonomous Driving,"We present an efficient 3D object detection framework based on a single RGB image in the scenario of autonomous driving. Our efforts are put on extracting the underlying 3D information in a 2D image and determining the accurate 3D bounding box of object without point cloud or stereo data. Leveraging the off-the-shelf 2D object detector, we propose an artful approach to efficiently obtain a coarse cuboid for each predicted 2D box. The coarse cuboid has enough accuracy to guide us to determine the 3D box of the object by refinement. In contrast to previous state-of-the-art methods that only use the features extracted from the 2D bounding box for box refinement, we explore the 3D structure information of the object by employing the visual features of visible surfaces. The new features from surfaces are utilized to eliminate the problem of representation ambiguity brought by only using 2D bounding box. Moreover, we",5
7202f35a96471f5fad790f81bf80e5e4b7def1a9,An innovative analyser for multi-classifier e-mail classification based on grey list analysis,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
bcfe57e2d05648c7ace15f3e96bb899b3fa262f2,HDNET: Exploiting HD Maps for 3D Object Detection,"In this paper we show that High-Definition (HD) maps provide strong priors that can boost the performance and robustness of modern 3D object detectors. Towards this goal, we design a single stage detector that extracts geometric and semantic features from the HD maps. As maps might not be available everywhere, we also propose a map prediction module that estimates the map on the fly from raw LiDAR data. We conduct extensive experiments on KITTI as well as a large-scale 3D detection benchmark containing 1 million frames, and show that the proposed map-aware detector consistently outperforms the state-of-the-art in both mapped and un-mapped scenarios. Importantly the whole framework runs at 20 frames per second.",4
0c6c30e3052fcc01aa5ee38252d77f75322d7b3f,DjiNN and Tonic: DNN as a service and its implications for future warehouse scale computers,"As applications such as Apple Siri, Google Now, Microsoft Cortana, and Amazon Echo continue to gain traction, webservice companies are adopting large deep neural networks (DNN) for machine learning challenges such as image processing, speech recognition, natural language processing, among others. A number of open questions arise as to the design of a server platform specialized for DNN and how modern warehouse scale computers (WSCs) should be outfitted to provide DNN as a service for these applications. In this paper, we present DjiNN, an open infrastructure for DNN as a service in WSCs, and Tonic Suite, a suite of 7 end-to-end applications that span image, speech, and language processing. We use DjiNN to design a high throughput DNN system based on massive GPU server designs and provide insights as to the varying characteristics across applications. After studying the throughput, bandwidth, and power properties of DjiNN and Tonic Suite, we investigate",6
ce3dbfe801438c3e70d116b2f18ca1a055c1cabc,"The convergence and interplay of edge, fog, and cloud in the AI-driven Internet of Things (IoT)","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
0e69a8259d0b8d787e443d5b0f8346edabfc31e7,Impact analysis of SYN flood DDOS attack on HAPROXY and NLB cluster-base web servers,"In recent, the high available internet service is main demand of the most people. However, online services occasionally become inaccessible due to various threats and attacks. Synchronization (SYN) flood Distributed Denial of Service (DDoS) is the most used and has a serious effect on the public network services. Hence, the outcome of this attack on the commonly utilized cluster-based web servers is systematically illustrated in this paper. Moreover, performance of Internet Information Service 10.0 (IIS 10.0) on Windows server 2016 and Apache 2 on Linux Ubuntu 16.04 server is evaluated efficiently. The performance measuring process is done on both Network Load Balancing (NLB) and High Available Proxy (HAProxy) in Windows and Linux environments respectively as methods for web server load balancing. Furthermore, stability, efficiency and responsiveness of the web servers are depended as the study evaluation metrics. Additionally, average CPU usage and throughput of the both mechanisms are measured in",4
abce35b357dff68131fa038f291c99a82729bd9a,An Observational Study of Cloud-Topped Mixed Layers,"Abstract The turbulence and mean structure of oceanic stratocumulus was studied using aircraft data collected during the summer of 1976 off the coast of California. Three cloud-topped mixed layers were studied in detail. They consisted of 1) a thin cloud capped by an inversion at a height of ∼1000 m, 2) a relatively thick but broken cloud layer capped by a weak inversion at ∼600 m and 3) a solid cloud capped by a strong inversion at ∼600 m. The mean temperature, moisture, liquid water and radiative characteristics obtained for these three cases were compared. Heat and moisture fluxes were also calculated and compared. Although there was considerable variation in the characteristics of the three cloud-topped mixed layers studied, all indicated the validity of the general approach used in simple mixed-layer models of stratocumulus. But for these models to be useful, they should be generalized to allow clouds other than",6
4e1f37dbbde87067db80379a2bcec4fa9825ee5b,Augmented Smartphone Applications Through Clone Cloud Execution,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
34db8de90d1c44b180862ca352d545bfa5013a3f,"Rose: compressed, log-structured replication","Rose is a database storage engine for high-throughput replication. It targets seek-limited, write-intensive transaction processing workloads that perform near real-time decision support and analytical processing queries. Rose uses log structured merge (LSM) trees to create full database replicas using purely sequential I/O, allowing it to provide orders of magnitude more write throughput than B-tree based replicas. Also, LSM-trees cannot become fragmented and provide fast, predictable index scans. Rose's write performance relies on replicas' ability to perform writes without looking up old values. LSM-tree lookups have performance comparable to B-tree lookups. If Rose read each value that it updated then its write throughput would also be comparable to a B-tree. Although we target replication, Rose provides high write throughput to any application that updates tuples without reading existing data, such as append-only, streaming and versioning databases. We introduce a page compression format that takes advantage of LSM-tree's sequential, sorted data layout.",5
66c268d2a74f863586788cc154ad2ec06aa075e7,Graph-Based Object Classification for Neuromorphic Vision Sensing,"Neuromorphic vision sensing (NVS) devices represent visual information as sequences of asynchronous discrete events (a.k.a., ""spikes'"") in response to changes in scene reflectance. Unlike conventional active pixel sensing (APS), NVS allows for significantly higher event sampling rates at substantially increased energy efficiency and robustness to illumination changes. However, object classification with NVS streams cannot leverage on state-of-the-art convolutional neural networks (CNNs), since NVS does not produce frame representations. To circumvent this mismatch between sensing and processing with CNNs, we propose a compact graph representation for NVS. We couple this with novel residual graph CNN architectures and show that, when trained on spatio-temporal NVS data for object classification, such residual graph CNNs preserve the spatial and temporal coherence of spike events, while requiring less computation and memory. Finally, to address the absence of large real-world NVS datasets for complex recognition tasks, we present and make available a 100k dataset of NVS",3
ed0fea630168d3b63dbf12dd165b1b608ea98dd9,The NICE Cyber Security Framework,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
a0185d4f32dde88aa1749f3a8000ed4721787b65,Visual Transformers: Token-based Image Representation and Processing for Computer Vision,"Computer vision has achieved great success using standardized image representations -- pixel arrays, and the corresponding deep learning operators -- convolutions. In this work, we challenge this paradigm: we instead (a) represent images as a set of visual tokens and (b) apply visual transformers to find relationships between visual semantic concepts. Given an input image, we dynamically extract a set of visual tokens from the image to obtain a compact representation for high-level semantics. We then use visual transformers to operate over the visual tokens to densely model relationships between them. We find that this paradigm of token-based image representation and processing drastically outperforms its convolutional counterparts on image classification and semantic segmentation. To demonstrate the power of this approach on ImageNet classification, we use ResNet as a convenient baseline and use visual transformers to replace the last stage of convolutions. This reduces the stage's MACs by up to 6.9x,",6
a4d5e2b1f3a7ad4f8f4dd133c8c5f4306a7a50f6,Taxonomy of Security Attacks and Risk Assessment of Cloud Computing,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
3a2823f29bb664ebcd8d440fc5b0952399c3aa10,Local Spectral Graph Convolution for Point Set Feature Learning,"Feature learning on point clouds has shown great promise, with the introduction of effective and generalizable deep learning frameworks such as pointnet++. Thus far, however, point features have been abstracted in an independent and isolated manner, ignoring the relative layout of neighboring points as well as their features. In the present article, we propose to overcome this limitation by using spectral graph convolution on a local graph, combined with a novel graph pooling strategy. In our approach, graph convolution is carried out on a nearest neighbor graph constructed from a point's neighborhood, such that features are jointly learned. We replace the standard max pooling step with a recursive clustering and pooling strategy, devised to aggregate information from within clusters of nodes that are close to one another in their spectral coordinates, leading to richer overall feature descriptors. Through extensive experiments on diverse datasets, we show a consistent demonstrable advantage for",12
3407e4b1993b44d14c71c1683994b3e58444eb67,On Distributed and Coordinated Resource Allocation for Interference Mitigation in Self-Organizing LTE Networks,"We propose a distributed and coordinated radio resource allocation algorithm for orthogonal frequency division multiple access (OFDMA)-based cellular networks to self-organize efficient and stable frequency reuse patterns. In the proposed radio resource allocation algorithm, each cell independently and dynamically allocates modulation and coding scheme (MCS), resource block (RB), and transmit power to its users in a way that its total downlink (DL) transmit power is minimized, while users' throughput demands are satisfied. Moreover, each cell informs neighboring cells of the RBs that have been scheduled for its cell-edge users' DL transmissions through message passing. Accordingly, the neighboring cells abstain from assigning high transmit powers to the specified RBs. Extensive simulation results attempt to demonstrate that DL power control on a per-RB basis may play a key role in future networks, and show that the distributed minimization of DL transmit power at each cell, supported by intercell interference coordination, is able",3
38b744afa7aab4e2bc969ea876c9535c7e48500d,Pix2Vox++: Multi-scale Context-aware 3D Object Reconstruction from Single and Multiple Images,"Recovering the 3D shape of an object from single or multiple images with deep neural networks has been attracting increasing attention in the past few years. Mainstream works (e.g. 3D-R2N2) use recurrent neural networks (RNNs) to sequentially fuse feature maps of input images. However, RNN-based approaches are unable to produce consistent reconstruction results when given the same input images with different orders. Moreover, RNNs may forget important features from early input images due to long-term memory loss. To address these issues, we propose a novel framework for single-view and multi-view 3D object reconstruction, named Pix2Vox++. By using a well-designed encoder-decoder, it generates a coarse 3D volume from each input image. A multi-scale context-aware fusion module is then introduced to adaptively select high-quality reconstructions for different parts from all coarse 3D volumes to obtain a fused 3D volume. To further correct the wrongly recovered parts in the fused 3D volume, a",3
2873601bd02fcc8b91e70293a78457863adfe714,A Framework of Adaptive Interaction Support in Cloud-Based Internet of Things (IoT) Environment,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
1a39bb2caa151d15efd6718f3a80d9f4bff95af2,Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs,"A number of problems can be formulated as prediction on graph-structured data. In this work, we generalize the convolution operator from regular grids to arbitrary graphs while avoiding the spectral domain, which allows us to handle graphs of varying size and connectivity. To move beyond a simple diffusion, filter weights are conditioned on the specific edge labels in the neighborhood of a vertex. Together with the proper choice of graph coarsening, we explore constructing deep neural networks for graph classification. In particular, we demonstrate the generality of our formulation in point cloud classification, where we set the new state of the art, and on a graph classification dataset, where we outperform other deep learning approaches.",38
6a2ff3baa579618dcadc2b4099738b287b22b9b8,The Effect of Cloud Sides on Reflected Solar Radiation as Deduced from Satellite Observations,"Abstract We report the observation of a feature that is characteristic of the reflection of solar radiation from absorbing, finite clouds. When absorption takes place, more radiation can be reflected by broken cloud fields than by extensive unbroken cloud fields. We observe this feature in solar radiation at 3.7 μm reflected by low-level, single-layered systems of water clouds over the Pacific Ocean. Interpreting the effect as due to geometrical factors, we note that absorption causes the reflected radiances to be highly anisotropic, so that they are generally greater from the sun-facing cloud sides than from the cloud tops. Diffusive leakage of radiation through the cloud sides is also reduced, and as a result maximum reflectivities occur in situations that maximize the contributions to the reflected radiation from the sides relative to that from the tops. Interpreting the effect as due to changes in liquid water content and cloud droplet sizes,",5
d734a8365f7dab731a698cf77a8588b44166b4b2,Exploring Spatial Context for 3D Semantic Segmentation of Point Clouds,"Deep learning approaches have made tremendous progress in the field of semantic segmentation over the past few years. However, most current approaches operate in the 2D image space. Direct semantic segmentation of unstructured 3D point clouds is still an open research problem. The recently proposed PointNet architecture presents an interesting step ahead in that it can operate on unstructured point clouds, achieving encouraging segmentation results. However, it subdivides the input points into a grid of blocks and processes each such block individually. In this paper, we investigate the question how such an architecture can be extended to incorporate larger-scale spatial context. We build upon PointNet and propose two extensions that enlarge the receptive field over the 3D scene. We evaluate the proposed strategies on challenging indoor and outdoor datasets and show improved results in both scenarios.",6
eaf723c77b9866ee7561c07cddf55db62174980f,Cloud Assisted P2P Media Streaming for Bandwidth Constrained Mobile Subscribers,"Multimedia streaming applications have disruptively occupied bandwidth in wire line Internet, yet today’s fledging mobile media streaming still poses many challenges in efficient content distribution due to the form of mobile devices. At the same time, cloud computing is gaining power as a promising technology to transform IT industry and many eminent enterprises are developing their own cloud infrastructures. However, the lack of applications hinders clouds’ large-scale implementation. In this paper, we envision a cloud-assisted power-efficient mobile P2P media streaming architecture that addresses the weakness of today’s wireless access technologies. Clouds are responsible for storage and computing demanding tasks, and mobile devices colocating with each other share bandwidth and cooperatively stream media content to distribute the load. We first model interactions among mobile devices as a coalition game, and then discuss the optimal chunk retrieval scheduling. Finally, we draw on realistic mobile phone data and utilize an ARIMA model for",4
b131da79e874fc610b87cda26d3dcf3a13352dd6,Provisioning of Service Mashup Topologies,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
fdde9a63877db44c1b6a7f5cff5d47f01465e793,Point-Voxel CNN for Efficient 3D Deep Learning,"We present Point-Voxel CNN (PVCNN) for efficient, fast 3D deep learning. Previous work processes 3D data using either voxel-based or point-based NN models. However, both approaches are computationally inefficient. The computation cost and memory footprints of the voxel-based models grow cubically with the input resolution, making it memory-prohibitive to scale up the resolution. As for point-based networks, up to 80% of the time is wasted on structuring the irregular data which have rather poor memory locality, not on the actual feature extraction. In this paper, we propose PVCNN that represents the 3D input data in points to reduce the memory consumption, while performing the convolutions in voxels to largely reduce the irregular data access and improve the locality. Our PVCNN model is both memory and computation efficient. Evaluated on semantic and part segmentation datasets, it achieves much higher accuracy than the voxel-based baseline with 10x GPU memory reduction; it also",4
9653c070724e44f023e8cc3ec79f0b9e6d59480d,iBOT: Image BERT Pre-Training with Online Tokenizer,"The success of language Transformers is primarily attributed to the pretext task of masked language modeling (MLM), where texts are first tokenized into semantically meaningful pieces. In this work, we study masked image modeling (MIM) and indicate the advantages and challenges of using a semantically meaningful visual tokenizer. We present a self-supervised framework iBOT that can perform masked prediction with an online tokenizer. Specifically, we perform self-distillation on masked patch tokens and take the teacher network as the online tokenizer, along with self-distillation on the class token to acquire visual semantics. The online tokenizer is jointly learnable with the MIM objective and dispenses with a multi-stage training pipeline where the tokenizer needs to be pre-trained beforehand. We show the prominence of iBOT by achieving an 82.3% linear probing accuracy and an 87.8% fine-tuning accuracy evaluated on ImageNet-1K. Beyond the state-of-the-art image classification results, we underline emerging local semantic patterns, which",6
3c8a456509e6c0805354bd40a35e3f2dbf8069b1,"PyTorch: An Imperative Style, High-Performance Deep Learning Library","Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed",23
36ba2075f098abcfdf9662853cbf90b4fe590137,Adversarial Autoencoders for Generating 3D Point Clouds,"Deep generative architectures provide a way to model not only images, but also complex, 3-dimensional objects, such as point clouds. In this work, we present a novel method to obtain meaningful representations of 3D shapes that can be used for clustering and reconstruction. Contrary to existing methods for 3D point cloud generation that train separate decoupled models for representation learning and generation, our approach is the first end-to-end solution that allows to simultaneously learn a latent space of representation and generate 3D shape out of it. To achieve this goal, we extend a deep Adversarial Autoencoder model (AAE) to accept 3D input and create 3D output. Thanks to our end-to-end training regime, the resulting method called 3D Adversarial Autoencoder (3dAAE) obtains either binary or continuous latent space that covers much wider portion of training data distribution, hence allowing smooth interpolation between the shapes. Finally, our extensive quantitative evaluation shows that",3
119bb19d6a6fc34eaf4e517d0acc102a7cbb4d65,PU-GAN: A Point Cloud Upsampling Adversarial Network,"Point clouds acquired from range scans are often sparse, noisy, and non-uniform. This paper presents a new point cloud upsampling network called PU-GAN, which is formulated based on a generative adversarial network (GAN), to learn a rich variety of point distributions from the latent space and upsample points over patches on object surfaces. To realize a working GAN network, we construct an up-down-up expansion unit in the generator for upsampling point features with error feedback and self-correction, and formulate a self-attention unit to enhance the feature integration. Further, we design a compound loss with adversarial, uniform and reconstruction terms, to encourage the discriminator to learn more latent patterns and enhance the output point distribution uniformity. Qualitative and quantitative evaluations demonstrate the quality of our results over the state-of-the-arts in terms of distribution uniformity, proximity-to-surface, and 3D reconstruction quality.",5
74e2c932d85fe166e158fb8ce3104d559e3af095,Addressing response time of cloud-based mobile applications,"With more mobile applications being developed to take advantage of the elastic cloud computing resources instead of restricting to native mobile device resources, this paper investigates a timely question: is there any fundamental challenge that needs to be overcome to enable cloud-based mobile applications? We show that using cloud resources makes applications highly interactive and real-time, making low response time a key requirement for satisfactory user experience. Using two promising Cloud Mobile applications, Cloud Mobile Gaming (CMG) and Cloud Mobile Desktop (CMD), we demonstrate that meeting response time requirements can be a significant challenge. We show why existing Internet PC based solutions for delay and response time management may not be adequate to address the response time challenge of Cloud Mobile applications. We describe response time management techniques that have been recently developed for Cloud Mobile applications, and propose new directions, including developing Mobile Network Clouds, and Mobile Cloud Scheduling,",5
7b95c341af5a732c094f1143f12677fb4b2eb41a,A Computational Economy for Grid Computing and its Implementation in the Nimrod-G Resource Brok,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
6351ebb4a3287f5f3e1273464b3b91e5df5a16d7,Masked Autoencoders Are Scalable Vision Learners,"This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. Our MAE approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. Second, we find that masking a high proportion of the input image, e.g., 75%, yields a nontrivial and meaningful self-supervisory task. Coupling these two designs enables us to train large models efficiently and effectively: we accelerate training (by 3× or more) and improve accuracy. Our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla ViT-Huge model achieves the best accuracy (87.8%) among methods that use only ImageNet-1K data.",4
a2f808a24d996f9e9d0bfc054128c69b73d96767,Distributed Reputation Management for Secure and Efficient Vehicular Edge Computing and Networks,"Vehicular edge computing (VEC) is introduced to extend computing capacity to vehicular network edge recently. With the advent of VEC, service providers directly host services in close proximity of mobile vehicles for great improvements. As a result, a new networking paradigm, vehicular edge networks is emerged along with the development of VEC. However, it is necessary to address security issues for facilitating VEC well. In this paper, we focus on reputation management to ensure security protection and improve network efficiency in the implementation of VEC. A distributed reputation management system (DREAMS) is proposed, wherein VEC servers are adopted to execute local reputation management tasks for vehicles. This system has remarkable features for improving overall performance: 1) distributed reputation maintenance; 2) trusted reputation manifestation; 3) accurate reputation update; and 4) available reputation usage. In particular, we utilize multi-weighted subjective logic for accurate reputation update in DREAMS. To enrich reputation usage in",5
7d906f6632f8740b540ce4d710f53ab0f97cfd5b,Dynamo: amazon's highly available key-value store,"Reliability at massive scale is one of the biggest challenges we face at Amazon.com, one of the largest e-commerce operations in the world; even the slightest outage has significant financial consequences and impacts customer trust. The Amazon.com platform, which provides services for many web sites worldwide, is implemented on top of an infrastructure of tens of thousands of servers and network components located in many datacenters around the world. At this scale, small and large components fail continuously and the way persistent state is managed in the face of these failures drives the reliability and scalability of the software systems. This paper presents the design and implementation of Dynamo, a highly available key-value storage system that some of Amazon's core services use to provide an ""always-on"" experience. To achieve this level of availability, Dynamo sacrifices consistency under certain failure scenarios. It makes extensive use of object versioning and application-assisted conflict",13
255ba5fa2861f8cf097e5bd0f93fdfd95a7a0444,"Markets are dead, long live markets","Researchers have long proposed using economic approaches to resource allocation in computer systems. However, few of these proposals became operational, let alone commercial. Questions persist about the economic approach regarding its assumptions, value, applicability, and relevance to system design. The goal of this paper is to answer these questions. We find that market-based resource allocation is useful, and more importantly, that mechanism design and system design should be integrated to produce systems that are both economically and computationally efficient.",2
29081e5c63d24fa8952e938dba68956cd47ac81d,Robust and Communication-Efficient Federated Learning From Non-i.i.d. Data,"Federated learning allows multiple parties to jointly train a deep learning model on their combined data, without any of the participants having to reveal their local data to a centralized server. This form of privacy-preserving collaborative learning, however, comes at the cost of a significant communication overhead during training. To address this problem, several compression methods have been proposed in the distributed training literature that can reduce the amount of required communication by up to three orders of magnitude. These existing methods, however, are only of limited utility in the federated learning setting, as they either only compress the upstream communication from the clients to the server (leaving the downstream communication uncompressed) or only perform well under idealized conditions, such as i.i.d. distribution of the client data, which typically cannot be found in federated learning. In this article, we propose sparse ternary compression (STC), a new compression framework that is",8
dbaeb471f1965b2c4c2b8b3d57cd1d9cbfac17af,IoT enabled cancer prediction system to enhance the authentication and security using cloud computing,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
6fffaf5db22866eec6ae8d2a61c9e2286382e1d6,A Mobile Crowdsensing Ecosystem Enabled by a Cloud-Based Publish/Subscribe Middleware,"We are witnessing the rise of a novel class of wearable devices equipped with various sensing capabilities as well as further miniaturization of sensing components that are nowadays being integrated into mobile devices. The inherent mobility of such devices has the capacity to produce dense and rich spatiotemporal information about our environment creating the mobile Internet of Things (IoT). The management of mobile resources to enable sensor discovery and seamless integration of mobile geotagged sensor data with cloud-based IoT platforms creates new challenges due to device dynamicity, energy constraints, and varying sensor data quality. The paper presents an ecosystem for mobile crowdsensing applications which relies on the CloUd-based PUblish/Subscribe middleware (CUPUS) to acquire sensor data from mobile devices in a context-aware and energy-efficient manner. The ecosystem offers the means for location management of mobile Internet-connected objects and adaptive data acquisition from such devices. In addition, our solution enables filtering of",7
e00b7576829fbd2bda40825d057eefcc5a74c506,Falkon: a Fast and Light-weight tasK executiON framework,"To enable the rapid execution of many tasks on compute clusters, we have developed Falkon, a Fast and Light-weight tasK executiON framework. Falkon integrates (1) multi-level scheduling to separate resource acquisition (via, e.g., requests to batch schedulers) from task dispatch, and (2) a streamlined dispatcher. Falkon's integration of multi-level scheduling and streamlined dispatchers delivers performance not provided by any other system. We describe Falkon architecture and implementation, and present performance results for both microbenchmarks and applications. Microbenchmarks show that Falkon throughput (487 tasks/sec) and scalability (to 54,000 executors and 2,000,000 tasks processed in just 112 minutes) are one to two orders of magnitude better than other systems used in production Grids. Large-scale astronomy and medical applications executed under Falkon by the Swift parallel programming system achieve up to 90% reduction in end-to-end run time, relative to versions that execute tasks via separate scheduler submissions.",7
43f2ad297941db230c089ba353efc3f281ab678c,5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",22
ea7139d55978c63a18eaee24cbb1b0f91035de9d,On Reducing IoT Service Delay via Fog Offloading,"With the Internet of Things (IoT) becoming a major component of our daily life, understanding how to improve the quality of service for IoT applications through fog computing is becoming an important problem. In this paper, we introduce a general framework for IoT-fog-cloud applications, and propose a delay-minimizing collaboration and offloading policy for fog-capable devices that aims to reduce the service delay for IoT applications. We then develop an analytical model to evaluate our policy and show how the proposed framework helps to reduce IoT service delay.",4
7d39d69b23424446f0400ef603b2e3e22d0309d6,"YOLO9000: Better, Faster, Stronger","We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. Using a novel, multi-scale training method the same YOLOv2 model can run at varying sizes, offering an easy tradeoff between speed and accuracy. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that dont have labelled detection data.",10
344c84951ec0d7f40784168fb91a3ee829994a81,"Turbulent Mixing, Spectral Evolution and Dynamics in a Warm Cumulus Cloud","Abstract The analysis of Paluch suggests that some cumuli contain cloudy air from only two sources: cloud base and cloud top. A framework is presented for the investigation of droplet spectral evolution in clouds composed of air from only these two sources. The key is the investigation of the dependence of droplet concentration N on the fraction of cloud base air F in a sample of cloudy air. This N-vs-F analysis is coupled with an investigation of droplet spectral parameters to infer the types and scales of entrainment and mixing events. The technique is used in a case study of a small, nonprecipitating continental cumulus cloud which was sampled during the 1981 CCOPE project in eastern Montana. The mixing between cloudy and entrained air in this cloud often appears to occur without total removal of droplets, although there is evidence that total evaporation occurs in some regions with low liquid",7
c4196bf59533f8f853f3470941b6c4029c659f6f,The role of cloud microphysical processes in climate: an assessment from a one-dimensional perspective,"The potential link between cloud microphysical processes and climate is investigated and theorized. We base our theory on results simulated from a one-dimensional climate model with an interactive cloud formation and precipitation program. This cloud program includes temperature-dependent parameterization equations for condensation, evaporation, and precipitation derived from growth equations for water droplets. We show that the cloud liquid water content is directly related to precipitation processes, which are governed by the mean cloud particle radius. In particular, we illustrate that the rate of precipitation generation is directly proportional to the fourth power of this radius. A doubling of CO2 is used as the radiative forcing. If the perturbed mean cloud particle radii for model high, middle, and low clouds are less than the climatological mean values, precipitation decreases because of the presence of smaller cloud particles, leading to an increase in the cloud liquid water content. Cloud solar albedo effects",4
ceb2ebef0b41e31c1a21b28c2734123900c005e2,A Style-Based Generator Architecture for Generative Adversarial Networks,"We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.",4
f6abfcfc6c3bbe1d13ed6f1512b7d15a94ac4756,White,"Many terrorist groups, it would seem, cause great turmoil but no lasting impact. This might include radical student groups of the 1960s and terrorist organizations of the 1970s. Yet, we know that in some instances political violence, or revolution, does lead to great social change. Consider Cuba as an example. This might suggest that terrorists and revolutionaries face a zero-sum game: total failure or total victory. There is a middle ground, however. The PLO, as an example, has not achieved an independent Palestine, but who in the 1970s would have imagined a Palestinian Authority led by Yasir Arafat. This case study of the Irish Republican Army and its political wing, Sinn Fein, examines this middle ground in Ireland in the 1916-1948 time period.",4
35ed248cfe4287a6d989b9972671dd903dc543dd,Anti-spoofing cloud-based multi-spectral biometric identification system for enterprise security and privacy-preservation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
7bcd0f35385aa970c4fd6c789be416f000198048,Integrating wireless sensor networks within a city cloud,"Smart City solutions are currently based on multiple architectures, standards and platforms, which have led to a highly fragmented landscape. In order to allow cities to share data across systems and coordinate processes across domains, it is essential to break these silos. A way to achieve the purpose is sensor virtualization, discovery and data restitution. In this paper, a federation of FIT IoT-LAB within OpenIoT is presented. OpenIoT is a middleware that enables the collection of data streams from multiple heterogeneous geographically dispersed data sources, as well as their semantic unification and streaming with a cloud infrastructure. Future Internet of Things IoT-LAB (FIT IoT-LAB) provides a very large scale infrastructure facility suitable for testing small wireless sensor devices and heterogeneous communicating objects. The integration proposed represents a way to reduce the gap existing in the Internet of Things (IoT) fragmentation, and, moreover, allows users to develop smart city applications by",3
9b925d8c60f53e929f2651c2ea24713f820d9feb,Autonomous door opening and plugging in with a personal robot,"We describe an autonomous robotic system capable of navigating through an office environment, opening doors along the way, and plugging itself into electrical outlets to recharge as needed. We demonstrate through extensive experimentation that our robot executes these tasks reliably, without requiring any modification to the environment. We present robust detection algorithms for doors, door handles, and electrical plugs and sockets, combining vision and laser sensors. We show how to overcome the unavoidable shortcoming of perception by integrating compliant control into manipulation motions. We present a visual-differencing approach to high-precision plug-insertion that avoids the need for high-precision hand-eye calibration.",1
fbc28ade3af77164679081af127e49803a635045,Survey of access control models and technologies for cloud computing,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
b8337665c72596062c70d5809a691f2f452134c2,"Hash, Displace, and Compress","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
24622a6a8f1a77d62f9ca73caa8b3939b1295fb9,EnaCloud: An Energy-Saving Application Live Placement Approach for Cloud Computing Environments,"With the increasing prevalence of large scale cloud computing environments, how to place requested applications into available computing servers regarding to energy consumption has become an essential research problem, but existing application placement approaches are still not effective for live applications with dynamic characters. In this paper, we proposed a novel approach named EnaCloud, which enables application live placement dynamically with consideration of energy efficiency in a cloud platform. In EnaCloud, we use a Virtual Machine to encapsulate the application, which supports applications scheduling and live migration to minimize the number of running machines, so as to save energy. Specially, the application placement is abstracted as a bin packing problem, and an energy-aware heuristic algorithm is proposed to get an appropriate solution. In addition, an over-provision approach is presented to deal with the varying resource demands of applications. Our approach has been successfully implemented as useful components and fundamental services",7
f1560ef3ef7264c65daff14d8de16d86c78cf4b7,"A Logging Model for Enabling Digital Forensics in IoT, in an Inter-connected IoT, Cloud Eco-systems","Rapid advancement in the smart device technologies have accelerated the deployment of Internet-of-Things (IoT) to control, monitor or to exchange information of any real world systems and improve the quality of life. The IoT allows to create a network of billions of devices, using multitude of communication and data processing technologies, supporting varying business needs both in civilian settings and sensitive applications. This also creates an increased footprint for security vulnerabilities and cyber-attacks. Therefore, the security and digital forensics capabilities have to be built into the design of the IoT. In this work, we summarized the IoT forensic challenges and defined the IoT forensic requirements. We then proposed a conceptual event logging model and design architecture to support digital forensics in IoT, for an integrated IoT-Cloud computing environment. The model exploits the power of the Cloud computing, same time complements the deficiencies of IoT, utilizing an integrated environment.",3
a975d0c779179b33bbdbb9e56a48fab8a153c7f5,Distributed Computing Economics,"Computing is free. The world’s most powerful computer is free (SETI@Home is a 54-teraflop machine). Google freely provides a trillion searches per year to the world’s largest online database (two petabytes). Hotmail freely carries a trillion e-mail messages per year. Amazon.com offers a free book-search tool. Many sites offer free news and other free content. Movies, sports events, concerts, and entertainment are freely available via television.",8
32b918246037976ba5f8363104ec042f56db42d6,Learning Localized Generative Models for 3D Point Clouds via Graph Convolution,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
5a3e2899deed746f1513708f1f0f24a25f4a0750,3D Point Cloud Registration for Localization Using a Deep Neural Network Auto-Encoder,"We present an algorithm for registration between a large-scale point cloud and a close-proximity scanned point cloud, providing a localization solution that is fully independent of prior information about the initial positions of the two point cloud coordinate systems. The algorithm, denoted LORAX, selects super-points&#x2013;local subsets of points&#x2013;and describes the geometric structure of each with a low-dimensional descriptor. These descriptors are then used to infer potential matching regions for an efficient coarse registration process, followed by a fine-tuning stage. The set of super-points is selected by covering the point clouds with overlapping spheres, and then filtering out those of low-quality or nonsalient regions. The descriptors are computed using state-of-the-art unsupervised machine learning, utilizing the technology of deep neural network based auto-encoders. Abstract This novel framework provides a strong alternative to the common practice of using manually designed key-point descriptors for coarse point cloud registration. Utilizing super-points instead of key-points allows",3
50711657ca793dc473e81f97958e2242c95741e2,Distributed processing in vehicular cloud networks,"Vehicular Clouds processing is a new field of research that aims to exploit the vehicles' onboard computational resources as a part of a cooperative distributed cloud computing environment. In this paper, we propose a vehicular cloud network architecture where a group of vehicles near a traffic light cluster and form a temporal vehicular cloud by aggregating their computational resources in that cluster. The goal of the proposed architecture is to minimize the processing and network power consumed in the data center of a cloud operator. To this end, arriving processing tasks are optimally assigned to the centralized cloud and/or the formed vehicular clouds to reduce the total power consumption of the centralized cloud by reducing its average processing workload and network traffic. Furthermore, task assignment among vehicular clouds is constrained by tasks completion time. Our proposed system is analyzed using a mixed integer linear programming (MILP) model where two task",5
6f017b648677725a49780ebbdf35198487351382,"Enabling Workload Engineering in Edge, Fog, and Cloud Computing through OpenStack-based Middleware","To enable and support smart environments, a recent ICT trend promotes pushing computation from the remote Cloud as close to data sources as possible, resulting in the emergence of the Fog and Edge computing paradigms. Together with Cloud computing, they represent a stacked architecture, in which raw datasets are first pre-processed locally at the Edge and then vertically offloaded to the Fog and/or the Cloud. However, as hardware is becoming increasingly powerful, Edge devices are seen as candidates for offering data processing capabilities, able to pool and share computing resources to achieve better performance at a lower network latency—a pattern that can be also applied to Fog nodes. In these circumstances, it is important to enable efficient, intelligent, and balanced allocation of resources, as well as their further orchestration, in an elastic and transparent manner. To address such a requirement, this article proposes an OpenStack-based middleware platform through which resource",3
7615f13cee4ec0248e88cec2624e451b90a51574,ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans,"We introduce ScanComplete, a novel data-driven approach for taking an incomplete 3D scan of a scene as input and predicting a complete 3D model along with per-voxel semantic labels. The key contribution of our method is its ability to handle large scenes with varying spatial extent, managing the cubic growth in data size as scene size increases. To this end, we devise a fully-convolutional generative 3D CNN model whose filter kernels are invariant to the overall scene size. The model can be trained on scene subvolumes but deployed on arbitrarily large scenes at test time. In addition, we propose a coarse-to-fine inference strategy in order to produce high-resolution output while also leveraging large input context sizes. In an extensive series of experiments, we carefully evaluate different model design choices, considering both deterministic and probabilistic models for completion and semantic inference. Our results show that we outperform other methods not only",8
cc8d1aa1308d145bdb2652e2c6a6d39418525dbe,Quality-Aware Traffic Offloading in Wireless Networks,"In cellular networks, due to many practical deployment issues, some areas have good wireless coverage while other areas may not. This results in significant throughput (service quality) difference between wireless carriers at some locations. We first analyze the factors that affect the service quality and then validate the existence of service quality difference between different carriers via extensive measurements. To deal with this problem, a mobile device (node) with low service quality can offload its data traffic to nearby nodes with better service quality through Device-to-Device interfaces, such as WiFi direct, to save energy and reduce delay. To achieve this goal, we propose a Quality-Aware Traffic Offloading (QATO) framework to offload network tasks to neighboring nodes with better service quality. QATO can identify neighbors with better service quality and motivate nodes to help each other using incentive schemes. To validate our design, we have implemented QATO on Android platform and",2
96136ae613b2b917a09d7c8f49a1d07673e6cd63,A Classification of Emerging and Traditional Grid Systems,"Advances in grid computing are stimulating the emergence of novel types of grids, such as accessible, manageable, interactive, and personal grids. More and more researchers are realizing emerging grids' potential to bridge the gap between grid technologies and users. This review of emerging grids sets out to develop a comprehensive classification of both traditional and emerging grid systems, with an aim to motivate further research and to help establish a solid foundation in this rapidly developing field.",4
1c838ffc6c4b63a577c9cb3d8d86c8ba14915640,PVNet: A Joint Convolutional Network of Point Cloud and Multi-View for 3D Shape Recognition,"3D object recognition has attracted wide research attention in the field of multimedia and computer vision. With the recent proliferation of deep learning, various deep models with different representations have achieved the state-of-the-art performance. Among them, point cloud and multi-view based 3D shape representations are promising recently, and their corresponding deep models have shown significant performance on 3D shape recognition. However, there is little effort concentrating point cloud data and multi-view data for 3D shape representation, which is, in our consideration, beneficial and compensated to each other. In this paper, we propose the Point-View Network (PVNet), the first framework integrating both the point cloud and the multi-view data towards joint 3D shape recognition. More specifically, an embedding attention fusion scheme is proposed that could employ high-level features from the multi-view data to model the intrinsic correlation and discriminability of different structure features from the point cloud data. In particular, the",7
76cee11c6a9f1424f03571378a966c1417ff2935,Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling,"We study the problem of 3D object generation. We propose a novel framework, namely 3D Generative Adversarial Network (3D-GAN), which generates 3D objects from a probabilistic space by leveraging recent advances in volumetric convolutional networks and generative adversarial nets. The benefits of our model are three-fold: first, the use of an adversarial criterion, instead of traditional heuristic criteria, enables the generator to capture object structure implicitly and to synthesize high-quality 3D objects; second, the generator establishes a mapping from a low-dimensional probabilistic space to the space of 3D objects, so that we can sample objects without a reference image or CAD models, and explore the 3D object manifold; third, the adversarial discriminator provides a powerful 3D shape descriptor which, learned without supervision, has wide applications in 3D object recognition. Experiments demonstrate that our method generates high-quality 3D objects, and our unsupervisedly learned features achieve impressive performance on 3D object recognition,",31
a25d6f407eaa62897118f1fb0567db75cff3bab0,Workload characterization of interactive cloud services on big and small server platforms,"Key-value stores (e.g., Memcached) and web servers (e.g., NGINX) are widely used by cloud providers. As interactive services, they have strict service-level objectives, with typical 99th-percentile tail latencies on the order of a few milliseconds. Unlike average latency, tail latency is more sensitive to changes in usage load and traffic patterns, system configurations, and resource availability. Understanding the sensitivity of tail latency to application and system factors is critical to efficiently design and manage systems for these latency-critical services. We present a comprehensive study of the impact a diverse set of application, hardware, and isolation configurations have on tail latency for two representative interactive services, Memcached and NGINX. Examined factors include input load, thread-level parallelism, request size, virtualization, and resource partitioning. We conduct this study on two server platforms with significant differences in terms of architecture and price points: an Intel Xeon and an ARM-based Cavium ThunderX server. Experimental results",4
844ee166ad16dbaa45d00824cbed71960aa98ac1,Accelerating smart eHealth services execution at the fog computing infrastructure,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
1335190de78e0b58fbf7a7c7c52fa1a15f14858a,Learning 3D Shape Completion from Laser Scan Data with Weak Supervision,"3D shape completion from partial point clouds is a fundamental problem in computer vision and computer graphics. Recent approaches can be characterized as either data-driven or learning-based. Data-driven approaches rely on a shape model whose parameters are optimized to fit the observations. Learning-based approaches, in contrast, avoid the expensive optimization step and instead directly predict the complete shape from the incomplete observations using deep neural networks. However, full supervision is required which is often not available in practice. In this work, we propose a weakly-supervised learning-based approach to 3D shape completion which neither requires slow optimization nor direct supervision. While we also learn a shape prior on synthetic data, we amortize, i.e., learn, maximum likelihood fitting using deep neural networks resulting in efficient shape completion without sacrificing accuracy. Tackling 3D shape completion of cars on ShapeNet [5] and KITTI [18], we demonstrate that the proposed amortized maximum likelihood approach is",7
cbc1395a4bb8a7540749e056753c139c2b6fff15,3DMatch: Learning the Matching of Local 3D Geometry in Range Scans,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
5af2b332dceb6e8eebe33beb1b6264c66fa3e12d,The Architectural Implications of Cloud Microservices,"Cloud services have recently undergone a shift from monolithic applications to microservices, with hundreds or thousands of loosely-coupled microservices comprising the end-to-end application. Microservices present both opportunities and challenges when optimizing for quality of service (QoS) and cloud utilization. In this paper we explore the implications cloud microservices have on system bottlenecks, and datacenter server design. We first present and characterize an end-to-end application built using tens of popular open-source microservices that implements a movie renting and streaming service, and is modular and extensible. We then use the end-to-end service to study the scalability and performance bottlenecks of microservices, and highlight implications they have on the design of datacenter hardware. Specifically, we revisit the long-standing debate of brawny versus wimpy cores in the context of microservices, we quantify the I-cache pressure they introduce, and measure the time spent in computation versus communication between microservices over RPCs. As more cloud applications",5
d997beefc0922d97202789d2ac307c55c2c52fba,PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,"Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.",101
b7c7e9a98725991f801cc8b57440973e9912e0bd,Contextualization: Providing One-Click Virtual Clusters,"As virtual appliances become more prevalent, we encounter the need to stop manually adapting them to their deployment context each time they are deployed. We examine appliance contextualization needs and present architecture for secure, consistent, and dynamic contextualization, in particular for groups of appliances that must work together in a shared security context. This architecture allows for programmatic cluster creation and use, as well as mitigating potential errors and unnecessary charges during setup time. For portability across many deployment mechanisms, we introduce the concept of a standalone context broker. We describe the current implementation of the entire architecture using the virtual workspaces toolkit, showing real-life examples of dynamically contextualized Grid clusters.",3
689b98a18fe2fe73a06836527a9dd0b2d6724cb3,"Specification, planning, and execution of QoS‐aware Grid workflows within the Amadeus environment","Commonly, at a high level of abstraction Grid applications are specified based on the workflow paradigm. However, majority of Grid workflow systems either do not support Quality of Service (QoS), or provide only partial QoS support for certain phases of the workflow lifecycle. In this paper we present Amadeus, which is a holistic service‐oriented environment for QoS‐aware Grid workflows. Amadeus considers user requirements, in terms of QoS constraints, during workflow specification, planning, and execution. Within the Amadeus environment workflows and the associated QoS constraints are specified at a high level using an intuitive graphical notation. A distinguishing feature of our system is the support of a comprehensive set of QoS requirements, which considers in addition to performance and economical aspects also legal and security aspects. A set of QoS‐aware service‐oriented components is provided for workflow planning to support automatic constraint‐based service negotiation and workflow optimization. For improving the efficiency of",3
feddf764b54746b40c9a675f4020bfa504e0035c,Amazon Simple Storage Service (S3),"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
09a295517fa585772f9d502884a4b56d641eb59a,Mobile cloud computing educational tool for image/video processing algorithms,"This paper shows the importance and benefit of coupling cloud computing with mobile especially due to power limitations that mobile devices exhibit. Moreover, the work done shows that mobile computing can be applied for educational purposes, where a tool for students termed Mobi4Ed is presented. This educational tool aims at exploiting the concept of cloud computing in the context of image and video processing, where students can assess several algorithms in real-time. Two possible system architectures are detailed, where one uses the cellular channel and the other uses the data channel. Consequently, one of the approaches is adopted and a detailed simulation is done where an Android client device is shown communicating with a server running openCV and using the Haar face-detection algorithm. The work assures the credibility of the adopted system architecture, in terms of deployment, and several future lines of work are proposed.",4
722ad6ac92286507437b31486f47987d6ece05c9,BEiT: BERT Pre-Training of Image Transformers,"We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e, image patches (such as 16x16 pixels), and visual tokens (i.e., discrete tokens). We first""tokenize""the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods. For example, base-size BEiT achieves 83.2% top-1 accuracy on ImageNet-1K, significantly outperforming from-scratch DeiT training",7
24472a31618bbc260e2bf45bd72427097875142b,End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures,"We study pseudo-labeling for the semi-supervised training of ResNet, Time-Depth Separable ConvNets, and Transformers for speech recognition, with either CTC or Seq2Seq loss functions. We perform experiments on the standard LibriSpeech dataset, and leverage additional unlabeled data from LibriVox through pseudo-labeling. We show that while Transformer-based acoustic models have superior performance with the supervised dataset alone, semi-supervision improves all models across architectures and loss functions and bridges much of the performance gaps between them. In doing so, we reach a new state-of-the-art for end-to-end acoustic models decoded with an external language model in the standard supervised learning setting, and a new absolute state-of-the-art with semi-supervised training. Finally, we study the effect of leveraging different amounts of unlabeled audio, propose several ways of evaluating the characteristics of unlabeled audio which improve acoustic modeling, and show that acoustic models trained with more audio rely less on external language models.",4
d54f79fd52ef0b7d9aa7366a77f0736a37622131,PowerChief: Intelligent power allocation for multi-stage applications to improve responsiveness on power constrained CMP,"Modern user facing applications consist of multiple processing stages with a number of service instances in each stage. The latency profile of these multi-stage applications is intrinsically variable, making it challenging to provide satisfactory responsiveness. Given a limited power budget, improving the end-to-end latency requires intelligently boosting the bottleneck service across stages using multiple boosting techniques. However, prior work fail to acknowledge the multi-stage nature of user-facing applications and perform poorly in improving responsiveness on power constrained CMP, as they are unable to accurately identify bottleneck service and apply the boosting techniques adaptively. In this paper, we present PowerChief, a runtime framework that 1) provides joint design of service and query to monitor the latency statistics across service stages and accurately identifies the bottleneck service during runtime; 2) adaptively chooses the boosting technique to accelerate the bottleneck service with improved responsiveness; 3) dynamically reallocates the constrained power budget across service",3
4390aaba3f5bf35c65997858abc01c282b06a725,Autoscaling tiered cloud storage in Anna,"In this paper, we describe how we extended a distributed key-value store called Anna into an autoscaling, multi-tier service for the cloud. In its extended form, Anna is designed to overcome the narrow cost–performance limitations typical of current cloud storage systems. We describe three key aspects of Anna’s new design: multi-master selective replication of hot keys, a vertical tiering of storage layers with different cost–performance trade-offs, and horizontal elasticity of each tier to add and remove nodes in response to load dynamics. Anna’s policy engine uses these mechanisms to balance service-level objectives around cost, latency, and fault tolerance. Experimental results explore the behavior of Anna’s mechanisms and policy, exhibiting orders of magnitude efficiency improvements over both commodity cloud KVS services and research systems.",2
6b42da07552dd40974f793f8da1ca6521f1e49e8,The Case for VM-Based Cloudlets in Mobile Computing,"Mobile computing continuously evolve through the sustained effort of many researchers. It seamlessly augments users' cognitive abilities via compute-intensive capabilities such as speech recognition, natural language processing, etc. By thus empowering mobile users, we could transform many areas of human activity. This article discusses the technical obstacles to these transformations and proposes a new architecture for overcoming them. In this architecture, a mobile user exploits virtual machine (VM) technology to rapidly instantiate customized service software on a nearby cloudlet and then uses that service over a wireless LAN; the mobile device typically functions as a thin client with respect to the service. A cloudlet is a trusted, resource-rich computer or cluster of computers that's well-connected to the Internet and available for use by nearby mobile devices. Our strategy of leveraging transiently customized proximate infrastructure as a mobile device moves with its user through the physical world is called cloudlet-based, resource-rich,",18
268d347e8a55b5eb82fb5e7d2f800e33c75ab18a,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,"While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.",27
729d5c7dc6bfb32e47b5bd24cdb01ccaaf62bba5,A scalable active framework for region annotation in 3D shape collections,"Large repositories of 3D shapes provide valuable input for data-driven analysis and modeling tools. They are especially powerful once annotated with semantic information such as salient regions and functional parts. We propose a novel active learning method capable of enriching massive geometric datasets with accurate semantic region annotations. Given a shape collection and a user-specified region label our goal is to correctly demarcate the corresponding regions with minimal manual work. Our active framework achieves this goal by cycling between manually annotating the regions, automatically propagating these annotations across the rest of the shapes, manually verifying both human and automatic annotations, and learning from the verification results to improve the automatic propagation algorithm. We use a unified utility function that explicitly models the time cost of human input across all steps of our method. This allows us to jointly optimize for the set of models to annotate and for the set",31
c538865c619113cb82b54e74646c32a8cafd6063,Deep Projective 3D Semantic Segmentation,"Semantic segmentation of 3D point clouds is a challenging problem with numerous real-world applications. While deep learning has revolutionized the field of image semantic segmentation, its impact on point cloud data has been limited so far. Recent attempts, based on 3D deep learning approaches (3D-CNNs), have achieved below-expected results. Such methods require voxelizations of the underlying point cloud data, leading to decreased spatial resolution and increased memory consumption. Additionally, 3D-CNNs greatly suffer from the limited availability of annotated datasets.",5
3849f7c699dce0d70c7002e0e82005a0b712df58,Cascaded Refinement Network for Point Cloud Completion,"Point clouds are often sparse and incomplete. Existing shape completion methods are incapable of generating details of objects or learning the complex point distributions. To this end, we propose a cascaded refinement network together with a coarse-to-fine strategy to synthesize the detailed object shapes. Considering the local details of partial input with the global shape information together, we can preserve the existing details in the incomplete point set and generate the missing parts with high fidelity. We also design a patch discriminator that guarantees every local area has the same pattern with the ground truth to learn the complicated point distribution. Quantitative and qualitative experiments on different datasets show that our method achieves superior results compared to existing state-of-the-art approaches on the 3D point cloud completion task. Our source code is available at https://github.com/xiaogangw/cascaded-point-completion.git.",5
5f37774725e71d44b387ba24297cccf653b3c8c6,Comments on “The Effects of Very Large Drops on Cloud Absorption. Part I: Parcel Models”,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
2cd605106b88c85d7d8b865b1ef0f8c8293debf1,Zero-Shot Text-to-Image Generation,"Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.",13
0f4640f960e2f469b9624af80c18acdfd3ea5427,Vertical distribution of dimethylsulphide in the marine atmosphere,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
f23bf58437140927ee7b2107597568e23a398ba1,STD: Sparse-to-Dense 3D Object Detector for Point Cloud,"We propose a two-stage 3D object detection framework, named sparse-to-dense 3D Object Detector (STD). The first stage is a bottom-up proposal generation network that uses raw point clouds as input to generate accurate proposals by seeding each point with a new spherical anchor. It achieves a higher recall with less computation compared with prior works. Then, PointsPool is applied for proposal feature generation by transforming interior point features from sparse expression to compact representation, which saves even more computation. In box prediction, which is the second stage, we implement a parallel intersection-over-union (IoU) branch to increase awareness of localization accuracy, resulting in further improved performance. We conduct experiments on KITTI dataset, and evaluate our method on 3D object and Bird’s Eye View (BEV) detection. Our method outperforms other methods by a large margin, especially on the hard set, with 10+ FPS inference speed.",6
c1ab2b7915131e8f55fcc4162bfcc2fd3fdfd12e,Dimethyl sulfide in the marine atmosphere,"We have performed over 900 measurements of atmospheric dimethyl sulfide (DMS) in five different marine locations: the equatorial Pacific; Cape Grim, Tasmania; the Bahamas; the North Atlantic; and the Sargasso Sea. At all locations, DMS concentrations were usually in the range of 100–400 ng S m−3, with similar average concentrations of approximately 150 ng S m−3 (107 parts per thousand by volume). Highest concentrations occurred during, but were not limited to, periods of sustained high winds and overcast skies, presumably owing to faster exchange from surface seawater and less photochemical activity in the atmosphere. Lowest values occurred during airflow from continental regions, which provides higher levels of oxidants and free radicals to react with DMS. Averaged over time, the concentrations in clean marine air reached a maximum at night and a minimum in the afternoon, when concentrations were about one third lower than during the nighttime maximum. The observed concentrations",6
c4ab27207352d48197380efb9977f5731128cdd6,WEAKLY SUPERVISED SEGMENTATION-AIDED CLASSIFICATION OF URBAN SCENES FROM 3D LIDAR POINT CLOUDS,"Abstract. We consider the problem of the semantic classification of 3D LiDAR point clouds obtained from urban scenes when the training set is limited. We propose a non-parametric segmentation model for urban scenes composed of anthropic objects of simple shapes, partionning the scene into geometrically-homogeneous segments which size is determined by the local complexity. This segmentation can be integrated into a conditional random field classifier (CRF) in order to capture the high-level structure of the scene. For each cluster, this allows us to aggregate the noisy predictions of a weakly-supervised classifier to produce a higher confidence data term. We demonstrate the improvement provided by our method over two publicly-available large-scale data sets.",5
ebc96892b9bcbf007be9a1d7844e4b09fde9d961,YOLOv3: An Incremental Improvement,"We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at this https URL",6
4e08a86b8e56e82b7307af6f57c8e5b228e2f681,Moving the OS to the Web,"With the increasing use of high-speed Internet technologies, the concept of cloud computing has become more popular. In cloud computing, users work with Web-based, rather than local, storage and software. These applications are accessible via a browser and look and act like desktop programs.",2
72f0f9e9d798414aeb77efa415d1550276e72d07,Numpywren: Serverless Linear Algebra,"Linear algebra operations are widely used in scientific computing and machine learning applications. However, it is challenging for scientists and data analysts to run linear algebra at scales beyond a single machine. Traditional approaches either require access to supercomputing clusters, or impose configuration and cluster management challenges. In this paper we show how the disaggregation of storage and compute resources in so-called ""serverless"" environments, combined with compute-intensive workload characteristics, can be exploited to achieve elastic scalability and ease of management. We present numpywren, a system for linear algebra built on a serverless architecture. We also introduce LAmbdaPACK, a domain-specific language designed to implement highly parallel linear algebra algorithms in a serverless setting. We show that, for certain linear algebra algorithms such as matrix multiply, singular value decomposition, and Cholesky decomposition, numpywren's performance (completion time) is within 33% of ScaLAPACK, and its compute efficiency (total CPU-hours) is up to 240% better",4
30922a3953ff740486bfd01461cc1f0c5185c39c,Self-adaptive and self-configured CPU resource provisioning for virtualized servers using Kalman filters,"Data center virtualization allows cost-effective server consolidation which can increase system throughput and reduce power consumption. Resource management of virtualized servers is an important and challenging task, especially when dealing with fluctuating workloads and complex multi-tier server applications. Recent results in control theory-based resource management have shown the potential benefits of adjusting allocations to match changing workloads. This paper presents a new resource management scheme that integrates the Kalman filter into feedback controllers to dynamically allocate CPU resources to virtual machines hosting server applications. The novelty of our approach is the use of the Kalman filter-the optimal filtering technique for state estimation in the sum of squares sense-to track the CPU utilizations and update the allocations accordingly. Our basic controllers continuously detect and self-adapt to unforeseen workload intensity changes. Our more advanced controller self-configures itself to any workload condition without any a priori information. Indicatively, it results in within 4.8%",2
6ac1852ab5fc4c94fe22bcfbbb3fe9bba71dc3d1,What Will 5G Be?,"What will 5G be? What it will not be is an incremental advance on 4G. The previous four generations of cellular technology have each been a major paradigm shift that has broken backward compatibility. Indeed, 5G will need to be a paradigm shift that includes very high carrier frequencies with massive bandwidths, extreme base station and device densities, and unprecedented numbers of antennas. However, unlike the previous four generations, it will also be highly integrative: tying any new 5G air interface and spectrum together with LTE and WiFi to provide universal high-rate coverage and a seamless user experience. To support this, the core network will also have to reach unprecedented levels of flexibility and intelligence, spectrum regulation will need to be rethought and improved, and energy and cost efficiencies will become even more critical considerations. This paper discusses all of these topics, identifying key challenges for future research and preliminary",7
9f3ebaf46bda931ba596c0959f0321ddfe34e922,Cloud Computing Pyramid,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
a44419cc045880f5135b61c5803d577adb481c84,An automatic heart disease prediction using cluster-based bi-directional LSTM (C-BiLSTM) algorithm,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
726f9a27cb60df3d9a26c22dca41b10ecd63e661,Alto: lightweight VMs using virtualization-aware managed runtimes,"Virtualization enables datacenter operators to safely run computations that belong to untrusted tenants. An ideal virtual machine has three properties: a small memory footprint; strong isolation from other VMs and the host OS; and the ability to maintain in-memory state across client requests. Unfortunately, modern virtualization technologies cannot provide all three properties at once. In this paper, we explain why, and propose a new virtualization approach, called Alto, that virtualizes at the layer of a managed runtime interface. Through careful design of (1) the application-facing managed interface and (2) the internal runtime architecture, Alto provides VMs that are small, secure, and stateful. Conveniently, Alto also simplifies VM operations like suspension, migration, and resumption. We provide several details about the proposed design, and discuss the remaining challenges that must be solved to fully realize the Alto vision.",6
38ab4cdfe004b0b2e4075de7a91f7a7fbe063853,Economic Models and Algorithms for Distributed Systems,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
7bbcd665f4847652e307ca717b209de92cd95dd2,Deep Parametric Continuous Convolutional Neural Networks,"Standard convolutional neural networks assume a grid structured input is available and exploit discrete convolutions as their fundamental building blocks. This limits their applicability to many real-world applications. In this paper we propose Parametric Continuous Convolution, a new learnable operator that operates over non-grid structured data. The key idea is to exploit parameterized kernel functions that span the full continuous vector space. This generalization allows us to learn over arbitrary data structures as long as their support relationship is computable. Our experiments show significant improvement over the state-of-the-art in point cloud segmentation of indoor and outdoor scenes, and lidar motion estimation of driving scenes.",17
d2420d9ce64d101b28641660b4641c415fc7a6c9,Feature Intertwiner for Object Detection,"A well-trained model should classify objects with a unanimous score for every category. This requires the high-level semantic features should be as much alike as possible among samples. To achive this, previous works focus on re-designing the loss or proposing new regularization constraints. In this paper, we provide a new perspective. For each category, it is assumed that there are two feature sets: one with reliable information and the other with less reliable source. We argue that the reliable set could guide the feature learning of the less reliable set during training - in spirit of student mimicking teacher behavior and thus pushing towards a more compact class centroid in the feature space. Such a scheme also benefits the reliable set since samples become closer within the same category - implying that it is easier for the classifier to identify. We refer to this mutual learning process as feature intertwiner",3
ba8d37f2e98d70f917d0d3a49c387cef6867e65e,Learning shape correspondence with anisotropic convolutional neural networks,"Establishing correspondence between shapes is a fundamental problem in geometry processing, arising in a wide variety of applications. The problem is especially difficult in the setting of non-isometric deformations, as well as in the presence of topological noise and missing parts, mainly due to the limited capability to model such deformations axiomatically. Several recent works showed that invariance to complex shape transformations can be learned from examples. In this paper, we introduce an intrinsic convolutional neural network architecture based on anisotropic diffusion kernels, which we term Anisotropic Convolutional Neural Network (ACNN). In our construction, we generalize convolutions to non-Euclidean domains by constructing a set of oriented anisotropic diffusion kernels, creating in this way a local intrinsic polar representation of the data (`patch'), which is then correlated with a filter. Several cascades of such filters, linear, and non-linear operators are stacked to form a deep neural network whose parameters are learned",30
35d81066cb1369acf4b6c5117fcbb862be2af350,Fast Approximate Nearest Neighbors with Automatic Algorithm Configuration,"For many computer vision problems, the most time consuming component consists of nearest neighbor matching in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional problems that are faster than linear search. Approximate algorithms are known to provide large speedups with only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system will take any given dataset and desired degree of precision and use these to automatically determine the best algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical k-means trees, which we have found to provide the best known performance on many datasets. After testing a range of alternatives, we",4
681ee294b6556865c407fd5aec892f02c7b18df5,"Cloud Computing: Benefits, Risks and Recommendations for Information Security","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
3b11ed066ed30e5e235e9ef15cd3b8ada96d9899,Fine-Tuned DenseNet-169 for Breast Cancer Metastasis Prediction Using FastAI and 1-Cycle Policy,"Lymph node metastasis in breast cancer may be accurately predicted using a DenseNet-169 model. However, the current system for identifying metastases in a lymph node is manual and tedious. A pathologist well-versed with the process of detection and characterization of lymph nodes goes through hours investigating histological slides. Furthermore, because of the massive size of most whole-slide images (WSI), it is wise to divide a slide into batches of small image patches and apply methods independently on each patch. The present work introduces a novel method for the automated diagnosis and detection of metastases from whole slide images using the Fast AI framework and the 1-cycle policy. Additionally, it compares this new approach to previous methods. The proposed model has surpassed other state-of-art methods with more than 97.4% accuracy. In addition, a mobile application is developed for prompt and quick response. It collects user information and models to diagnose metastases",4
a4d0d6b6fce22162518f8b6a569c2c61e8d03da1,Calling the Cloud: Enabling Mobile Phones as Interfaces to Cloud Applications,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
6f96eecaf8f854021cc294427a5d4e47875ef120,Towards Reliable Grasping and Manipulation in Household Environments,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
b42b1ba256783184f714cc27ececbfb52e247f34,DensePoint: Learning Densely Contextual Representation for Efficient Point Cloud Processing,"Point cloud processing is very challenging, as the diverse shapes formed by irregular points are often indistinguishable. A thorough grasp of the elusive shape requires sufficiently contextual semantic information, yet few works devote to this. Here we propose DensePoint, a general architecture to learn densely contextual representation for point cloud processing. Technically, it extends regular grid CNN to irregular point configuration by generalizing a convolution operator, which holds the permutation invariance of points, and achieves efficient inductive learning of local patterns. Architecturally, it finds inspiration from dense connection mode, to repeatedly aggregate multi-level and multi-scale semantics in a deep hierarchy. As a result, densely contextual information along with rich semantics, can be acquired by DensePoint in an organic manner, making it highly effective. Extensive experiments on challenging benchmarks across four tasks, as well as thorough model analysis, verify DensePoint achieves the state of the arts.",2
b0dcc005c9903d2b6e0e36e5bc7a8f4df762a0c4,Systematic identification of threats in the cloud: A survey,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
fd853dd72c97b0d4bd5c92884404152220cff15d,IoT-Fog-Based Healthcare Framework to Identify and Control Hypertension Attack,"Hypertension is a chronic disease causing risk of different types of disorders, such as hypertension attacks, cerebrovascular attacks, kidney failure, and cardiovascular diseases. To prevent such risks, statistics related to hypertension have to be monitored and analyzed in real-time. Internet of Things (IoT)-assisted fog health monitoring system can be used to monitor blood pressure (BP) and to diagnose the stage of hypertension in real-time. In this paper, IoT-fog-based healthcare system is proposed for continuous monitoring and analysis of BP statistics to predict hypertensive users. The proposed system initially identifies the stage of hypertension on the basis of user’s health parameters collected using IoT sensors at fog layer. After identifying the hypertensive stage, artificial neural network is used for predicting the risk level of hypertension attack in users at remote sites. The vital point of this paper is to continuously generate emergency alerts of BP fluctuation from fog system to hypertensive",4
d312672f278eb3914cc541520737e7a26980503d,Towards 3D Point cloud based object maps for household environments,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
6d7d48fdde91604d8047e8574b11d05465d9e0be,3D fully convolutional network for vehicle detection in point cloud,"2D fully convolutional network has been recently successfully applied to the object detection problem on images. In this paper, we extend the fully convolutional network based detection techniques to 3D and apply it to point cloud data. The proposed approach is verified on the task of vehicle detection from lidar point cloud for autonomous driving. Experiments on the KITTI dataset shows significant performance improvement over the previous point cloud based detection approaches.",12
1f3b03bc2f5a049fbcd4c7eab74066b562a6ab70,Y^2Seq2Seq: Cross-Modal Representation Learning for 3D Shape and Text by Joint Reconstruction and Prediction of View and Word Sequences,"Jointly learning representations of 3D shapes and text is crucial to support tasks such as cross-modal retrieval or shape captioning. A recent method employs 3D voxels to represent 3D shapes, but this limits the approach to low resolutions due to the computational cost caused by the cubic complexity of 3D voxels. Hence the method suffers from a lack of detailed geometry. To resolve this issue, we propose Y2Seq2Seq, a view-based model, to learn cross-modal representations by joint reconstruction and prediction of view and word sequences. Specifically, the network architecture of Y2Seq2Seq bridges the semantic meaning embedded in the two modalities by two coupled “Y” like sequence-tosequence (Seq2Seq) structures. In addition, our novel hierarchical constraints further increase the discriminability of the cross-modal representations by employing more detailed discriminative information. Experimental results on cross-modal retrieval and 3D shape captioning show that Y2Seq2Seq outperforms the state-of-the-art methods.",6
51c25e737058f6e6d603cad16c378971f50fac58,A Dual-Link Soft Handover Scheme for C/U Plane Split Network in High-Speed Railway,"The heterogeneous network architecture based on control/user (C/U) plane split is a research hot spot in the fifth generation (5G) communication system. This new architecture for the high-speed railway (HSR) communication system can provide high quality of service (QoS) for the passengers, such as higher system transmission capacity, better transmission reliability, and lower co-channel interference. The relatively critical C plane is expanded and maintained in a reliable low-frequency band to guarantee transmission reliability, and the U plane is supported by the available high-frequency band to meet the increasing system capacity demands. However, there are still many problems to be solved in the C/U plane split network to ensure reliable transmission. In the HSR communication system, the C plane and the U plane are supported by the macro evolved NodeBs (eNBs) and the small eNBs, respectively. The handover between the different macro eNBs involves two types of handovers, which directly reduces",8
79cf9462a583e1889781868cbf8c31e43b36dd2f,Towards Federated Learning at Scale: System Design,"Federated Learning is a distributed machine learning approach which enables model training on a large corpus of decentralized data. We have built a scalable production system for Federated Learning in the domain of mobile devices, based on TensorFlow. In this paper, we describe the resulting high-level design, sketch some of the challenges and their solutions, and touch upon the open problems and future directions.",9
ece3b623232c90bb8a9021a3eb25223c4fde7069,Learning Deep Embeddings with Histogram Loss,"We suggest a new loss for learning deep embeddings. The key characteristics of the new loss is the absence of tunable parameters and very good results obtained across a range of datasets and problems. The loss is computed by estimating two distribution of similarities for positive (matching) and negative (non-matching) point pairs, and then computing the probability of a positive pair to have a lower similarity score than a negative pair based on these probability estimates. We show that these operations can be performed in a simple and piecewise-differentiable manner using 1D histograms with soft assignment operations. This makes the proposed loss suitable for learning deep embeddings using stochastic optimization. The experiments reveal favourable results compared to recently proposed loss functions.",2
e5e4ea8f08d3a52cc92b9dfe5622d116dbad6166,Dominant Set Clustering and Pooling for Multi-View 3D Object Recognition,"View based strategies for 3D object recognition have proven to be very successful. The state-of-the-art methods now achieve over 90% correct category level recognition performance on appearance images. We improve upon these methods by introducing a view clustering and pooling layer based on dominant sets. The key idea is to pool information from views which are similar and thus belong to the same cluster. The pooled feature vectors are then fed as inputs to the same layer, in a recurrent fashion. This recurrent clustering and pooling module, when inserted in an off-the-shelf pretrained CNN, boosts performance for multi-view 3D object recognition, achieving a new state of the art test set recognition accuracy of 93.8% on the ModelNet 40 database. We also explore a fast approximate learning strategy for our cluster-pooling CNN, which, while sacrificing end-to-end learning, greatly improves its training efficiency with only a slight reduction of recognition accuracy to",8
18a5f443299784479e78d9e77f175af57cb2fa2b,Bigtable: a distributed storage system for structured data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",17
700701edfd2c03eb88aaaa15b306ea5c48ce13a6,Accelerating large-scale data exploration through data diffusion,"Data-intensive applications often require exploratory analysis of large datasets. If analysis is performed on distributed resources, data locality can be crucial to high throughput and performance. We propose a ""data diffusion"" approach that acquires compute and storage resources dynamically, replicates data in response to demand, and schedules computations close to data. As demand increases, more resources are acquired, thus allowing faster response to subsequent requests that refer to the same data; when demand drops, resources are released. This approach can provide the benefits of dedicated hardware without the associated high costs, depending on workload and resource characteristics. The approach is reminiscent of cooperative caching, web-caching, and peer-to-peer storage systems, but addresses different application demands. Other data-aware scheduling approaches assume dedicated resources, which can be expensive and/or inefficient if load varies significantly. To explore the feasibility of the data diffusion approach, we have extended the Falkon resource provisioning and task scheduling",6
b3fba5e9bfc8fa7a94fc0448ec3e065a7849cf12,Toward loosely coupled programming on petascale systems,"We have extended the Falkon lightweight task execution framework to make loosely coupled programming on petascale systems a practical and useful programming model. This work studies and measures the performance factors involved in applying this approach to enable the use of petascale systems by a broader user community, and with greater ease. Our work enables the execution of highly parallel computations composed of loosely coupled serial jobs with no modifications to the respective applications. This approach allows a new-and potentially far larger-class of applications to leverage petascale systems, such as the IBM Blue Gene/P supercomputer. We present the challenges of I/O performance encountered in making this model practical, and show results using both microbenchmarks and real applications from two domains: economic energy modeling and molecular dynamics. Our benchmarks show that we can scale up to 160 K processor-cores with high efficiency, and can achieve sustained execution rates of thousands of",2
8c44c2d2b9966dfec1127ad8122176492b436a53,"Scientific Workflow Systems for 21st Century, New Bottle or New Wine?","With the advances in e-sciences and the growing complexity of scientific analyses, more and more scientists and researchers are relying on workflow systems for process coordination, derivation automation, provenance tracking, and bookkeeping. While workflow systems have been in use for decades, it is unclear whether scientific workflows can or even should build on existing workflow technologies, or they require fundamentally new approaches. In this paper, we analyze the status and challenges of scientific workflows, investigate both existing technologies and emerging languages, platforms and systems, and identify the key challenges that must be addressed by workflow systems for e-science in the 21st century.",5
5749a19135d2037412ce26ec52c4efc6a2a59d37,Handling Flash Crowds from Your Garage,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
7b760f0468a520bc25a813b3f29664a92beb200a,Jittor: a novel deep learning framework with meta-operators and unified graph execution,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
2231d52573df30203e79e0f6f08d20a0c1be832c,Editorial: A Special Issue from the Open Grid Forum,"We describe the results of the RDF(S) activity within the Open Grid Forum () (OGF) Database Access and Integration Services (DAIS) Working Group () whose objective is to develop standard service-based grid access mechanisms for data expressed in RDF and RDF Schema. We produce two specifications, focused on the provision of SPARQL querying capabilities for accessing RDF data and a set of RDF Schema ontology handling primitives for creating, retrieving, updating, and deleting RDF data. In this paper we present a set of use cases that justify this work and an overview of these specifications, which will enter in editorial process at OGF25. We conclude by outlining the future work that will be made in the context of this standardization process. Copyright © 2009 John Wiley & Sons, Ltd. Note: All URLs in this paper are as of 07-22-2008.",3
9bf2f2cd935d2fd220d24d0569e97c237fd4b134,NURBS-based postbuckling analysis of functionally graded carbon nanotube-reinforced composite shells,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
a472ab2b4511842f4d104bd6b173c711c4f622bf,Agency,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
4af67db7cb510052f9219f23c3d4d309f222ef20,SoftRAN: software defined radio access network,"An important piece of the cellular network infrastructure is the radio access network (RAN) that provides wide-area wireless connectivity to mobile devices. The fundamental problem the RAN solves is figuring out how best to use and manage limited spectrum to achieve this connectivity. In a dense wireless deployment with mobile nodes and limited spectrum, it becomes a difficult task to allocate radio resources, implement handovers, manage interference, balance load between cells, etc. We argue that LTE's current distributed control plane is suboptimal in achieving the above objective. We propose SoftRAN, a fundamental rethink of the radio access layer. SoftRAN is a software defined centralized control plane for radio access networks that abstracts all base stations in a local geographical area as a virtual big-base station comprised of a central controller and radio elements (individual physical base stations). In defining such an architecture, we create a framework through which a local",4
861e677983965847b5213dc11d01a584fd92ac06,Improving MapReduce Performance in Heterogeneous Environments,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
359ae7f918e7ab865cc10847dcbfa9ce8bf95365,Joint Computation Offloading and Resource Allocation Optimization in Heterogeneous Networks With Mobile Edge Computing,"In this paper, we propose a distributed joint computation offloading and resource allocation optimization (JCORAO) scheme in heterogeneous networks with mobile edge computing. An optimization problem is formulated to provide the optimal computation offloading strategy policy, uplink subchannel allocation, uplink transmission power allocation, and computation resource scheduling. The optimization problem is decomposed into two sub-problems due to the NP-hard property. In order to analyze the offloading strategy, a sub-algorithm named distributed potential game is built. The existence of Nash equilibrium is proved. To jointly allocate uplink subchannel, uplink transmission power, and computation resource for the offloading mobile terminals, a sub-algorithm named cloud and wireless resource allocation algorithm is designed. The solutions for subchannel allocation consist of uniform zero frequency reuse method without interference and fractional frequency reuse method based on Hungarian and graph coloring with interference. A distributed JCORAO scheme is proposed to solve the optimization problem by the mutual",7
e82ea6979df1a5a8c7037c73f0349ddb5f393f88,Classification of Diseases Using Machine Learning Algorithms: A Comparative Study,"Machine learning in the medical area has become a very important requirement. The healthcare professional needs useful tools to diagnose medical illnesses. Classifiers are important to provide tools that can be useful to the health professional for this purpose. However, questions arise: which classifier to use? What metrics are appropriate to measure the performance of the classifier? How to determine a good distribution of the data so that the classifier does not bias the medical patterns to be classified in a particular class? Then most important question: does a classifier perform well for a particular disease? This paper will present some answers to the questions mentioned above, making use of classification algorithms widely used in machine learning research with datasets relating to medical illnesses under the supervised learning scheme. In addition to state-of-the-art algorithms in pattern classification, we introduce a novelty: the use of meta-learning to determine, a priori, which",5
876be80390bcaffb9b910ed05680b2e81a37d64d,PNUTS: Yahoo!'s hosted data serving platform,"We describe PNUTS, a massively parallel and geographically distributed database system for Yahoo!'s web applications. PNUTS provides data storage organized as hashed or ordered tables, low latency for large numbers of concurrent requests including updates and queries, and novel per-record consistency guarantees. It is a hosted, centrally managed, and geographically distributed service, and utilizes automated load-balancing and failover to reduce operational complexity. The first version of the system is currently serving in production. We describe the motivation for PNUTS and the design and implementation of its table storage and replication layers, and then present experimental results.",4
81522f0edfa4ec9cd836d38086f0b89b809b613a,Economics of the cloud computing,"Cloud computing has its root deep into ground and in the market. The evolution of cloud computing is one of the major advances in the computing area as well as in economics of using computing. There are three major technologies which represent cloud computing: Software-asa-Service (SaaS), Platform-as-a-Service (PaaS) and Infrastructure-as-a-Service (Iaas). In our example we discuss pros and cons of implementing PaaS or SaaS. While there are quite a few papers covering technical aspects of cloud computing technologies, this paper will have focus on economics of the cloud. In this paper we will try to explain which criteria should be considered when deciding to move or not to move to cloud. There is also general view on Return on Investment shown which takes into account various intangible impacts of cloud computing, apart from cost. These impacts include better flexibility, scalability and faster time to market.",1
e0c37e1c4b9181b34c42dca31dd2f3757d285770,Laser-based perception for door and handle identification,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
bc11a01d61b5c217b90a2d575f8d07a42984c099,Joint Load Balancing and Offloading in Vehicular Edge Computing and Networks,"The emergence of computation intensive and delay sensitive on-vehicle applications makes it quite a challenge for vehicles to be able to provide the required level of computation capacity, and thus the performance. Vehicular edge computing (VEC) is a new computing paradigm with a great potential to enhance vehicular performance by offloading applications from the resource-constrained vehicles to lightweight and ubiquitous VEC servers. Nevertheless, offloading schemes, where all vehicles offload their tasks to the same VEC server, can limit the performance gain due to overload. To address this problem, in this paper, we propose integrating load balancing with offloading, and study resource allocation for a multiuser multiserver VEC system. First, we formulate the joint load balancing and offloading problem as a mixed integer nonlinear programming problem to maximize system utility. Particularly, we take IEEE 802.11p protocol into consideration for modeling the system utility. Then, we decouple the problem as two subproblems",1
ed1e724a9a5f7207a5fc19b11a51767f61b5bc16,Observations of marine stratocumulus clouds during FIRE,"Abstract During June and July 1987, a major collaborative experiment (part of The First ISCCP [International Satellite Cloud Climatology Project] Regional Experiment (FIRE) took place off the coast of California to study the extensive fields of stratocumulus clouds that are a persistent feature of subtropical marine boundary layers. For the first time, measurements were made on both the regional scale and on the detailed local scale to permit the widest possible interpretation of the mean, turbulent, microphysical, radiative, and chemical characteristics of stratocumulus, together with the interactions among these quantities that am believed to he important in controlling the structure and evolution of these clouds. Multiple aircraft were used to make detailed, in situ measurements and to provide a bridge between the microscale and features seen from satellites. Ground-based remote-sensing systems on San Nicolas Island captured the time evolution of the boundary-.layer structure during the three-week dura...",5
8afa6dd9f9ac46462a1fb70a757c4ae1cd45bbf6,FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models,"A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network. Likelihood-based training of these models requires restricting their architectures to allow cheap computation of Jacobian determinants. Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson's trace estimator to give a scalable unbiased estimate of the log-density. The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density estimation, image generation, and variational inference, achieving the state-of-the-art among exact likelihood methods with efficient sampling.",9
b73d5fabc909f8e584dc95b098046185d2b21581,Guest Editor's Introduction: Dynamic Pricing in the Virtual Marketplace,"From its simple beginnings in the town square, the ""marketplace"" has grown to encompass the entire global business environment. The vast and intricately woven infrastructure necessary for this level of commerce involves issues of money, credit, insurance, legal infrastructure, corporate and individual identities, and fraud detection and deterrence. As market activities move online, we have an opportunity to re-examine the processes and conventions that governed pre-Internet commerce, and to restructure those that need it for the virtual marketplace. One concept being challenged by new technologies is fixed pricing, which became prevalent in western society during the industrial revolution when mass production and widespread delivery of goods made price negotiation impractical. A Wyoming frontiersman could not negotiate with Sears, Roebuck and Co. about the mail-order catalog price of a pair of boots in the late 1890s. The Internet now has the potential to reverse that trend.",8
bc89fc6d6333e358e3b65c8e956567621cb60a3d,Point feature extraction on 3D range scans taking into account object boundaries,"In this paper we address the topic of feature extraction in 3D point cloud data for object recognition and pose identification. We present a novel interest keypoint extraction method that operates on range images generated from arbitrary 3D point clouds, which explicitly considers the borders of the objects identified by transitions from foreground to background. We furthermore present a feature descriptor that takes the same information into account. We have implemented our approach and present rigorous experiments in which we analyze the individual components with respect to their repeatability and matching capabilities and evaluate the usefulness for point feature based object detection methods.",5
c6213f02f3feb4357464b2421f06c0012ff124b4,The Economics of Cloud Computing,"The paper examines the economic impact of the diffusion of a new technology as cloud computing. This will allow firms to rent computing power and storage from service providers and to pay on demand, with a profound impact on the cost structure of all the industries, turning some of the fixed costs into marginal costs of production. Such a change will have a substantial impact on the incentives to create new business, and through this, on investments and macroeconomic growth, job creation in all industries and job reallocation in the Information and Communications Technology (ICT) sector, and public finance accounts, through the direct impact on the public sector spending and the indirect one on the tax revenues. The paper investigates the consequences of the diffusion of cloud computing on market structures and competition, and tries to disentangle the above-mentioned aspects with a particular focus on a simulation run for the",2
64aef0277a1e33d28779b34b95284f12255180ac,RFS: a network file system for mobile devices and the cloud,"Due to the increasing number of applications (and their data) being placed on mobile devices, access to dependable storage is becoming a key issue in mobile system design -- and cloud storage is becoming an attractive solution. However, this introduces a number of new issues related to unpredictable wireless network connectivity and data privacy over the network. In this article we present RFS, a wireless-friendly network file system for mobile devices and the cloud. RFS provides deviceaware cache management and client-driven data security and privacy protection. We implement the RFS client in the Linux kernel and the RFS server with Amazon S3 cloud storage, and we employ two new optimizations: server prepush (a server-side data pre-fetching mechanism) and client reintegration (synchronizing a mobile device's cache with the cloud). The empirical results over wired, WiFi and 3G networks show that RFS achieves good performance compared to Coda and FScache, and it",5
31efbd02dcb1916c0b7a42da84e3b2dc96a08ea8,Cloud Computing: Interview with Russ Daniels and Franco Travostino,"Milojicić discusses cloud computing with Russ Daniels, Vice President and Chief Technology Officer of Hewlett-Packard’s cloud services strategy, and Franco Travostino, a distinguished architect at eBay.",3
e2751a898867ce6687e08a5cc7bdb562e999b841,FCOS: Fully Convolutional One-Stage Object Detection,"We propose a fully convolutional one-stage object detector (FCOS) to solve object detection in a per-pixel prediction fashion, analogue to semantic segmentation. Almost all state-of-the-art object detectors such as RetinaNet, SSD, YOLOv3, and Faster R-CNN rely on pre-defined anchor boxes. In contrast, our proposed detector FCOS is anchor box free, as well as proposal free. By eliminating the pre-defined set of anchor boxes, FCOS completely avoids the complicated computation related to anchor boxes such as calculating overlapping during training. More importantly, we also avoid all hyper-parameters related to anchor boxes, which are often very sensitive to the final detection performance. With the only post-processing non-maximum suppression (NMS), FCOS with ResNeXt-64x4d-101 achieves 44.7% in AP with single-model and single-scale testing, surpassing previous one-stage detectors with the advantage of being much simpler. For the first time, we demonstrate a much simpler and flexible detection framework achieving improved detection accuracy. We hope that",3
49f6bcda210e7a60a0f4584dcf6cbcc8a041d0e8,"Wirelessly Powered Crowd Sensing: Joint Power Transfer, Sensing, Compression, and Transmission","Leveraging massive numbers of sensors in user equipment as well as opportunistic human mobility, mobile crowd sensing (MCS) has emerged as a powerful paradigm, where prolonging battery life of constrained devices and motivating human involvement are two key design challenges. To address these, we envision a novel framework, named wirelessly powered crowd sensing (WPCS), which integrates MCS with wireless power transfer for supplying the involved devices with extra energy and thus facilitating user incentivization. This paper considers a multiuser WPCS system where an access point (AP) transfers energy to multiple mobile sensors (MSs), each of which performing data sensing, compression, and transmission. Assuming lossless (data) compression, an optimization problem is formulated to simultaneously maximize data utility and minimize energy consumption at the operator side, by jointly controlling wireless-power allocation at the AP as well as sensing-data sizes, compression ratios, and sensor-transmission durations at the MSs. Given fixed compression ratios, the",3
dbba66e9e70ebaa2cb536441c28bb0ffbb152b38,Locality-Sensitive Deconvolution Networks with Gated Fusion for RGB-D Indoor Semantic Segmentation,"This paper focuses on indoor semantic segmentation using RGB-D data. Although the commonly used deconvolution networks (DeconvNet) have achieved impressive results on this task, we find there is still room for improvements in two aspects. One is about the boundary segmentation. DeconvNet aggregates large context to predict the label of each pixel, inherently limiting the segmentation precision of object boundaries. The other is about RGB-D fusion. Recent state-of-the-art methods generally fuse RGB and depth networks with equal-weight score fusion, regardless of the varying contributions of the two modalities on delineating different categories in different scenes. To address the two problems, we first propose a locality-sensitive DeconvNet (LS-DeconvNet) to refine the boundary segmentation over each modality. LS-DeconvNet incorporates locally visual and geometric cues from the raw RGB-D data into each DeconvNet, which is able to learn to upsample the coarse convolutional maps with large context whilst recovering sharp object boundaries. Towards",7
449310e3538b08b43227d660227dfd2875c3c3c1,Neural Ordinary Differential Equations,"We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.",11
f0ff1e0739494fcbaeefc3e30038457ed606b1c4,Morphing and Sampling Network for Dense Point Cloud Completion,"3D point cloud completion, the task of inferring the complete geometric shape from a partial point cloud, has been attracting attention in the community. For acquiring high-fidelity dense point clouds and avoiding uneven distribution, blurred details, or structural loss of existing methods' results, we propose a novel approach to complete the partial point cloud in two stages. Specifically, in the first stage, the approach predicts a complete but coarse-grained point cloud with a collection of parametric surface elements. Then, in the second stage, it merges the coarse-grained prediction with the input point cloud by a novel sampling algorithm. Our method utilizes a joint loss function to guide the distribution of the points. Extensive experiments verify the effectiveness of our method and demonstrate that it outperforms the existing methods in both the Earth Mover's Distance (EMD) and the Chamfer Distance (CD).",8
bc40f994a8ac8870681b8d4b8fd8ed84e2ba77b9,Making cluster applications energy-aware,"Power consumption has become a critical issue in large scale clusters. Existing solutions for addressing the servers' energy consumption suggest ""shrinking"" the set of active machines, at least until the more power-proportional hardware devices become available. This paper demonstrates that leveraging the sleeping state, however, may lead to unacceptably poor performance and low data availability if the distributed services are not aware of the power management's actions. Therefore, we present an architecture for cluster services in which the deployed services overcome this problem by actively participating in any action taken by the power management. We propose, implement, and evaluate modifications for the Hadoop Distributed File System and the MapReduce clone that make them capable of operating efficiently under limited power budgets.",3
31d896ca580640023baea9924e0c4bb57c2cb01b,Sky computing,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
79e216bd3c228c049c16de11797b15ba4fe81569,Fog-Enabled Smart Health: Toward Cooperative and Secure Healthcare Service Provision,"The rise of smart health promotes ubiquitous healthcare services with the adoption of information and communication technologies. However, increasing demands of medical services require more computing and storage resources in proximity of medical users for intelligent sensing, processing, and analysis. Fog computing emerges to enable in situ data processing and service provision for smart health in proximity of medical users, exploiting a large number of small-scale servers. In this article, we investigate fog-enabled smart health toward cooperative and secure healthcare service provision. Specifically, we first introduce the overall infrastructure and some promising applications, including emergent healthcare service, health risk assessment, and healthcare notification. We then discuss the challenges of fog-enabled smart health from the perspectives of cooperation and security. A case study is presented to demonstrate efficient and secure health data sharing through naive Bayes classification and attribute-based encryption with assistance from fog computing. Finally, by exploring interesting future directions,",2
314de57c64548c9ceae9e3aca383c306e838ca2b,Adversarial autoencoders for compact representations of 3D point clouds,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
af30cce8d2fdf779b9c847cb7d3512ba7ead9701,A Conversation with Jim Gray,"Clear your schedule, because once you’ve started reading this interview, you won’t be able to put it down until you’ve finished it.",3
a7ea80777175046c36431b131148c63f20443c49,Towards Analyzing Data Security Risks in Cloud Computing Environments,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
ffaaf30b1013352ebccf81d924f351863dbc2025,Fast Point R-CNN,"We present a unified, efficient and effective framework for point-cloud based 3D object detection. Our two-stage approach utilizes both voxel representation and raw point cloud data to exploit respective advantages. The first stage network, with voxel representation as input, only consists of light convolutional operations, producing a small number of high-quality initial predictions. Coordinate and indexed convolutional feature of each point in initial prediction are effectively fused with the attention mechanism, preserving both accurate localization and context information. The second stage works on interior points with their fused feature for further refining the prediction. Our method is evaluated on KITTI dataset, in terms of both 3D and Bird's Eye View (BEV) detection, and achieves state-of-the-arts with a 15FPS detection rate.",8
ac4c170e12da0b9220ed94c9a7b94624f7523cf0,Centralized radio access networks over wavelength-division multiplexing: a plug-and-play implementation,"The evolution of centralized radio access networks is discussed from a pragmatic perspective, taking into account the network and radio requirements. The use of wavelength-division multiplexing technology to support this evolution is proposed, and the opportunities for network operators in terms of operational cost, energy efficiency, reuse of already deployed infrastructures, and network convergence are discussed.",2
0f7dd6bcaf4c2a64b3a51b7351929dab23584ea8,MAUI: making smartphones last longer with code offload,"This paper presents MAUI, a system that enables fine-grained energy-aware offload of mobile code to the infrastructure. Previous approaches to these problems either relied heavily on programmer support to partition an application, or they were coarse-grained requiring full process (or full VM) migration. MAUI uses the benefits of a managed code environment to offer the best of both worlds: it supports fine-grained code offload to maximize energy savings with minimal burden on the programmer. MAUI decides at run-time which methods should be remotely executed, driven by an optimization engine that achieves the best energy savings possible under the mobile device's current connectivity constrains. In our evaluation, we show that MAUI enables: 1) a resource-intensive face recognition application that consumes an order of magnitude less energy, 2) a latency-sensitive arcade game application that doubles its refresh rate, and 3) a voice-based language translation application that bypasses the limitations of the smartphone",20
4901eaa5a3b8cca41e4bb664ef0446d6118bd87c,Beyond Triplet Loss: A Deep Quadruplet Network for Person Re-identification,"Person re-identification (ReID) is an important task in wide area video surveillance which focuses on identifying people across different cameras. Recently, deep learning networks with a triplet loss become a common framework for person ReID. However, the triplet loss pays main attentions on obtaining correct orders on the training set. It still suffers from a weaker generalization capability from the training set to the testing set, thus resulting in inferior performance. In this paper, we design a quadruplet loss, which can lead to the model output with a larger inter-class variation and a smaller intra-class variation compared to the triplet loss. As a result, our model has a better generalization ability and can achieve a higher performance on the testing set. In particular, a quadruplet deep network using a margin-based online hard negative mining is proposed based on the quadruplet loss for the person ReID. In extensive experiments, the proposed",2
30cdd34bab63b3c6850675dfa2cda19f47e90393,A holistic view on hyper-dense heterogeneous and small cell networks,"The wireless industry has been experiencing an explosion of data traffic usage in recent years and is now facing an even bigger challenge, an astounding 1000-fold data traffic increase in a decade. The required traffic increase is in bits per second per square kilometer, which is equivalent to bits per second per Hertz per cell × Hertz × cell per square kilometer. The innovations through higher utilization of the spectrum (bits per second per Hertz per cell) and utilization of more bandwidth (Hertz) are quite limited: spectral efficiency of a point-to-point link is very close to the theoretical limits, and utilization of more bandwidth is a very costly solution in general. Hyper-dense deployment of heterogeneous and small cell networks (HetSNets) that increase cells per square kilometer by deploying more cells in a given area is a very promising technique as it would provide a huge capacity gain by bringing small",3
8e4d635ab9620340128f96ae889bdb570bd5fef0,Self-supervised Point Cloud Prediction Using 3D Spatio-temporal Convolutional Networks,"Exploiting past 3D LiDAR scans to predict future point clouds is a promising method for autonomous mobile systems to realize foresighted state estimation, collision avoidance, and planning. In this paper, we address the problem of predicting future 3D LiDAR point clouds given a sequence of past LiDAR scans. Estimating the future scene on the sensor level does not require any preceding steps as in localization or tracking systems and can be trained self-supervised. We propose an end-to-end approach that exploits a 2D range image representation of each 3D LiDAR scan and concatenates a sequence of range images to obtain a 3D tensor. Based on such tensors, we develop an encoder-decoder architecture using 3D convolutions to jointly aggregate spatial and temporal information of the scene and to predict the future 3D point clouds. We evaluate our method on multiple datasets and the experimental results suggest that our method outperforms existing point",3
e53a7926a448a90717eccd521aeddfffd8eec92c,Paranoid Android: versatile protection for smartphones,"Smartphone usage has been continuously increasing in recent years. Moreover, smartphones are often used for privacy-sensitive tasks, becoming highly valuable targets for attackers. They are also quite different from PCs, so that PC-oriented solutions are not always applicable, or do not offer comprehensive security. We propose an alternative solution, where security checks are applied on remote security servers that host exact replicas of the phones in virtual environments. The servers are not subject to the same constraints, allowing us to apply multiple detection techniques simultaneously. We implemented a prototype of this security model for Android phones, and show that it is both practical and scalable: we generate no more than 2KiB/s and 64B/s of trace data for high-loads and idle operation respectively, and are able to support more than a hundred replicas running on a single server.",8
658bcb7729770487216843abd422c5088a96b843,SDIoT: a software defined based internet of things framework,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
15ca7adccf5cd4dc309cdcaa6328f4c429ead337,FPNN: Field Probing Neural Networks for 3D Data,"Building discriminative representations for 3D data has been an important task in computer graphics and computer vision research. Convolutional Neural Networks (CNNs) have shown to operate on 2D images with great success for a variety of tasks. Lifting convolution operators to 3D (3DCNNs) seems like a plausible and promising next step. Unfortunately, the computational complexity of 3D CNNs grows cubically with respect to voxel resolution. Moreover, since most 3D geometry representations are boundary based, occupied regions do not increase proportionately with the size of the discretization, resulting in wasted computation. In this work, we represent 3D spaces as volumetric fields, and propose a novel design that employs field probing filters to efficiently extract features from them. Each field probing filter is a set of probing points --- sensors that perceive the space. Our learning algorithm optimizes not only the weights associated with the probing points, but also their locations, which",26
fa9ca8b87a75e32ba09a1bd864b8f7b8331e524b,CROWD: An SDN Approach for DenseNets,"Traffic demands in mobile networks are expected to grow substantially in the next years, both in terms of total traffic volume and of bit-rate required by individual users. It is generally agreed that the only possible solution to overcome the current limitations is to deploy very dense and heterogeneous wireless networks, which we call DenseNets. However, simply scaling down existing networks by orders of magnitude, as required to fulfill traffic forecasts, is not possible because of the following constraints: i) the bottleneck would shift from the Radio Access Network (RAN) to the backhaul, ii) control overhead, especially related to mobility management, would make the network collapse, iii) operational costs of the network would be unbearable due to energy consumption and maintenance/optimisation. In this paper, Software Defined Network (SDN) for mobile networks is claimed as the paradigm shift necessary to tackle adequately the above challenges. A novel architecture is proposed, which",1
d8c3b190c8f53acfc48b9abacb43f34a83bacb40,Pocket cloudlets,"Cloud services accessed through mobile devices suffer from high network access latencies and are constrained by energy budgets dictated by the devices' batteries. Radio and battery technologies will improve over time, but are still expected to be the bottlenecks in future systems. Non-volatile memories (NVM), however, may continue experiencing significant and steady improvements in density for at least ten more years. In this paper, we propose to leverage the abundance in memory capacity of mobile devices to mitigate latency and energy issues when accessing cloud services. We first analyze NVM technology scaling trends, and then propose a cloud service cache architecture that resides on the mobile device's NVM (pocket cloudlet). This architecture utilizes both individual user and community access models to maximize its hit rate, and subsequently reduce overall service latency and energy consumption. As a showcase we present the design, implementation and evaluation of PocketSearch, a search and advertisement",3
7ce15c684af9e8df03244ae95e4d6ac77e292c3d,Computation Offloading Scheme to Improve QoE in Vehicular Networks with Mobile Edge Computing,"Mobile edge computing (MEC) is a new paradigm to improve the quality of vehicular services by providing computation offloading close to vehicular terminals (VTs).However, due to the computation limitation of the MEC servers, how to optimally utilize the limited computation resources of MEC servers while maintaining a high quality of experience (QoE) of VTs becomes a challenge. To address the problem, we investigate a novel computation offloading scheme based on the MEC offloading framework in vehicular networks. Firstly, the utility of VTs for offloading their computation tasks is presented, where the utility is jointly determined by the execution time, computation resources and the energy for completing the computation tasks. Next, with the theoretical analysis of the utility, the QoE of each VT can be guaranteed. Then, combined with the pricing scheme of the MEC servers, we propose an efficient distributed computation offloading algorithm to make the optimal offloading decisions for",3
ad61a05a10319f4a95733b833fc4be1115670d95,The Case for Energy-Proportional Computing,"Energy-proportional designs would enable large energy savings in servers, potentially doubling their efficiency in real-life use. Achieving energy proportionality will require significant improvements in the energy usage profile of every system component, particularly the memory and disk subsystems.",8
c100b6b151fcc5e126b50016ffda4ba1e1b3d5cb,"FutureGrid: A Reconfigurable Testbed for Cloud, HPC, and Grid Computing","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
c4cf934b5ee4eadbac3a36ed3711475db2670642,Making offloading decisions resistant to network unavailability for mobile cloud collaboration,"Offloading is one major type of collaborations between mobile devices and clouds to achieve less execution time and less energy consumption. Offloading decisions for mobile cloud collaboration involve many decision factors. One of important decision factors is the network unavailability that has not been well studied. This paper presents an offloading decision model that takes network unavailability into consideration. Network with some unavailability can be modeled as an alternating renewal process. Then, application execution time and energy consumption in both ideal network and network with some unavailability are analyzed. Based on the presented theoretical model, an application partition algorithm and a decision module are presented to produce an offloading decision that is resistant to network unavailability. Simulation results demonstrate good performance of proposed scheme, where the proposed partition algorithm is analyzed in different application and cloud scenarios.",5
ebd7e7e440d953948895acce35b388d599d47bb2,Secure web applications via automatic partitioning,"Swift is a new, principled approach to building web applications that are secure by construction. In modern web applications, some application functionality is usually implemented as client-side code written in JavaScript. Moving code and data to the client can create security vulnerabilities, but currently there are no good methods for deciding when it is secure to do so. Swift automatically partitions application code while providing assurance that the resulting placement is secure and efficient. Application code is written as Java-like code annotated with information flow policies that specify the confidentiality and integrity of web application information. The compiler uses these policies to automatically partition the program into JavaScript code running in the browser, and Java code running on the server. To improve interactive performance, code and data are placed on the client side. However, security-critical code and data are always placed on the server. Code and data can also be",3
dc200ab22bf63e10e8b2af328a9e072d82cf75b7,Multi-view 3D Object Detection Network for Autonomous Driving,"This paper aims at high-accuracy 3D object detection in autonomous driving scenario. We propose Multi-View 3D networks (MV3D), a sensory-fusion framework that takes both LIDAR point cloud and RGB images as input and predicts oriented 3D bounding boxes. We encode the sparse 3D point cloud with a compact multi-view representation. The network is composed of two subnetworks: one for 3D object proposal generation and another for multi-view feature fusion. The proposal network generates 3D candidate boxes efficiently from the birds eye view representation of 3D point cloud. We design a deep fusion scheme to combine region-wise features from multiple views and enable interactions between intermediate layers of different paths. Experiments on the challenging KITTI benchmark show that our approach outperforms the state-of-the-art by around 25% and 30% AP on the tasks of 3D localization and 3D detection. In addition, for 2D detection, our approach obtains 14.9% higher AP than the",19
e72907406058f0c9cbca07ff590b41f3a3a57193,IP Spoofing In and Out of the Public Cloud: From Policy to Practice,"In recent years, a trend that has been gaining particular popularity among cybercriminals is the use of public Cloud to orchestrate and launch distributed denial of service (DDoS) attacks. One of the suspected catalysts for this trend appears to be the increased tightening of regulations and controls against IP spoofing by world-wide Internet service providers (ISPs). Three main contributions of this paper are (1) For the first time in the research literature, we provide a comprehensive look at a number of possible attacks that involve the transmission of spoofed packets from or towards the virtual private servers hosted by a public Cloud provider. (2) We summarize the key findings of our research on the regulation of IP spoofing in the acceptable-use and term-of-service policies of 35 real-world Cloud providers. The findings reveal that in over 50% of cases, these policies make no explicit mention or prohibition of IP spoofing, thus",2
87c757138d273ccd38216ca5266406a503507077,Generative and Discriminative Voxel Modeling with Convolutional Neural Networks,"When working with three-dimensional data, choice of representation is key. We explore voxel-based models, and present evidence for the viability of voxellated representations in applications including shape modeling and object classification. Our key contributions are methods for training voxel-based variational autoencoders, a user interface for exploring the latent space learned by the autoencoder, and a deep convolutional neural network architecture for object classification. We address challenges unique to voxel-based representations, and empirically evaluate our models on the ModelNet benchmark, where we demonstrate a 51.5% relative improvement in the state of the art for object classification.",33
0f910174d2e19101ca8f008909006e79416821fd,When Edge Meets Learning: Adaptive Control for Resource-Constrained Distributed Machine Learning,"Emerging technologies and applications including Internet of Things (IoT), social networking, and crowd-sourcing generate large amounts of data at the network edge. Machine learning models are often built from the collected data, to enable the detection, classification, and prediction of future events. Due to bandwidth, storage, and privacy concerns, it is often impractical to send all the data to a centralized location. In this paper, we consider the problem of learning model parameters from data distributed across multiple edge nodes, without sending raw data to a centralized place. Our focus is on a generic class of machine learning models that are trained using gradient-descent based approaches. We analyze the convergence rate of distributed gradient descent from a theoretical point of view, based on which we propose a control algorithm that determines the best trade-off between local update and global parameter aggregation to minimize the loss function under a given resource",8
54658a73fad95c7359c53341ed916a0f53bd2003,Automated Classification of Web-Application Attacks for Intrusion Detection,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
452317d13263afd962ae3237066cd0a2e2a93edb,Face image manipulation detection based on a convolutional neural network,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
e81acd4f35eb2202bf753266ec83d3174645820f,PointGrid: A Deep Network for 3D Shape Understanding,"Volumetric grid is widely used for 3D deep learning due to its regularity. However the use of relatively lower order local approximation functions such as piece-wise constant function (occupancy grid) or piece-wise linear function (distance field) to approximate 3D shape means that it needs a very high-resolution grid to represent finer geometry details, which could be memory and computationally inefficient. In this work, we propose the PointGrid, a 3D convolutional network that incorporates a constant number of points within each grid cell thus allowing the network to learn higher order local approximation functions that could better represent the local geometry shape details. With experiments on popular shape recognition benchmarks, PointGrid demonstrates state-of-the-art performance over existing deep learning methods on both classification and segmentation.",10
67ebef836b3993a68f81840fd65ed0b37a9e5d6e,Implementation of Insider Threat Detection System Using Honeypot Based Sensors and Threat Analytics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
b650f87804410b6cec9e0858afc7efb269b36c51,Incident Response,"Are you prepared to manage a security incident? We all love the Sunday papers – until they report the latest high profile breach and we find ourselves answering that Monday morning question, "" how would we deal with this type of incident? "" Incidents are increasing in frequency which means businesses are spending more time and money on remediation – often working in the eye of a corporate storm to resolve issues at the same time as trying to maintain business as usual. Complex threats such as APT, are difficult and time consuming to unpick and may require specialist knowledge and resources to comprehensively resolve. They also exploit the siloed nature of traditional incident response, that does not necessarily understand the interdependencies in business systems and applications. The maturity of incident response varies considerably, but high performing businesses treat information security breaches as part of their Business Continuity planning. They",7
c071fc4bb3b20175436b29caca0a65493fa0cdf0,RAN as a service: Challenges of designing a flexible RAN architecture in a cloud-based heterogeneous mobile network,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
510d98681e5e85fb1265513728f16e2543ae1b4b,Hypergraph Neural Networks,"In this paper, we present a hypergraph neural networks (HGNN) framework for data representation learning, which can encode high-order data correlation in a hypergraph structure. Confronting the challenges of learning representation for complex data in real practice, we propose to incorporate such data structure in a hypergraph, which is more flexible on data modeling, especially when dealing with complex data. In this method, a hyperedge convolution operation is designed to handle the data correlation during representation learning. In this way, traditional hypergraph learning procedure can be conducted using hyperedge convolution operations efficiently. HGNN is able to learn the hidden layer representation considering the high-order data structure, which is a general framework considering the complex data correlations. We have conducted experiments on citation network classification and visual object recognition tasks and compared HGNN with graph convolutional networks and other traditional methods. Experimental results demonstrate that the proposed HGNN method outperforms recent",5
9118e5b69edee6acd0c3dc096735df19b9fa6d28,"Small Cell Networks: Deployment, PHY Techniques, and Resource Management","This comprehensive resource explores state-of-the-art advances in the successful deployment and operation of small cell networks. A broad range of technical challenges, and possible solutions, are addressed, including practical deployment considerations and interference management techniques, all set within the context of the most recent cutting-edge advances. Key aspects covered include 3GPP standardisation, applications of stochastic geometry, PHY techniques, MIMO techniques, handover, and radio resource management, including techniques designed to make the best possible use of the available spectrum. Detailed technical information is provided throughout, with a consistent emphasis on real-world applications. Bringing together world-renowned experts from industry and academia, this is an indispensable volume for researchers, engineers and systems designers in the wireless communication industry.",5
e4248ba1e47de1c671b541431df9fce4e8c7b742,Methanesulfonic acid and non-sea-salt sulfate in pacific air: Regional and seasonal variations,"Concentrations of aerosol methanesulfonic acid (MSA) and non-sea-salt (nss) sulfate were measured at six island stations in the Pacific Ocean to investigate regional and seasonal patterns of organosulfur emissions and the origin of nss sulfate over the Pacific. The mean MSA concentrations, in μg/m3, at the stations were: Shemya, 0.097±0.098; Midway, 0.029±0.021; Fanning, 0.044±0.012; American Samoa, 0.026±0.012; New Caledonia, 0.021±0.009; Norfolk, 0.024±0.019. The extremely high MSA levels found at Shemya indicate a major source of organosulfur emissions in the western North Pacific. Significant seasonal trends in MSA were observed, with higher MSA occurring during warm months. The amplitude of the seasonal variation was greatest at higher latitude stations. At Fanning and American Samoa, which have minimal input of continental material, there is a significant positive correlation between MSA and nss sulfate. MSA/nss sulfate ratios at other Pacific stations exhibit greater variability, which may be related to variations in: the input",3
c3200f0b7ac78f63a63dee38af9593c1bacba7d9,Keynote I: Massively Distributed Systems: From Grids and P2P to Clouds,"This keynote describes the evolution of massively distributed computing systems and their key techniques. Clusters of computers now prevail, expand, and become the core components in large-scale computational/information/data Grids. The Open Grid Service Architecture, specifying the Grid software, protocol, and service standards, are only partially implemented in Globus and other Grid toolkits. Grid security demand globalization among various PKI authorities and interoperability between wired and wireless networks. Very little progress being made in special networks, hardware, languages, and operating systems for Grid/Cloud computing. Business Grids/Clouds are under development by Google, IBM, Sun, Microsoft, etc., and widespread acceptance is hindered by selfish behavior and security concerns. Briefly, the keynote includes rise and fall of computing technologies and hot paradigms in the last 35 Years, and presents the implication that computing clouds over the Internet will be the next battlefield among competitors. About the speaker: Kai Hwang is a Professor of Electrical",5
ef32feb9acc8e2c4d53c1b9cdd658aa0bca15bd2,GROUNDS OF MODERN MODELS AND SYSTEMS OF ORGANIZATIONAL CREATIVITY SUPPORT,"the actual base, the basis of rules and the mechanism of conclusions but also directly solve issues related to the time frame. In practice, they are called creativity support systems, and they unite various types of information systems to improve creativity. Creativity support systems can be used to enhance the user’s ability to perform creative tasks (the ability that the user owns), to support users in the field of acquiring knowledge, and to provide users with a new experience of creative tasks, which gives them new abilities. There are two types of creative support systems: individual creativity support systems and group creative support systems. The authors substantiate the expediency of creating and using the complex type of systems of support for creativity called “System of support of organizational creativity”. The system of support for organizational creativity opens a new form of creative support. Unlike previous types of systems, such a",5
88c52b1ef876baf0eadfbd4aa792e8e3b861564f,SoftCell: scalable and flexible cellular core network architecture,"Cellular core networks suffer from inflexible and expensive equipment, as well as from complex control-plane protocols. To address these challenges, we present SoftCell, a scalable architecture that supports fine-grained policies for mobile devices in cellular core networks, using commodity switches and servers. SoftCell enables operators to realize high-level service policies that direct traffic through sequences of middleboxes based on subscriber attributes and applications. To minimize the size of the forwarding tables, SoftCell aggregates traffic along multiple dimensions---the service policy, the base station, and the mobile device---at different switches in the network. Since most traffic originates from mobile devices, SoftCell performs fine-grained packet classification at the access switches, next to the base stations, where software switches can easily handle the state and bandwidth requirements. SoftCell guarantees that packets belonging to the same connection traverse the same sequence of middleboxes in both directions, even in the presence of mobility. We demonstrate that",1
e5c91e9f6688e522acc9d3fd7a95475b9c8e0f58,"Mobile CPU's rise to power: Quantifying the impact of generational mobile CPU design trends on performance, energy, and user satisfaction","In this paper, we assess the past, present, and future of mobile CPU design. We study how mobile CPU designs trends have impacted the end-user, hardware design, and the holistic mobile device. We analyze the evolution often cutting-edge mobile CPU designs released over the past seven years. Specifically, we report measured performance, power, energy and user satisfaction trends across mobile CPU generations. A key contribution of our work is that we contextualize the mobile CPU's evolution in terms of user satisfaction, which has largely been absent from prior mobile hardware studies. To bridge the gap between mobile CPU design and user satisfaction, we construct and conduct a novel crowdsourcing study that spans over 25,000 survey participants using the Amazon Mechanical Turk service. Our methodology allows us to identify what mobile CPU design techniques provide the most benefit to the end-user's quality of user experience. Our results quantitatively demonstrate that CPUs",3
9167644b1ff5a9d124f527400f66425e760d220e,Aneka: a Software Platform for .NET based Cloud Computing,"Aneka is a platform for deploying Clouds developing applications on top of it. It provides a runtime environment and a set of APIs that allow developers to build .NET applications that leverage their computation on either public or private clouds. One of the key features of Aneka is the ability of supporting multiple programming models that are ways of expressing the execution logic of applications by using specific abstractions. This is accomplished by creating a customizable and extensible service oriented runtime environment represented by a collection of software containers connected together. By leveraging on these architecture advanced services including resource reservation, persistence, storage management, security, and performance monitoring have been implemented. On top of this infrastructure different programming models can be plugged to provide support for different scenarios as demonstrated by the engineering, life science, and industry applications.",9
b0d99d995b841f32590fcfde1d17a12a60c81584,Pocket: Elastic Ephemeral Storage for Serverless Analytics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
ea4b28d2c3f34786163852c8deb2bf29f6c4acd6,Fog-assisted personalized healthcare-support system for remote patients with diabetes,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
193f54879601e76884d6562a5e5e01117fed3ded,Cybersecurity compliance in financial institutions: A comparative analysis of global standards and regulations,"Cybersecurity is a critical concern for financial institutions worldwide, given the increasing frequency and sophistication of cyberattacks. This paper conducts a comparative analysis of global standards and regulations governing cybersecurity compliance in financial institutions. By examining the regulatory frameworks of key jurisdictions, including the United States, the European Union, and Asia-Pacific countries, this study aims to identify common trends, differences, and best practices in cybersecurity compliance. The analysis begins by outlining the regulatory landscape for cybersecurity in financial institutions, highlighting the key objectives and principles underlying these regulations. It then compares the regulatory frameworks of different regions, focusing on areas such as data protection, incident response, and risk management. By examining the specific requirements and guidelines set forth by each jurisdiction, this study identifies the strengths and weaknesses of current cybersecurity regulations and offers recommendations for enhancing compliance and resilience. One of the key findings of this study is the",4
3bc1d69fd6b8010e220f2dbb53f01f14bac3dfcc,Harnessing adversarial machine learning for advanced threat detection: AI-driven strategies in cybersecurity risk assessment and fraud prevention,"The abstract is ""The rapid evolution of cyber threats necessitates innovative defenses, particularly in the domains of risk assessment and fraud detection. This paper explores the integration of Artificial Intelligence (AI) and Adversarial Machine Learning (ML) techniques as a formidable strategy against increasingly sophisticated cyber-attacks. We present a comprehensive framework that leverages AI to dynamically assess cybersecurity risks and detect fraudulent activities with unprecedented accuracy and speed. Firstly, we delve into the foundational principles of adversarial machine learning, outlining how these techniques can be employed to simulate potential cyber threats, thereby enabling the development of more resilient AI-driven cybersecurity systems. We highlight the dual role of adversarial ML in both enhancing security defenses and potentially serving as a vector for sophisticated attacks, underscoring the importance of developing robust, adversarial-resistant models. Subsequently, we introduce a novel adaptive risk assessment methodology that incorporates real-time data analysis, machine learning algorithms, and predictive modeling",1
0b2e4715c70c5f79eeaffad6a9774cb0392babd0,A Critical Cybersecurity Analysis and Future Research Directions for the Internet of Things: A Comprehensive Review,"The emergence of the Internet of Things (IoT) technology has brought about tremendous possibilities, but at the same time, it has opened up new vulnerabilities and attack vectors that could compromise the confidentiality, integrity, and availability of connected systems. Developing a secure IoT ecosystem is a daunting challenge that requires a systematic and holistic approach to identify and mitigate potential security threats. Cybersecurity research considerations play a critical role in this regard, as they provide the foundation for designing and implementing security measures that can address emerging risks. To achieve a secure IoT ecosystem, scientists and engineers must first define rigorous security specifications that serve as the foundation for developing secure devices, chipsets, and networks. Developing such specifications requires an interdisciplinary approach that involves multiple stakeholders, including cybersecurity experts, network architects, system designers, and domain experts. The primary challenge in IoT security is ensuring the system can defend against both",2
a253daee62951a067b63ef06d119632bb81d32d7,Cybersecurity Threats Detection in Intelligent Networks using Predictive Analytics Approaches,"The modern scenario of network vulnerabilities necessitates the adoption of sophisticated detection and mitigation strategies. Predictive analytics is surfaced to be a powerful tool in the fight against cybercrime, offering unparalleled capabilities for automating tasks, analyzing vast amounts of data, and identifying complex patterns that might elude human analysts. This paper presents a comprehensive overview of how AI is transforming the field of cybersecurity. Machine intelligence can bring revolution to cybersecurity by providing advanced defense capabilities. Addressing ethical concerns, ensuring model explainability, and fostering collaboration between researchers and developers are crucial for maximizing the positive impact of AI in this critical domain.",2
f169931858410fe06af98967fc131669a8c81ac4,LSTM Recurrent Neural Networks for Cybersecurity Named Entity Recognition,"The automated and timely conversion of cybersecurity information from unstructured online sources, such as blogs and articles to more formal representations has become a necessity for many applications in the domain nowadays. Named Entity Recognition (NER) is one of the early phases towards this goal. It involves the detection of the relevant domain entities, such as product, version, attack name, etc. in technical documents. Although generally considered a simple task in the information extraction field, it is quite challenging in some domains like cybersecurity because of the complex structure of its entities. The state of the art methods require time-consuming and labor intensive feature engineering that describes the properties of the entities, their context, domain knowledge, and linguistic characteristics. The model demonstrated in this paper is domain independent and does not rely on any features specific to the entities in the cybersecurity domain, hence does not require expert knowledge to",1
fdc3a3723513bd55fd9e828455cce0ad34a8287f,"The future of Cybersecurity in renewable energy systems: A review, identifying challenges and proposing strategic solutions","This study provides a comprehensive examination of cybersecurity within renewable energy systems, highlighting the critical role of cybersecurity measures in ensuring the sustainability and reliability of these systems. With the increasing reliance on renewable energy sources, the need for robust cybersecurity frameworks to protect against evolving cyber threats has never been more pressing. Through a systematic literature review and content analysis, this research identifies the prevalent cyber threats and vulnerabilities specific to renewable energy infrastructures, evaluates the effectiveness of current cybersecurity measures, and explores cutting-edge technologies and practices in the field. The methodology encompasses a detailed analysis of peer-reviewed academic journals, conference proceedings, industry reports, and white papers published from 2010 to 2024. This approach facilitates the identification of gaps in current cybersecurity practices and the proposal of strategic solutions to address these challenges. Key insights reveal the significance of adopting advanced cybersecurity technologies, such as artificial intelligence and machine",5
c81aa1a53904bd359aa014d6576fbb54809bd779,The integration of artificial intelligence in cybersecurity measures for sustainable finance platforms: An analysis,"This study delves into the integration of Artificial Intelligence (AI) in cybersecurity measures within smart cities, aiming to uncover both the challenges and opportunities this fusion presents. With the burgeoning reliance on interconnected digital infrastructures and the vast data ecosystems within urban environments, smart cities are increasingly susceptible to sophisticated cyber threats. Through a systematic literature review and content analysis, this research identifies the unique cybersecurity vulnerabilities faced by smart cities and evaluates how AI technologies can fortify urban cybersecurity frameworks. The methodology encompasses a comprehensive review of recent scholarly articles, industry reports, and case studies to assess the role of AI in enhancing threat detection, response, and prevention mechanisms. Key findings reveal that AI-driven cybersecurity solutions significantly enhance the resilience of smart cities against cyber threats by providing advanced analytical capabilities and real-time threat intelligence. However, the study also highlights the critical need for robust ethical and privacy considerations",3
07ac8f33e82eec20dc3733eb825deae5d6404967,Review of strategic alignment: Accounting and cybersecurity for data confidentiality and financial security,"In the contemporary landscape of rapidly evolving technological advancements and the increasing prevalence of cyber threats, organizations face a critical imperative to align their accounting practices with robust cybersecurity measures. This review explores the symbiotic relationship between accounting and cybersecurity in safeguarding data confidentiality and ensuring financial security. Focusing on the intersection of these two domains, we examine the strategic alignment required to fortify organizations against the escalating challenges posed by cyber threats to sensitive financial information. The review begins by delving into the intricate connection between accounting processes and the protection of financial data, emphasizing the pivotal role of accurate financial reporting and transparent disclosure in maintaining stakeholder trust. Subsequently, it scrutinizes the evolving threat landscape, identifying cyber risks that specifically target financial systems and data. The analysis underscores the need for a comprehensive strategic approach that integrates accounting practices with cybersecurity protocols to effectively mitigate these risks. Furthermore,",3
c6874a0d173de76c1e79df43324c4d58d30a30bc,Cybersecurity of Smart Inverters in the Smart Grid: A Survey,"The penetration of distributed energy resources (DERs) in smart grids significantly increases the number of field devices owned and controlled by consumers, aggregators, third parties, and utilities. As the interface between DER and power grids, DER inverters are becoming smarter with various grid-support functions and communication capabilities. Meanwhile, the cybersecurity risks of smart inverters are also on the rise due to the extensive utilization of information and communication technologies. The potential negative impacts of cyberattacks on smart inverters have attracted significant attention from scholars and organizations. To advance the research on smart inverter cybersecurity and provide insights into its technical achievements, barriers, and future directions, this article will give a comprehensive review of critical attacks and defense strategies for smart inverters and inverter-based systems like microgrids. We start this survey with an overview of the smart inverter introduction, including device- and grid-level architectures, grid-support functions, and communication protocols. We then",3
be8940fd490e058cb851a21bd455ffb9b01d025a,CYBERSECURITY DYNAMICS IN NIGERIAN BANKING: TRENDS AND STRATEGIES REVIEW,"This paper provides an in-depth review of the cybersecurity dynamics within the Nigerian banking sector, emphasizing recent trends and strategic approaches to address emerging challenges. As a review paper, it synthesizes existing literature, reports, and case studies to offer a comprehensive understanding of the current cybersecurity landscape in Nigerian banks. The focus is on identifying the predominant cyber threats, analyzing the sector's response strategies, and evaluating the effectiveness of these measures in the context of Nigeria's unique socio-economic and regulatory environment. Our analysis reveals a notable escalation in cyber threats, particularly phishing, ransomware, and insider attacks, which have been intensified by the rapid digital transformation in banking services. The review identifies key factors contributing to these challenges, such as the increasing sophistication of cybercriminals, the digital literacy gap among customers, and the evolving nature of cyber threats. It also examines the strategic responses of Nigerian banks, including the adoption of",3
cc1697038a9fcca37977b3b0e1bd9d434d3d9a3e,"AI-Driven Cybersecurity: An Overview, Security Intelligence Modeling and Research Directions","Artificial intelligence (AI) is one of the key technologies of the Fourth Industrial Revolution (or Industry 4.0), which can be used for the protection of Internet-connected systems from cyber threats, attacks, damage, or unauthorized access. To intelligently solve today’s various cybersecurity issues, popular AI techniques involving machine learning and deep learning methods, the concept of natural language processing, knowledge representation and reasoning, as well as the concept of knowledge or rule-based expert systems modeling can be used. Based on these AI methods, in this paper, we present a comprehensive view on “AI-driven Cybersecurity” that can play an important role for intelligent cybersecurity services and management. The security intelligence modeling based on such AI methods can make the cybersecurity computing process automated and intelligent than the conventional security systems. We also highlight several research directions within the scope of our study, which can help researchers do future research in the area.",10
b1c09857fea0540334b7dd9e1f7b5d2b1247d86c,DATA CONFIDENTIALITY AND INTEGRITY: A REVIEW OF ACCOUNTING AND CYBERSECURITY CONTROLS IN SUPERANNUATION ORGANIZATIONS,"In an era dominated by digital transformation, superannuation organizations face unprecedented challenges in safeguarding the confidentiality and integrity of sensitive financial data. This review explores the intricate relationship between accounting practices and cybersecurity controls within the context of superannuation entities. By examining the existing literature, regulatory frameworks, and industry best practices, this paper synthesizes the key considerations essential for ensuring robust data protection. The study delves into the critical role of accounting systems in managing financial information and the subsequent implications for data confidentiality. It investigates how evolving accounting standards and practices intersect with cybersecurity protocols to fortify the integrity of financial records within superannuation organizations. The dynamic nature of cyber threats necessitates a comprehensive analysis of technological safeguards, risk management frameworks, and compliance measures to uphold data confidentiality. Furthermore, the review underscores the imperative for a multidimensional approach to cybersecurity in the superannuation sector. It discusses the integration of",1
4f71d51b8e296c7b7350a79d668adf6416144a0c,"Cyberattacks in Smart Grids: Challenges and Solving the Multi-Criteria Decision-Making for Cybersecurity Options, Including Ones That Incorporate Artificial Intelligence, Using an Analytical Hierarchy Process","Smart grids have emerged as a transformative technology in the power sector, enabling efficient energy management. However, the increased reliance on digital technologies also exposes smart grids to various cybersecurity threats and attacks. This article provides a comprehensive exploration of cyberattacks and cybersecurity in smart grids, focusing on critical components and applications. It examines various cyberattack types and their implications on smart grids, backed by real-world case studies and quantitative models. To select optimal cybersecurity options, the study proposes a multi-criteria decision-making (MCDM) approach using the analytical hierarchy process (AHP). Additionally, the integration of artificial intelligence (AI) techniques in smart-grid security is examined, highlighting the potential benefits and challenges. Overall, the findings suggest that “security effectiveness” holds the highest importance, followed by “cost-effectiveness”, “scalability”, and “Integration and compatibility”, while other criteria (i.e., “performance impact”, “manageability and usability”, “compliance and regulatory requirements”, “resilience and redundancy”, “vendor support and collaboration”, and “future",8
39762dd992057072ccbde2f866e0448dec5d4069,Cybersecurity’s Role in Environmental Protection and Sustainable Development: Bridging Technology and Sustainability Goals,"This study investigates the pivotal role of cybersecurity in bolstering environmental protection and sustainable development, a critical yet underexplored nexus in contemporary research. Employing a systematic literature review and content analysis, the research scrutinizes peer-reviewed articles, conference proceedings, and industry reports from 2015 to 2023, sourced from databases such as IEEE Xplore, ScienceDirect, and Google Scholar. The methodology is anchored in a rigorous search strategy, leveraging keywords related to cybersecurity, sustainability, and communication technologies, and adheres to defined inclusion and exclusion criteria to ensure the relevance and quality of the literature reviewed. Key findings highlight cybersecurity as an indispensable enabler of sustainable development initiatives, safeguarding the technological infrastructure essential for environmental conservation efforts. The study identifies evolving cyber threats as a significant challenge, necessitating adaptive security measures that anticipate and mitigate potential vulnerabilities. Furthermore, it underscores the opportunities presented by advanced cybersecurity technologies, such as artificial intelligence and blockchain, in",0
b2319ad4828be04bc873a55762cee49583740fb3,Counterattacking Cyber Threats: A Framework for the Future of Cybersecurity,"Amidst the rapid advancements in the digital landscape, the convergence of digitization and cyber threats presents new challenges for organizational security. This article presents a comprehensive framework that aims to shape the future of cyber security. This framework responds to the complexities of modern cyber threats and provides guidance to organizations to enhance their resilience. The primary focus lies in the integration of capabilities with resilience. By combining these elements into cyber security practices, organizations can improve their ability to predict, mitigate, respond to, and recover from cyber disasters. This article emphasizes the importance of organizational leadership, accountability, and innovation in achieving cyber resilience. As cyber threat challenges continue to evolve, this framework offers strategic guidance to address the intricate dynamics between digitization and cyber security, moving towards a safer and more robust digital environment in the future.",7
807110054f8137a10ed5bb05a33e93bf596f897a,ChatGPT: Exploring the Role of Cybersecurity in the Protection of Medical Information,"ChatGPT is a large language model developed by OpenAI. It is trained on a dataset of conversational text and can be used to generate human-like responses to prompts in a variety of languages and formats. It can be used for tasks such as chatbots, language translation, and text completion. The role of ChatGPT is to generate human-like text based on a given prompt or context. It can be used in a variety of applications such as chatbots, language translation, text completion, and question answering. Additionally, it can be fine-tuned for specific tasks such as generating product descriptions or summarizing articles. It can also be used to generate creative writing such as poetry and stories. It can be integrated into a wide range of industries from customer service to entertainment, to research.",6
bf0e9446eca16e8ac1e759dce6a7b3f22d2111de,When LLMs Meet Cybersecurity: A Systematic Literature Review,"The rapid development of large language models (LLMs) has opened new avenues across various fields, including cybersecurity, which faces an evolving threat landscape and demand for innovative technologies. Despite initial explorations into the application of LLMs in cybersecurity, there is a lack of a comprehensive overview of this research area. This paper addresses this gap by providing a systematic literature review, covering the analysis of over 300 works, encompassing 25 LLMs and more than 10 downstream scenarios. Our comprehensive overview addresses three key research questions: the construction of cybersecurity-oriented LLMs, the application of LLMs to various cybersecurity tasks, the challenges and further research in this area. This study aims to shed light on the extensive potential of LLMs in enhancing cybersecurity practices and serve as a valuable resource for applying LLMs in this field. We also maintain and regularly update a list of practical guides on LLMs for cybersecurity at",4
e9d573b0a7f72883c76a8457c6fc62cec69769d1,Digital Transformation and Cybersecurity Challenges for Businesses Resilience: Issues and Recommendations,"This systematic literature review explores the digital transformation (DT) and cybersecurity implications for achieving business resilience. DT involves transitioning organizational processes to IT solutions, which can result in significant changes across various aspects of an organization. However, emerging technologies such as artificial intelligence, big data and analytics, blockchain, and cloud computing drive digital transformation worldwide while increasing cybersecurity risks for businesses undergoing this process. This literature survey article highlights the importance of comprehensive knowledge of cybersecurity threats during DT implementation to prevent interruptions due to malicious activities or unauthorized access by attackers aiming at sensitive information alteration, destruction, or extortion from users. Cybersecurity is essential to DT as it protects digital assets from cyber threats. We conducted a systematic literature review using the PRISMA methodology in this research. Our literature review found that DT has increased efficiency and productivity but poses new challenges related to cybersecurity risks, such as data",2
208c0148b8e4bad8a557be72e424a01092389dc9,Aligning sustainable development goals with cybersecurity strategies: Ensuring a secure and sustainable future,"This study explores the critical intersection between cybersecurity and sustainable development, aiming to understand how cybersecurity measures can support the achievement of the Sustainable Development Goals (SDGs). Employing a systematic literature review and content analysis, the research scrutinizes peer-reviewed articles, conference proceedings, and reports from international organizations, focusing on literature published from 2010 to 2024. The inclusion criteria targeted works that directly address the role of cybersecurity in sustainable development, particularly those discussing emerging technologies and their potential to enhance digital security in support of the SDGs. The exclusion criteria filtered out non-peer-reviewed articles, opinion pieces, and studies not explicitly linking cybersecurity with sustainable development efforts. Key findings highlight the indispensable role of cybersecurity in safeguarding digital infrastructure essential for achieving SDGs, emphasizing the transformative potential of innovations such as blockchain technology and artificial intelligence in enhancing cybersecurity measures. The study identifies significant challenges at the intersection of cybersecurity and",2
1e8ccc3909baf44b45161f8ee10bd25a49fc01a1,A comprehensive study on cybersecurity challenges and opportunities in the IoT world,"It has become possible to link anything and everything to the Internet in recent decades due to the expanding Internet of Things (IoT). As a result, our usage of technology has changed a lot, causing digital disruption in the real world. IoT allows drones, sensors, digital set‐top boxes, surveillance cameras, wearable technology, and medical equipment to be connected to the internet. Healthcare, manufacturing, utilities, transportation, and housing are among the various sectors that has become intelligent. Recently, we have seen a surge in cybersecurity challenges and opportunities for the improvement of various IoT applications. Although cybersecurity and the IoT are extensively researched, there is a dearth of studies that exclusively focus on the evolution of cybersecurity challenges in the area of AI and machine learning, blockchain and zero trust, lightweight security, integration of IoT with 5G networks, and many more in the IoT world. The availability of environment‐capturing sensors and",1
81e8396f2257952819dabd425fd6ac7c48d16fb8,Towards Artificial Intelligence-Based Cybersecurity: The Practices and ChatGPT Generated Ways to Combat Cybercrime,"Today, cybersecurity is considered one of the most noteworthy topics that are circulated frequently among companies in order to protect their data from hacking operations. The emergence of cyberspace contributed to the growth of electronic systems. It is a virtual digital space through which interconnection is established between computers and smartphones connected within the Internet of Things environment. This space is critical in building a safe digital environment free of threats and cybercrime. It is only possible to make a digital environment with the presence of cyberspace, which contains modern technologies that make this environment safe and far from unauthorized individuals. Cybersecurity has a wide range of challenges and obstacles in performance, and it is difficult for companies to face them. In this report, the most significant practices, sound, and good strategies will be studied to stop cybercrime and make a digital environment that guarantees data transfers between electronic devices",4
ef8f8dc9eff937d65a312ee619c16cf06eb3e456,Recent Advances on Federated Learning for Cybersecurity and Cybersecurity for Federated Learning for Internet of Things,"Decentralized paradigm in the field of cybersecurity and machine learning (ML) for the emerging Internet of Things (IoT) has gained a lot of attention from the government, academia, and industries in recent years. Federated cybersecurity (FC) is regarded as a revolutionary concept to make the IoT safer and more efficient in the future. This emerging concept has the potential of detecting security threats, taking countermeasures, and limiting the spreading of threats over the IoT network system efficiently. An objective of cybersecurity is achieved by forming the federation of the learned and shared model on top of various participants. Federated learning (FL), which is regarded as a privacy-aware ML model, is particularly useful to secure the vulnerable IoT environment. In this article, we start with background and comparison of centralized learning, distributed on-site learning, and FL, which is then followed by a survey of the application of FL to cybersecurity for",6
a88d5fb82358d19d0daed7d35d49f03ea6796b57,Large Language Models in Cybersecurity: State-of-the-Art,"The rise of Large Language Models (LLMs) has revolutionized our comprehension of intelligence bringing us closer to Artificial Intelligence. Since their introduction, researchers have actively explored the applications of LLMs across diverse fields, significantly elevating capabilities. Cybersecurity, traditionally resistant to data-driven solutions and slow to embrace machine learning, stands out as a domain. This study examines the existing literature, providing a thorough characterization of both defensive and adversarial applications of LLMs within the realm of cybersecurity. Our review not only surveys and categorizes the current landscape but also identifies critical research gaps. By evaluating both offensive and defensive applications, we aim to provide a holistic understanding of the potential risks and opportunities associated with LLM-driven cybersecurity.",2
8895cfd205a7f3d4ba99caea175dc4f7d0db3b7b,"Chatgpt for cybersecurity: practical applications, challenges, and future directions","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
b2084a383f69fbcc3ab779f4b1aa425c5224229e,Deep Learning Based Attack Detection for Cyber-Physical System Cybersecurity: A Survey,"With the booming of cyber attacks and cyber criminals against cyber-physical systems (CPSs), detecting these attacks remains challenging. It might be the worst of times, but it might be the best of times because of opportunities brought by machine learning (ML), in particular deep learning (DL). In general, DL delivers superior performance to ML because of its layered setting and its effective algorithm for extract useful information from training data. DL models are adopted quickly to cyber attacks against CPS systems. In this survey, a holistic view of recently proposed DL solutions is provided to cyber attack detection in the CPS context. A six-step DL driven methodology is provided to summarize and analyze the surveyed literature for applying DL methods to detect cyber attacks against CPS systems. The methodology includes CPS scenario analysis, cyber attack identification, ML problem formulation, DL model customization, data acquisition for training, and performance evaluation. The",3
b652b2ce62479f8524a4917126da760dae7a048c,Cybersecurity Challenges for Manufacturing Systems 4.0: Assessment of the Business Impact Level,"An ever-growing number of companies are moving toward the Industry 4.0 paradigm, adopting a range of advanced technologies (e.g., smart sensors, big data analytics, and cloud computing) and networking their manufacturing systems. This improves the efficiency and effectiveness of operations but also introduces new cybersecurity challenges. In this article, the impact assessment methodology is applied in the context of manufacturing systems 4.0 (also known as smart manufacturing systems, cyber manufacturing systems, or digital manufacturing systems), thus identifying the critical assets to be protected against cyber-attacks and assessing the business impacts in the case of subtractive and additive technologies. The research design of the single case study with multiple units of analysis is applied. In particular, a large company, a leader in the manufacturing of aeronautical components, is considered a representative case study, and its two main types of manufacturing cells that is, those based on networked computer numerical control machines",2
754f3d75adbf243cda601bb815784a2d73bbb711,MASTERING COMPLIANCE: A COMPREHENSIVE REVIEW OF REGULATORY FRAMEWORKS IN ACCOUNTING AND CYBERSECURITY,"In the rapidly evolving landscape of business and technology, the intersection of accounting and cybersecurity has become a focal point for organizations striving to maintain integrity, security, and regulatory adherence. This paper presents a meticulous examination of regulatory frameworks governing both accounting and cybersecurity domains. The study aims to provide a comprehensive understanding of the intricate compliance landscape, offering valuable insights for practitioners, policymakers, and scholars. The investigation unfolds through a dual lens, meticulously dissecting the regulatory intricacies surrounding financial reporting in accounting and the safeguarding of digital assets in cybersecurity. A critical analysis of prominent global regulatory bodies, such as the Financial Accounting Standards Board (FASB), the International Financial Reporting Standards (IFRS), and cybersecurity standards like ISO 27001 and NIST Cybersecurity Framework, forms the cornerstone of this research. The paper delves into the historical evolution of accounting and cybersecurity regulations, identifying key milestones and paradigm shifts that have shaped",2
317ad53bea6fb603c20f692bb2f1a01e2dc86161,From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,"Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI",6
e1ba19c3a819a79b5979cd57289011ba905bad70,Machine learning in cybersecurity: A review of threat detection and defense mechanisms,"The cybersecurity concerns get increasingly intricate as the digital world progresses. In light of the increasing complexity of cyber threats, it is imperative to develop and implement advanced and flexible security strategies. Machine Learning (ML) has become a potent tool in strengthening cybersecurity, providing the capacity to scrutinise extensive information, recognise trends, and improve threat detection and defence methods. This paper examines the significance of ML in the field of cybersecurity, with a special emphasis on the identification of threats and the implementation of protective measures. By incorporating ML algorithms into cybersecurity frameworks, organisations may automate decision-making processes, facilitating prompt responses to ever-changing threats. The initial segment explores the terrain of cyber threats, highlighting the necessity for dynamic and aggressive security methods. Conventional solutions that rely on signatures are frequently inadequate when it comes to handling sophisticated, shape-shifting attacks. ML algorithms, in contrast, have exceptional proficiency in identifying nuanced patterns",4
aa1b6eb2563523b72d01d2570f71a81930a83320,Artificial intelligence (AI) cybersecurity dimensions: a comprehensive framework for understanding adversarial and offensive AI,"As Artificial Intelligence (AI) rapidly advances and integrates into various domains, cybersecurity emerges as a critical field grappling with both the benefits and pitfalls of AI technologies. This paper explores the multifaceted dimensions of AI-driven cyberattacks, offering insights into their implications, mitigation strategies, underlying motivations, and profound societal impacts. The research centres on developing and presenting the AI Cybersecurity Dimensions (AICD) Framework, a comprehensive, multidimensional schema designed to guide academics, policymakers, and industry professionals in understanding and combating the evolving challenges posed by AI-driven cyber threats. The research unveils the complex dynamics of offensive AI, stressing the need for adaptive defences and ethical considerations. Concurrently, the study highlights adversarial AI threats, calling for proactive measures to address their potential ramifications. Through rigorous textual analyses and extensive literature reviews, the paper underscores the urgency for interdisciplinary approaches to bridge the technology-humanity chasm traditionally observed in cybersecurity discussions. By synthesising these diverse",6
983968c21137edc191dd6d8b1578858f98ca5a93,A REVIEW OF CYBERSECURITY STRATEGIES IN MODERN ORGANIZATIONS: EXAMINING THE EVOLUTION AND EFFECTIVENESS OF CYBERSECURITY MEASURES FOR DATA PROTECTION,"In an era where digital threats are increasingly pervasive, understanding the evolution and efficacy of cybersecurity strategies in modern organizations is paramount. This study provides a comprehensive analysis of the dynamic landscape of cybersecurity, exploring its progression from traditional methods to innovative, technology-driven approaches. The digital age has ushered in complex cyber threats, necessitating robust cybersecurity measures. This study examines cybersecurity strategies' historical development, current trends, and future directions across different organizational contexts and industries. The primary aim is to assess the evolution and effectiveness of cybersecurity measures, identify existing gaps, and understand the interplay between human behavior, technology, and policy in cybersecurity. The paper encompasses a comprehensive methodological framework for cybersecurity analysis, exploring the effectiveness of traditional versus modern approaches, the role of AI and ML, and the impact of international policies. It also presents case studies to illustrate successes and failures in cybersecurity implementation. Key findings reveal a",3
49771cf58fc601e7592fec0cc0de71e0364c3ff2,The Role of AI in Cybersecurity: Addressing Threats in the Digital Age,"In the contemporary digital landscape, cybersecurity stands as a paramount concern due to the increasing sophistication and frequency of cyber threats. Artificial Intelligence (AI) has emerged as a potent tool in fortifying defenses against these evolving threats. This paper examines the multifaceted role of AI in cybersecurity, elucidating its applications in threat detection, vulnerability assessment, incident response, and predictive analysis. By leveraging machine learning algorithms, AI systems can swiftly analyze vast troves of data to identify anomalous patterns indicative of potential security breaches. Moreover, AI-driven technologies enable proactive defense mechanisms, empowering organizations to preemptively mitigate risks and safeguard sensitive information. However, the deployment of AI in cybersecurity also raises pertinent ethical and privacy considerations, necessitating a balanced approach towards its implementation. Through a comprehensive analysis, this paper underscores the imperative of integrating AI into cybersecurity frameworks to effectively mitigate threats in the digital age.",2
2c2accf9d8a80d996ee79049af202385b87bfd3f,Best practices in cybersecurity for green building management systems: Protecting sustainable infrastructure from cyber threats,"This study explores the critical intersection of cybersecurity and sustainable infrastructure, with a focus on Green Building Management Systems (GBMS). Recognizing the increasing sophistication of cyber threats and the integration of digital technologies in sustainable buildings, this research aims to understand the challenges and prospects of cybersecurity within this context. Employing a systematic literature review and content analysis, the study examines peer-reviewed articles, conference proceedings, and industry reports from 2010 to 2024. The methodology facilitates a comprehensive understanding of the evolution, current practices, and future directions of cybersecurity measures in sustainable infrastructure. Key findings reveal that robust cybersecurity measures are foundational to protecting the digital and physical assets underpinning sustainable infrastructure. The study identifies core principles of cybersecurity, such as resilience and the integration of cybersecurity with sustainability efforts, as crucial for enhancing the security posture of GBMS. Looking ahead, the research anticipates a future where cybersecurity measures are seamlessly",3
3139e0c7002df948519a66b5a57a43fab9e013b9,Artificial intelligence in cybersecurity: Protecting national infrastructure: A USA review,"Artificial Intelligence (AI) has emerged as a transformative force in the field of cybersecurity, playing a pivotal role in safeguarding national infrastructure. This review focuses on the application of AI technologies within the context of the United States, examining their efficacy in fortifying critical systems against evolving cyber threats. The paper delves into various AI-driven cybersecurity strategies, ranging from anomaly detection and predictive analysis to threat intelligence and automated response mechanisms. The integration of AI in cybersecurity not only enhances the speed and accuracy of threat detection but also addresses the dynamic nature of cyber threats. The specific AI technologies employed in the United States, including machine learning, natural language processing, and neural networks, highlighting their contributions to bolstering the resilience of national infrastructure are also examined. Furthermore, the challenges and ethical considerations associated with the widespread adoption of AI in cybersecurity are assessed. It discusses the need for robust",6
f70158eddb1b09b48672a08e074f68dd7d26d327,Exploring the Top Five Evolving Threats in Cybersecurity: An In-Depth Overview,"The term cybersecurity refers to an environment capable of protecting digital devices, networks and information from unauthorized access and preventing data theft or alteration. It is composed of a collection of carefully crafted techniques, processes, and practices to protect sensitive information and deterring cyber-attacks. In the recent period, the domain of cybersecurity has undergone rapid growth in response to the increasing cyber threats. Cybersecurity includes important tactics that help protect the digital environment, which are firewalls, encryption, secure passwords, and threat detection and response systems. Employees must be trained on these tactics. This article will discuss the five most pressing challenges facing the cybersecurity industry today that must be taken into account by businesses, organizations, and individuals in order to secure their confidential data from cybercrime. The conclusion of the article highlighted the significance of growing awareness about cybersecurity risks in order to effectively handle digital environments and protect them",3
427a38f01ee3ea20a7c850550e444190ec98852d,Machine Learning in Cybersecurity: Techniques and Challenges,"In the computer world, data science is the force behind the recent dramatic changes in cybersecurity's operations and technologies. The secret to making a security system automated and intelligent is to extract patterns or insights related to security incidents from cybersecurity data and construct appropriate data-driven models. Data science, also known as diverse scientific approaches, machine learning techniques, processes, and systems, is the study of actual occurrences via the use of data. Due to its distinctive qualities, such as flexibility, scalability, and the capability to quickly adapt to new and unknowable obstacles, machine learning techniques have been used in many scientific fields. Due to notable advancements in social networks, cloud and web technologies, online banking, mobile environments, smart grids, etc., cyber security is a rapidly expanding sector that requires a lot of attention. Such a broad range of computer security issues have been effectively addressed by various machine learning techniques.",9
9ed1c306e77ddcc195b2beffa09049399a07a470,Artificial intelligence for cybersecurity: Literature review and future research directions,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
a5747b67b3213c7eccba6183b9bffb4828e8a299,CYBERSECURITY IN BANKING: A GLOBAL PERSPECTIVE WITH A FOCUS ON NIGERIAN PRACTICES,"The paper review cybersecurity practices in banking, with a specific focus on Nigerian banks. Cybersecurity has become a paramount concern in the banking industry worldwide, given the escalating frequency and sophistication of cyber threats. This study provides an overview of the global landscape of cybersecurity in banking, with a specific focus on practices observed in Nigeria. The global banking sector is witnessing a surge in digital transformation, marked by the adoption of advanced technologies and online financial services. However, this digitization brings with it unprecedented cybersecurity challenges, ranging from data breaches and ransomware attacks to sophisticated financial fraud. Financial institutions globally are compelled to fortify their cybersecurity frameworks to protect sensitive customer information, ensure the integrity of financial transactions, and maintain trust in the digital financial ecosystem. Nigeria, as a key player in the African banking landscape, faces unique cybersecurity challenges and has developed distinct strategies to safeguard its financial",2
1d028098b8301aa66e6a575e2e92573c9da1e92a,Cybersecurity risks in online banking: A detailed review and preventive strategies applicatio,"In an era where the digital transformation of the banking sector intersects with the escalating complexity of cyber threats, this paper endeavors to dissect the multifaceted realm of cybersecurity within the banking industry. With a backdrop of increasing online banking adoption and the concomitant rise in cybercrime, the study aims to illuminate the current cybersecurity landscape, evaluate the efficacy of existing frameworks and propose strategic enhancements to fortify digital defenses. Employing a methodological amalgam of literature review and analysis of recent cybersecurity incidents, this investigation delves into the intricacies of cyber threats, the financial repercussions of breaches and the robustness of current cybersecurity measures in banking. The scope of this paper encompasses a comprehensive examination of recent cyber incidents, an assessment of the financial impact of cyber-attacks, an evaluation of the effectiveness of existing cybersecurity frameworks and the formulation of strategic recommendations for bolstering cybersecurity measures. Through this scholarly inquiry,",2
154862cd1839ebeae9c0ed79e9d4eadefad5843b,"Cybersecurity for Sustainable Smart Healthcare: State of the Art, Taxonomy, Mechanisms, and Essential Roles","Cutting-edge technologies have been widely employed in healthcare delivery, resulting in transformative advances and promising enhanced patient care, operational efficiency, and resource usage. However, the proliferation of networked devices and data-driven systems has created new cybersecurity threats that jeopardize the integrity, confidentiality, and availability of critical healthcare data. This review paper offers a comprehensive evaluation of the current state of cybersecurity in the context of smart healthcare, presenting a structured taxonomy of its existing cyber threats, mechanisms and essential roles. This study explored cybersecurity and smart healthcare systems (SHSs). It identified and discussed the most pressing cyber threats and attacks that SHSs face, including fake base stations, medjacking, and Sybil attacks. This study examined the security measures deployed to combat cyber threats and attacks in SHSs. These measures include cryptographic-based techniques, digital watermarking, digital steganography, and many others. Patient data protection, the prevention of data breaches, and the maintenance of",5
1098d3743083c4c6a39a124efb725c10d2b7423c,COMPREHENSIVE REVIEW ON CYBERSECURITY: MODERN THREATS AND ADVANCED DEFENSE STRATEGIES,"In the rapidly evolving landscape of cyberspace, the prevalence of sophisticated cyber threats has escalated, posing formidable challenges to individuals, organizations, and nations. This comprehensive review explores the contemporary panorama of cybersecurity, focusing on the latest threats and the advanced defense strategies employed to mitigate them. The analysis encompasses a wide spectrum of cyber threats, including malware, ransomware, phishing attacks, and advanced persistent threats (APTs), shedding light on their evolving tactics, techniques, and procedures. The review delves into the intricate world of cybercrime, emphasizing the motives behind attacks and the diverse range of threat actors involved, from individual hackers to state-sponsored entities. By examining recent case studies and real-world incidents, the review provides valuable insights into the dynamic nature of cyber threats, emphasizing the need for proactive and adaptive cybersecurity measures. Furthermore, the review critically evaluates cutting-edge defense mechanisms and strategies deployed to counteract these threats. It explores advancements in",6
1dce1ebadb25d7466de773335e7965a3d4a328ef,Cyber Threat Intelligence Mining for Proactive Cybersecurity Defense: A Survey and New Perspectives,"Today’s cyber attacks have become more severe and frequent, which calls for a new line of security defenses to protect against them. The dynamic nature of new-generation threats, which are evasive, resilient, and complex, makes traditional security systems based on heuristics and signatures struggle to match. Organizations aim to gather and share real-time cyber threat information and then turn it into threat intelligence for preventing attacks or, at the very least, responding quickly in a proactive manner. Cyber Threat Intelligence (CTI) mining, which uncovers, processes, and analyzes valuable information about cyber threats, is booming. However, most organizations today mainly focus on basic use cases, such as integrating threat data feeds with existing network and firewall systems, intrusion prevention systems, and Security Information and Event Management systems (SIEMs), without taking advantage of the insights that such new intelligence can deliver. In order to make the most of CTI so as to",2
767e710dd7036a4b01a9a2156b006b66bc4b2250,AI-Driven Cybersecurity: Balancing Advancements and Safeguards,"As Artificial Intelligence (AI) continues its rapid evolution, its profound influence on cybersecurity becomes increasingly evident. This study delves into the pivotal role of AI in fortifying cybersecurity measures, emphasizing its capacity for enhanced threat detection, automated response mechanisms, and the development of resilient security frameworks. However, alongside its promise, recognition of AI's susceptibility to exploitation in sophisticated cyber-attacks exists, underscoring the imperative for continual advancements in AI-driven security solutions. This research offers a nuanced perspective on AI's impact on cybersecurity, advocating for the proactive integration of AI strategies, sustained research efforts, and formulating ethical guidelines. Adopting supervised machine learning (ML) algorithms like decision trees, support vector machines, and neural networks aims to harness AI's potential to bolster cybersecurity while concurrently addressing associated risks, paving the way for a secure digital landscape. Regarding accuracy, the neural network outperforms other models by 98%.",2
5ccd0970fbdb1e4a321434223ee3e13399ad0851,CYBERSECURITY CHALLENGES IN THE AGE OF AI: THEORETICAL APPROACHES AND PRACTICAL SOLUTIONS,"In the ever-evolving landscape of cybersecurity, the proliferation of artificial intelligence (AI) technologies introduces both promising advancements and daunting challenges. This paper explores the theoretical underpinnings and practical implications of addressing cybersecurity challenges in the age of AI. With the integration of AI into various facets of digital infrastructure, including threat detection, authentication, and response mechanisms, cyber threats have become increasingly sophisticated and difficult to mitigate. Theoretical approaches delve into understanding the intricate interplay between AI algorithms, human behavior, and adversarial tactics, elucidating the underlying mechanisms of cyber attacks and defense strategies. However, this complexity also engenders novel vulnerabilities, as AI-driven attacks leverage machine learning algorithms to evade traditional security measures, posing formidable challenges to organizations across sectors. As such, practical solutions necessitate a multifaceted approach, encompassing robust threat intelligence, adaptive defense mechanisms, and ethical considerations to safeguard against AI-driven cyber threats effectively. Leveraging AI for cybersecurity defense holds promise",4
66fc6467aec08ebb6047a3429a5c9ff6a8cceb90,Current trends in AI and ML for cybersecurity: A state-of-the-art survey,"Abstract This paper provides a comprehensive survey of the state-of-the-art use of Artificial Intelligence (AI) and Machine Learning (ML) in the field of cybersecurity. The paper illuminates key applications of AI and ML in cybersecurity, while also addressing existing challenges and posing unresolved questions for future research. The paper also emphasizes the ethical and legal implications associated with their implementation. The researchers conducted a thorough survey by reviewing numerous papers and articles from respected sources such as IEEE, ACM, and Springer. Their focus centered on the latest AI and ML breakthroughs in cybersecurity, while also exploring current challenges and open research questions. The results indicate that integrating AI and ML into cybersecurity systems shows great potential for future research and development. Intrusion detection and response, malware detection, and network security are among the most promising applications identified. According to the survey, 45% of organizations have already implemented AI and ML",2
6a77366ff3d934a27d158708353c1875602c0d37,Developing comprehensive cybersecurity frameworks for protecting green infrastructure: Conceptual models and practical applications,"This study investigates the critical intersection of cybersecurity and green infrastructure (GI), aiming to elucidate the challenges, opportunities, and strategic approaches necessary for safeguarding these essential systems against cyber threats. Employing a systematic literature review and content analysis, the research scrutinizes peer-reviewed articles, industry reports, and regulatory publications from 2014 to 2024. The methodology focuses on identifying prevalent cybersecurity vulnerabilities within GI, the evolution of protective practices, the impact of regulatory frameworks, and the strategic implications for diverse stakeholders. Key findings reveal a complex landscape where the integration of digital technologies in GI introduces both innovative solutions and new vulnerabilities. The study highlights the pivotal role of international standards and regulatory bodies in shaping cybersecurity strategies, underscoring the necessity for a holistic approach that encompasses technological, regulatory, and human factors. Strategic recommendations advocate for interdisciplinary collaboration, enhanced regulatory frameworks, and stakeholder engagement to fortify the cybersecurity of GI. The research",4
e30a06e161d7ef4612ae56e5e91f7c8c15fe6951,CYBERSECURITY IN THE FINANCIAL SECTOR: A COMPARATIVE ANALYSIS OF THE USA AND NIGERIA,"This paper provides a comprehensive review and comparative analysis of cybersecurity challenges and strategies within the financial sectors of the United States of America (USA) and Nigeria. It aims to elucidate the complexities and variances in cybersecurity practices, focusing on the different approaches taken by these nations to safeguard their financial data against increasing cyber threats. Through a detailed examination of existing literature, including academic journals, industry reports, and cybersecurity incident databases, this study identifies the unique and common cybersecurity vulnerabilities, regulatory environments, and defense mechanisms employed by the financial sectors in both countries. The review reveals that the USA's financial sector benefits from advanced cybersecurity technologies and a strong regulatory framework, yet faces challenges related to sophisticated cyber-attacks and the management of insider threats. Conversely, Nigeria's financial sector grapples with issues such as limited cybersecurity awareness, technological constraints, and evolving regulatory frameworks. Despite these disparities, both countries share the",1
a2fe496b4db6c3baf093463f2af7c5c3bdf9c0c5,The Significance of Machine Learning and Deep Learning Techniques in Cybersecurity: A Comprehensive Review,"People in the modern era spend most of their lives in virtual environments that offer a range of public and private services and social platforms. Therefore, these environments need to be protected from cyber attackers that can steal data or disrupt systems. Cybersecurity refers to a collection of technical, organizational, and executive means for preventing the unauthorized use or misuse of electronic information and communication systems to ensure the continuity of their work, guarantee the confidentiality and privacy of personal data, and protect consumers from threats and intrusions. Accordingly, this article explores the cybersecurity practices that protect computer systems from attacks, hacking, and data thefts and investigates the role of artificial intelligence in this domain. This article also summarizes the most significant literature that explore the roles and effects of machine learning and deep learning techniques in cybersecurity. Results show that machine learning and deep learning techniques play significant roles",9
ad98eed098edbc93040f9eb3054a1cd7f4b95795,The elephant in the room: cybersecurity in healthcare,"Cybersecurity has seen an increasing frequency and impact of cyberattacks and exposure of Protected Health Information (PHI). The uptake of an Electronic Medical Record (EMR), the exponential adoption of Internet of Things (IoT) devices, and the impact of the COVID-19 pandemic has increased the threat surface presented for cyberattack by the healthcare sector. Within healthcare generally and, more specifically, within anaesthesia and Intensive Care, there has been an explosion in wired and wireless devices used daily in the care of almost every patient—the Internet of Medical Things (IoMT); ventilators, anaesthetic machines, infusion pumps, pacing devices, organ support and a plethora of monitoring modalities. All of these devices, once connected to a hospital network, present another opportunity for a malevolent party to access the hospital systems, either to gain PHI for financial, political or other gain or to attack the systems directly to cause erroneous monitoring, altered settings of any device",0
4d39e473e298765ef0f11dcccd204ac0c2ee8ad5,Cybersecurity Risk Analysis of Electric Vehicles Charging Stations,"The increasing availability of Electric Vehicles (EVs) is driving a shift away from traditional gasoline-powered vehicles. Subsequently, the demand for Electric Vehicle Charging Systems (EVCS) is rising, leading to the significant growth of EVCS as public and private charging infrastructure. The cybersecurity-related risks in EVCS have significantly increased due to the growing network of EVCS. In this context, this paper presents a cybersecurity risk analysis of the network of EVCS. Firstly, the recent advancements in the EVCS network, recent EV adaptation trends, and charging use cases are described as a background of the research area. Secondly, cybersecurity aspects in EVCS have been presented considering infrastructure and protocol-centric vulnerabilities with possible cyber-attack scenarios. Thirdly, threats in EVCS have been validated with real-time data-centric analysis of EV charging sessions. The paper also highlights potential open research issues in EV cyber research as new knowledge for domain researchers and practitioners.",2
947f081d87410c3462e4013878663afbe21c929a,Mitigating Sinkhole attack in RPL based Internet of Things Environment using Optimized K means Clustering technique,"Internet of Things connects objects seamlessly for various applications viz., smart healthcare, industries, farming and many more. In an Internet of Things environment, various standards and protocols have been used to connect applications. Routing protocol for low power and lossy network is one such protocol used to connect devices for data transmission. As these protocols have been used, it is essential to preserve the security and privacy of the users. This paper proposes a secure routing protocol for low power and lossy network using an optimized k means clustering technique. Initially, every node calculates the sequence number variance, route presence ratio and transited routing messages for itself. Then optimized k means clustering technique has been used to cluster the nodes into normal and malicious. The nodes designated as abnormal are eliminated from the network. The proposed technique is simulated and performance analysis is carried out on performance metrics viz., packet",2
7625289aa5efe48d67ed559d25ffed69111afc88,Light gradient boosting machine with optimized hyperparameters for identification of malicious access in IoT network,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
377ccff6dc127cc2dbccf35cfcf70c3b6b3eb9ec,Premier Wallet: banking the unbanked population in Somalia,"Learning outcomes Upon reading, analyzing and participating in the classroom discussion of this case study, students will be able to use the blue ocean strategy (mainly the Strategy Canvas tool) to analyze how companies establish their products as viable and the go-to solution for consumers; perform a competitive analysis for competitive products; learn how to use data from the case, including industry trends, to predict the future market position of products; and learn how to develop strategies for new products in the market. Case overview/synopsis Abdishakur M. Afrah, who served as the Head of Business Development at Premier Bank, oversaw a substantial banking portfolio, which included Premier Wallet – the first digital wallet in Somalia. This case study outlines Premier Wallet’s journey and its transformative impact on the banking sector. Owing to the mobile wallet, consumers could, for the first time, engage in purchasing, withdrawing cash, shopping online and topping",5
88cf9400046e0467ee55837ba3bbc26285dc27d2,A systematic review of passenger profiling in airport security system: Taking a potential case study of CAPPS II,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
ea0fae16132710121c168c34f147259d6851a36f,Internet of Things (IoT) Cybersecurity: Literature Review and IoT Cyber Risk Management,"Along with the growing threat of cyberattacks, cybersecurity has become one of the most important areas of the Internet of Things (IoT). The purpose of IoT cybersecurity is to reduce cybersecurity risk for organizations and users through the protection of IoT assets and privacy. New cybersecurity technologies and tools provide potential for better IoT security management. However, there is a lack of effective IoT cyber risk management frameworks for managers. This paper reviews IoT cybersecurity technologies and cyber risk management frameworks. Then, this paper presents a four-layer IoT cyber risk management framework. This paper also applies a linear programming method for the allocation of financial resources to multiple IoT cybersecurity projects. An illustration is provided as a proof of concept.",3
6d9e20d4c5025c58c464237d2d6cde22495a8b45,A framework to overcome challenges to the adoption of artificial intelligence in Indian Government Organizations,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
1b593a815ccee90b8bf76b3bfb1917bf597223ab,A survey on cyber threat intelligence sharing based on Blockchain,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
a36f3c7ef2ba3769fa9a5ad549740ab0a01a0cfa,Federated Learning and Blockchain: A Cross-Domain Convergence,"Gaining significant attention within decentralized contexts, Federated Learning (FL) has been positioned as a highly desirable method for machine learning. By enabling multiple entities to train a shared model cooperatively, data privacy and security are preserved by Federated Learning. Harnessing inherent transparency and accountability of blockchain technology to trace and authenticate updates effectively in federated learning has transpired as an up-and-coming avenue to tackle data challenges related to confidentiality, protection, and reliability. This study examines the viability of federated learning and blockchain integration across multiple dimensions. The technological components of this integration., including incentive systems, consensus mechanisms, data validation, and smart contracts, are delved into. In the study, a novel proposed model for federated learning integrated with blockchain is designed and implemented. It is observed that the mean cypher size is 100 bytes for varying values of gradients. The average throughput recorded is 1.7 bytes per second, while the mean",1
2282d297e618510fdc58e3ecef65c6e2c1c3a0ab,A Thorough Examination of Smart City Applications: Exploring Challenges and Solutions Throughout the Life Cycle with Emphasis on Safeguarding Citizen Privacy,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
68acc57cbbc5df96deb1a243e5b355db59ceee62,In-Vehicle Communication Cyber Security: Challenges and Solutions,"In-vehicle communication has become an integral part of today’s driving environment considering the growing add-ons of sensor-centric communication and computing devices inside a vehicle for a range of purposes including vehicle monitoring, physical wiring reduction, and driving efficiency. However, related literature on cyber security for in-vehicle communication systems is still lacking potential dedicated solutions for in-vehicle cyber risks. Existing solutions are mainly relying on protocol-specific security techniques and lacking an overall security framework for in-vehicle communication. In this context, this paper critically explores the literature on cyber security for in-vehicle communication focusing on technical architecture, methodologies, challenges, and possible solutions. In-vehicle communication network architecture is presented considering key components, interfaces, and related technologies. The protocols for in-vehicle communication have been classified based on their characteristics, and usage type. Security solutions for in-vehicle communication have been critically reviewed considering machine learning, cryptography, and port-centric techniques. A multi-layer secure framework is also",3
7b85a5c5c7586c2fd9228fa5255e8e8b075e3f97,Using Digital Twin to Detect Cyber-Attacks in Industrial Control Systems,"The digital transition is largely impacting industrial control systems. The integration of information and communication technologies in industrial control systems on the one hand is improving the related functionalities, on the other hand is increasing the related vulnerabilities and the attack surfaces of industrial systems. This results in the non-negligible need for protection of the operational and production processes. Although many tools are available from the Information Technology sector, these are currently not appropriate to guarantee confidentiality, integrity, and availability in the industrial domain. As a consequence, it is crucial to investigate the proper strategies and methodologies to guarantee the protection of industrial control systems. In this context, this paper aims at defining a novel tool for the detection of cyber-attacks in industrial control systems, which is based on the implementation of a virtual model for both the physical and the control layers to detect attacks. In fact, the majority",3
67c5932e303a63adb37e71e4fb3698a9529b0a5c,The Distinction between R-CNN and Fast R-CNN in Image Analysis: A Performance Comparison,"Deep learning techniques have become vital in many fields in the modern era because they are excellent at analysing and predicting real big data to act in different situations. Although it is marvellous in many aspects, it is prone to misinterpretation of data, so teams of experienced specialists cannot be dispensed with in following up on the execution stages of data analysis. Convolutional Neural Network is one of the most significant deep learning techniques. It is widely employed in visual image analysis. In this article, R-CNN and Fast R-CNN are summarised and compared and are the best in image analysis. This article concluded that the most suitable performance is for Fast R-CNN in testing and training.",5
8822357efe500caded16e603d21239be3a39547c,ChatGPT: The End of Online Exam Integrity?,"This study evaluated the ability of ChatGPT, a recently developed artificial intelligence (AI) agent, to perform high-level cognitive tasks and produce text that is indistinguishable from human-generated text. This capacity raises concerns about the potential use of ChatGPT as a tool for academic misconduct in online exams. The study found that ChatGPT is capable of exhibiting critical thinking skills and generating highly realistic text with minimal input, making it a potential threat to the integrity of online exams, particularly in tertiary education settings where such exams are becoming more prevalent. Returning to invigilated and oral exams could form part of the solution, while using advanced proctoring techniques and AI-text output detectors may be effective in addressing this issue, they are not likely to be foolproof solutions. Further research is needed to fully understand the implications of large language models like ChatGPT and to devise strategies for combating the risk of",6
2d1b5db1ea16383bd85eb2de0afd5161de7b1b2d,Cyber resilience and cyber security issues of intelligent cloud computing systems,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
928fa44848bb6ef2b483c254b4f5185c935c4345,A comprehensive survey of AI-enabled phishing attacks detection techniques,"In recent times, a phishing attack has become one of the most prominent attacks faced by internet users, governments, and service-providing organizations. In a phishing attack, the attacker(s) collects the client’s sensitive data (i.e., user account login details, credit/debit card numbers, etc.) by using spoofed emails or fake websites. Phishing websites are common entry points of online social engineering attacks, including numerous frauds on the websites. In such types of attacks, the attacker(s) create website pages by copying the behavior of legitimate websites and sends URL(s) to the targeted victims through spam messages, texts, or social networking. To provide a thorough understanding of phishing attack(s), this paper provides a literature review of Artificial Intelligence (AI) techniques: Machine Learning, Deep Learning, Hybrid Learning, and Scenario-based techniques for phishing attack detection. This paper also presents the comparison of different studies detecting the phishing attack for each AI technique and examines the qualities",5
03a9b1456b21a61ab0429ea5896fffad6a6646ea,Security Vulnerability Analysis using Penetration Testing Execution Standard (PTES): Case Study of Government's Website,"The rapid development of technology has impacted various aspects of life, including the way individuals, organizations, and governments deliver accurate, effective, and efficient information. XYZ local government, which is responsible for serving the community in the trade field, manages its information through the Communication and Information Agency (Diskominfo) of the XYZ region. Diskominfo employs technological advancements to provide the people of the XYZ region with direct access to accurate, precise, and reliable data through their website. However, the security of the website has become a crucial aspect to prevent attacks from malicious individuals that can cause damage to the system and harm the website owner. To analyze the website's security loopholes and vulnerabilities, the author performed a simulation of an attacker. The analysis aimed to evaluate the level of risk and confidence in the website. The results showed 42 alerts categorized into four risk levels: 9 vulnerabilities with a high-risk",4
ffa13df31597b8952af56a2a1bea719726422724,ChatGpt: Open Possibilities,"ChatGPT-3 is a powerful language model developed by OpenAI that has the potential to revolutionize the way we interact with technology. This model has been trained on a massive amount of data, allowing it to understand and generate human-like text with remarkable accuracy. One of the most exciting possibilities of ChatGPT-3 is its potential to improve natural language processing (NLP) and natural language understanding (NLU) in a wide range of applications. In particular, ChatGPT-3 can be used to power chatbots, virtual assistants, and other conversational interfaces. These types of systems are becoming increasingly important as more and more people use voice and text to interact with technology, we list ChatGpt role in each of the follwoing sections[1].",6
1eb5770253bfbe119499eea033981d1b188532a5,AttacKG+: Boosting attack graph construction with Large Language Models,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
978f023037d72aefac75cc01a7d37d7f65baa67a,Optimisation of artificial intelligence models and response surface methodology for predicting viscosity and relative viscosity of GNP-alumina hybrid nanofluid: incorporating the effects of mixing ratio and temperature,"The viscosity properties of GNP-alumina hybrid nanofluids are of significant importance in various engineering applications. This study compares the predictive performance of response surface methodology (RSM), artificial neural network (ANN), and adaptive neuro-fuzzy inference system (ANFIS) for the viscosity (µrel) and relative viscosity (µrel) of GNP-alumina hybrid nanofluid at varying mixing ratio (0–3) and temperature (15–55 °C). The ANN and ANFIS models were optimised by varying the number and type of neurons and membership functions (MFs), respectively. In contrast, the RSM model was optimised by varying the source model. The efficacy of the models was assessed using various measures of performance metrics, including residual sum of squares, root mean square error, mean absolute error, and mean absolute percentage error (MAPE). The ANN architecture with 4 neurons exhibited exceptional proficiency in forecasting the µnf, achieving an R2 value of 0.9997 and a MAPE of 0.3100. Meanwhile, the best ANN architecture for",4
d1e9001b61a771a9f7abe0796d0fb41a18cc9803,Resilient Detection of Cyber Attacks in Industrial Devices,"With the advent of smartphones, laptops, and home computers, smart systems are becoming more and more flexible. As the use of internet increases, there will be more cyber threats occurring on most third-party connectivity websites. The powerful technique used to detect the threats present in the IoT applications are discussed in the proposed system. Based on the KAGGLE NIDS(Network Intrusion Detection System)(Intrusion Detection System) dataset, the number of possible attacks is calculated in the proposed architecture. A similar occurrence of intrusion creating a task is detected by the system, triggering the model to prevent the intrusion by notifying the user immediately. The existing attack detection systems have a number of limitations which includes the need of human intervention to detect the attacks encountered, slower detection rate and inaccuracy in detection. An advanced deep learning algorithm is proposed for detecting possible intrusions to overcome these limitations. The proposed design focuses on",4
48bc8067d5f6698b9d23ecf0562f0fde7290ce15,Assessing AI-Powered Patient Education: A Case Study in Radiology.,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
d6c17007dd21be4eebaed4d5fee9a2bf1a8ccefe,Sustainable IT practices in Nigerian banking: Environmental perspectives review,"This review paper aims to critically analyze sustainable information technology (IT) practices in the Nigerian banking sector, focusing on environmental perspectives. The primary objective is to identify and evaluate the extent to which Nigerian banks have integrated sustainable IT practices and the impact of these practices on environmental sustainability. The methodology involves a comprehensive review of existing literature, including academic journals, industry reports, and case studies, to gather insights into the current state of sustainable IT in Nigerian banking. Key findings reveal that while some Nigerian banks have begun to adopt green IT initiatives, such as paperless operations, energy-efficient data centers, and electronic banking services, the overall adoption rate is relatively low compared to global standards. The study identifies barriers to adoption, including lack of awareness, limited regulatory frameworks, and inadequate infrastructure. Despite these challenges, the paper highlights the potential benefits of sustainable IT practices, such as reduced carbon footprint,",5
651619d57e890359cf020f982af6ce1f4bcb8b86,Is Generative AI the Next Tactical Cyber Weapon For Threat Actors? Unforeseen Implications of AI Generated Cyber Attacks,"In an era where digital threats are increasingly sophisticated, the intersection of Artificial Intelligence and cybersecurity presents both promising defenses and potent dangers. This paper delves into the escalating threat posed by the misuse of AI, specifically through the use of Large Language Models (LLMs). This study details various techniques like the switch method and character play method, which can be exploited by cybercriminals to generate and automate cyber attacks. Through a series of controlled experiments, the paper demonstrates how these models can be manipulated to bypass ethical and privacy safeguards to effectively generate cyber attacks such as social engineering, malicious code, payload generation, and spyware. By testing these AI generated attacks on live systems, the study assesses their effectiveness and the vulnerabilities they exploit, offering a practical perspective on the risks AI poses to critical infrastructure. We also introduce Occupy AI, a customized, finetuned LLM specifically engineered to automate",6
dc6b44f07b34c6260c885206b6840fc4b0d84b0b,"Technological innovations in mitigating winter health challenges in New York City, USA","This review paper examines the role of technological innovations in mitigating winter health challenges in New York City (NYC). The primary objective is to analyze how emerging technologies are integrated into public health strategies to address the unique health risks posed by the winter season in one of the world's most populous urban environments. The methodology involves a comprehensive literature review focusing on recent advancements in technology within the context of public health and urban planning. Key sources include peer-reviewed articles, case studies, and reports on smart city initiatives, climate change impacts, and the implementation of health technologies in NYC. Key findings reveal that the integration of smart city technologies, such as advanced data analytics, IoT devices, and AI-driven solutions, has significantly improved healthcare delivery and emergency response during winter. However, challenges in implementation, particularly in under-resourced settings, highlight the need for tailored, context-driven technological solutions. The impact of climate",1
4d58325ceeeb5cdbc4638dccad53a96d558c04f6,PhishAgent: A Robust Multimodal Agent for Phishing Webpage Detection,"Phishing attacks are a major threat to online security, exploiting user vulnerabilities to steal sensitive information. Various methods have been developed to counteract phishing, each with varying levels of accuracy, but they also face notable limitations. In this study, we introduce PhishAgent, a multimodal agent that combines a wide range of tools, integrating both online and offline knowledge bases with Multimodal Large Language Models (MLLMs). This combination leads to broader brand coverage, which enhances brand recognition and recall. Furthermore, we propose a multimodal information retrieval framework designed to extract the relevant top k items from offline knowledge bases, using available information from a webpage, including logos and HTML. Our empirical results, based on three real-world datasets, demonstrate that the proposed framework significantly enhances detection accuracy and reduces both false positives and false negatives, while maintaining model efficiency. Additionally, PhishAgent shows strong resilience against various types of adversarial attacks.",5
e18fa403f20d2b7d1320a9e2bb486ef03982e5fe,Extracting Information about Security Vulnerabilities from Web Text,"The Web is an important source of information about computer security threats, vulnerabilities and cyber attacks. We present initial work on developing a framework to detect and extract information about vulnerabilities and attacks from Web text. Our prototype system uses Wikitology, a general purpose knowledge base derived from Wikipedia, to extract concepts that describe specific vulnerabilities and attacks, map them to related concepts from DBpedia and generate machine understandable assertions. Such a framework will be useful in adding structure to already existing vulnerability descriptions as well as detecting new ones. We evaluate our approach against vulnerability descriptions from the National Vulnerability Database. Our results suggest that it can be useful in monitoring streams of text from social media or chat rooms to identify potential new attacks and vulnerabilities or to collect data on the spread and volume of existing ones.",6
e63eb4d4507bfc806dce6425ee9954d383bf6a14,"Comparative analysis of Internet of Things (IOT) implementation: A case study of Ghana and the USA - vision, architectural elements, and future directions","This paper presents a comprehensive comparative analysis of the Internet of Things (IoT) implementation in Ghana and the USA, focusing on their respective visions, architectural elements, and future directions. The study begins with an introduction to IoT's significance in modern society, followed by a detailed methodology outlining the research design, data collection methods, and criteria for comparative analysis. The findings reveal distinct approaches to IoT implementation in Ghana and the USA, reflecting varying levels of technological infrastructure, economic impact, and societal influence. The analysis delves into the comparative aspects of IoT vision, including strategic goals and technological advancements, and examines the architectural elements such as hardware, software, network solutions, and data management. The paper also addresses the challenges and barriers in IoT implementation, highlighting technical, policy, and economic constraints. Furthermore, it explores emerging trends, opportunities, and recommendations for future IoT development, providing final thoughts on the trajectories of IoT in",2
295494acf46f94bb55c43523936e75a90471af47,Performance Analysis of Secure MQTT Communication Protocol,"Nowadays the growth of IoT is rapid and the MQTT protocol has become widely used in IoT communication. MQTT protocol does not come with strong security features except the username and password authentication. However, without TLS, the username and password are not good enough to secure communication. Therefore, the security and efficiency of MQTT protocol are the core basic issue. This paper discusses a method to secure the MQTT protocol via TLS and analysis of the performance. Using TLS in MQTT will encrypt the message transported from MQTT client to the server. The packet was analyzed using Wireshark, it showed that applying TLS into MQTT will encrypt the message in the network traffic. In a nutshell, security in MQTT protocol is important as MQTT has become a de facto standard for IoT.",2
c0f3072aeab373fd64c98126afe1b3964ed3438d,Chatbots in a Honeypot World,"Question-and-answer agents like ChatGPT offer a novel tool for use as a potential honeypot interface in cyber security. By imitating Linux, Mac, and Windows terminal commands and providing an interface for TeamViewer, nmap, and ping, it is possible to create a dynamic environment that can adapt to the actions of attackers and provide insight into their tactics, techniques, and procedures (TTPs). The paper illustrates ten diverse tasks that a conversational agent or large language model might answer appropriately to the effects of command-line attacker. The original result features feasibility studies for ten model tasks meant for defensive teams to mimic expected honeypot interfaces with minimal risks. Ultimately, the usefulness outside of forensic activities stems from whether the dynamic honeypot can extend the time-to-conquer or otherwise delay attacker timelines short of reaching key network assets like databases or confidential information. While ongoing maintenance and monitoring may be required, ChatGPT's ability to",4
d038b775fd47f3d16a056ae4361f0c98e67c8e15,MapReduce based intelligent model for intrusion detection using machine learning technique,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
1ce3257e98d86d36a5073ce4ec232a1b74d543e7,Improving employees’ intellectual capacity for cybersecurity through evidence-based malware training,"An organization’s ability to successfully manage intellectual capital is determined by the actions of its employees to prevent or minimize information security incidents. To prevent more data breaches to intellectual capital, organizations must provide regular cybersecurity awareness training for all personnel. The purpose of this paper is to investigate the effect of different evidence-based cybersecurity training methods on employees’ cybersecurity risk perception and self-reported behavior.,The study participants were randomly assigned into four groups (i.e. malware report, malware videos, both malware report and malware videos and no interventions) to assess the effects of cybersecurity training on their perceptions of vulnerability, severity, self-efficacy, security intention as well as their self-reported cybersecurity behaviors.,The results show that evidence-based malware report is a relatively better training method in affecting employees’ intentions of engaging in recommended cybersecurity behaviors comparing with the other training methods used in this study. A closer analysis suggests whether the training method",4
0d4a41c12eb1d104f4e5794295d0a4bfb2c780ea,POLICIES AND STRATEGIES AIMED AT ENSURING THE SECURITY OF BANKING INSTITUTIONS AND THEIR IT SYSTEMS,"With the development of the banking system, its security and, implicitly,security polic ies emerged as cr itical factors in the entire banking s ector . In the context of thecurrent technological development, the vulnerability of banking institutions has increaseddramatically . For both bank employee s and customer s , cybersecurity, operational securityand data privacy have become top priorities. Th erefore , a central concern for banks is theprompt detection of threats and the development of measures aimed ateliminat ing such dangers , which might both considerably increas e the level of security in thebanking sector.",4
f237312a67601a8965adb9f5580e5602653c249d,A review of explainable artificial intelligence in supply chain management using neurosymbolic approaches,"Artificial Intelligence (AI) has emerged as a complementary technology in supply chain research. However, the majority of AI approaches explored in this context afford little to no explainability, which is a significant barrier to a broader adoption of AI in supply chains. In recent years, the need for explainability has been a strong impetus for research in hybrid AI methodologies that combine neural architectures with logic-based reasoning, which are collectively referred to as Neurosymbolic AI. The aim of this paper is to provide a comprehensive overview of supply chain management literature that employs approaches within the neurosymbolic AI spectrum. To that end, a systematic review is conducted, followed by bibliometric, descriptive and thematic analyses on the identified studies. Our findings indicate that researchers have primarily focused on the limited subset of neurofuzzy approaches, while some supply chain applications, such as performance evaluation and sustainability, and sectors such as pharmaceutical and",4
86c10e08b8f1e848ddb6b5f59f7dae061e7e8bd9,"Ethical considerations in implementing generative AI for healthcare supply chain optimization: A cross-country analysis across India, the United Kingdom, and the United States of America","This review paper critically examines the ethical considerations involved in implementing generative Artificial Intelligence (AI) in healthcare supply chain optimization across three distinct regions: India, the United Kingdom, and the United States of America. The study synthesizes findings from various case studies and academic research to highlight both common and unique ethical challenges faced in these countries. Key themes such as data privacy, algorithmic transparency, and equitable access to AI-driven healthcare solutions are explored, alongside the unique socio-cultural, legal, and regulatory challenges specific to each region. The paper proposes a set of best practices for incorporating ethical considerations into the deployment of generative AI in healthcare. These include the development of inclusive ethical frameworks, regular ethical audits, comprehensive training and education programs, public engagement initiatives, and interdisciplinary collaboration. The paper also delves into future research directions and policy development, emphasizing the need to address healthcare disparities, adapt legal and regulatory",4
7a81369d06b9c2bcbed102f61146793631eed547,A New AI-Based Semantic Cyber Intelligence Agent,"The surge in cybercrime has emerged as a pressing concern in contemporary society due to its far-reaching financial, social, and psychological repercussions on individuals. Beyond inflicting monetary losses, cyber-attacks exert adverse effects on the social fabric and psychological well-being of the affected individuals. In order to mitigate the deleterious consequences of cyber threats, adoption of an intelligent agent-based solution to enhance the speed and comprehensiveness of cyber intelligence is advocated. In this paper, a novel cyber intelligence solution is proposed, employing four semantic agents that interact autonomously to acquire crucial cyber intelligence pertaining to any given country. The solution leverages a combination of techniques, including a convolutional neural network (CNN), sentiment analysis, exponential smoothing, latent Dirichlet allocation (LDA), term frequency-inverse document frequency (TF-IDF), Porter stemming, and others, to analyse data from both social media and web sources. The proposed method underwent evaluation from 13 October 2022 to 6 April 2023,",2
48982c1f8d8ff4e64eeac4dc6f0adb6c0580727e,Machine Learning and Data Mining Methods for Cyber Security: A Survey,"Data mining and machine learning (ML) methods are used more than ever in cyber security. The use of machine learning (ML) is one of the potential solutions that may be successful against zero-day attacks, starting with categorising IP traffic and filtering harmful traffic for intrusion detection. In this field, certain published systematic reviews were taken into consideration. Recent systematic reviews may incorporate older and more recent works in the topic of investigation.. Both security professionals and hackers use data mining capabilities. Applications for data mining may be used to analyze programme activity, surfing patterns, and other factors to identify potential cyber-attacks in the future. The new study uses statistical traffic features, ML, and data mining approaches. This research performs a concentrated literature review on machine learning and its usage in cyber analytics for email filtering, traffic categorization, and intrusion detection. Each approach was identified, and a summary was provided based",5
1931f3236ebdab94a05f7c7ef6c8c87edf8b5618,Industry 4.0 technologies: Implementation patterns in manufacturing companies,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
cb6ba09d94fca9b425c6358343c9475635e02414,Status of electric vehicles charging methods,"Compared with vehicles powered by fuel, electric vehicles are more efficient in energy saving, emission reduction, and environmental protection. As a result, it is becoming most important with more applications in the transportation sector. As Electric vehicles usage is growing from day to day Electric vehicles (EVs) will become a reality in the future. The time taking the method of charging an EV becomes a major problem to accept the electronic revolution of the automobile industry. In this paper, we have discussed the various charging methods for an Electric vehicle, which also gives us a view of electric vehicle use in today’s world. It gives a brief overview of the present and methods recommended for EV charging.",4
366106261d032127798e1cf476a660680c73c983,Navigating the Eisenhower Interstate System: Paving the way for cyberspace,"This project discerns an early cybernetic paradigm for the internet in the worldwide movement towards uninterrupted motor travel that developed in the first half of the twentieth century. Freeway designers, especially in Germany and the United States, pursued utopias of control over nature, independence from the topography of a particular locale and unrestricted transportation on a national scale. As a physical analogue of the digital landscape that would follow it, the execution of the Eisenhower Interstate System prioritized modern technological values in real space that went on to guide the design of virtual space. Moreover, in recent years physical and virtual transportation networks have become even more closely linked through location-based social navigation technologies such as Waze and Google Maps. Located at the intersection, or rather at the interchange, of media ecology and urban communication, this project seeks to illuminate the utopias of design that guide real and virtual space",5
56edaa1368ff4dfa45388e4be24fdfbded7d88a7,A Primer on Neural Network Models for Natural Language Processing,"Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.",3
bca75f991da798044e12a5c871354c0ab86f5ff3,AI SENTRY: REINVENTING CYBERSECURITY THROUGH INTELLIGENT THREAT DETECTION,"In recent years, the escalating complexity and frequency of cyber threats have presented a formidable challenge to traditional cybersecurity measures. The emergence of artificial intelligence (AI) technologies has revolutionized the landscape, offering a promising solution to fortify defenses against evolving threats. This paper introduces AI Sentry, an innovative approach to cybersecurity that leverages the power of AI for intelligent threat detection and prevention. AI Sentry embodies a paradigm shift in cybersecurity, integrating machine learning, neural networks, and advanced algorithms to proactively identify, analyze, and mitigate potential threats in real time. By continuously learning from vast datasets and adapting to new attack vectors, AI Sentry enhances its ability to recognize anomalous patterns and behaviors, thereby thwarting sophisticated cyber assaults. The core strength of AI Sentry lies in its capability to detect anomalies and predict threats with a high degree of accuracy, surpassing the limitations of traditional signature-based systems. Through anomaly detection,",3
522d082fe688b22847bee08291e0f0372bd78df4,"Load Balancing Approaches in Cloud and Fog Computing Environments: A Framework, Classification, and Systematic Review","Cloud and fog computing are modern technologies that handle multiple dynamic user requests. Cloud provides demand-based services to users over the internet on pay-as-you-go basis. Fog handles real-time requests that are received from smart devices. Millions of requests arrive at the cloud-fog layer, often leading to overloaded virtual machines (VMs). Load balancing (LB) is an important issue for cloud-fog systems and has been proved to be an NP-hard problem. It is essential as it distributes the load equally among VMs to properly utilize resources and improve quality of service (QoS). Therefore, this paper presents a complete classification of LB algorithms and also a comprehensive study using heuristic, meta-heuristic, and hybrid approaches in cloud and fog computing environments. The main goal of this paper is to highlight the importance of LB to overcome the challenges of the systems. This study reviews papers of the last seven years and systematically discusses them",2
a84c8b01ac151295c1c8eeb88e27715f591fda86,Ensemble Machine Learning Techniques for Accurate and Efficient Detection of Botnet Attacks in Connected Computers,"The transmission of information, ideas, and thoughts requires communication, which is a crucial component of human contact. The utilization of Internet of Things (IoT) devices is a result of the advent of enormous volumes of messages delivered over the internet. The IoT botnet assault, which attempts to perform genuine, lucrative, and effective cybercrimes, is one of the most critical IoT dangers. To identify and prevent botnet assaults on connected computers, this study uses both quantitative and qualitative approaches. This study employs three basic machine learning (ML) techniques—random forest (RF), decision tree (DT), and generalized linear model (GLM)—and a stacking ensemble model to detect botnets in computer network traffic. The results reveled that random forest attained the best performance with a coefficient of determination (R2) of 0.9977, followed by decision tree with an R2 of 0.9882, while GLM was the worst among the basic machine learning models with an R2 of",3
0893549771094fac547432cb4f84e9605c911a86,The imperative for regulatory oversight of large language models (or generative AI) in healthcare,"The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images",4
7699d50391d9f26a8bdfa2421ccd1e1abaf4bdbc,SUSTAINABLE CITIES AND PRECARIOUS HOUSING: THE CASE OF ALGERIA,"After its experience with the Millennium Development Goals program, Algeria is committed to achieving the Sustainable Development Goals (SDGs) by 2030. This is to develop and improve its regions and cities that suffer from several problems, including the persisting proliferation of precarious housing. The government has set up a national development strategy and implemented it through a policy based on the reconciliation of the three pillars of sustainable development to ensure sustainable cities and regions. Through a review of government policy instruments and their deliverables, this paper explores the extent of success of the policies. It investigates the relationship between sustainable cities and precarious housing by means of an analysis of the measures taken to incorporate the concept of sustainable development into urban planning policies to achieve the SDGs by 2030. Finally, it suggests the need to include communities in any urban planning policy implementation.",4
3179e9d4cab937383eac23dc21e6d4b7012fd923,An improved trust-based security framework for internet of things,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
9c5726e96a269bb2c72491b23c6619a8f2788b65,Impact of AI in Financial Technology- A Comprehensive Study and Analysis,"Presently across the world, financial institutions strive tremendously hard to make financial services smarter to benefit from the advantages of digitization. To enhance client services, financial technology (Fintech) uses a variety of modern breakthrough technologies, including Artificial Intelligence (AI), 5G/6G, Blockchain, Metaverse, IoT, and others, in the financial sector. Many important financial services and procedures, including loans, authentication, fraud detection, quality control, creditworthiness, and several more, would be streamlined and improved by the adoption of technology. However, a need exists for the development of innovative financial products as well as the corresponding technological ecosystem. To launch Information and Communication Technology (ICT) alternatives, various major tech companies have placed their emphasis on Fintech. In this paper, we first explore the latest opportunities in Fintech. Furthermore, we also attempt to present a foundation of the Fintech accelerators, such as IoT, 5G, Digital twins, and Metaverse. Additionally, we also outline recommendations for future",2
91504b58ebd7ee7b04ab88c0486273e620e49939,Characterization of threats in IoT from an MQTT protocol-oriented dataset,"Nowadays, the cybersecurity of Internet of Thing (IoT) environments is a big challenge. The analysis of network traffic and the use of automated estimators built up with machine learning techniques have been useful in detecting intrusions in traditional networks. Since the IoT networks require new and particular protocols to control the communications between the different devices involved in the networks, the knowledge acquired in the study of general networks may be unuseful some times. The goal of this paper is twofold. On the one hand, we aim to obtain a consistent dataset of the network traffic of an IoT system based on the Message Queue Telemetry Transport protocol (MQTT) and undergoing certain type of attacks. On the other hand, we want to characterize each of these attacks in terms of the minimum possible number of significant variables allowed by this protocol. Obtaining the data set has been achieved by studying",2
71babeb9cd0eecc38aa58863d4d9042630af3839,"Advanced Persistent Threats (APT): evolution, anatomy, attribution and countermeasures","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
cbf8fcfaf98affd6e7743a8ee369d8cf3a8811cc,Outside the Comfort Zone: Analysing LLM Capabilities in Software Vulnerability Detection,"The significant increase in software production driven by automation and faster development lifecycles has resulted in a corresponding surge in software vulnerabilities. In parallel, the evolving landscape of software vulnerability detection, highlighting the shift from traditional methods to machine learning and large language models (LLMs), provides massive opportunities at the cost of resource-demanding computations. This paper thoroughly analyses LLMs' capabilities in detecting vulnerabilities within source code by testing models beyond their usual applications to study their potential in cybersecurity tasks. We evaluate the performance of six open-source models that are specifically trained for vulnerability detection against six general-purpose LLMs, three of which were further fine-tuned on a dataset that we compiled. Our dataset, alongside five state-of-the-art benchmark datasets, were used to create a pipeline to leverage a binary classification task, namely classifying code into vulnerable and non-vulnerable. The findings highlight significant variations in classification accuracy across benchmarks, revealing the critical",3
45cdc6205a088ad1c5b5907eb929b1458957baa9,Integrated Risk Management and Artificial Intelligence in Hospital,"The topic revolves around the integration of Artificial Intelligence (AI) in Hospital Integrated Risk Management (IRM). AI offers significant advantages in enhancing risk identification, assessment, and mitigation across various areas of hospital operations. It can contribute to patient safety by enabling early detection of critical conditions, improving clinical risk management, and enhancing decisionmaking processes. AI also plays a vital role in information security and privacy, operational risk management, regulatory compliance, and human resources in hospitals. However, the use of AI in Hospital IRM comes with certain disadvantages and risks that need to be mitigated. These include data quality and bias, interpretability and transparency challenges, privacy and security concerns, reduced human oversight, ethical considerations, and implementation challenges. Mitigating these risks requires robust data governance, addressing bias in AI algorithms, ensuring transparency and accountability, implementing strong cybersecurity measures, and upholding ethical guidelines. To achieve successful implementation, hospitals should prioritize employee competencies, such",7
efe6c7f2aa2e05d4e97cdcbf94b80f885e4d62fa,A modified secure hash design to circumvent collision and length extension attacks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
14ec57108a3ed7a1e21240ff05f74b75b86a889b,How Do Organizations Seek Cyber Assurance? Investigations on the Adoption of the Common Criteria and Beyond,"Cyber assurance, which is the ability to operate under the onslaught of cyber attacks and other unexpected events, is essential for organizations facing inundating security threats on a daily basis. Organizations usually employ multiple strategies to conduct risk management to achieve cyber assurance. Utilizing cybersecurity standards and certifications can provide guidance for vendors to design and manufacture secure Information and Communication Technology (ICT) products as well as provide a level of assurance of the security functionality of the products for consumers. Hence, employing security standards and certifications is an effective strategy for risk management and cyber assurance. In this work, we begin with investigating the adoption of cybersecurity standards and certifications by surveying 258 participants from organizations across various countries and sectors. Specifically, we identify adoption barriers of the Common Criteria through the designed questionnaire. Taking into account the seven identified adoption barriers, we show the recommendations for promoting cybersecurity",4
8f1a5a51c50b33af10348495bcecee98ccd30ac1,Attack Graph Model for Cyber-Physical Power Systems Using Hybrid Deep Learning,"Electrical power grids are vulnerable to cyber attacks, as seen in Ukraine in 2015 and 2016. However, existing attack detection methods are limited. Most of them are based on power system measurement anomalies that occur when an attack is successfully executed at the later stages of the cyber kill chain. In contrast, the attacks on the Ukrainian power grid show the importance of system-wide, early-stage attack detection through communication-based anomalies. Therefore, in this paper, we propose a novel method for online cyber attack situational awareness that enhances the power grid resilience. It supports power system operators in the identification and localization of active attack locations in Operational Technology (OT) networks in near real-time. The proposed method employs a hybrid deep learning model of Graph Convolutional Long Short-Term Memory (GC-LSTM) and a deep convolutional network for time series classification-based anomaly detection. It is implemented as a combination of software defined networking,",4
13ae33e86bdf07d04b3158a974b7404f4c8f78a0,"Phishing—A Cyber Fraud: The Types, Implications and Governance","Internet users are becoming ignorant with their data and the transparency of information due to the nature of high-speed internet today. Regrettably, internet users are deceived by engineering tactics performed by highly trained people, namely cybercriminals. Thus, in order to combat phishing attacks, internet users should be educated on security concerns, the influence of social engineering and anti-phishing knowledge. This paper presents a literature review of phishing, a type of cyber fraud, covering the types of phishing, the implications and governance. This study benefits the public to mitigate phishing attacks and increase phishing awareness.",3
51b97f34079acb1ca9edd151a357f18ee6a27b43,An AI-Driven VM Threat Prediction Model for Multi-Risks Analysis-Based Cloud Cybersecurity,"Cloud virtualization technology, ingrained with physical resource sharing, prompts cybersecurity threats on users’ virtual machines (VMs) due to the presence of inevitable vulnerabilities on the offsite servers. Contrary to the existing works which concentrated on reducing resource sharing and encryption/decryption of data before transfer for improving cybersecurity which raises computational cost overhead, the proposed model operates diversely for efficiently serving the same purpose. This article proposes a novel multiple risks analysis-based VM threat prediction model (MR-TPM) to secure computational data and minimize adversary breaches by proactively estimating the VMs threats. It considers multiple cybersecurity risk factors associated with the configuration and management of VMs, along with analysis of users’ behavior. All these threat factors are quantified for the generation of respective risk score values and fed as input into a machine learning-based classifier to estimate the probability of threat for each VM. The performance of MR-TPM is evaluated using benchmark",2
ff7f41eb9f118d80385253224aa9bd415a643dee,Detection of False Data Injection Attack using Machine Learning approach,"The ""False Data Injection"" (FDI) attack is one of the significant security risks that the deep neural Network is susceptible to. The purpose of the FDI attacks is to deceive industrial platforms by faking sensor readings. considered a few relevant systematic reviews that have been previously published. Recent systematic reviews may include both older and more recent works on the topic. Therefore, I restricted myself to recently published works. Specifically, we analyzed data from 2016-2021 for this work. Attacks using FDI have effectively beaten out traditional threat detection strategies. In this paper, we provide an innovative auto-encoder-based technique for FDI attack detection (AEs). use of the temporal and spatial correlation of sensor data, which may be used to spot fake data. Additionally, the fabricated data are denoised using AEs. Performance testing demonstrates that our method is effective in finding FDI attacks. Additionally, it performs much better than a similar technique",7
b169f2ce55e14584d2db6f64eeb5ad2702d39d40,"Artificial intelligence foundation and pre-trained models: Fundamentals, applications, opportunities, and social impacts","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
a2710ddfa0c7fb4b75b7294f3beeed74015616ba,Enforcing Resilience in Cyber-physical Systems via Equilibrium Verification at Runtime,"Cyber-physical systems often operate in dynamic environments where unexpected events should be managed while guaranteeing acceptable behavior. Providing comprehensive evidence of their dependability under change represents a major open challenge. In this article, we exploit the notion of equilibrium, that is, the ability of the system to maintain an acceptable behavior within its multidimensional viability zone and propose RUNE2 (RUNtime Equilibrium verification and Enforcement), an approach able to verify at runtime the equilibrium condition and to enforce the system to stay in its viability zone. RUNE2 includes (i) a system specification that takes into account the uncertainties related to partial knowledge and possible changes; (ii) the computation of the equilibrium condition to define the boundaries of the viability zone; (iii) a runtime equilibrium verification method that leverages Bayesian inference to reason about the ability of the system to remain viable; and (iv) a resilience enforcement mechanism that exploits the posterior",4
a2dbe6f50b26b251b4f6f9c0d9870074e47cac01,Towards detection of software supply chain attacks by forensic artifacts,"Third-party dependencies may introduce security risks to the software supply chain and hence yield harm to their dependent software. There are many known cases of malicious open source packages posing risks to developers and end users. However, while efforts are made to detect vulnerable open source packages, malicious packages are not yet considered explicitly. In order to tackle this problem we perform an exploratory case study on previously occurred attacks on the software supply chain with respect to observable artifacts created. Based on gained insights, we propose Buildwatch, a framework for dynamic analysis of software and its third-party dependencies. We noticed that malicious packages introduce a significant amount of new artifacts during installation when compared to benign versions of the same package. The paper presents a first analysis of observable artifacts of malicious packages as well as a possible mitigation strategy that might lead to more insight in long term.",3
da2b72f5222748557865d168130c620c2350c9f7,Financial Inclusion in Emerging Economies: The Application of Machine Learning and Artificial Intelligence in Credit Risk Assessment,"In banking and finance, credit risk is among the important topics because the process of issuing a loan requires a lot of attention to assessing the possibilities of getting the loaned money back. At the same time in emerging markets, the underbanked individuals cannot access traditional forms of collateral or identification that is required by financial institutions for them to be granted loans. Using the literature review approach through documentary and conceptual analysis to investigate the impact of machine learning and artificial intelligence in credit risk assessment, this study discovered that artificial intelligence and machine learning have a strong impact on credit risk assessments using alternative data sources such as public data to deal with the problems of information asymmetry, adverse selection, and moral hazard. This allows lenders to do serious credit risk analysis, to assess the behaviour of the customer, and subsequently to verify the ability of the clients",4
c4b240aad03b5bfbd4fde21cc9990a8530aa34e2,AI and machine learning: A mixed blessing for cybersecurity,"While the usage of Artificial Intelligence and Machine Learning Software (AI/MLS) in defensive cybersecurity has received considerable attention, there remains a noticeable research gap on their offensive use. This paper reviews the defensive usage of AI/MLS in cybersecurity and then presents a survey of its offensive use. Inspired by the System-Fault-Risk (SFR) framework, we categorize AI/MLS-powered cyberattacks by their actions into seven categories. We cover a wide spectrum of attack vectors, discuss their practical implications and provide some recommendations for future research.",3
f794eb4079bc5f6e15360d4d3fbecd3228f512b5,Recent Progress of Using Knowledge Graph for Cybersecurity,"In today’s dynamic complex cyber environments, Cyber Threat Intelligence (CTI) and the risk of cyberattacks are both increasing. This means that organizations need to have a strong understanding of both their internal CTI and their external CTI. The potential for cybersecurity knowledge graphs is evident in their ability to aggregate and represent knowledge about cyber threats, as well as their ability to manage and reason with that knowledge. While most existing research has focused on how to create a full knowledge graph, how to utilize the knowledge graph to tackle real-world industrial difficulties in cyberattack and defense situations is still unclear. In this article, we give a quick overview of the cybersecurity knowledge graph’s core concepts, schema, and building methodologies. We also give a relevant dataset review and open-source frameworks on the information extraction and knowledge creation job to aid future studies on cybersecurity knowledge graphs. We perform a comparative",5
40d3db2cc4284ad097ef84385693ba720c9d5f85,A Novel Data Encryption Algorithm To Ensure Database Security,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
59ba48329f228c216336b8853612a94a0823a91a,The evolution of ransomware attacks in light of recent cyber threats. How can geopolitical conflicts influence the cyber climate?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
c9cda4d7a549ddac99eb2b710d27c45f16f2382f,The Purpose of Cybersecurity Governance in the Digital Transformation of Public Services and Protecting the Digital Environment,"The process of digital transformation is considered one of the most influential matters in circulation at the present time, as it seeks to integrate computer-based technologies into the public services provided by companies or institutions. To achieve digital transformation, basics and points must be established, while relying on a set of employee skills and involving customers in developing this process. Today, all governments are seeking electronic transformation by converting all public services into digital, where changes in cybersecurity must be taken into account, which constitutes a large part of the priorities of nations and companies. The vulnerability to cyberspace, the development of technologies and devices, and the use of artificial intelligence in the growth of modern applications have led to the acceleration of the digital transformation process and the utilization of its services. To adopt straightforward programs and strategies to establish cybersecurity governance that can be trusted and practical in",8
a120a7e36dd47e24f62fe67f4770938bd071375c,Security prioritized multiple workflow allocation model under precedence constraints in cloud computing environment,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
ff3270fa5eefd970f11d95d53b98a69abb706b25,Internet of Things (IoT) Cybersecurity Research: A Review of Current Research Topics,"As an emerging technology, the Internet of Things (IoT) revolutionized the global network comprising of people, smart devices, intelligent objects, data, and information. The development of IoT is still in its infancy and many related issues need to be solved. IoT is a unified concept of embedding everything. IoT has a great chance to make the world a higher level of accessibility, integrity, availability, scalability, confidentiality, and interoperability. However, how to protect IoT is a challenging task. System security is the foundation for the development of IoT. This article systematically reviews IoT cybersecurity. The key considerations are the protection and integration of heterogeneous smart devices and information communication technologies (ICT). This review provides useful information and insights to researchers and practitioners who are interested in cybersecurity of IoT, including the current research of IoT cybersecurity, IoT cybersecurity architecture and taxonomy, key enabling countermeasures and strategies, major applications in industries, research",7
1c4a3a4d128885cb64a3ac1ffcf5c1e8010de331,Concealing the Data using Cryptography,"Data security has emerged as a major challenge. Many techniques and procedures have been developed in order to reach a level of security like data encryption, data backup, data masking, etc., which may require high initial costs and maintenance. Also, once sensitive data has been masked, it cannot be changed back to its original form. Cryptography can be used for data security by data encryption and decryption. One can quickly discover the existence of concealed information in carrier files by employing cryptography. The strategy used in this project utilizes cryptographic methods. In cryptography, the proposed method uses AES algorithm. This helps to maintain the data in a secure way. Cryptography is used to conceal the data in any text file document by utilizing the AES technique. This ensures that no other network user can access the information that is protected. The original message can only be viewed by the sender",3
4a419e68e4b6da86359b04ddefc1347ed6443db2,Alert-Driven Attack Graph Generation Using S-PDFA,"Ideal cyber threat intelligence (CTI) includes insights into attacker strategies that are specific to a network under observation. Such CTI currently requires extensive expert input for obtaining, assessing, and correlating system vulnerabilities into a graphical representation, often referred to as an attack graph (AG). Instead of deriving AGs based on system vulnerabilities, this work advocates the direct use of intrusion alerts. We propose SAGE, an explainable sequence learning pipeline that automatically constructs AGs from intrusion alerts without a priori expert knowledge. SAGE exploits the temporal and probabilistic dependence between alerts in a suffix-based probabilistic deterministic finite automaton (S-PDFA) — a model that brings infrequent severe alerts into the spotlight and summarizes paths leading to them. Attack graphs are extracted from the model on a per-victim, per-objective basis. SAGE is thoroughly evaluated on three open-source intrusion alert datasets collected through security testing competitions in order to analyze distributed multi-stage attacks. SAGE",4
f6d5df0cfd7454251fabc47b37c13610991d876f,Explainable Intelligence-Driven Defense Mechanism Against Advanced Persistent Threats: A Joint Edge Game and AI Approach,"Advanced persistent threats (APT) have novel features such as long-term latency, precision strikes and uncertain strategies. APT poses severe threats to the resource-limited edge devices in advanced networks. Cyber threat intelligence (CTI) conducts data analysis on attack strategies by artificial intelligence (AI) and generates threat intelligence to optimize the detection model and guide defense strategies. However, AI lacks explanations for the decisions and thus reduces the transparency and performance of the detection model. Besides, the tradeoff between the detection accuracy and the computational resource limitation of edge devices needs an optimal and rapid dynamic resource allocation method, which edge game and AI can help. In this article, we propose an explainable intelligence-driven APT edge defense mechanism. The proposed mechanism provides guidelines and explanations for designing the defense strategy and resource allocation scheme of the edge defender to detect APT. The edge defense strategy model is based on edge Bayesian Stackelberg",1
c18c1091823b60025ee2a4e6ac1e4f72e5fd2dfa,BUSINESS INTELLIGENCE IN THE ERA OF BIG DATA: A REVIEW OF ANALYTICAL TOOLS AND COMPETITIVE ADVANTAGE,"In the contemporary business landscape, the proliferation of Big Data has revolutionized the way organizations gather, process, and utilize information for strategic decision-making. This paper provides a comprehensive overview of the evolving role of Business Intelligence (BI) in harnessing the potential of Big Data and the subsequent impact on gaining a competitive advantage. The review delves into the arsenal of analytical tools that have emerged to handle the vast volumes of data generated in the digital age. From traditional reporting and querying to advanced analytics, machine learning, and predictive modeling, organizations now have a myriad of options to extract valuable insights from their data reservoirs. This paper investigates the efficiency, scalability, and adaptability of these tools in the context of Big Data, emphasizing their role in transforming raw data into actionable intelligence. Furthermore, the paper explores how the integration of BI and Big Data analytics contributes to the development of",5
6ce36067a576742038e6026a52a0c7735552200a,Anomaly detection in IoT-based healthcare: machine learning for enhanced security,"Internet of Things (IoT) integration in healthcare improves patient care while also making healthcare delivery systems more effective and economical. To fully realize the advantages of IoT in healthcare, it is imperative to overcome issues with data security, interoperability, and ethical considerations. IoT sensors periodically measure the health-related data of the patients and share it with a server for further evaluation. At the server, different machine learning algorithms are applied which help in early diagnosis of diseases and issue alerts in case vital signs are out of the normal range. Different cyber attacks can be launched on IoT devices which can result in compromised security and privacy of applications such as health care. In this paper, we utilize the publicly available Canadian Institute for Cybersecurity (CIC) IoT dataset to model machine learning techniques for efficient detection of anomalous network traffic. The dataset consists of 33 types of IoT attacks which",4
163b4d6a79a5b19af88b8585456363340d9efd04,GPT-4 Technical Report,"We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",7
8df693cde7e57e6c6db55ee3179a5e76b48aa186,Exploring the potential of Elon musk's proposed quantum AI: A comprehensive analysis and implications,"Elon Musk has recently introduced the concept of Quantum AI, suggesting a revolutionary integration of quantum computing capabilities with artificial intelligence. This research aims to delve into the theoretical foundations, technological aspects, and potential applications of Musk's proposed Quantum AI. By conducting an in-depth analysis, this study seeks to unravel the unique features and challenges associated with the fusion of quantum computing and artificial intelligence, offering insights into the transformative impact on computational power, machine learning, and problem-solving capabilities. Additionally, the research will explore the ethical considerations and societal implications of deploying Quantum AI, paving the way for a comprehensive understanding of its potential benefits and risks. This investigation aims to contribute to the evolving discourse on the convergence of quantum computing and artificial intelligence, shedding light on the path towards harnessing the full potential of Musk's visionary proposal.",5
4177ec52d1b80ed57f2e72b0f9a42365f1a8598d,Speech recognition with deep recurrent neural networks,"Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.",10
11dccd17d223a7e3ec145136413c13d15fc7cce1,A Bayesian network approach for cybersecurity risk assessment implementing and extending the FAIR model,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
143a229923a60370ceb2ad55167cb12ce71d407a,"A Comprehensive Review of Cyber Security Vulnerabilities, Threats, Attacks, and Solutions","Internet usage has grown exponentially, with individuals and companies performing multiple daily transactions in cyberspace rather than in the real world. The coronavirus (COVID-19) pandemic has accelerated this process. As a result of the widespread usage of the digital environment, traditional crimes have also shifted to the digital space. Emerging technologies such as cloud computing, the Internet of Things (IoT), social media, wireless communication, and cryptocurrencies are raising security concerns in cyberspace. Recently, cyber criminals have started to use cyber attacks as a service to automate attacks and leverage their impact. Attackers exploit vulnerabilities that exist in hardware, software, and communication layers. Various types of cyber attacks include distributed denial of service (DDoS), phishing, man-in-the-middle, password, remote, privilege escalation, and malware. Due to new-generation attacks and evasion techniques, traditional protection systems such as firewalls, intrusion detection systems, antivirus software, access control lists, etc., are no longer effective in detecting these",6
39484b449188aa6f459495b5f54eb876291097ae,An Adaptive Deep Learning Neural Network Model to Enhance Machine-Learning-Based Classifiers for Intrusion Detection in Smart Grids,"Modern smart grids are built based on top of advanced computing and networking technologies, where condition monitoring relies on secure cyberphysical connectivity. Over the network infrastructure, transported data containing confidential information, must be protected as smart grids are vulnerable and subject to various cyberattacks. Various machine learning based classifiers were proposed for intrusion detection in smart grids. However, each of them has respective advantage and disadvantages. Aiming to improve the performance of existing machine learning based classifiers, this paper proposes an adaptive deep learning algorithm with a data pre-processing module, a neural network pre-training module and a classifier module, which work together classify intrusion data types using their high-dimensional data features. The proposed Adaptive Deep Learning (ADL) algorithm obtains the number of layers and the number of neurons per layer by determining the characteristic dimension of the network traffic. With transfer learning, the proposed ADL algorithm can extract the original",4
5e2ef6abd77e9d3512e4f9ba694d7c6ad35c8db5,Explainable Artificial Intelligence Applications in Cyber Security: State-of-the-Art in Research,"This survey presents a comprehensive review of current literature on Explainable Artificial Intelligence (XAI) methods for cyber security applications. Due to the rapid development of Internet-connected systems and Artificial Intelligence in recent years, Artificial Intelligence including Machine Learning (ML) and Deep Learning (DL) has been widely utilized in the fields of cyber security including intrusion detection, malware detection, and spam filtering. However, although Artificial Intelligence-based approaches for the detection and defense of cyber attacks and threats are more advanced and efficient compared to the conventional signature-based and rule-based cyber security strategies, most ML-based techniques and DL-based techniques are deployed in the “black-box” manner, meaning that security experts and customers are unable to explain how such procedures reach particular conclusions. The deficiencies of transparencies and interpretability of existing Artificial Intelligence techniques would decrease human users’ confidence in the models utilized for the defense against cyber attacks, especially in current situations where",7
25bec9a4dd90ca682d5155d4977a51e2f6e28917,Privacy and Data Protection in ChatGPT and Other AI Chatbots: Strategies for Securing User Information,"The evolution of artificial intelligence (AI) and machine learning (ML) has led to the development of sophisticated large language models (LLMs) that are used extensively in applications such as chatbots. This research investigates the critical issues of data protection and privacy enhancement in the context of LLM-based chatbots, with a focus on OpenAI's ChatGPT. It explores the dual challenges of safeguarding sensitive user information while ensuring the efficiency of machine learning models. It assesses existing privacy-enhancing technologies (PETs) and proposes innovative methods, such as differential privacy, federated learning, and data minimization techniques. The study also includes a survey of Chatbot users to measure their concerns related to data privacy with the use of these LLM-based applications. This study is meant to serve as a comprehensive guide for developers, policymakers, and researchers, contributing to the discourse on data protection in artificial intelligence.",3
d8b77c88962ad9afc725b43cc408f6fef27998b4,SDSM: Secure Data Sharing for Multilevel Partnerships in IoT Based Supply Chain,"Symmetric encryption algorithms enable rapid encryption of data in IoT based supply chains, which helps to alleviate the concerns of supply chain participants about privacy disclosure when sharing data. However, in supply chain management where multilevel partnerships exist universally, a pure symmetric encryption scheme cannot provide efficient data sharing and fine-grained access control. To overcome these problems, this paper proposes a secure data sharing scheme (SDSM) for IoT based supply chains by combining blockchain and ciphertext-based attribute cryptography. This scheme supports the enforcement of fine-grained access control for different levels of partnerships. In addition, to identify partnerships, we propose a metric based on the historical transaction facts on the blockchain, where the level of partnerships among participants is automatically calculated by smart contracts. Finally, we introduce personalized attributes of participants in the ciphertext-based attribute encryption algorithm to support the construction of access policies that include partnerships, allowing for more fine-grained",5
988c3d3f276784ffdcfe9bb46b7c1e9107db1240,Impact of Remote Patient Monitoring on Length of Stay for Patients with COVID-19.,"Background: Remote patient monitoring (RPM) can be deployed as part of a tiered approach to open up hospital bed availability by allowing earlier discharge of patients with continued virtual monitoring. We describe the impact of RPM on length of stay (LOS) for patients with COVID-19. Methods: We deployed RPM during two COVID-19 surges at a tertiary academic hospital from March to June 2020 as a feasibility pilot to establish the infrastructure for RPM including electronic health record changes and virtual health center (VHC) protocols, and October 2020 to February 2021, during the second surge of COVID-19. Discharging patients received a wearable vital sign monitoring device, allowing real-time data transmission to the VHC using a smart phone application. The data, monitored 24 h a day for 8 days by a technician, had built-in escalation protocols to nurses and/or attending physicians. Results: We compared patients discharged with RPM with those discharged without",4
d52d05c98f835995817b21ae7f1bac9ae887135f,Unmasking Cybercrime with Artificial-Intelligence-Driven Cybersecurity Analytics,"Cybercriminals are becoming increasingly intelligent and aggressive, making them more adept at covering their tracks, and the global epidemic of cybercrime necessitates significant efforts to enhance cybersecurity in a realistic way. The COVID-19 pandemic has accelerated the cybercrime threat landscape. Cybercrime has a significant impact on the gross domestic product (GDP) of every targeted country. It encompasses a broad spectrum of offenses committed online, including hacking; sensitive information theft; phishing; online fraud; modern malware distribution; cyberbullying; cyber espionage; and notably, cyberattacks orchestrated by botnets. This study provides a new collaborative deep learning approach based on unsupervised long short-term memory (LSTM) and supervised convolutional neural network (CNN) models for the early identification and detection of botnet attacks. The proposed work is evaluated using the CTU-13 and IoT-23 datasets. The experimental results demonstrate that the proposed method achieves superior performance, obtaining a very satisfactory success rate (over 98.7%) and a false positive",4
adea6fc6741f30c8829a8b16a150ec6907532a1c,Cyber Security for Detecting Distributed Denial of Service Attacks in Agriculture 4.0: Deep Learning Model,"Attackers are increasingly targeting Internet of Things (IoT) networks, which connect industrial devices to the Internet. To construct network intrusion detection systems (NIDSs), which can secure Agriculture 4.0 networks, powerful deep learning (DL) models have recently been deployed. An effective and adaptable intrusion detection system may be implemented by using the architectures of long short-term memory (LSTM) and convolutional neural network combined with long short-term memory (CNN–LSTM) for detecting DDoS attacks. The CIC-DDoS2019 dataset was used to design a proposal for detecting different types of DDoS attacks. The dataset was developed using the CICFlowMeter-V3 network. The standard network traffic dataset, including NetBIOS, Portmap, Syn, UDPLag, UDP, and normal benign packets, was used to test the development of deep learning approaches. Precision, recall, F1-score, and accuracy were among the measures used to assess the model’s performance. The suggested technology was able to reach a high degree of precision (100%). The CNN–LSTM",3
9d2d86e5faa11832d814b180f5b6e28b05d0d682,FCNN Model for Diagnosis and Analysis of Symmetric Key Cryptosystem,"An important part of a cryptosystem is a cryptographic algorithm, which protects unauthorized attackers from obtaining private and sensitive data. This study is a research project on identifying cryptographic algorithms using deep learning techniques and categorizing cryptographic algorithms based on feature extraction. The research involves employing block cipher modes called electronic codebook with the encryption algorithms Blowfish and advanced encryption standard (AES), where the data will be encrypted using the same key and a different key. The model has been developed by changing the structure and parameters of the proposed model and the training rate of the data. This model will build several dense FCNN of n layers on regular fully connected neural networks. Its construction will consist of five hidden layers, with each layer consisting of 128 neurons and hidden layers activation Relu except for the output layer, which consists of two classifiers and the SoftMax activation function. FCNN",4
f539efb9f0d3a75fd95d4f0e6076f3556a243d6b,PRIVACY LAW CHALLENGES IN THE DIGITAL AGE: A GLOBAL REVIEW OF LEGISLATION AND ENFORCEMENT,"As the world becomes increasingly interconnected through digital technologies, the protection of individuals' privacy has emerged as a critical concern. This paper conducts a comprehensive global review of privacy legislation and enforcement mechanisms, shedding light on the challenges posed by the digital age. With a focus on the intricate balance between technological advancements and the fundamental right to privacy, the study explores the evolving legal landscape and its implications for individuals, businesses, and governments. The analysis encompasses diverse jurisdictions, highlighting the variations in privacy laws and enforcement approaches across regions. From the European Union's robust General Data Protection Regulation (GDPR) to the nuanced approaches in Asia and the Americas, this review synthesizes the evolving regulatory frameworks. Special attention is given to emerging issues such as the use of artificial intelligence, biometrics, and surveillance technologies, which pose unique challenges to existing privacy paradigms. Moreover, the paper investigates the effectiveness of enforcement",5
b8a2fb97fb72725210ffd8af52446a88c88f072d,Deep Cybersecurity: A Comprehensive Overview from Neural Network and Deep Learning Perspective,"Deep learning, which is originated from an artificial neural network (ANN), is one of the major technologies of today’s smart cybersecurity systems or policies to function in an intelligent manner. Popular deep learning techniques, such as multi-layer perceptron, convolutional neural network, recurrent neural network or long short-term memory, self-organizing map, auto-encoder, restricted Boltzmann machine, deep belief networks, generative adversarial network, deep transfer learning, as well as deep reinforcement learning, or their ensembles and hybrid approaches can be used to intelligently tackle the diverse cybersecurity issues. In this paper, we aim to present a comprehensive overview from the perspective of these neural networks and deep learning techniques according to today’s diverse needs. We also discuss the applicability of these techniques in various cybersecurity tasks such as intrusion detection, identification of malware or botnets, phishing, predicting cyberattacks, e.g. denial of service, fraud detection or cyberanomalies, etc. Finally, we highlight several research issues",5
f1026bf720fb771ecf021717977cfae00f3a25c6,Robust and Secure Quality Monitoring for Welding through Platform-as-a-Service: A Resistance and Submerged Arc Welding Study,"For smart manufacturing systems, quality monitoring of welding has already started to shift from empirical modeling to knowledge integration directly from the captured data by utilizing one of the most promising Industry 4.0’s key enabling technologies, artificial intelligence (AI)/machine learning (ML). However, beyond the advantages that they bring, AI/ML introduces new types of security threats, which are related to their very nature and eventually, they will pose real threats to the production cost and quality of products. These types of security threats, such as adversarial attacks, are causing the targeted AI system to produce incorrect or malicious outputs. This may undermine the performance (and the efficiency) of the quality monitoring systems. Herein, a software platform servicing quality monitoring for welding is presented in the context of resistance and submerged arc welding. The hosted ML classification models that are trained to perform quality monitoring are subjected to two different types of",2
a476a2bab5bc1570858c1a88f663a85d0b858b2e,A novel approach for analyzing the nuclear supply chain cyber-attack surface,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
577042e6e971acb77a721ad9f30377741b573593,The Emerging Threat of Ai-driven Cyber Attacks: A Review,"ABSTRACT Cyberattacks are becoming more sophisticated and ubiquitous. Cybercriminals are inevitably adopting Artificial Intelligence (AI) techniques to evade the cyberspace and cause greater damages without being noticed. Researchers in cybersecurity domain have not researched the concept behind AI-powered cyberattacks enough to understand the level of sophistication this type of attack possesses. This paper aims to investigate the emerging threat of AI-powered cyberattacks and provide insights into malicious used of AI in cyberattacks. The study was performed through a three-step process by selecting only articles based on quality, exclusion, and inclusion criteria that focus on AI-driven cyberattacks. Searches in ACM, arXiv Blackhat, Scopus, Springer, MDPI, IEEE Xplore and other sources were executed to retrieve relevant articles. Out of the 936 papers that met our search criteria, a total of 46 articles were finally selected for this study. The result shows that 56% of the AI-Driven cyberattack technique identified was demonstrated in",3
8fbac1419ee06a8a035adf27519123713dcb26fd,Cyberpsychology: A Longitudinal Analysis of Cyber Adversarial Tactics and Techniques,"The rapid proliferation of cyberthreats necessitates a robust understanding of their evolution and associated tactics, as found in this study. A longitudinal analysis of these threats was conducted, utilizing a six-year data set obtained from a deception network, which emphasized its significance in the study’s primary aim: the exhaustive exploration of the tactics and strategies utilized by cybercriminals and how these tactics and techniques evolved in sophistication and target specificity over time. Different cyberattack instances were dissected and interpreted, with the patterns behind target selection shown. The focus was on unveiling patterns behind target selection and highlighting recurring techniques and emerging trends. The study’s methodological design incorporated data preprocessing, exploratory data analysis, clustering and anomaly detection, temporal analysis, and cross-referencing. The validation process underscored the reliability and robustness of the findings, providing evidence of increasingly sophisticated, targeted cyberattacks. The work identified three distinct network traffic behavior clusters and temporal attack",5
b6a3555a960a448ba6d9b4aa9c02038982e3d3e1,CIPHER: Cybersecurity Intelligent Penetration-Testing Helper for Ethical Researcher,"Penetration testing, a critical component of cybersecurity, typically requires extensive time and effort to find vulnerabilities. Beginners in this field often benefit from collaborative approaches with the community or experts. To address this, we develop Cybersecurity Intelligent Penetration-testing Helper for Ethical Researchers (CIPHER), a large language model specifically trained to assist in penetration testing tasks as a chatbot. Unlike software development, penetration testing involves domain-specific knowledge that is not widely documented or easily accessible, necessitating a specialized training approach for AI language models. CIPHER was trained using over 300 high-quality write-ups of vulnerable machines, hacking techniques, and documentation of open-source penetration testing tools augmented in an expert response structure. Additionally, we introduced the Findings, Action, Reasoning, and Results (FARR) Flow augmentation, a novel method to augment penetration testing write-ups to establish a fully automated pentesting simulation benchmark tailored for large language models. This approach fills a significant gap in traditional",8
9c0620e2eb158e429fdfcbbc619b9bdcb39e55af,Real-Time Threat Detection with JavaScript: Monitoring and Response Mechanisms,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
b0a05dafc199f146a25ce8d4f0ec56b886bc8887,A Survey on Adversarial Attacks for Malware Analysis,"Machine learning-based malware analysis approaches are widely researched and deployed in critical infrastructures for detecting and classifying evasive and growing malware threats. However, minor perturbations or ineffectual byte insertions can easily ‘fool’ these trained ML classifiers, making them ineffective against these crafted and smart malicious software. This survey aims to provide an encyclopedic overview of adversarial evasion attacks specifically targeting malware detection and classification systems, standing apart from previous surveys by focusing exclusively and comprehensively on this unique application domain. While significant strides have been made in adversarial research in other fields, the specific challenges of adversarial malware remain under-explored due to the intricate nature and constraints of the malware domain. Our survey addresses this gap by analyzing literature on adversarial evasion attacks published between 2013 and 2024, making it one of the first to systematically focus on malware-specific adversarial attacks in a detailed, self-contained manner. The paper will begin",4
3cb20a2c117b5d82bacb13424d91aaa745a4b36c,"Defining Digital Public Health and the Role of Digitization, Digitalization, and Digital Transformation: Scoping Review","Background The recent proliferation and application of digital technologies in public health has spurred interest in digital public health. However, as yet, there appears to be a lack of conceptual clarity and consensus on its definition. Objective In this scoping review, we seek to assess formal and informal definitions of digital public health in the literature and to understand how these definitions have been conceptualized in relation to digitization, digitalization, and digital transformation. Methods We conducted a scoping literature search in Ovid MEDLINE, Embase, Google Scholar, and 14 government and intergovernmental agency websites encompassing 6 geographic regions. Among a total of 409 full articles identified, we reviewed 11 publications that either formally defined digital public health or informally described the integration of digital technologies into public health in relation to digitization, digitalization, and digital transformation, and we conducted a thematic analysis of the identified definitions. Results Two explicit definitions of",2
435817be30165d26ae9af5383e3579d8baddd55d,Preventing Cryptographic Attacks Using AI-hard Password Authentication,"Contemporary adversaries are incapable of cracking a hash function within reasonable time. However, advancements in quantum computing would empower such adversaries to perform more computations in a shorter time span, leading to a major security crisis. Integrating artificial intelligence based approaches that are hard problems such as natural language understanding or CAPTCHA can help with future-proofing security. Hence, this work proposes a CAPTCHA-like challenge that adds AI-Hardness to authenticate the client password. In the proposed system, no information about the password is directly sent in client-server communication and cannot be captured by adversaries. Server generates a challenge text and sends it to the client, which is then hashed with the client password. The output is embedded into an image and is XORed twice with the hash generated with the client password and sent to the server. This introduces randomness in the image. The server reverses the process using its copy",4
0724dfc64566c8ac67cb8305890ccf543053c43d,Cybersecurity in Cyber–Physical Power Systems,"The current energy transition combined with the modernization of power systems has provided meaningful transformations in the transmission, distribution, operation, planning, monitoring, and control of power systems. These advancements are heavily dependent on the employment of new computing and communications technologies, which, combined with traditional physical systems, lead to the emergence of cyber–physical systems (CPSs). In this sense, besides the traditional challenges of keeping a reliable, affordable, and safe power grid, one must now deal with the new vulnerabilities to cyberattacks that emerge with the advancement of CPSs. Aware of this perspective and the severity of the ongoing challenges faced by the industry due to cyberattacks, this paper aims to provide a comprehensive survey of the literature on cybersecurity in cyber–physical power systems. For this, clear definitions, historical timelines, and classifications of the main types of cyberattacks, including the concepts, architectures, and basic components that make up, as well as",5
d2cf009b7ec6ebf042f4648213106156d678cbc9,A Survey of Artificial Intelligence in Cybersecurity,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research",4
8932145f1165085c7057fd0eec0af273b2beb553,"Defining Security Requirements With the Common Criteria: Applications, Adoptions, and Challenges","Advances in emerging Information and Communications Technology (ICT) technologies push the boundaries of what is possible and open up new markets for innovative ICT products and services. The adoption of ICT products and systems with security properties depends on consumers’ confidence and markets’ trust in the security functionalities and whether the assurance measures applied to these products meet the inherent security requirements. Such confidence and trust are primarily gained through the rigorous development of security requirements, validation criteria, evaluation, and certification. The Common Criteria for Information Technology Security Evaluation (often referred to as Common Criteria or CC) is an international standard (ISO/IEC 15408) for cyber security. Motivated by encouraging the adoption of the CC that is used for ICT security evaluation and certification, in this paper, we conduct a systematic review of the CC standard and its adoptions. Adoption barriers of the CC are investigated based on the analysis of",6
7dfc8244440f173050fe9b8d8e2589c194b8d0c0,Renewable energy policies: A comparative analysis of Nigeria and the USA,"This paper presents a comprehensive comparative analysis of renewable energy policies between Nigeria and the United States of America. It delves into the different approaches and strategies employed by these two nations in promoting and implementing renewable energy initiatives. The analysis begins by exploring the current energy landscapes in both countries, highlighting their respective energy demands, sources, and challenges. Special emphasis is laid on the policy frameworks, including governmental regulations, incentives, and subsidies that have been instrumental in driving the growth of renewable energy sectors in Nigeria and the USA. The study further examines the impact of these policies on renewable energy development, particularly in terms of increased capacity, technological advancements, and environmental sustainability. It evaluates the effectiveness of various renewable energy programs and projects, including solar, wind, hydro, and biomass, by analyzing their contributions to each country's energy mix and their role in reducing carbon emissions. Moreover, the paper",4
5e3927d647360a60686e60b7c14ff37b20cd5d71,Assessing the seriousness of cybercrime: The case of computer misuse crime in the United Kingdom and the victims’ perspective,"The reform of the Crime Survey of England and Wales (a national victim survey) has exposed a very high number of individuals who fall victim to computer misuse cybercrimes such as hacking, computer viruses and ransomware. These crimes receive very little attention from the criminal justice system and very few are brought to justice, partly because of the nature of them (global crimes), but also because of a lack of capability among the police. This paper draws on official statistics, an empirical survey and interview research with computer misuse victims. The paper juxtaposes the low priority and lack of resources given to this crime by political and police leaders against many victims’ perceptions and experiences of the crime as equivalent if not more serious than physical counterparts such as burglary, where there is greater interest. The increasing prominence of the virtual world in human life and the impacts of these",6
6296aa7cab06eaf058f7291040b320b5a83c0091,Generative Adversarial Networks,"Generative Adversarial Networks (GANs) are a type of deep learning techniques that have shown remarkable success in generating realistic images, videos, and other types of data. This paper provides a comprehensive guide to GANs, covering their architecture, loss functions, training methods, applications, evaluation metrics, challenges, and future directions. We begin with an introduction to GANs and their historical development, followed by a review of the background and related work. We then provide a detailed overview of the GAN architecture, including the generator and discriminator networks, and discuss the key design choices and variations. Next, we review the loss functions utilized in GANs, including the original minimax objective, as well as more recent approaches s.a. Wasserstein distance and gradient penalty. We then delve into the training of GANs, discussing common techniques s.a. alternating optimization, minibatch discrimination, and spectral normalization. We also provide a survey of the various applications of GANs across",20
87f40e6f3022adbc1f1905e3e506abad05a9964f,Distributed Representations of Words and Phrases and their Compositionality,"The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of ""Canada"" and ""Air"" cannot be easily combined to obtain ""Air Canada"". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.",73
eb8c300d2d8d3bb6938c883ea2fb452639c92b4f,Automatic Labeling for Entity Extraction in Cyber Security,"Timely analysis of cyber-security information necessitates automated information extraction from unstructured text. While state-of-the-art extraction methods produce extremely accurate results, they require ample training data, which is generally unavailable for specialized applications, such as detecting security related entities; moreover, manual annotation of corpora is very costly and often not a viable solution. In response, we develop a very precise method to automatically label text from several data sources by leveraging related, domainspecific, structured data and provide public access to a corpus annotated with cyber-security entities. Next, we implement a Maximum Entropy Model trained with the average perceptron on a portion of our corpus ( 750,000 words) and achieve near perfect precision, recall, and accuracy, with training times under 17 seconds.",5
5cd3cad99092f77f19c7120fe541a59b2c92eb98,Cyber Information Retrieval Through Pragmatics Understanding and Visualization,"The amount of cybersecurity-related information is extraordinarily increasing, given the fast-growing number of cybersecurity attacks and the significant influence brought by them. How to efficiently obtain and precisely understand the relevant knowledge in the sea of information on cybersecurity becomes a challenge. In this article, we propose an innovative cybersecurity retrieval scheme that supports automatic indexing and searching of cybersecurity information based on semantic contents and hidden metadata. The proposed scheme leverages a customized neural model that incorporates new linguistic features and word embedding by identifying the entities related to cybersecurity incidents from the text. We implement a novel cybersecurity search engine to demonstrate effective, understandable and pragmatic cybersecurity information retrieval based on the proposed schema. Comprehensive performance evaluation over real-world datasets has been conducted to validate the new algorithms and techniques developed for cybersecurity information retrieval. The new engine makes it possible to conduct augmented search, cybersecurity analytics, and",5
2b79d1a8ce840578fcdfea7f18779a9cc8b907d1,Targeted Phishing Campaigns using Large Scale Language Models,"In this research, we aim to explore the potential of natural language models (NLMs) such as GPT-3 and GPT-2 to generate effective phishing emails. Phishing emails are fraudulent messages that aim to trick individuals into revealing sensitive information or taking actions that benefit the attackers. We propose a framework for evaluating the performance of NLMs in generating these types of emails based on various criteria, including the quality of the generated text, the ability to bypass spam filters, and the success rate of tricking individuals. Our evaluations show that NLMs are capable of generating phishing emails that are difficult to detect and that have a high success rate in tricking individuals, but their effectiveness varies based on the specific NLM and training data used. Our research indicates that NLMs could have a significant impact on the prevalence of phishing attacks and emphasizes the need for further study on the ethical",8
d08cf6708d3f0cc186df7fbcf3826e1180207746,Automated Cyber Defence: A Review,"Within recent times, cybercriminals have curated a variety of organised and resolute cyber attacks within a range of cyber systems, leading to consequential ramifications to private and governmental institutions. Current security-based automation and orchestrations focus on automating fixed purpose and hard-coded solutions, which are easily surpassed by modern-day cyber attacks. Research within Automated Cyber Defence will allow the development and enabling intelligence response by autonomously defending networked systems through sequential decision-making agents. This article comprehensively elaborates the developments within Automated Cyber Defence through a requirement analysis divided into two sub-areas, namely, automated defence and attack agents and Autonomous Cyber Operation (ACO) Gyms. The requirement analysis allows the comparison of automated agents and highlights the importance of ACO Gyms for their continual development. The requirement analysis is also used to critique ACO Gyms with an overall aim to develop them for deploying automated agents within real-world networked systems. Relevant future challenges",1
25275bbcd21cdbd0e5c946fb316355bde4c7665a,Review of AI and machine learning applications to predict and Thwart cyber-attacks in real-time,"The contemporary cybersecurity landscape demands innovative solutions to combat the relentless evolution of cyber threats. Traditional approaches are facing unprecedented challenges, compelling a paradigm shift towards the integration of Artificial Intelligence (AI) and Machine Learning (ML). This paper meticulously explores the potential of AI and ML to fortify real-time cybersecurity, with a focus on the swift prediction and mitigation of cyber-attacks. Against the backdrop of an escalating threat landscape, this paper propels the inquiry into advanced technologies to fortify cybersecurity. The limitations of traditional methodologies underscore the urgency of investigating the efficacy of AI and ML in reinforcing defense mechanisms. This paper endeavors to comprehensively investigate the role of AI and ML in real-time cybersecurity. It places a distinct emphasis on their potential to predict and thwart cyber-attacks promptly. The exploration encompasses diverse dimensions, ranging from the intricacies of model complexity to crucial considerations in security, ethics, and emerging trends.",3
7079280c437b99b2cd8608f9f84dd77815e32425,Exploring the Full Potentials of IoT for Better Financial Growth and Stability: A Comprehensive Survey,"Cutting-edge technologies, with a special emphasis on the Internet of Things (IoT), tend to operate as game changers, generating enormous alterations in both traditional and modern enterprises. Understanding multiple uses of IoT has become vital for effective financial management, given the ever-changing nature of organizations and the technological disruptions that come with this paradigm change. IoT has proven to be a powerful tool for improving operational efficiency, decision-making processes, overall productivity, and data management. As a result of the continuously expanding data volume, there is an increasing demand for a robust IT system capable of adeptly handling all enterprise processes. Consequently, businesses must develop suitable IoT architectures that can efficiently address these continually evolving requirements. This research adopts an incremental explanatory approach, guided by the principles of the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA). A rigorous examination of 84 research papers has allowed us to delve deeply",3
d08463bd665589d04619f04dbde84183ffcf2e63,Towards a Human-like Open-Domain Chatbot,"We present Meena, a multi-turn open-domain chatbot trained end-to-end on data mined and filtered from public domain social media conversations. This 2.6B parameter neural network is simply trained to minimize perplexity of the next token. We also propose a human evaluation metric called Sensibleness and Specificity Average (SSA), which captures key elements of a human-like multi-turn conversation. Our experiments show strong correlation between perplexity and SSA. The fact that the best perplexity end-to-end trained Meena scores high on SSA (72% on multi-turn evaluation) suggests that a human-level SSA of 86% is potentially within reach if we can better optimize perplexity. Additionally, the full version of Meena (with a filtering mechanism and tuned decoding) scores 79% SSA, 23% higher in absolute SSA than the existing chatbots we evaluated.",3
d78a2e6155fc9afd927850ca2d58f7b790a470dd,Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise,"While large language models (LLMs) like GPT-4 have recently demonstrated astonishing zero-shot capabilities in general domain tasks, they often generate content with hallucinations in specific domains such as Chinese law, hindering their application in these areas. This is typically due to the absence of training data that encompasses such a specific domain, preventing GPT-4 from acquiring in-domain knowledge. A pressing challenge is that it's not plausible to continue training LLMs of such scale on in-domain data. This paper introduces a simple and effective domain adaptation framework for GPT-4 by reformulating generation as an \textbf{adapt-retrieve-revise} process. The initial step is to \textbf{adapt} an affordable 7B LLM to the target domain by continuing learning on in-domain data. When solving a task, we leverage the adapted LLM to generate a draft answer given a task query. Then, the draft answer will be used to \textbf{retrieve} supporting evidence candidates from an external in-domain knowledge",2
1cd68f817f4ddd8457c8af9b8fe37bf70b4c06b3,Analysis of Cyber Security Attacks and Its Solutions for the Smart grid Using Machine Learning and Blockchain Methods,"Smart grids are rapidly replacing conventional networks on a worldwide scale. A smart grid has drawbacks, just like any other novel technology. A smart grid cyberattack is one of the most challenging things to stop. The biggest problem is caused by millions of sensors constantly sending and receiving data packets over the network. Cyberattacks can compromise the smart grid’s dependability, availability, and privacy. Users, the communication network of smart devices and sensors, and network administrators are the three layers of an innovative grid network vulnerable to cyberattacks. In this study, we look at the many risks and flaws that can affect the safety of critical, innovative grid network components. Then, to protect against these dangers, we offer security solutions using different methods. We also provide recommendations for reducing the chance that these three categories of cyberattacks may occur.",5
ef3fd925ed85e3295770cd0b35b7e9effe787445,Quantum-Inspired Blockchain-Based Cybersecurity: Securing Smart Edge Utilities in IoT-Based Smart Cities,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
3beb8ca627c1486f170ae7b671e138b245e853f3,Next-Generation Cyber Threat Detection and Mitigation Strategies: A Focus on Artificial Intelligence and Machine Learning,"The principal objective of this research was to examine strategies for detecting and mitigating cyber threats in the next generation, by underscoring Artificial Intelligence (AI) and Machine Learning (ML). This study provides a comprehensive overview of the role of AI, ML, and deep learning (DL) in the domain of cybersecurity. Furthermore, this study highlights the benefits of integrating deep learning into cybersecurity practices. The researcher explored the effectiveness of consolidating AI and ML techniques into the Feedzai security system to reinforce the detection of fraudulent activities. To validate the methodology, the investigator experimented by employing the supervised machine learning random forest algorithm on a dataset comprising historical transaction records in CSV format. The results of the research ascertained that by employing Feedzai's AI-based software combined with the random forest algorithms, future financial institutions can achieve real-time fraud detection and accurate identification of legitimate transactions. The Random Forest framework had the",4
3cc0cd9a47a08a175150c2e3901b6069bda953f5,Blockchain technology in the future of business cyber security and accounting,"This study looks into the current, and potential uses of Blockchain technology in business, specifically in Accounting and in cybersecurity. We relate Blockchain uses to current concerns within cyb...",5
412ac028e91a783e62b69920f7d7820dcc740f0c,Home working and cyber security – an outbreak of unpreparedness?,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
41e091272ee3e55d2b6b27b2cce38bd25bcd881a,Generating Phishing Attacks using ChatGPT,"The ability of ChatGPT to generate human-like responses and understand context has made it a popular tool for conversational agents, content creation, data analysis, and research and innovation. However, its effectiveness and ease of accessibility makes it a prime target for generating malicious content, such as phishing attacks, that can put users at risk. In this work, we identify several malicious prompts that can be provided to ChatGPT to generate functional phishing websites. Through an iterative approach, we find that these phishing websites can be made to imitate popular brands and emulate several evasive tactics that have been known to avoid detection by anti-phishing entities. These attacks can be generated using vanilla ChatGPT without the need of any prior adversarial exploits (jailbreaking).",1
aa0b5821458e34d35d96ba0878b595950ec8bb8e,LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis,"Automated log analysis plays a crucial role in software maintenance as it allows for efficient identification and resolution of issues. How-ever, traditional methods employed in log analysis heavily rely on extensive historical data for training purposes and lack rationales for its predictions. The performance of these traditional methods significantly deteriorates when in-domain logs for training are lim-ited and unseen log data are the majority, particularly in rapidly changing online environments. Additionally, the lack of rationales hampers the interpretability of analysis results and impacts analysts' subsequent decision-making processes. To address these challenges, we proposes LogPrompt, an novel approach that leverages large language models (LLMs) and advanced prompting techniques to achieve performance improvements in zero-shot scenarios (i.e., no in-domain training). Moreover, LogPrompt has garnered positive evaluations from experienced practitioners in its log interpretation ability. Code available at https://github.com/lunyiliu/LogPrompt.",3
8438356284e01d3ae17154765759cddcac56e5c7,Digital Workplaces and Information Security Behavior of Business Employees: An Empirical Study of Saudi Arabia,"In the post pandemic era, the telecommuting of business employees has widely become acceptable in organizations, which demands extensive dependence on digital technologies. In addition, this poses additional security threats for business employees as well as organizations. In order to better respond to security threats, business employees must have a higher level of awareness of the potential threats that are relevant to digital infrastructure used within the workplace. In this paper, we present a quantitative study conducted in line with the theory of planned behavior to gain insight into employee behavior toward information security within different business sectors in Saudi Arabia. The key factors chosen for our model were password management, infrastructure security management, email management, organizational security policy, organizational support and training, and the perception of the level of security. We have applied structured equation modelling to identify most of the relevant factors based on the respondents’ feedback. The",3
1f50f5b33832dc8099b788a126916f65cd2cc237,Employee’s Attitude Towards Artificial Intelligence in the Indian Banking Sector,"Purpose: This paper aims to examine employees' attitudes towards the utilization of Artificial Intelligence (AI) in the Indian Banking Sector. The study delves into understanding how employees perceive the integration of AI technologies and its impact on various aspects of banking operations. Theoretical framework: Built upon the significance of AI as a transformative technology, this research seeks insights into employees' perspectives on AI adoption within the Indian Banking Sector. The study is framed within the context of technological implementation and its influence on organizational processes. Design/Methodology/Approach: Utilizing a mixed-methods approach involving surveys and interviews, this study collects data on employees' attitudes towards AI in banking. A questionnaire captures diverse viewpoints, while interviews provide deeper insights into the reasons underlying these attitudes. Findings: The study uncovers a range of employee attitudes towards AI integration in the Indian Banking Sector. Positive responses highlight AI's contributions in areas like accounting, sales, contracts, and",4
d301a1f242a39e395e2756cd33b2e7ce0e4afe15,"Decoding the Threat Landscape : ChatGPT, FraudGPT, and WormGPT in Social Engineering Attacks","In the ever-evolving realm of cybersecurity, the rise of generative AI models like ChatGPT, FraudGPT, and WormGPT has introduced both innovative solutions and unprecedented challenges. This research delves into the multifaceted applications of generative AI in social engineering attacks, offering insights into the evolving threat landscape using blog mining technique. Generative AI models have revolutionized the field of cyberattacks, empowering malicious actors to craft convincing and personalized phishing lures, manipulate public opinion through deepfakes, and exploit human cognitive biases. These models, ChatGPT, FraudGPT, and WormGPT, have augmented existing threats and ushered in new dimensions of risk. From phishing campaigns that mimic trusted organizations to deepfake technology impersonating authoritative figures, we explore how generative AI amplifies the arsenal of cybercriminals. Furthermore, we shed light on the vulnerabilities that AI-driven social engineering exploits, including psychological manipulation, targeted phishing, and the crisis of authenticity. To counter these threats, we outline a range of",1
7813c7274ddb3fa90ff76c2ec4f8f1c327823aa1,Internet of Things for Current COVID-19 and Future Pandemics: an Exploratory Study,"In recent years, the Internet of Things (IoT) has gained convincing research ground as a new research topic in a wide variety of academic and industrial disciplines, especially in healthcare. The IoT revolution is reshaping modern healthcare systems by incorporating technological, economic, and social prospects. It is evolving healthcare systems from conventional to more personalized healthcare systems through which patients can be diagnosed, treated, and monitored more easily. The current global challenge of the pandemic caused by the novel severe respiratory syndrome coronavirus 2 presents the greatest global public health crisis since the pandemic influenza outbreak of 1918. At the time this paper was written, the number of diagnosed COVID-19 cases around the world had reached more than 31 million. Since the pandemic started, there has been a rapid effort in different research communities to exploit a wide variety of technologies to combat this worldwide threat, and IoT technology is",2
2118e6adac6d15d9d6e3078c1570e8f883bf9bcf,Review of Intelligence for Additive and Subtractive Manufacturing: Current Status and Future Prospects,"Additive manufacturing (AM), an enabler of Industry 4.0, recently opened limitless possibilities in various sectors covering personal, industrial, medical, aviation and even extra-terrestrial applications. Although significant research thrust is prevalent on this topic, a detailed review covering the impact, status, and prospects of artificial intelligence (AI) in the manufacturing sector has been ignored in the literature. Therefore, this review provides comprehensive information on smart mechanisms and systems emphasizing additive, subtractive and/or hybrid manufacturing processes in a collaborative, predictive, decisive, and intelligent environment. Relevant electronic databases were searched, and 248 articles were selected for qualitative synthesis. Our review suggests that significant improvements are required in connectivity, data sensing, and collection to enhance both subtractive and additive technologies, though the pervasive use of AI by machines and software helps to automate processes. An intelligent system is highly recommended in both conventional and non-conventional subtractive manufacturing (SM) methods to monitor and inspect the",2
e2fe6426823794f4855b0acec0a5e029a8c4d050,Electric Vehicle Attack Impact on Power Grid Operation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
ede0a8039a561905f40777ec2ae66c2010e3f2bc,Cybersecurity data science: an overview from machine learning perspective,"In a computing context, cybersecurity is undergoing massive shifts in technology and its operations in recent days, and data science is driving the change. Extracting security incident patterns or insights from cybersecurity data and building corresponding data-driven model, is the key to make a security system automated and intelligent. To understand and analyze the actual phenomena with data, various scientific methods, machine learning techniques, processes, and systems are used, which is commonly known as data science. In this paper, we focus and briefly discuss on cybersecurity data science, where the data is being gathered from relevant cybersecurity sources, and the analytics complement the latest data-driven patterns for providing more effective security solutions. The concept of cybersecurity data science allows making the computing process more actionable and intelligent as compared to traditional ones in the domain of cybersecurity. We then discuss and summarize a number of associated research issues and future",12
93a5d21d2ee12c11bf3f8331c49824a730543045,Survey on Intrusion Detection Systems Based on Machine Learning Techniques for the Protection of Critical Infrastructure,"Industrial control systems (ICSs), supervisory control and data acquisition (SCADA) systems, and distributed control systems (DCSs) are fundamental components of critical infrastructure (CI). CI supports the operation of transportation and health systems, electric and thermal plants, and water treatment facilities, among others. These infrastructures are not insulated anymore, and their connection to fourth industrial revolution technologies has expanded the attack surface. Thus, their protection has become a priority for national security. Cyber-attacks have become more sophisticated and criminals are able to surpass conventional security systems; therefore, attack detection has become a challenging area. Defensive technologies such as intrusion detection systems (IDSs) are a fundamental part of security systems to protect CI. IDSs have incorporated machine learning (ML) techniques that can deal with broader kinds of threats. Nevertheless, the detection of zero-day attacks and having technological resources to implement purposed solutions in the real world are concerns for CI operators. This",7
1b093f31c3c329a645f45758fa11ab8468dc1545,"Threats Detection in the Internet of Things Using Convolutional neural networks, long short-term memory, and gated recurrent units","Security for IoT gadgets is an undertaking that has been made more troublesome by the far-reaching utilization of network safety in different applications, including wise modern frameworks, homes, individual devices, and vehicles. The fact that has been introduced makes deep learning for interruption recognition one productive security method. I thought about a few relevant systematic reviews that had already been written. Recent systematic reviews may include older and more recent works on the subject. For better IoT security, late exploration has focused on improving deep learning calculations. The ideal methodology for carrying out interruption recognition in the Internet of Things is determined by looking at the exhibition of different deep learning executions and investigating interruption location techniques that utilise them. Convolutional neural networks (CNNs), long short-term memory (LSTM), and gated recurrent units (GRUs) are the deep learning models used in this review. A standard dataset for IoT interruption identification is",3
f75b77c4769f1d18bb50e466ad031d8d3ed270e3,Secure Power Distribution Against Reactive Power Control Malfunction in DER Units,"Penetration of distributed energy resources (DERs) such as wind, solar and battery units are rapidly increasing in distribution power system (DPS). In view of power grid reliability and efficiency, cyber and physical secure of these units are highly important since it can directly impact power system operations. This paper investigates the dynamic behavior of power distribution during cyber, physical and natural strikes on reactive power control in DER units. Various fault scenarios including modifications in voltage-reactive power (Volt-Var) curve pattern such as slope of the curve, dead band; and changes in capacitive or/and inductive reactive power delivery to the power grid are presented. Further, fault scenarios are investigated with the presence of dynamic VAR (volt-ampere reactive) compensation (DVC) units in the system. A southern California 140-bus commercial distribution power system is selected as a test system and faults are analyzed in both Matlab/Simulink and ETAP simulation platforms. The results evidence",5
fd7d06f3c1e7185f6c67846e4bb09b7a7bcffa2e,"Security and privacy of internet of medical things: A contemporary review in the age of surveillance, botnets, and adversarial ML","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
09835de62562558a4e127f3a2f01b9d594b4706d,Artificial Intelligence-based Control Techniques for HVDC Systems,"The electrical energy industry depends, among other things, on the ability of networks to deal with uncertainties from several directions. Smart-grid systems in high-voltage direct current (HVDC) networks, being an application of artificial intelligence (AI), are a reliable way to achieve this goal as they solve complex problems in power system engineering using AI algorithms. Due to their distinctive characteristics, they are usually effective approaches for optimization problems. They have been successfully applied to HVDC systems. This paper presents a number of issues in HVDC transmission systems. It reviews AI applications such as HVDC transmission system controllers and power flow control within DC grids in multi-terminal HVDC systems. Advancements in HVDC systems enable better performance under varying conditions to obtain the optimal dynamic response in practical settings. However, they also pose difficulties in mathematical modeling as they are non-linear and complex. ANN-based controllers have replaced traditional PI controllers in the",2
fb1f88184ba2063a79e7d34d32d146dfe4c528b7,The tensions of cyber-resilience: From sensemaking to practice,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
de41d128db7a51398c8a88dcc1c2bed5e3995c2b,IoT Based Smart Systems using Artificial Intelligence and Machine Learning: Accessible and Intelligent Solutions,"The Internet of Things (IoT) has grown in importance in both the technological and social spheres as consumers want smarter homes, more efficient businesses, and more efficient healthcare systems. The social setting is very important for this. Communication networks provide uninterrupted internet connectivity for both fixed and mobile devices like PCs and smartphones. Customers may now keep up their level of engagement while interacting with one or more apps at any time and from any location, thanks to developments in information and communication technologies. Many kinds of smart devices might potentially coordinate their responses to events, sending out alerts or keeping records of the system’s condition in line with a predetermined policy. Constant progress toward intelligent solutions is improving many facets of modern life, including manufacturing, transportation, electronic healthcare, electronic education, and many more. Machine-to-machine (M2M) communication in the IoT is autonomous and dynamic. Diverse approaches are being developed to",5
a5ca89b0650b44e4b0a9dba1c699c7f3b0f39334,"Modeling the Development of Energy Network Software, Taking into Account the Detection and Elimination of Vulnerabilities","This paper solves the problem of modeling the scheme for developing software systems, which can be used in building solutions for secure energy networks. A development scheme is proposed in a set of representations through which each program of the software complex passes, namely the following representations: idea, conceptual model, architecture, algorithm, source code, graphic code, abstract syntax tree, assembler code, machine code, byte code, executed code. The main properties of each representation are indicated, such as the form (text, graphic, programming language, binary, and decoded), development (transformation) methods, as well as vulnerabilities that are detected in it. An example of each representation is given, particularly as applied to the energy networks. The scheme elements (representations, vulnerabilities, forms, etc.) and the main operations for working with their elements (representation transformation, vulnerability injection, and detection) are presented in an analytical form. An example of a development scheme for a simple software",3
324e6cdf975a8a63c23ca10e2504b603cdc7e3a3,Explainable and Interpretable Multimodal Large Language Models: A Comprehensive Survey,"The rapid development of Artificial Intelligence (AI) has revolutionized numerous fields, with large language models (LLMs) and computer vision (CV) systems driving advancements in natural language understanding and visual processing, respectively. The convergence of these technologies has catalyzed the rise of multimodal AI, enabling richer, cross-modal understanding that spans text, vision, audio, and video modalities. Multimodal large language models (MLLMs), in particular, have emerged as a powerful framework, demonstrating impressive capabilities in tasks like image-text generation, visual question answering, and cross-modal retrieval. Despite these advancements, the complexity and scale of MLLMs introduce significant challenges in interpretability and explainability, essential for establishing transparency, trustworthiness, and reliability in high-stakes applications. This paper provides a comprehensive survey on the interpretability and explainability of MLLMs, proposing a novel framework that categorizes existing research across three perspectives: (I) Data, (II) Model, (III) Training \&Inference. We systematically analyze interpretability from token-level to embedding-level representations, assess approaches",3
16f8fe12c0a4f60c7a720df2d231e51d66e5cd19,Phasor data correction and transmission system state estimation under Man-in-the-Middle attack,"Cyberinfrastructure (e.g., sensors, actuators and the associated communication network) has become an integral part of our modern power grid. While these cyber technologies enhance situational awareness and operational efficiency, they also expose the physical system to cyber-attacks. In this paper, we consider the problem of transmission system state estimation based on measurements from a number of PMUs. In this context, a PMU data integrity attack, Man-in-the-Middle (MitM) attack that can potentially cause a severe impact on the grid is analyzed. Specifically, we propose a novel method based on an alternate expectation-maximization framework to mitigate the effects of these attacks on the state estimation process. Numerical tests are conducted on IEEE-14, 30 and 118 bus systems with different attack scenarios to validate the developed method. Unlike existing works, the proposed algorithm provides accurate state estimates without any prior knowledge of the location of the attack or the number of meters being",3
403281bcb23f4d388333f49d827f67c6d097b80e,Google Trends,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
a087744edfeb4057dfd0576f9f4b555a429e468c,COVID‐19 pandemic cybersecurity issues,"This paper studies the cybersecurity issues that have occurred during the coronavirus (COVID‐19) pandemic. During the pandemic, cyber criminals and Advanced Persistent Threat (APT) groups have taken advantage of targeting vulnerable people and systems. This paper emphasizes that there is a correlation between the pandemic and the increase in cyber‐attacks targeting sectors that are vulnerable. In addition, the growth in anxiety and fear due to the pandemic is increasing the success rate of cyber‐attacks. We also highlight that healthcare organizations are one of the main victims of cyber‐attacks during the pandemic. The pandemic has also raised the issue of cybersecurity in relation to the new normal of expecting staff to work from home (WFH), the possibility of state‐sponsored attacks, and increases in phishing and ransomware. We have also provided various practical approaches to reduce the risks of cyber‐attacks while WFH including mitigation of security risks related to healthcare. It is",6
08eb878c0aa3f76ba7da1bc6eae73d9755aa000c,Credit Card Analytics: A Review of Fraud Detection and Risk Assessment Techniques,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
5241aaac522ec4d301b56234707075e572d5393b,REVIEW OF LABORATORY DIAGNOSTICS EVOLUTION IN NIGERIA'S RESPONSE TO COVID-19,"This comprehensive review elucidates the evolution of laboratory diagnostics in Nigeria's response to COVID-19, emphasizing its pivotal role in managing infectious diseases. The purpose of this review is to analyze the advancements in diagnostic approaches and their implications on effective pandemic management and future preparedness. A robust and comprehensive research strategy was employed, involving a systematic synthesis and critical review of peer-reviewed articles, focusing on innovations, developments, and challenges in diagnostic procedures during the pandemic. The results revealed significant progress in diagnostic methodologies and technologies, with enhanced capabilities to detect and control the spread of infectious diseases, despite logistical, infrastructural, and regulatory challenges. The review concluded that the advancements in diagnostics have multifaceted impacts on shaping effective pandemic management strategies and altering public health policy and practice. Recommendations include strengthening laboratory capacities, developing sustainable strategies, investing in research and development, promoting international collaboration, and enhancing health systems. The insights derived",5
31126624d028d61a8f68e5d9b7204a3a53f13947,Introduction to The Data Mining Techniques in Cybersecurity,"As a result of the evolution of the Internet and the massive amount of data that is transmitted every second, as well as the methods for protecting and preserving it and distinguishing those who are authorized to view it, the role of cyber security has evolved to provide the best protection for information over the network. In this paper, the researcher discusses the role of data mining methods in cyber security. Data mining has several uses in security, including national security (for example, surveillance) and cyber security (e.g., virus detection). Attacks against buildings and the destruction of key infrastructure, such as power grids and telecommunications networks, are examples of national security concerns. Cybersecurity is concerned with safeguarding computer and network systems from harmful malware such as Trojan horses and viruses. In addition, data mining is being used to deliver solutions such as intrusion detection and auditing.",5
6edfe852ddd798e0aea50ef777ba5cce98fe677e,"Urban Computing for Sustainable Smart Cities: Recent Advances, Taxonomy, and Open Research Challenges","The recent proliferation of ubiquitous computing technologies has led to the emergence of urban computing that aims to provide intelligent services to inhabitants of smart cities. Urban computing deals with enormous amounts of data collected from sensors and other sources in a smart city. In this article, we investigated and highlighted the role of urban computing in sustainable smart cities. In addition, a taxonomy was conceived that categorized the existing studies based on urban data, approaches, applications, enabling technologies, and implications. In this context, recent developments were elucidated. To cope with the engendered challenges of smart cities, we outlined some crucial use cases of urban computing. Furthermore, prominent use cases of urban computing in sustainable smart cities (e.g., planning in smart cities, the environment in smart cities, energy consumption in smart cities, transportation in smart cities, government policy in smart cities, and business processes in smart cities) for smart urbanization",1
5ba46bd7084dfd41ce4f34deffd414e2e74cb973,Secure framework against cyber attacks on cyber-physical robotic systems,"Abstract. Robot-based platforms and processes have integrated the security and efficiency of data into a comprehensive range for domains, such as manufacturing, industrial, logistical, agricultural, healthcare, and internet services. Smart cyberattacks have been on the rise, specifically targeting corporate, industrial robotic systems. These attacks execute once the internet of things, internet, and organization integration is implemented with the industrial units. We implemented security criteria-based indices for cyber-physical systems (CPS) with industrial components and embedded sensors that process the information logs and processes. We proposed an attack tree-based secure framework that does not include every CPS device but takes into consideration the critical exploitable vulnerabilities to execute the attacks. We categorized each physical device and integrated sensors based on logs and information in a sensor indices device library. This research simulated real-time exploitation of vulnerabilities on CPS robotic systems using the proposed framework in form of a two-phased process. This validates",2
a06a8ca70096e567e5cf1e433cc99ac1d519c4d0,A survey on adversarial attacks and defences,"Deep learning has evolved as a strong and efficient framework that can be applied to a broad spectrum of complex learning problems which were difficult to solve using the traditional machine learning techniques in the past. The advancement of deep learning has been so radical that today it can surpass human ‐ level performance. As a consequence, deep learning is being extensively used in most of the recent day ‐ to ‐ day applications. However, efficient deep learning systems can be jeopardised by using crafted adversarial samples, which may be imperceptible to the human eye, but can lead the model to misclassify the output. In recent times, different types of adversaries based on their threat model leverage these vulnerabilities to compromise a deep learning system where ad-versaries have high incentives. Hence, it is extremely important to provide robustness to deep learning algorithms against these adversaries. However, there are only a",2
dcaefc616f6594949c226285ed78582b6631294d,Multi-Criteria Decision Making (MCDM) Methods and Concepts,"Multi-criteria decision-making (MCDM) is one of the main decision-making problems which aims to determine the best alternative by considering more than one criterion in the selection process. MCDM has manifold tools and methods that can be applied in different fields from finance to engineering design. This entry aims to provide a survey on the MCDM concept, its applications, main categories, and different methods. The final section provides manifold information and statistics on the published works in the MCDM fields. Some of the main methods are also listed in this section.",2
56f751e56cb6ae7eecacdcceb258131a03b9e24f,ANVIL: Anomaly-based Vulnerability Identification without Labelled Training Data,"Supervised learning-based software vulnerability detectors often fall short due to the inadequate availability of labelled training data. In contrast, Large Language Models (LLMs) such as GPT-4, are not trained on labelled data, but when prompted to detect vulnerabilities, LLM prediction accuracy is only marginally better than random guessing. In this paper, we explore a different approach by reframing vulnerability detection as one of anomaly detection. Since the vast majority of code does not contain vulnerabilities and LLMs are trained on massive amounts of such code, vulnerable code can be viewed as an anomaly from the LLM's predicted code distribution, freeing the model from the need for labelled data to provide a learnable representation of vulnerable code. Leveraging this perspective, we demonstrate that LLMs trained for code generation exhibit a significant gap in prediction accuracy when prompted to reconstruct vulnerable versus non-vulnerable code. Using this insight, we implement ANVIL, a detector",5
06a6182851c486f0650e394a246b677ba3c9b25e,Flexible zero trust architecture for the cybersecurity of industrial IoT infrastructures,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
17c25ce0114fcde1acb04cd0f9c7b86e4733641d,Fundamental design strategies for advancing the development of high entropy alloys for thermo-mechanical application: A critical review,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
4381132f77f84c49c15acab902ab93e184845f9b,A Secure Blockchain-Enabled Remote Healthcare Monitoring System for Home Isolation,"This article presents a secure framework for remote healthcare monitoring in the context of home isolation, thereby addressing the concerns related to untrustworthy client connections to a hospital information system (HIS) within a secure network. Our proposed solution leverages a public blockchain network as a secure distributed database to buffer and transmit patient vital signs. The framework integrates an algorithm for the secure gathering and transmission of vital signs to the Ethereum network. Additionally, we introduce a publish/subscribe paradigm, thus enhancing security using the TLS channel to connect to the blockchain network. An analysis of the maintenance cost of the distributed database underscores the cost-effectiveness of our approach. In conclusion, our framework provides a highly secure and economical solution for remote healthcare monitoring in home isolation scenarios.",4
c48c59e1a392cd6e5cdad300872632e408b2607d,Interaction Design of Wellness Building Space by Deep Learning and VR Technology in the Context of Internet of Things,"This study explores the application of deep learning theory and virtual reality (VR) technology to the interactive behavior design of building space according to the interaction behavior of wellness building space in the context of the Internet of Things (IoT). Firstly, VR theory is made into an image-based 3-dimensional (3D) modeling process. Secondly, the interactive behavior information data is analyzed according to the theory of deep learning and edge computing. Finally, the particle swarm optimization (PSO) is used to analyze the predicted temperature with the wellness building space model, as well as to make a study based on the changes in the user’s psychological indicators. The results show that the model predictions of deep learning-edge computing are most like the actual environmental settings. Both PSO and deep learning algorithms have varying degrees of influence on the final prediction results. The average temperature of the wellness building space established by deep",2
667e4d2232485c99a1f7615357e2fb6a86442b27,Artificial Intelligence Techniques in Smart Grid: A Survey,"The smart grid is enabling the collection of massive amounts of high-dimensional and multi-type data about the electric power grid operations, by integrating advanced metering infrastructure, control technologies, and communication technologies. However, the traditional modeling, optimization, and control technologies have many limitations in processing the data; thus, the applications of artificial intelligence (AI) techniques in the smart grid are becoming more apparent. This survey presents a structured review of the existing research into some common AI techniques applied to load forecasting, power grid stability assessment, faults detection, and security problems in the smart grid and power systems. It also provides further research challenges for applying AI technologies to realize truly smart grid systems. Finally, this survey presents opportunities of applying AI to smart grid problems. The paper concludes that the applications of AI techniques can enhance and improve the reliability and resilience of smart grid systems.",1
18f3affc62662c1255f951d09f747657f42a029e,"Artificial Intelligence Trust, Risk and Security Management (AI TRiSM): Frameworks, applications, challenges and future research directions","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
045a68c3bb871eb9acc1a329bee3c3c6d2146117,Network Attacks Detection Methods Based on Deep Learning Techniques: A Survey,"With the development of the fifth-generation networks and artificial intelligence technologies, new threats and challenges have emerged to wireless communication system, especially in cybersecurity. In this paper, we offer a review on attack detection methods involving strength of deep learning techniques. Specifically, we firstly summarize fundamental problems of network security and attack detection and introduce several successful related applications using deep learning structure. On the basis of categorization on deep learning methods, we pay special attention to attack detection methods built on different kinds of architectures, such as autoencoders, generative adversarial network, recurrent neural network, and convolutional neural network. Afterwards, we present some benchmark datasets with descriptions and compare the performance of representing approaches to show the current working state of attack detection methods with deep learning structures. Finally, we summarize this paper and discuss some ways to improve the performance of attack detection under thoughts of utilizing deep learning",3
c1d1fbfa5f735460573b8e24be3a9179f66481ab,From Pixels to Sustainability: Trends and Collaborations in Remote Sensing for Advancing Sustainable Cities and Communities (SDG 11),"Remote sensing data and methods have become indispensable for observing and modeling the Earth and have great potential for monitoring a substantial portion of the targets defined under the United Nations Sustainable Development Goals (SDGs). This study investigates remote sensing research on SDG 11 (sustainable cities and communities) from 2016 to 2023, highlighting the growing interest in the field. By evaluating a large number of selected articles (6820) using a specialized keyword selection strategy and various filters, a significant increase in publication frequency was observed. Remote Sensing and Sustainability were found to be the most relevant journals. A trend towards research addressing urban ecological quality, changes in land use patterns, and the impact of impervious surfaces was found in domain-specific citations. Semi-niche motor themes encompass deep learning, feature extraction, and semantic segmentation. Simultaneously, remote sensing, machine learning, and change detection serve as foundational motor themes, merging elements of both basic",2
a5cf77b8cf7d1e2044ee3f2e5092a42b7845d395,Intrusion Detection Framework for the Internet of Things Using a Dense Random Neural Network,"The Internet of Things (IoT) devices, networks, and applications have become an integral part of modern societies. Despite their social, economic, and industrial benefits, these devices and networks are frequently targeted by cybercriminals. Hence, IoT applications and networks demand lightweight, fast, and flexible security solutions to overcome these challenges. In this regard, artificial-intelligence-based solutions with Big Data analytics can produce promising results in the field of cybersecurity. This article proposes a lightweight dense random neural network (DnRaNN) for intrusion detection in the IoT. The proposed scheme is well suited for implementation in resource-constrained IoT networks due to its inherent improved generalization capabilities and distributed nature. The suggested model was evaluated by conducting extensive experiments on a new generation IoT security dataset ToN_IoT. All the experiments were conducted under different hyperparameters and the efficiency of the proposed DnRaNN was evaluated through multiple performance metrics. The findings of the proposed study provide",2
10145a22ebfee898be909ad44f83bd3c490adb53,Balancing Specialized and General Skills in LLMs: The Impact of Modern Tuning and Data Strategy,"This paper introduces a multifaceted methodology for fine-tuning and evaluating large language models (LLMs) for specialized monetization tasks. The goal is to balance general language proficiency with domain-specific skills. The methodology has three main components: 1) Carefully blending in-domain and general-purpose data during fine-tuning to achieve an optimal balance between general and specialized capabilities; 2) Designing a comprehensive evaluation framework with 45 questions tailored to assess performance on functionally relevant dimensions like reliability, consistency, and business impact; 3) Analyzing how model size and continual training influence metrics to guide efficient resource allocation during fine-tuning. The paper details the design, data collection, analytical techniques, and results validating the proposed frameworks. It aims to provide businesses and researchers with actionable insights on effectively adapting LLMs for specialized contexts. We also intend to make public the comprehensive evaluation framework, which includes the 45 tailored questions and their respective scoring guidelines, to foster transparency",6
576eb64aa919cab47da009c53c603f459eddba5f,The impacts of curbside feedback mechanisms on recycling performance of households in the United States,"As environmental issues continue to rise and global understanding of the effects of uncontrolled waste production grows, recycling has become an essential part of sustainable waste management methods. The implementation of curbside feedback mechanisms has emerged as a progressive strategy to enhance household recycling performance in the United States. This paper explores the four most popular types of feedback mechanisms (Contamination alerts/penalty, Smart Bins, Mobile Apps, and Incentive Programs) across the United States, their impacts on recycling performance (specifically on recycling participation, reduction in contamination rates, and recycling accuracy), the challenges associated with their acceptance and usage, and the recommended future directions aimed at improving the functionalities of these curbside feedback mechanisms. A comprehensive literature review synthesizes findings from important journals and examines the current state of recycling, the role of behavioral science in recycling, and the factors influencing household recycling performance which are attitude and perception, knowledge and awareness,",6
f329109f03f8f809f9df52e3baa95d0790057003,A Hybrid AES with a Chaotic Map-Based Biometric Authentication Framework for IoT and Industry 4.0,"The Internet of Things (IoT) is being applied in multiple domains, including smart homes and energy management. This work aims to tighten security in IoTs using fingerprint authentications and avoid unauthorized access to systems for safeguarding user privacy. Captured fingerprints can jeopardize the security and privacy of personal information. To solve privacy- and security-related problems in IoT-based environments, Biometric Authentication Frameworks (BAFs) are proposed to enable authentications in IoTs coupled with fingerprint authentications on edge consumer devices and to ensure biometric security in transmissions and databases. The Honeywell Advanced Encryption Security-Cryptography Measure (HAES-CM) scheme combined with Hybrid Advanced Encryption Standards with Chaotic Map Encryptions is proposed. BAFs enable private and secure communications between Industry 4.0’s edge devices and IoT. This work’s suggested scheme’s evaluations with other encryption methods reveal that the suggested HAES-CM encryption strategy outperforms others in terms of processing speeds.",5
ca8421e5ce56594e27a33ee9693f77aa2ce4a916,"Book review: Christopher Hadnagy, Social Engineering: The Science of Human Hacking","Christopher Hadnagy, Social Engineering: The Science of Human Hacking (2nd ed.). John Wiley & Sons, Inc, 2018, 320 pp., ₹1,645.",1
571bf90eba8a8f74d3b2fa988839425777ce2368,An OCPP-Based Approach for Electric Vehicle Charging Management,"This paper proposes a smart system for managing the operations of grid-connected charging stations for electric vehicles (EV) that use photovoltaic (PV) sources. This system consists of a mobile application for EV drivers to make charging reservations, an algorithm to optimize the charging schedule, and a remote execution module of charging operations based on the open charge point protocol (OCPP). The optimal charging schedule was obtained by solving a binary integer programming problem. The merits of our solution are illustrated by simulating different charging demand scenarios.",10
f5a7da72496e2ca8edcd9f9123773012c010cfc6,Neural Architectures for Named Entity Recognition,"Comunicacio presentada a la 2016 Conference of the North American Chapter of the Association for Computational Linguistics, celebrada a San Diego (CA, EUA) els dies 12 a 17 de juny 2016.",6
26bc862af033eff985d58a01eafad1922875e10a,AutoLog: Anomaly detection by deep autoencoding of system logs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
38ee99eeb3620a734eca557a68abb82bcc58a1bd,Enhanced Approach of Risk Assessment for Insider Threats Detection in Smart Manufacturing,"The smart manufacturing integrates Internet of Things (IoT), cloud systems, data analytics and machine learning for autonomous implementation particularly in the factory’s supply chain. The additional components from Information Technology (IT) gives convenience accessibility in spike of welcomed threats from inside or outside the boundary to do harmful events. The valuable information in smart manufacturing consists of intellectual property (IP), assets (hardware and software) data and human talent that lead to data theft and illegal activities due to its monetary values. However, little work is done on assessing risks invaluable information particularly threats from inside. In fact, studies on risk assessments are focusing on financial profit, supply chain production and IT assets. Therefore, an enhanced approach of risk assessment for insider threat detection (RAFITD) is introduced. The proposed approach contributes to a log monitoring of the log on and log out activities, based on the role of employee on a",3
5addc498706646e0e1aed256db2242846fabf045,Dynamic Reduced-Round TLS Extension for Secure and Energy-Saving Communication of IoT Devices,"The security of wireless Internet of Things (IoT) communication is a complex challenge due to not only growing attack surfaces and threats but also the limitations of energy consumption. As a significant portion of the IoT market is composed of both security- and energy-critical sectors, e.g., smart homes and e-health, there is a pressing demand for solutions to secure billions of IoT devices while minimizing energy footprint. To this end, this article proposes a transport layer security (TLS) extension to integrate a lightweight and self-monitored mechanism that dynamically balances communication security and power consumption according to the IoT device’s current battery level. Integrated within the TLSv1.3 protocol, the secure extension automatically adjusts the encryption round number of the negotiated cipher according to an operator-defined policy while ensuring the minimum required security level. A Proof-of-Concept (PoC) has been implemented on the wolfSSL library and a real-world IoT platform, on which the",5
f404086bf5880f7735fd710d83620bff3fc69437,ScalableDigitalHealth (SDH): An IoT-Based Scalable Framework for Remote Patient Monitoring,"Addressing the increasing demand for remote patient monitoring, especially among the elderly and mobility-impaired, this study proposes the “ScalableDigitalHealth” (SDH) framework. The framework integrates smart digital health solutions with latency-aware edge computing autoscaling, providing a novel approach to remote patient monitoring. By leveraging IoT technology and application autoscaling, the “SDH” enables the real-time tracking of critical health parameters, such as ECG, body temperature, blood pressure, and oxygen saturation. These vital metrics are efficiently transmitted in real time to AWS cloud storage through a layered networking architecture. The contributions are two-fold: (1) establishing real-time remote patient monitoring and (2) developing a scalable architecture that features latency-aware horizontal pod autoscaling for containerized healthcare applications. The architecture incorporates a scalable IoT-based architecture and an innovative microservice autoscaling strategy in edge computing, driven by dynamic latency thresholds and enhanced by the integration of custom metrics. This work ensures heightened accessibility, cost-efficiency, and rapid responsiveness",3
8b22edef760d3f53405f228f21e6f0f2b7f6a483,Extracting Cybersecurity Related Linked Data from Text,"The Web is typically our first source of information about new software vulnerabilities, exploits and cyber-attacks. Information is found in semi-structured vulnerability databases as well as in text from security bulletins, news reports, cyber security blogs and Internet chat rooms. It can be useful to cyber security systems if there is a way to recognize and extract relevant information and represent it as easily shared and integrated semantic data. We describe such an automatic framework that generates and publishes a RDF linked data representation of cyber security concepts and vulnerability descriptions extracted from the National Vulnerability Database and from text sources. A CRF-based system is used to identify cybersecurity-relatedentities, concepts and relations in text, which are then represented using custom ontologies for the cyber security domain and also mapped to objects in the DBpedia knowledge base. The resulting cyber security linked data collection can be used for many purposes, including",4
a5fd49b48cec62798199cde74487ece72388f04a,ReinforSec: An Automatic Generator of Synthetic Malware Samples and Denial-of-Service Attacks through Reinforcement Learning,"In recent years, cybersecurity has been strengthened through the adoption of processes, mechanisms and rapid sources of indicators of compromise in critical areas. Among the most latent challenges are the detection, classification and eradication of malware and Denial of Service Cyber-Attacks (DoS). The literature has presented different ways to obtain and evaluate malware- and DoS-cyber-attack-related instances, either from a technical point of view or by offering ready-to-use datasets. However, acquiring fresh, up-to-date samples requires an arduous process of exploration, sandbox configuration and mass storage, which may ultimately result in an unbalanced or under-represented set. Synthetic sample generation has shown that the cost associated with setting up controlled environments and time spent on sample evaluation can be reduced. Nevertheless, the process is performed when the observations already belong to a characterized set, totally detached from a real environment. In order to solve the aforementioned, this work proposes a methodology for the",3
0ba4d4fb6f63c49c8f0eab96ba453535fcf0d3c2,Cyber Security in Control of Grid-Tied Power Electronic Converters—Challenges and Vulnerabilities,"Grid-tied power electronic converters are key enabling technologies for interfacing renewable energy sources, energy storage, electrical vehicles, microgrids, and high-voltage dc transmission lines with the electrical power grid. As the number of power converters in modern grids continually increases, their monitoring and coordinated control in a way to support the grid have become topics of increased practical and research interest. In connection with this, latest standards have also defined a mandatory set of control parameters for grid-tied converters, which should be adjustable by a remote entity that sends commands through a communication network. While such a remote control capability allows many new control functions in grid-tied converters, it also renders them vulnerable to cyber-attacks. The aim of this article is first to shed light on the portions of the power converter control systems that are vulnerable to cyber-attacks. Next, typical cyber-attacks are overviewed by considering different applications of the grid-tied",6
67c81170719d6118064e9a34fb82e10db380a029,Challenges and Cybersecurity Threats in Digital Economic Transformation,"The integration of digital technology in economic transformation can introduce new risks and threats caused by the emergence of new technologies and features in the digital economy. It is crucial for governments, as implementers and overseers of the economy, to identify potential risks and threats in order to ensure the security of the national economy during the digital economic transformation. The efficiency of the measures developed and implemented to minimize risks and eliminate threats to national economic security depends on the quality and precision of the policies implemented. A comprehensive approach to analyzing the risks and threats posed by cyber threats in the digital economy is necessary and should cover all economic processes, particularly the relationships among the actors involved in the economic process.",3
3b8ccc7ec80b8775de603e248ac1ca2b919d6b70,Chatbots in a Botnet World,"Question-and-answer formats provide a novel experimental platform for investigating cybersecurity questions. Unlike previous chatbots, the latest ChatGPT model from OpenAI supports an advanced understanding of complex coding questions. The research demonstrates thirteen coding tasks that generally qualify as stages in the MITRE ATT&CK framework, ranging from credential access to defense evasion. With varying success, the experimental prompts generate examples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled ransomware. The empirical results illustrate cases that support the broad gain of functionality, including self-replication and self-modification, evasion, and strategic understanding of complex cybersecurity goals. One surprising feature of ChatGPT as a language-only model centers on its ability to spawn coding approaches that yield images that obfuscate or embed executable programming steps or links.",2
0be6fb7b8f5fc023ef036e6595864f43eeed1cd1,"Wearable Activity Trackers: A Survey on Utility, Privacy, and Security","Over the past decade, wearable activity trackers (WATs) have become increasingly popular. However, despite many research studies in different fields (e.g. psychology, health, and design), few have sought to jointly examine the critical aspects of utility (i.e., benefits brought by these devices), privacy, and security (i.e., risks and vulnerabilities associated with them). To fill this gap, we reviewed 236 studies that researched the benefits of using WATs, the implications for the privacy of users of WATs, and the security vulnerabilities of these devices. Our survey revealed that these devices expose users to several threats. For example, WAT data can be mined to infer private information, such as the personality traits of the user. Whereas many works propose empirical findings about users’ privacy perceptions and their behaviors in relation to privacy, we found relatively few studies researching technologies to better protect users’ privacy with these devices. This survey contributes to systematizing",6
08cc9e37177afdcae2060e3af6f1d2f9358370a0,"Framework for Improving Critical Infrastructure Cybersecurity, Version 1.1 (French Translation)",<jats:p />,3
7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea,"Machine Learning: Algorithms, Real-World Applications and Research Directions","In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and",5
ecd0b23e4828fca585a05eff56563852d35858d9,ChatGPT,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
4d5ed385b3a9b7d5d192047c54578ceeaaf2639f,"Telemedicine, privacy, and information security in the age of COVID-19","COVID-19 has highlighted the shortcomings of healthcare systems globally as countries struggle to meet the high demand for patient care. The spread of COVID-19 has resulted in unprecedented circumstances that necessitate a shift towards adopting infrastructure to enable care to be provided virtually. This shift is critical to minimize insufficiencies and maximize the quality of care in healthcare systems. While COVID-19 has dramatically accelerated the adoption of technology into care delivery, ongoing work is needed to ensure that our technology infrastructure provides an environment for safe and effective care delivery. Telemedicine usage has substantially increased over the past decade (1), and many hospital systems have robust telemedicine programs. Yet traditional in-person visits remain the cornerstone of clinical care, despite the fact that a significant amount of these visits, including follow-ups, treatment for minor illnesses, and chronic disease management could be substituted by virtual communication. Telemedicine has previously been identified as",4
dcf40736c78c5dcbf16252f750384cbfca100b00,ABC-RuleMiner: User behavioral rule-based machine learning method for context-aware intelligent services,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
5849d51fa6992005e947b57a404f400a2a1fe3a2,COMMUNITY-BASED MENTAL HEALTH INTERVENTIONS IN AFRICA: A REVIEW AND ITS IMPLICATIONS FOR U.S. HEALTHCARE PRACTICES,"This study critically examines community-based mental health interventions in Africa and their implications for U.S. healthcare practices. The primary aim was to explore the effectiveness of these interventions and assess their potential integration into the U.S. healthcare framework. The methodology employed was a comprehensive literature review, focusing on recent peer-reviewed articles and reports. This approach facilitated an in-depth analysis of the evolution of mental health care models, the significance of community-based approaches in African contexts, and their relevance to U.S. healthcare systems The findings reveal that African community-based mental health models are distinct in their emphasis on community engagement, integration with traditional practices, and the pivotal role of non-governmental organizations. These elements have contributed significantly to their success and offer valuable insights for U.S. mental health care enhancement. The study also identified key research gaps, providing a foundation for future scholarly work. In conclusion, the study highlights the potential benefits",5
f9058d3ff45bffe357a21461ac3970e852145018,POSTER: A Common Framework for Resilient and Safe Cyber-Physical System Design,"Cyber-physical systems (CPS), which are often required to satisfy critical properties such as safety, have been shown to be vulnerable to exploits originating from cyber and/or physical sides. Recently, novel resilient architectures, which equip CPS with capabilities of recovering to normal operations, have been developed to guarantee the safety of CPS under cyber attacks. These resilient architectures utilize distinct mechanisms involving different parameters and are seemingly unrelated. Currently, the analysis and design methods of one novel resilient architecture for CPS are not readily applicable to one another. Consequently, evaluating the appropriateness and effectiveness of a set of candidate resilient architectures to a given CPS is currently impractical. In this poster, we report our progress on the development of a common framework for analyzing the safety and assessing recovery performance of two or more resilient architectures intended for CPS under attacks. We formulate a hybrid model as a common representation of",2
88778410c78c420baa9e9b1a60cc99e9b3a24fed,SteinerLog: Prize Collecting the Audit Logs for Threat Hunting on Enterprise Network,"Advanced cyberattacks are carried out in multiple stages, where each stage performs a specific task corresponding to the campaign. While these steps are designed to blend in with benign activities, they leave their activity footprints across multiple logs on the machines inside the victim environment. The majority of these footprints when looked at in isolation seem benign to the activity monitors. Existing threat hunting systems require a significant amount of human effort to correlate these events in order to detect and reconstruct an attack campaign. This paper introduces SteinerLog, an end-to-end system to automate the task of correlating the alerts to detect ongoing attack campaigns within an enterprise network. SteinerLog takes the alerts generated by mature intelligence-based and anomaly-based alerting systems and uses causal analysis to extract the group of events that are most likely to represent the attackers' activities. It performs hierarchical graph traversal to perform cross-host attacker activity",2
ceeb63c64cc30edc21a92c454ea905770196b43f,MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response,"Large Language Models (LLMs) have shown immense potential in multimodal applications, yet the convergence of textual and musical domains remains not well-explored. To address this gap, we present MusiLingo, a novel system for music caption generation and music-related query responses. MusiLingo employs a single projection layer to align music representations from the pre-trained frozen music audio model MERT with a frozen LLM, bridging the gap between music audio and textual contexts. We train it on an extensive music caption dataset and fine-tune it with instructional data. Due to the scarcity of high-quality music Q&A datasets, we created the MusicInstruct (MI) dataset from captions in the MusicCaps datasets, tailored for open-ended music inquiries. Empirical evaluations demonstrate its competitive performance in generating music captions and composing music-related Q&A pairs. Our introduced dataset enables notable advancements beyond previous ones.",5
9564908c08e690b02ad55598b9dc4f27c8fe2f53,Artificial Intelligence Based Predictive Threat Hunting In The Field of Cyber Security,"Artificial intelligence (AI) is a broad field of computer science that focuses on designing smart machines capable of performing tasks typically requiring human intelligence. Despite the fact that security solutions are growing progressively modern and stable, cyberattacks are still evolving and are at their extreme. The main reason is that conventional methods of malware detection fail. Cyber attackers are actively developing new ways to prevent defence programmes from infecting malware networks and servers. Most anti-malware and antivirus applications currently use signature-based detection to identify attacks, which is unsuccessful in detecting new threats. This is where Artificial Intelligence is most handy. The standardised models for threatened hunting and performance quantification from the start of hazard hunting to the end still allow methodological rigour and completeness to be studied remain undefined. The organised practise of hazard hunts seeks to disclose the presence of TTP in the field of detection that has not",1
197424fd727aa79889554e9b79cb24f1a7146c1b,Empowering sustainable power generation: The vital role of power electronics in California's renewable energy transformation,"This paper elucidates the pivotal role played by power electronics in catalyzing the ongoing transformation of California's energy landscape towards sustainability through renewable sources. As California intensifies its efforts to combat climate change and foster energy resilience, the integration of renewable energy technologies becomes paramount. Through a comprehensive analysis, this study unveils the indispensable functions of power electronics in enabling the efficient generation, transmission, and utilization of renewable energy resources. By exploring key renewable energy systems such as solar, wind, and hydro power, and their intricate interactions with power electronics, this research underscores their collective impact on the state's energy transition. Insights garnered from this examination not only shed light on the technical intricacies of renewable energy integration but also inform strategic decision-making for policymakers, utilities, and stakeholders vested in California's sustainable energy future.",4
af87339f36f9735bae708369256e0ed9734dcc22,Do ChatGPT and Other AI Chatbots Pose a Cybersecurity Risk? - An Exploratory Study,"The rise of artificial intelligence (AI) has opened up new frontiers in various fields, including natural language processing. One of the most significant advancements in this area is the development of conversational agents (i.e., chatbots), which are computer programs designed to interact with humans through messaging interfaces. The emergence of large language models, such as ChatGPT, has enabled the creation of highly sophisticated chatbots that can mimic human conversations with impressive accuracy. However, the use of these chatbots also poses significant cyber risks that must be addressed. This research paper seeks to investigate the cyber risks associated with the use of ChatGPT and other similar AI-based chatbots, including potential vulnerabilities that could be exploited by malicious actors. As part of this research, a survey was conducted to explore the cybersecurity risks associated with AI-based chatbots like ChatGPT. Further, the paper also suggests mitigation methods that can be used to mitigate",9
680e2d6c84f5208e183a9f24bba856845b22a5a9,Revisiting Evolutionary Program Repair via Code Language Model,"Software defects are an inherent part of software development and maintenance. To address these defects, Automated Program Repair (APR) has been developed to fix bugs automatically. With the advent of Large Language Models, Code Language Models (CLMs) trained on code corpora excels in code generation, making them suitable for APR applications. Despite this progress, a significant limitation remains: many bugs necessitate multi-point edits for repair, yet current CLM-based APRs are restricted to single-point bug fixes, which severely narrows the scope of repairable bugs. Moreover, these tools typically only consider the direct context of the buggy line when building prompts for the CLM, leading to suboptimal repair outcomes due to the limited information provided. This paper introduces a novel approach, ARJA-CLM, which integrates the multiobjective evolutionary algorithm with CLM to fix multilocation bugs in Java projects. We also propose a context-aware prompt construction stratege, which enriches the prompt with additional information",4
ccd1a1d1e4694fd99e04a0154ecaafebe775544c,Real-Time Cost Optimization Approach Based on Deep Reinforcement Learning in Software-Defined Security Middle Platform,"In today’s business environment, reducing costs is crucial due to the variety of Internet of Things (IoT) devices and security infrastructure. However, applying security measures to complex business scenarios can lead to performance degradation, making it a challenging task. To overcome this problem, we propose a novel algorithm based on deep reinforcement learning (DRL) for optimizing cost in multi-party computation software-defined security middle platforms (MPC-SDSmp) in real-time. To accomplish this, we first integrate fragmented security requirements and infrastructure into the MPC-SDSmp cloud model with privacy protection capabilities to reduce deployment costs. By leveraging the power of DRL and cloud computing technology, we enhance the real-time matching and dynamic adaptation capabilities of the security middle platform (Smp). This enables us to generate a real-time scheduling strategy for Smp resources that meet low-cost goals to reduce operating costs. Our experimental results demonstrate that the proposed method not only reduces the costs by",6
b7187d8b12d4a9bfd4077f2b40093bd0ecf2626a,"Deep learning: Applications, architectures, models, tools, and frameworks: A comprehensive survey","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
8505e78ef008f6313d3cab755183dbecdd0c4b6a,Transformative synergy: SSEHCET - bridging mobile edge computing and AI for enhanced eHealth security and efficiency,"Blockchain technologies (BCT) are utilized in healthcare to facilitate a smart and secure transmission of patient data. BCT solutions, however, are unable to store data produced by IoT devices in smart healthcare applications because these applications need a quick consensus process, meticulous key management, and enhanced eprivacy standards. In this work, a smart and secure eHealth framework SSEHCET (Smart and Secure EHealth Framework using Cutting-edge Technologies) is proposed that leverages the potentials of modern cutting-edge technologies (IoT, 5G, mobile edge computing, and BCT), which comprises six layers: 1) The sensing layer-WBAN consists of medical sensors that normally are on or within the bodies of patients and communicate data to smartphones. 2) The edge layer consists of elements that are near IoT devices to collect data. 3) The Communication layer leverages the potential of 5G technology to transmit patients' data between multiple layers efficiently. 4) The storage layer consists of cloud",3
7522862ab073d3e25ba28e46eed42a36de0c9310,Application of Artificial Intelligence for EV Charging and Discharging Scheduling and Dynamic Pricing: A Review,"The high penetration of electric vehicles (EVs) will burden the existing power delivery infrastructure if their charging and discharging are not adequately coordinated. Dynamic pricing is a special form of demand response that can encourage EV owners to participate in scheduling programs. Therefore, EV charging and discharging scheduling and its dynamic pricing model are important fields of study. Many researchers have focused on artificial intelligence-based EV charging demand forecasting and scheduling models and suggested that artificial intelligence techniques perform better than conventional optimization methods such as linear, exponential, and multinomial logit models. However, only a few research studies focused on EV discharging scheduling (i.e., vehicle-to-grid, V2G) because the concept of EV discharging electricity back to the power grid is relatively new and evolving. Therefore, a review of existing EV charging and discharging-related studies is needed to understand the research gaps and to make some improvements in future studies. This paper",4
da40866c64b7ec3408f87542c8726284fdbd854c,Analysis Of Cyber Threat Detection And Emulation Using MITRE Attack Framework,"With a rapid increase in Cyber-attacks, Threat hunters such as Cyber Threat Intelligence (CTI) and their teams requires to analyze different techniques being employed by adversaries to hit a target objective. The attacker objectives can be from entering in your network, accessing system files and folders remotely, getting higher system privileges, stealing confidential passwords etc. to destroying systems and network. Pre attack patterns defined in enterprise knowledge base can play a major role to track adversary techniques and procedures in order to defend and response from such attacks. Anomalous and intrusion activities need to be unfolded by the approach adversaries are adopting to demolish secure enterprise networks. An appropriate system is required to better handle modern attack approaches and strategies used by attackers in order to identify vulnerabilities and successfully defend network channels. In this paper, we present an in-depth analysis of different threat detection methods and how to mitigate",7
0388edb9ac1a73d378cf33092770cb2f87a7c3e9,Business IT Alignment Impact on Corporate Sustainability,"Business–IT alignment (BITA) has become crucial for effective organisational management in today’s interconnected global economy. This article investigates the relationship between BITA and corporate sustainability, exploring how businesses can leverage BITA for sustainable growth and development. The study employs a case research approach in a multinational manufacturing organisation, utilising a mixed methods research (MMR) design. In the quantitative part of the research, the PLS-SEM technique was used to examine the influence of six BITA factors on employees’ self-perceived action competence for sustainability (SPACS). This study confirmed that all six BITA factors strongly influence all three SPACS factors. In the qualitative part of the research, semi-structured interviews were used to measure the BITA maturity level of the organisation and the influence of BITA factors on corporate sustainability. Based on quantitative and qualitative research results, it can be confirmed that BITA strongly influences corporate sustainability. Results also confirm that there is no",5
57e849d0de13ed5f91d086936296721d4ff75a75,LLaMA: Open and Efficient Foundation Language Models,"We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.",11
1a014a929b0f55cbd0e7879fbfecbbd69f8d80bf,Investigation of Smart Grid Operation Modes with Electrical Energy Storage System,"The paper considers the issues of maintaining an equality of flow in generated and consumed electric energy in an electric network incorporating an electric power storage system. An analysis of ways to equalize the energy and power balance was carried out, and the advantages of using electricity storage systems in electrical networks was assessed. Upon simulation using the Power Factory program, we noted that, after switching on the load, a transient process occurs, characterized by a jump in active power, which was caused by the need for time to initiate the electric energy storage system. However, immediately after this, the process of issuing the accumulated energy to the electrical network and compensating for energy consumption began. Moreover, when the load was disconnected, there is a certain dip in the active power curve and a further increase in consumption. This was found to be due to the transition of the electricity",4
cc289996d8b14b9bdb22f240055a185316273461,"Robotics cyber security: vulnerabilities, attacks, countermeasures, and recommendations","The recent digital revolution led robots to become integrated more than ever into different domains such as agricultural, medical, industrial, military, police (law enforcement), and logistics. Robots are devoted to serve, facilitate, and enhance the human life. However, many incidents have been occurring, leading to serious injuries and devastating impacts such as the unnecessary loss of human lives. Unintended accidents will always take place, but the ones caused by malicious attacks represent a very challenging issue. This includes maliciously hijacking and controlling robots and causing serious economic and financial losses. This paper reviews the main security vulnerabilities, threats, risks, and their impacts, and the main security attacks within the robotics domain. In this context, different approaches and recommendations are presented in order to enhance and improve the security level of robotic systems such as multi-factor device/user authentication schemes, in addition to multi-factor cryptographic algorithms. We also review the recently presented",3
d0a118e1c9a46a00f004b3883cba0fd772125a6a,"Digitalization in Energy Production, Distribution, and Consumption: A Systematic Literature Review","For this study, we conducted a systematic review of the literature on digitalization in energy production, distribution, and consumption over a sufficiently long period in order to reveal the trends and particularities of this phenomenon at the sectoral level. For the systematic review of the literature, representative articles on the subject indexed in the Web of Science and Scopus databases were selected using the PRISMA 2020 flow diagram. As a result of the systematic review of the literature, a significant number of articles on the subject of digitalization in the energy sector were found—both over the entire period considered and especially in the last five years—indicating the magnitude of the digitalization process in this field. The impacts of digitalization in the energy production, distribution, and consumption sectors materialized in the aspects of health, safety, and environmental improvement; process improvements; and cost reductions. The most important technologies used in the digitalization",1
ec9690961a55c998d2439e7be148350dafdf2de7,LoRaWAN-based hybrid internet of wearable things system implementation for smart healthcare,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
6be479eaa9bcb8bf381a5a37980be176d8ed7999,Quantum Computing and Machine Learning for Cybersecurity: Distributed Denial of Service (DDoS) Attack Detection on Smart Micro-Grid,"Machine learning (ML) is efficiently disrupting and modernizing cities in terms of service quality for mobility, security, robotics, healthcare, electricity, finance, etc. Despite their undeniable success, ML algorithms need crucial computational efforts with high-speed computing hardware to deal with model complexity and commitments to obtain efficient, reliable, and resilient solutions. Quantum computing (QC) is presented as a strong candidate to help MLs reach their best performance especially for cybersecurity issues and digital defense. This paper presents quantum support vector machine (QSVM) model to detect distributed denial of service (DDoS) attacks on smart micro-grid (SMG). An evaluation of our approach against a real dataset of DDoS attack instances shows the effectiveness of our proposed model. Finally, conclusions and some open issues and challenges of the fitting of ML with QC are presented.",6
00dc6eb86b729f3865445130a782a8c935e14f96,Taking AI risks seriously: a new assessment model for the AI Act,"The EU Artificial Intelligence Act (AIA) defines four risk categories: unacceptable, high, limited, and minimal. However, as these categories statically depend on broad fields of application of AI, the risk magnitude may be wrongly estimated, and the AIA may not be enforced effectively. This problem is particularly challenging when it comes to regulating general-purpose AI (GPAI), which has versatile and often unpredictable applications. Recent amendments to the compromise text, though introducing context-specific assessments, remain insufficient. To address this, we propose applying the risk categories to specific AI scenarios, rather than solely to fields of application, using a risk assessment model that integrates the AIA with the risk approach arising from the Intergovernmental Panel on Climate Change (IPCC) and related literature. This integrated model enables the estimation of AI risk magnitude by considering the interaction between (a) risk determinants, (b) individual drivers of determinants, and (c) multiple risk types. We illustrate",6
ab1218eddda162a60682bc44086a13a2f7b26195,Exploring the Challenges and Issues in Adopting Cybersecurity in Saudi Smart Cities: Conceptualization of the Cybersecurity-Based UTAUT Model,"This study aims to explore the challenges and issues in adopting cybersecurity practices in smart Saudi cities and to develop and validate a newly developed cybersecurity-based unified theory of acceptance and use of technology 3 (UTAUT3) model. The study has a twofold purpose. First, it identified the key challenges and issues in adopting smart cities in Saudi smart cities. Second, it developed a technology-based model to adopt cybersecurity practices in Saudi smart cities. Two surveys were conducted to achieve these objectives. The first survey identified challenges and gaps in adopting cybersecurity practices in smart cities, revealing concerns about weak cybersecurity platforms, privacy breaches, and the impact of IT infrastructure advancements on Saudi culture (N = 554: common public). The second survey focused on developing and validating a cybersecurity-based UTAUT3 model (N = 108: IT professionals), emphasizing nine factors: performance expectancy, effort expectancy, social influence, facilitating conditions, safety, resiliency, availability, confidentiality,",8
193edd20cae92c6759c18ce93eeea96afd9528eb,Deep learning in neural networks: An overview,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",14
ba74cce1724ec7635ee7943dcb6f921c5765d2dc,RePair: Automated Program Repair with Process-based Feedback,"The gap between the trepidation of program reliability and the expense of repairs underscores the indispensability of Automated Program Repair (APR). APR is instrumental in transforming vulnerable programs into more robust ones, bolstering program reliability while simultaneously diminishing the financial burden of manual repairs. Commercial-scale language models (LM) have taken APR to unprecedented levels. However, the emergence reveals that for models fewer than 100B parameters, making single-step modifications may be difficult to achieve the desired effect. Moreover, humans interact with the LM through explicit prompts, which hinders the LM from receiving feedback from compiler and test cases to automatically optimize its repair policies. In this literature, we explore how small-scale LM (less than 20B) achieve excellent performance through process supervision and feedback. We start by constructing a dataset named CodeNet4Repair, replete with multiple repair records, which supervises the fine-tuning of a foundational model. Building upon the encouraging outcomes of reinforcement",3
cb66dbe052c7343792516b6be9e17796f024ddc2,Deep recurrent neural network for IoT intrusion detection system,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
6912aca2fcb75c8a99948b9b557d8c2cd9f41599,Development of a Scale to Measure Cybercrime-Awareness on Social Media,"ABSTRACT This study developed a psychometric scale to measure users’ cybercrime awareness level on social media. Psychometric properties of the Cybercrime Awareness on Social Media Scale (CASM-S) were tested based on data collected from 1045 social media users. Exploratory factor analysis (EFA) with principal components analysis was used to identify the underlying factor structure of the scale (N = 545). The results revealed that the scale has a unidimensional factor structure. The scale was found to have a high internal reliability (α = .957). Confirmatory factor analysis (CFA) was conducted to verify factor structure of the CASM-S (N = 500). Results revealed that the one-factor model fits the data well (x 2/DF = 2.757, CFI = .939, SRMR = .0366, RMSEA = .059). Further, the study evaluated the concurrent validity of the scale (r = .855, p < .001). The findings revealed that the CASM-S is a reliable and valid",3
dd20ce4d2bac69111519d500b94879cccdbb35be,On Self-Security of Grid-Interactive Smart Inverters,"The capability to exchange information with utility operators, aggregators, and nearby smart devices can make a grid-interactive inverter an intelligent cyber-physical device. However, the capability of exchanging information can also put the inverters at the risk of insecure operation. In this paper, possible software manipulations into the inverters are studied to understand their vulnerability to cyber-attacks. Moreover, the state-of-the-art system-level and device-level cyber-defense measures are discussed, and advantages and drawbacks of each technique are provided. Studies show that a reference model can be implemented in device-level security to effectively examine incoming setpoints for detecting and preventing malicious or harmful actions. This paper particularly underlines the significance of device-level self-security and its advantages for grid-interactive inverters. Finally, recommendations for future studies are provided.",8
8218a27cf8e37758697ecd37a2d0795af43878cb,"Distributed Denial-of-Service (DDoS) Attacks and Defense Mechanisms in Various Web-Enabled Computing Platforms: Issues, Challenges, and Future Research Directions","The demand for Internet security has escalated in the last two decades because the rapid proliferation in the number of Internet users has presented attackers with new detrimental opportunities. One of the simple yet powerful attack, lurking around the Internet today, is the Distributed Denial-of-Service (DDoS) attack. The expeditious surge in the collaborative environments, like IoT, cloud computing and SDN, have provided attackers with countless new avenues to benefit from the distributed nature of DDoS attacks. The attackers protect their anonymity by infecting distributed devices and utilizing them to create a bot army to constitute a large-scale attack. Thus, the development of an effective as well as efficient DDoS defense mechanism becomes an immediate goal. In this exposition, we present a DDoS threat analysis along with a few novel ground-breaking defense mechanisms proposed by various researchers for numerous domains. Further, we talk about popular performance metrics that evaluate the defense",3
ed087b19cb55a30f095b751d71adc3eb384f5b7a,Enhancing Cyber Security in Industrial Internet of Things Systems: An Experimental Assessment,"In the digital age, Industry Control Systems (ICS) and the Industrial Internet of Things (IIoT) are having an impact on the operations of industry sectors. Although, with the development of technology even cyber-attacks have advanced in methods and techniques. The systems, which manage and control critical infrastructures such as power plants, manufacturing facilities, and transportation networks, are exposed to cyber-attacks. Nevertheless, security breaches can come from various cyber-attacks that target industrial systems, and in some cases, an infected device can affect the entire infrastructure in more disastrous attacks. This article digs into the existing models of ICS where we compare in terms of cyber-attacks, timely response, and impact control in the system is presented. This investigative work helps identify differences and create a proactive approach to security response. Finally, we will make an experimental assessment of the impact of security on existing models, in terms of recommendations for the advancement",5
a9f32a4801158a9432ece2158201cdbbcf2fcab4,"Leveraging AI/ML for anomaly detection, threat prediction, and automated response","The rapid evolution of information and communication technologies, notably the Internet, has yielded substantial benefits while posing challenges to information system security. With an increasing frequency of cyber threats—from unauthorized access to data breaches—the digital landscape's vulnerability is evident. Addressing the financial impact of cybercrime, this study delves into the role of Artificial Intelligence (AI) and Machine Learning (ML) technologies in cybersecurity. Analyzing advancements and outcomes, the research explores practical techniques for anomaly detection, threat prediction, and automated response. By investigating prior research and real-world implementations, the study provides valuable insights into the potential of AI/ML, uncovering current trends, challenges, and prospects in enhancing cybersecurity tactics amid a dynamically changing threat landscape.",6
6a97e8249f6bb0496bae7cf7790a60bf6bf4c1b1,Towards a Relation Extraction Framework for Cyber-Security Concepts,"In order to assist security analysts in obtaining information pertaining to their network, such as novel vulnerabilities, exploits, or patches, information retrieval methods tailored to the security domain are needed. As labeled text data is scarce and expensive, we follow developments in semi-supervised Natural Language Processing and implement a bootstrapping algorithm for extracting security entities and their relationships from text. The algorithm requires little input data, specifically, a few relations or patterns (heuristics for identifying relations), and incorporates an active learning component which queries the user on the most important decisions to prevent drifting from the desired relations. Preliminary testing on a small corpus shows promising results, obtaining precision of .82.",4
bc1022b031dc6c7019696492e8116598097a8c12,Natural Language Processing (Almost) from Scratch,"We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.",29
208dc9d832cf2888b8394d81f658bd856c7a0e81,Analysis of Consumer IoT Device Vulnerability Quantification Frameworks,"The increasing deployment of Internet of Things (IoT) devices in mission-critical systems has made them more appealing to attackers. Cyberattacks on IoT devices have the potential to expose sensitive data, disrupt operations, and even endanger lives. As a result, IoT security has recently gained traction in both industry and academia. However, no research has examined existing IoT vulnerability assessment frameworks in a systematic and comprehensive manner. To address this gap, this paper systematically reviews and analyses the research challenges and state-of-the-art IoT vulnerability assessment frameworks while taking into account both breadth and depth. The study provides insight into current IoT vulnerability assessment approaches, which is useful for ongoing efforts to characterise cybersecurity risks and manage IoT vulnerabilities. It will be of interest to a spectrum of readers, including those in the IoT research community, researchers in cybersecurity, risk and vulnerability management professionals, and others. By offering the latest perspective on",2
b10d3ef44f16f42999cbcbfe9dd65384775c1666,Cybersecurity in the Internet of Things in Industrial Management,"Nowadays, people live amidst the smart home domain, business opportunities in the industrial smart city and health care, though, along with concerns about security. Security is central for IoT systems to protect sensitive data and infrastructure, whilst security issues become increasingly expensive, in particular in Industrial Internet of Things (IIoT) domains. Nonetheless, there are some key challenges for dealing with those security issues in IoT domains: Applications operate in distributed environments such as Blockchain, varied smart objects are used, and sensors are limited in what comes to machine resources. In this way, traditional security does not fit in IoT systems. In this vein, the issue of cyber security has become paramount to the Internet of Things (IoT) and Industrial Internet of Things (IIoT) in mitigating cyber security risk for organizations and end users. New cyber security technologies / applications present improvements for IoT security management. Nevertheless, there is a gap",3
25b1c8045751777040f6c90df05c911bcab4f015,Protecting NextG Military Networks with Convolutional Neural Networks,"Nowadays, defense applications consider 5G networks to meet the requirements of the military communications. However, security aspects must be improved to face the challenges of the operational scenarios. Additionally, advanced AI-based security measures are being investigated in forthcoming NextG networks to detect and adapt to emerging threats. In this context, the integration of computer vision techniques in cybersecurity is very promising.In this paper we present a computationally-efficient real-time approach to convert network packets into images directly at base stations. This lightweight implementation aligns well with NextG real-time demands, allowing for the identification of threats at their source. Then we developed a custom Convolutional Neural Network (CNN) operating on the converted packets and aimed at intrusion detection in current and future wireless networks.We then evaluated the performance of this approach to identify and detect malicious content in network traffic utilizing a recent dataset built on a 5G network. Results demonstrate that",5
9688aa6337ef58c9ae921092e1159e65e69b22d7,Algorithmic predictions and pre-emptive violence: artificial intelligence and the future of unmanned aerial systems,"The military rationale of a pre-emptive strike is predicated upon the calculation and anticipation of threat. The underlying principle of anticipation, or prediction, is foundational to the operative logic of AI. The deployment of predictive, algorithmically driven systems in unmanned aerial systems (UAS) would therefore appear to be all but inevitable. However, the fatal interlocking of martial paradigms of pre-emption and models of predictive analysis needs to be questioned insofar as the irreparable decisiveness of a pre-emptive military strike is often at odds with the probabilistic predictions of AI. The pursuit of a human right to protect communities from aerial threats needs to therefore consider the degree to which algorithmic auguries—often erroneous but nevertheless evident in the prophetic mechanisms that power autonomous aerial apparatuses—essentially authorise and further galvanise the long-standing martial strategy of pre-emption. In the context of unmanned aerial systems, this essay will outline how AI actualises and summons",5
6a384fe76918f761e287341c2f55abf87d48156b,A Brief Survey on Important Interconnection Standards for Photovoltaic Systems and Electric Vehicles,"The consumer adoption of electric vehicles (EVs) has become most popular. Numerous studies are being carried out on the usage of EVs, the challenges of EVs, and their benefits. Based on these studies, factors such as battery charging time, charging infrastructure, battery cost, distance per charge, and the capital cost are considered factors in the adoption of electric vehicles and their interconnection with the grid. The large-scale development of electric vehicles has laid the path to Photovoltaic (PV) power for charging and grid support, as the PV panels can be placed at the top of the smart charging stations connected to a grid. By proper scheduling of PV and grid systems, the V2G connections can be made simple. For reliable operation of the grid, the ramifications associated with the PV interconnection must be properly addressed without any violations. To overcome the above issues, certain standards can be imposed on these",4
214afdf4872f2c1ddc4fbdebb56557589b8cd95b,Enhancing Security in DevOps by Integrating Artificial Intelligence and Machine Learning,"In modern software development and operations, DevOps (a combination of development and operations) has become a key methodology aimed at accelerating delivery, improving quality and enhancing security. Meanwhile, artificial intelligence (AI) and machine learning (ML) are also playing an increasingly important role in cybersecurity, helping to identify and respond to increasingly complex threats. In this article, we'll explore how AI and ML can be integrated into DevOps practices to ensure the security of software development and operations processes. We'll cover best practices, including how to use AI and ML for security-critical tasks such as threat detection, vulnerability management, and authentication. In addition, we will provide several case studies that show how these technologies have been successfully applied in real projects and how they have improved security, reduced risk and accelerated delivery. Finally, through this article, readers will learn how to fully leverage AI and ML in the DevOps process to",4
1f2ab27ec02a013d62b68d8c90b01b1b231e5141,The role of Big Data and Data Science in the context of information security and cybersecurity,"In the area of the fastest growing fields of ICT technology which determine the successive stages of progress in the field of online electronic banking, it is necessary to disseminate standards for conducting financial operations carried out in the so-called cloud as well as using the large data sets located in the so-called Big Data platforms.For the purposes of this article, research has been carried out on the broad issue of Big Data Analytics applications in the context of social, normative, economic, environmental, climate aspects. A questionnaire survey was conducted. The method of analysis of literature sources concerning the subject of the article was applied.Currently emerging trends in the development of technology based on Big Data dataset platforms usually allow to perform multidimensional calculations and reported results of analyzes in real time. The analyzes conducted on huge data sets allow for comprehensive, multi-aspect risk assessments at the level of the",6
51b89265c095a4d2ed5f7b92adf772c0a3b60bd8,Cyber Threat Intelligence Sharing for Co-Operative Defense in Multi-Domain Entities,"Cloud-hosted applications are prone to targeted attacks such as DDoS, advanced persistent threats, Cryptojacking which threaten service availability. Recently, methods for threat information sharing and defense require cooperation and trust between multiple domains/entities. There is a need for mechanisms that establish distributed trust to allow for such a collective defense. In this paper, we present a novel threat intelligence sharing and defense system, namely “DefenseChain,” to allow organizations to have incentive-based and trustworthy cooperation to mitigate the impact of cyber attacks. Our solution approach features a consortium Blockchain platform and an economic model to obtain threat data and select suitable peers to help with attack detection and mitigation. We apply DefenseChain in the financial technology industry for an insurance claim processing use case to demonstrate the effectiveness of DefenseChain in a real-world application setting. Our evaluation experiments with DefenseChain implementation are performed on an Open Cloud testbed with Hyperledger Composer",5
98a71b310ce8a9e796d15f295a447cce3bb29e11,"Review of Electric Vehicle Charger Cybersecurity Vulnerabilities, Potential Impacts, and Defenses","Worldwide growth in electric vehicle use is prompting new installations of private and public electric vehicle supply equipment (EVSE). EVSE devices support the electrification of the transportation industry but also represent a linchpin for power systems and transportation infrastructures. Cybersecurity researchers have recently identified several vulnerabilities that exist in EVSE devices, communications to electric vehicles (EVs), and upstream services, such as EVSE vendor cloud services, third party systems, and grid operators. The potential impact of attacks on these systems stretches from localized, relatively minor effects to long-term national disruptions. Fortunately, there is a strong and expanding collection of information technology (IT) and operational technology (OT) cybersecurity best practices that may be applied to the EVSE environment to secure this equipment. In this paper, we survey publicly disclosed EVSE vulnerabilities, the impact of EV charger cyberattacks, and proposed security protections for EV charging technologies.",4
f73c5f51f4edbb5f6ee7e5c1c6c75231dedaa758,LICALITY—Likelihood and Criticality: Vulnerability Risk Prioritization Through Logical Reasoning and Deep Learning,"Security and risk assessment aims to prioritize detected vulnerabilities for remediation in a computer networking system. The widely used expert-based risk prioritization approach, e.g., Common Vulnerability Scoring System (CVSS), cannot realistically associate vulnerabilities to the likelihood of exploitation. The CVSS metrics are calculated from static formulas, and cannot easily integrate attackers’ motivations and capabilities w.r.t. the network environmental factors. To address this issue, this paper proposes LICALITY, a vulnerability risk prioritization system. LICALITY captures the attacker’s preference on exploiting vulnerabilities through a threat modeling method, and learns threat attributes that contribute to the exploitation of vulnerability. LICALITY creatively uses a neuro-symbolic model, with neural network (NN) and probabilistic logic programming (PLP) techniques, to learn such threat attributes. The risk of vulnerability is assessed from the criticality of exploitation and the likelihood of exploitation. LICALITY consolidates these two measurements by using a logic reasoning engine. In the evaluation, the historical threat",5
8d59057fd7555e22e7b557b332e9b389ad4ecf28,Image Steganography Based on Chaos Function and Randomize Function,"The exchange of data is not limited to personal text information or information about institutions and governments, but includes digital media transferred via the Internet including everything, whether texts, images or videos and audio, or animation. These media need high-security protection and high speed during its transmission from one site to another. In this study, a new method is suggested for hiding a gray-level image within a larger color image based on the proposed steganography map that merged chaotic function and randomize function. The size of the chaos and randomize functions is 16 bytes. Experimental results obtained a successful method based on mean squared error, signal-to-noise ratio, peak signal noise rate, embedding capacity, entropy, and histogram. This method can rapidly hide and extract ciphertext in and from the gray image. The original image and the stego image are difficult to distinguish because the correlation between them is very close to",7
9bb8ec2f8cf36d66e68699812a28abfe4a0c3c8f,Digital advantage in the COVID-19 response: perspective from Canada’s largest integrated digitalized healthcare system,"The SARS-CoV-2 pandemic has challenged healthcare systems worldwide. Uncertainty of transmission, limitations of physical healthcare system infrastructure and supplies as well as workforce shortages require dynamic adaption of resource deployment to manage rapidly evolving care demands, ideally based on real time data for the entire population. Moreover, shut down of traditional face-to-face care infrastructure requires rapid deployment of virtual health care options to avoid collapse of health organizations. The Alberta Electronic Health Record Information System is one of the largest population based comprehensive electronic medical record (EMR) installations. Alberta’s long standing solid telehealth hardware-, training-, provider remuneration- and legislation infrastructure has enabled quick transition to virtual healthcare. Virtual health services including asynchronous secure clinical communications, real-time virtual care via messaging, telephony or video conferencing (telehealth) and ancillary functions like triage, scheduling, documentation and reporting, the previously established virtual hospital program with home monitoring, virtual health assessments, medication review, education and",4
61ec8c528d74d11f8bce9502bc56ae843877e5ee,Distinctive Assessment of Neural Network Models in Stock Price Estimation,"INTRODUCTION: Due to its potential to produce substantial returns and reduce risks, stock price prediction has garnered a lot of attention in the financial markets. OBJECTIVES: A comparison of neural network models for stock price prediction is presented in this research report. METHODS: Through this study, I aim to compare, on the basis of the precision and accuracy, the performance of different neural network models for stock price prediction. LSTM model along with RNN model accuracy in predicting the next day’s stock price i.e., which model can predict closest to the actual value. RESULTS: It is found that LSTM works better than RNN in predicting a value closer to the actual open price stock value. CONCLUSION: A comparison between the models shows LSTM is the more accurate model.",3
dcda693a003c88b8a81a01d7b61821e304969d21,Evaluating the Performance of Different Large Language Models on Health Consultation and Patient Education in Urolithiasis,"Objectives To evaluate the effectiveness of four large language models (LLMs) (Claude, Bard, ChatGPT4, and New Bing) that have large user bases and significant social attention, in the context of medical consultation and patient education in urolithiasis. Materials and methods In this study, we developed a questionnaire consisting of 21 questions and 2 clinical scenarios related to urolithiasis. Subsequently, clinical consultations were simulated for each of the four models to assess their responses to the questions. Urolithiasis experts then evaluated the model responses in terms of accuracy, comprehensiveness, ease of understanding, human care, and clinical case analysis ability based on a predesigned 5-point Likert scale. Visualization and statistical analyses were then employed to compare the four models and evaluate their performance. Results All models yielded satisfying performance, except for Bard, who failed to provide a valid response to Question 13. Claude consistently scored the highest in all dimensions compared with",3
8a9766e4e456a2c2ecef2c57f8d285b3157d05f0,"Mitigating the Risk of Advanced Cyber Attacks: The Role of Quality, Covertness and Intensity of Use of Cyber Weapons","ABSTRACT Modern countries employ computer networks that manage organizations in the private and public sectors. Cyber-attacks aim to disrupt, block, delete, manipulate or steal the data held in these networks, which challenge these countries’ national security. Consequently, cybersecurity programs must be developed to protect these networks from cyber-attacks in a manner that is similar to operations against terrorism. This study presents several models that analyze a contest between a network operator (defender) that deploys costly detectors to protect the network and a capable cyber attacker. Generally, when the deployed detectors become more potent or the defender exhibits higher vigilance, the attacker allocates more resources to R&D to ensure that the attack remains covert. We show that detectors may be substitutes, complements, or even degrade each other, implying that defenders must account for the cyber weapons’ characteristics and the attacker’s profile and strategic behavior. We derive the optimal number of detectors",5
4ae2d949c0c1c73c90a9a17e55821ed5eb4dfa59,Cybersecurity Threats in Healthcare Organizations: : Exposing Vulnerabilities in the Healthcare Information Infrastructure,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
f092a9b51ccaddc64064585e077683a1067dc90e,Enhancing Automated Program Repair with Solution Design,"Automatic Program Repair (APR) endeavors to autonomously rectify issues within specific projects, which generally encompasses three categories of tasks: bug resolution, new feature development, and feature enhancement. Despite extensive research proposing various methodologies, their efficacy in addressing real issues remains unsatisfactory. It’s worth noting that, typically, engineers have design rationales (DR) on solution— planed solutions and a set of underlying reasons—before they start patching code. In open-source projects, these DRs are frequently captured in issue logs through project management tools like Jira. This raises a compelling question: How can we leverage DR scattered across the issue logs to efficiently enhance APR?To investigate this premise, we introduce DRCodePilot, an approach designed to augment GPT-4-Turbo’s APR capabilities by incorporating DR into the prompt instruction. Furthermore, given GPT-4’s constraints in fully grasping the broader project context and occasional shortcomings in generating precise identifiers, we have devised a feedback-based self-reflective framework, in which we",6
d6d385b3d6770134e1af8b1d92f89077e20ea184,INDIA'S CYBER WARFARE CAPABILITIES: REPERCUSSIONS FOR PAKISTAN'S NATIONAL SECURITY,"Cyber warfare refers to a state's ability to penetrate another state's digital systems to cause disruption. Cyber warfare has emerged as the fifth operational warfighting domain. India has been strengthening its cyber warfare capabilities for a long time, which can seriously affect Pakistan. Considering the theoretical constructs of Barry Buzan and Ole Waever regarding the broader concept of security, this paper aims to highlight the possible threats and security challenges that India's cyberspace can pose to Pakistan's national security. The paper argues that India has acquired a robust cyberspace that can potentially cause financial damage, political instability, societal unrest, and radicalisation in Pakistan's society. Furthermore, strong cyberspace can also challenge nuclear deterrence between the two neighbours, thus threatening military security. The paper concludes with recommendations regarding what Pakistan can do to mitigate this growing cyber threat. Bibliography Entry Ashraf, Nageen and Dr. Saima Ashraf Kayani (2023) “India's Cyber Warfare Capabilities:",4
71746704500b5162e25952f6b6b069f827573813,Behavioral Analysis of Cybercrime: Paving the Way for Effective Policing Strategies,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
aec1df9adf9743a71832e7b5107ced522d587ec7,BEST—Blockchain-Enabled Secure and Trusted Public Emergency Services for Smart Cities Environment,"In the last few years, the Internet of things (IoT) has recently gained attention in developing various smart city applications such as smart healthcare, smart supply chain, smart home, smart grid, etc. The existing literature focuses on the smart healthcare system as a public emergency service (PES) to provide timely treatment to the patient. However, little attention is given to a distributed smart fire brigade system as a PES to protect human life and properties from severe fire damage. The traditional PES are developed on a centralised system, which requires high computation and does not ensure timely service fulfilment. Furthermore, these traditional PESs suffer from a lack of trust, transparency, data integrity, and a single point of failure issue. In this context, this paper proposes a Blockchain-Enabled Secure and Trusted (BEST) framework for PES in the smart city environment. The BEST framework focuses on providing a fire brigade service as",6
891275fefc1e09f7199f4ae5c392bea1437f5f38,Securing the Cyber Resilience of a Blockchain-Based Railroad Non-Stop Customs Clearance System,"Current railroad customs clearance systems are problematic in that the movement of trains is occasionally restricted for extended periods during inspections to verify cargo integrity at customs clearance. Consequently, significant human and material resources are consumed to obtain customs clearance to the destination, considering different processes exist for cross-border trade. Therefore, we developed a cross-border blockchain-based non-stop customs clearance (NSCC) system to address these delays and reduce resource consumption for cross-border trains. The integrity, stability, and traceability of blockchain technology are used to construct a stable and reliable customs clearance system to address these problems. The proposed method connects diverse trade and customs clearance agreements in a single blockchain network, which ensures integrity and minimal resource consumption, and includes railroads, freight vehicles, and transit stations in addition to the current customs clearance system. The integrity and confidentiality of customs clearance data are protected using sequence diagrams and the blockchain to",2
7a9dfd61a7002295b4a474c039d0b93dba75f1fb,"Tactics, Techniques and Procedures of Cybercrime: A Methodology and Tool for Cybercrime Investigation Process","Individuals, organizations and nation-states are increasingly falling victim to cyberattacks. A lot of research on how to understand the modus operandi of a cyber attacker through the MITRE ATT&CK framework, CAPEC enumeration and various cyber kill chain frameworks has been available for cyber incident responders for both pre-attack defensive posture preparation as well as post-attack mapping of the indicators. Cybercrime, on the other hand, has a very different set of motives, majorly financial, but also impersonation, harassment and hate crimes, which are targeted mostly towards individuals who are vulnerable. Investigative officers in cyber cells around the world use various investigative processes in their attempt to solve a cybercrime incident, detect the criminal(s), recover the lost money, shut down the accounts of perpetrators, or bring down the cyber-criminal gangs involved in reported cybercrime incidents. However, to the best of our knowledge, there is no framework to map the cybercrime incident narratives",3
960ad94cda39471cb5cefb94d05434e6b5b11c1f,"Security Threats, Countermeasures, and Challenges of Digital Supply Chains","The rapid growth of Information Communication Technologies (ICT) has impacted many fields. In this context, the supply chain has also quickly evolved toward the digital supply chain where digital and electronic technologies have been integrated into every aspect of its end-to-end process. This evolution provides numerous benefits such as profit maximization, loss reduction, and the optimization of supply chain lead times. However, the use of such technologies has also considerably opened up various security threats and risks which have widened the attack surface on the entire end-to-end supply chain. We present a holistic survey on supply chain security. We discuss the different security issues and attacks that target the different supply chain technologies. Then, we discuss various countermeasures and security solutions proposed by academic and industry researchers to mitigate the identified threats. Finally, we provide some recommendations and best practices that can be adopted to achieve a secure supply chain.",7
0c2b7130b433c4f7b5bb64479756d3c5adebfba6,Cyber Resilience: Research Opportunities,"Cyber attacks are considered the most dangerous threat to the world today. Cyber resilience involves multiple factors including industry, government, research institutions, and society. A new area of expertise, known as cyber resilience, has surfaced to tackle cyber issues that are beyond the scope of traditional cybersecurity. To control physical processes, attacks on these systems can have real-world consequences that can be detrimental. Therefore, cyber resilience is a fundamental attribute to ensure controlled human, environmental, and physical process security. By utilizing a thorough investigation and a cyber resilience matrix, this research examines the existing literature to seize the fundamental concepts of cyber resilience. The assessment focuses on measuring the capacity to recuperate from cyber threats and emphasizes the significance of offerings like reacting to unforeseen events, collecting information, and safeguarding strategies. As cyber resilience is closely associated with the internet, it plays a crucial role in shaping the future and",4
a7619004c1debcfe9b1854f7e50853a32b24ae29,Lithium-Ion Batteries—The Crux of Electric Vehicles with Opportunities and Challenges,"With the widespread use of lithium-ion batteries in a wide range of consumer electronics products, the CE industry has undergone a dramatic shift. The Li-ion battery has emerged as the heart of electric cars, and the focus has now shifted to the automotive sector. Liquid crystal displays have evolved over time to meet the demands of automobiles. International research groups and the performance of production electric vehicles are used to discuss and inform vehicle-driven battery targets. There is still a lot of room for improvement in terms of energy, life expectancy, cost, safety, and fast-charging capabilities for LIBs suited for the automotive sector. In this study, a review of lithium-ion battery applications in electric vehicles is presented.",4
949577343abbf4c292558b19ba3cd17c13adf3eb,When ChatGPT Meets Smart Contract Vulnerability Detection: How Far Are We?,"With the development of blockchain technology, smart contracts have become an important component of blockchain applications. Despite their crucial role, the development of smart contracts may introduce vulnerabilities and potentially lead to severe consequences, such as financial losses. Meanwhile, large language models, represented by ChatGPT, have gained great attentions, showcasing great capabilities in code analysis tasks. In this paper, we presented an empirical study to investigate the performance of ChatGPT in identifying smart contract vulnerabilities. Initially, we evaluated ChatGPT's effectiveness using a publicly available smart contract dataset. Our findings discover that while ChatGPT achieves a high recall rate, its precision in pinpointing smart contract vulnerabilities is limited. Furthermore, ChatGPT's performance varies when detecting different vulnerability types. We delved into the root causes for the false positives generated by ChatGPT, and categorized them into four groups. Second, by comparing ChatGPT with other state-of-the-art smart contract vulnerability detection tools, we found that",5
7e8f1c14d73394fbc1576414c8d07b69bdb90636,Feed-Forward Deep Neural Network (FFDNN)-Based Deep Features for Static Malware Detection,"The portable executable header (PEH) information is commonly used as a feature for malware detection systems to train and validate machine learning (ML) or deep learning (DL) classifiers. We propose to extract the deep features from the PEH information through hidden layers of a feed-forward deep neural network (FFDNN). The extraction of deep features of hidden layers represents the dataset with a better generalization for malware detection. While feeding the deep feature of one hidden layer to the succeeding layer, the Gaussian error linear unit (GeLU) activation function is applied. The FFDNN is trained with the GeLU activation function using the deep features of individual layers as well as concatenated deep features of all hidden layers. Similarly, the ML classifiers are also trained and validated in with individual layer deep features and concatenated features. Three highly effective ML classifiers, random forest (RF), support vector machine (SVM), and k-nearest neighbour (k-NN)",4
e797d46d3825f8d421b7ca7e8cf99d04ba363e2b,ADAPTING TO CYBERSECURITY CHALLENGES: ASSESSING THE EFFECTIVENESS OF INTERNATIONAL LAW AGAINST CYBER TERRORISM,"The study critically examines current condition of global rule in resolving the developing hazard of cyber terrorism. The research dives right into the complexities and problems posed by cyber terrorism as well as reviews the effectiveness of existing lawful platforms in responding to this progressing threat. Employing a diverse series of academic jobs, the study investigates the requirements for brand-new global lawful frameworks, developments in cybercrime inspection as well as digital forensics, as well as the function of surfacing modern technologies in rule administration. Also, the report stresses the significance of enhancing global cyber resilience and response abilities by means of worldwide teamwork and collaboration. The study's searching highlights varied attributes of cyber violence and demand for a complete, collaborated, and international reaction to fight this threat. The analysis uses valuable knowledge right into advancement of brand-new lawful platforms, technologies in cybercrime examination & enlargement of global cyber resilience to",4
9cb64447592f993eb9d231a9cd44fd52aa143083,Transformative Metamorphosis in Context to IoT in Education 4.0,"In the modern technology-driven era, it is important to consider a new model of education to keep pace with Industry 4.0. In view of this, the present paper critically explores the issues, discusses potential solutions along with a comprehensive analysis of the applications of technologies such as Internet of Things (IoT) in modern education specially Education 4.0, and examines the potential of these technologies to transform the education sector. The challenges faced by previous education models are analysed along with how they pave the way to the inclusion of IoT in education, leading to Education 4.0. The potential benefits of IoT in improving learning outcomes, enhancing student engagement and retention, and supporting teachers are also highlighted. In addition, it addresses the ethical and privacy concerns associated with the use of these technologies and suggests areas for future research.",2
84c3c50d23bdb72d0c558cce5bbd5ad19348bb82,Integrating cybersecurity risk management into strategic management: a comprehensive literature review,"Purpose- This literature review aims to delve into the nexus between cybersecurity risk management and strategic management, comprehensively exploring how organizations weave risk management strategies into their broader strategies to safeguard digital assets and infrastructure against the backdrop of ever-evolving cyber threats. Methodology- The review employs a qualitative methodology, synthesizing insights from a diverse selection of scholarly works encompassing cybersecurity, risk management, and strategic management. These insights are analyzed to unveil patterns and trends that highlight the integration of cybersecurity risk management within strategic organizational frameworks. Findings- The review uncovers a critical interdependence between cybersecurity risk management and strategic management, showcasing how organizations formulate proactive measures to mitigate cyber risks while aligning them with overarching strategic goals. It also underscores the role of organizational culture, leadership commitment, and technological advancements in shaping effective cybersecurity risk management strategies. Conclusion- The synthesis of scholarly findings accentuates the pivotal role of cybersecurity risk",3
ae3cfed909596eec94d90dc18c05e56ae03d82f7,Definition and Classification of Power System Stability – Revisited & Extended,"Since the publication of the original paper on power system stability definitions in 2004, the dynamic behavior of power systems has gradually changed due to the increasing penetration of converter interfaced generation technologies, loads, and transmission devices. In recognition of this change, a Task Force was established in 2016 to re-examine and extend, where appropriate, the classic definitions and classifications of the basic stability terms to incorporate the effects of fast-response power electronic devices. This paper based on an IEEE PES report summarizes the major results of the work of the Task Force and presents extended definitions and classification of power system stability.",5
e4bb2cebe117ccb520210e5510b9729bd9db2f09,MEFF - A model ensemble feature fusion approach for tackling adversarial attacks in medical imaging,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
4bc6b574f249ee4fac24de114b99eff56bed6b32,TIM: threat context-enhanced TTP intelligence mining on unstructured threat data,"TTPs (Tactics, Techniques, and Procedures), which represent an attacker’s goals and methods, are the long period and essential feature of the attacker. Defenders can use TTP intelligence to perform the penetration test and compensate for defense deficiency. However, most TTP intelligence is described in unstructured threat data, such as APT analysis reports. Manually converting natural language TTPs descriptions to standard TTP names, such as ATT&CK TTP names and IDs, is time-consuming and requires deep expertise. In this paper, we define the TTP classification task as a sentence classification task. We annotate a new sentence-level TTP dataset with 6 categories and 6061 TTP descriptions from 10761 security analysis reports. We construct a threat context-enhanced TTP intelligence mining (TIM) framework to mine TTP intelligence from unstructured threat data. The TIM framework uses TCENet (Threat Context Enhanced Network) to find and classify TTP descriptions, which we define as three continuous sentences, from textual",2
46d3d6afce8aa68919a32290508d07eff59beeac,Detection and Diagnosis of Data Integrity Attacks in Solar Farms Based on Multilayer Long Short-Term Memory Network,"Photovoltaic (PV) systems are becoming more vulnerable to cyber threats. In response to this emerging concern, developing cyber-secure power electronics converters has received increased attention from the IEEE Power Electronics Society that recently launched a cyber-physical-security initiative. This letter proposes a deep sequence learning based diagnosis solution for data integrity attacks on PV systems in smart grids, including dc–dc and dc–ac converters. The multilayer long short-term memory networks are used to leverage time-series electric waveform data from current and voltage sensors in PV systems. The proposed method has been evaluated in a PV smart grid benchmark model with extensive quantitative analysis. For comparison, we have evaluated classic data-driven methods, including $K$-nearest neighbor, decision tree, support vector machine, artificial neural network, and convolutional neural network. Comparison results verify performances of the proposed method for detection and diagnosis of various data integrity attacks on PV systems.",3
23a2e6492a90da085254ce7d6df211112712a45e,SAHEFT: Security Aware Heterogeneous Earliest Finish Time Workflow Allocation Strategy for IaaS Cloud Environment,"Security is one of the most emerging issues in the real-life scientific workflow's applications such as online marketing, big data, digital transaction etc. Cloud computing infrastructure is a platform that provides dynamically scalable on demand services. However, cloud users are to pay attention to the cost incurred with pay-per-use pricing model by leasing virtual machines (VMs) from cloud centers. IT companies and scientists are facing challenges of demanded Quality of service (QoS) in IaaS cloud environment. Therefore, many researchers making effort to achieve better performance for secure workflow allocation on heterogeneous virtual machines. In this paper, a Security Aware Heterogeneous Earliest Finish Time (SAHEFT), a list-based workflow allocation strategy for single workflow to optimize guarantee ratio has been proposed for IaaS cloud environment. SAHEFT has been compared with a standard algorithm, namely HEFT, to evaluate the performance. Experimental results shows the significantly improved performance of SAHEFT over HEFT by 32.11%",2
c7ad76dcc2b00529814610cdd530c1173c2e26ad,Cyber Efficiency and Cyber Resilience,Complementary objectives competing for the same resources.,6
cbdfa5f60f72a0a99257c04060ad5fd6256b0194,A tree-based stacking ensemble technique with feature selection for network intrusion detection,"Several studies have used machine learning algorithms to develop intrusion systems (IDS), which differentiate anomalous behaviours from the normal activities of network systems. Due to the ease of automated data collection and subsequently an increased size of collected data on network traffic and activities, the complexity of intrusion analysis is increasing exponentially. A particular issue, due to statistical and computation limitations, a single classifier may not perform well for large scale data as existent in modern IDS contexts. Ensemble methods have been explored in literature in such big data contexts. Although more complicated and requiring additional computation, literature has a note that ensemble methods can result in better accuracy than single classifiers in different large scale data classification contexts, and it is interesting to explore how ensemble approaches can perform in IDS. In this research, we introduce a tree-based stacking ensemble technique (SET) and test the effectiveness of the proposed",5
f5256b83f435b4d79b3c48a33b5fffc3cbf0209b,Perturbation-Based Diagnosis of False Data Injection Attack Using Distributed Energy Resources,"Modern smart grid relies on various sensor measurements for its operational control. In a successful false data injection attack, the attacker manipulates the measurements from the grid sensors such that undetected errors are introduced into the estimates of the system parameters leading to catastrophic situations. This article proposes a novel perturbation based false data injection attack detection mechanism that utilizes inverter based distributed energy resources (DERs) to create low magnitude perturbation signal in the distribution system voltage that is inconsequential to the normal grid operation. Two voltage sensitivity analysis based algorithms are designed to identify the optimal set of DERs that can create the voltage perturbation signal of desired magnitude. An analytical method of voltage sensitivity analysis is used to compute the magnitude of voltage perturbation signal at each node in a computationally efficient manner. Then, a detection mechanism is developed that checks for the presence of the perturbation sequence",3
d82fee95c37e2df2e0b5e46cc62c5a0bb3ba34aa,Cyber Attack Detection and Correction Mechanisms in a Distributed DC Microgrid,"DC microgrids (DCMGs) are evolving into cyber-physical systems with advanced communication networks and computational methodologies, making them sensitive to cyber-attacks. These attacks can threaten the safe operation of a system. In this article, a virtual sensor-based framework is proposed for continuously monitoring and detecting malicious activities at the hardware level of a DCMG system. An adaptive state observer with a low computational burden is designed to estimate the voltage and current of a dc–dc converter. The proposed method considers the effects of cyber-attacks by injecting false data (FD) at targeted nodes in an attempt to affect the voltage regulation and current sharing by modifying the onboard voltage and current sensors. In the presented strategy, first, a DCMG is operated and controlled without any false data injecting attacks with different load conditions. Next, the DCMG is exposed to various cyber-attacks, and the output voltages and currents of dc–dc converters are estimated.",2
891e3e29adde8ede3f14fdb804328c800db43138,Analysis of Deep Learning in Real-World Applications: Challenges and Progress,"Deep Learning (DL), a subset of machine learning (ML) based on artificial neural networks, has experienced significant advancements in recent years. While it has demonstrated remarkable capabilities in various domains, the true potential of DL shines when it is applied to real-world problems. This article delves into the fascinating world of deep learning in real-world applications, highlighting its impact, challenges, and future prospects. the translation of DL research into real-world applications presents a unique set of challenges. While DL models exhibit remarkable performance in controlled environments, their practical deployment is often impeded by issues related to data availability, model interpretability, ethical considerations, and computational requirements. This paper aims to provide a comprehensive analysis of the progress and challenges associated with deploying deep learning in real-world scenarios. Deep learning is the subset of man-made intelligence technique where there are number of layers of data which are tended to as neurons and",3
9e181105e907d41fde8094f00c4cb093f43e282c,TriCTI: an actionable cyber threat intelligence discovery system via trigger-enhanced neural network,"The cybersecurity report provides unstructured actionable cyber threat intelligence (CTI) with detailed threat attack procedures and indicators of compromise (IOCs), e.g., malware hash or URL (uniform resource locator) of command and control server. The actionable CTI, integrated into intrusion detection systems, can not only prioritize the most urgent threats based on the campaign stages of attack vectors (i.e., IOCs) but also take appropriate mitigation measures based on contextual information of the alerts. However, the dramatic growth in the number of cybersecurity reports makes it nearly impossible for security professionals to find an efficient way to use these massive amounts of threat intelligence. In this paper, we propose a trigger-enhanced actionable CTI discovery system (TriCTI) to portray a relationship between IOCs and campaign stages and generate actionable CTI from cybersecurity reports through natural language processing (NLP) technology. Specifically, we introduce the “campaign trigger” for an effective explanation of the campaign stages",8
6be8c12c930b42466accf1abf10254cff77c78a8,"From 5G to beyond 5G: A Comprehensive Survey of Wireless Network Evolution, Challenges, and Promising Technologies","The histrionic growth of mobile subscribers, disruptive ecosystems such as IoT-based applications, and astounding channel capacity requirements to connect trillions of devices are massive challenges of the earlier mobile generations, 5G turned up the key solution. The prime objective of the 5G network is not only to maintain a 1000-fold capacity gain and 10 Giga Bits per second delivered to a single user, but it also assured quality-of-service, higher spectral efficiency, the ultra-reliable and improved battery lifetime of devices and massive machine-type communication (mMTC). The huge traffic load and high amount of resource consumption in 5G applications, augmented reality and virtual reality for magnificent virtual experience, and wireless body area networks will seriously affect the channel capacity of cellular cells and interrupt the admission and service of other users which makes compulsory new means of channel capacity and spectral efficiency enhancement techniques. In this research, we review several key emerging",5
86e88ae8049cd84c0922893ba1501079428f2164,Blockchain-Based Data Access Control and Key Agreement System in IoT Environment,"Recently, with the increasing application of the Internet of Things (IoT), various IoT environments such as smart factories, smart homes, and smart grids are being generated. In the IoT environment, a lot of data are generated in real time, and the generated IoT data can be used as source data for various services such as artificial intelligence, remote medical care, and finance, and can also be used for purposes such as electricity bill generation. Therefore, data access control is required to grant access rights to various data users in the IoT environment who need such IoT data. In addition, IoT data contain sensitive information such as personal information, so privacy protection is also essential. Ciphertext-policy attribute-based encryption (CP-ABE) technology has been utilized to address these requirements. Furthermore, system structures applying blockchains with CP-ABE are being studied to prevent bottlenecks and single failures of cloud servers, as well as to support",4
270b015093073d3ba254928b6d736a59870d3fb1,Chatbots As Fluent Polyglots: Revisiting Breakthrough Code Snippets,"The research applies AI-driven code assistants to analyze a selection of influential computer code that has shaped modern technology, including email, internet browsing, robotics, and malicious software. The original contribution of this study was to examine half of the most significant code advances in the last 50 years and, in some cases, to provide notable improvements in clarity or performance. The AI-driven code assistant could provide insights into obfuscated code or software lacking explanatory commentary in all cases examined. We generated additional sample problems based on bug corrections and code optimizations requiring much deeper reasoning than a traditional Google search might provide. Future work focuses on adding automated documentation and code commentary and translating select large code bases into more modern versions with multiple new application programming interfaces (APIs) and chained multi-tasks. The AI-driven code assistant offers a valuable tool for software engineering, particularly in its ability to provide human-level",2
d45b87f56d02f702350267b5af1276cf41361003,Strategic Expansion and Dynamic Capacity Enhancement in Lion Tourism: Analyzing Advanced Deployment for Sustainable Growth,"Sustained growth and competitive advantage have always been the goals that enterprises strive to find and practice. This study uses the ""positioning"", ""process"" and ""path"" aspects of the dynamic capability perspective, and divides the stages according to ""time sequence"", to explore how enterprises adjust their organizational structure and practices in order to enhance their competitive advantages in a rapidly changing environment. Adapt to changing environments. This study uses a single case study to summarize the 35-year development process of Lion Tourism; summarizes the ""events"" that occurred in the ""time sequence"" into the perspective of dynamic capabilities, and explains how Lion Tourism responds to opportunities, advances deployment, and quickly adjusts Organizational structure and development strategy to ensure continuous growth and competitive advantage. Dynamic capabilities are more suitable for application in industries with rapidly changing environments. However, through the events experienced by the case companies, the theoretical model of the empirical dynamic",5
c69795c4c31d3189a1fe77e4e5d8b202ab7b8db1,A deeper look into cybersecurity issues in the wake of Covid-19: A survey,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
7e2d914e62138ce6113305b67631b2271c3d3773,The Role of Digital Technologies in Open Innovation Processes: An Exploratory Multiple Case Study Analysis,"Digital transformation has undoubtedly become a key enabler of innovation as evidenced by the numerous firms that use digital technologies to manage their innovation processes. This issue is even more relevant today when innovation processes have become more open and require greater resources in the different implementation phases to capture and transfer knowledge within and outside the firm's boundaries. This implies additional challenges in managing the increasing amount of knowledge and information flows. Accordingly, digital technologies can be used and implemented to manage open innovation processes through easier access and sharing the knowledge created and transferred. Nevertheless, literature in these fields does not provide a structured view of how and why digital technologies are used to manage innovation processes in an open perspective. This paper aims to bridge this gap by adopting the theoretical lenses of change management to identify the managerial actions at organizational and process level that companies",3
306627dfa6a7f595676e7d0ac74f6162fdcb37f1,"Mobile Data Science and Intelligent Apps: Concepts, AI-Based Modeling and Research Directions","Artificial intelligence (AI) techniques have grown rapidly in recent years in the context of computing with smart mobile phones that typically allows the devices to function in an intelligent manner. Popular AI techniques include machine learning and deep learning methods, natural language processing, as well as knowledge representation and expert systems, can be used to make the target mobile applications intelligent and more effective. In this paper, we present a comprehensive view on “mobile data science and intelligent apps” in terms of concepts and AI-based modeling that can be used to design and develop intelligent mobile applications for the betterment of human life in their diverse day-to-day situation. This study also includes the concepts and insights of various AI-powered intelligent apps in several application domains, ranging from personalized recommendation to healthcare services, including COVID-19 pandemic management in recent days. Finally, we highlight several research issues and future directions relevant to",3
ec813a3c757074f890bb0688800391837b1b276b,Cyber security in the age of COVID-19: A timeline and analysis of cyber-crime and cyber-attacks during the pandemic,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
edba974a20d51bf29d76e84ef91bea76caf6fce1,Deep Reinforcement Learning for Mitigating Cyber-Physical DER Voltage Unbalance Attacks,"The deployment of DER with smart-inverter functionality is increasing the controllable assets on power distribution networks and, consequently, the cyber-physical attack surface. Within this work, we consider the use of reinforcement learning as an online controller that adjusts DER Volt/Var and Volt/Watt control logic to mitigate network voltage unbalance. We specifically focus on the case where a network-aware cyber-physical attack has compromised a subset of single-phase DER, causing a large voltage unbalance. We show how deep reinforcement learning successfully learns a policy minimizing the unbalance, both during normal operation and during a cyber-physical attack. In mitigating the attack, the learned stochastic policy operates alongside legacy equipment on the network, i.e. tap-changing transformers, adjusting optimally predefined DER control-logic.",3
0b487de7808dd048525b2fac4bfbd325df547860,CRUSOE: A toolset for cyber situational awareness and decision support in incident handling,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
ee65885ef31a56a008dde6a2a403accd196448fb,A Machine Learning-Based Intrusion Detection System for IoT Electric Vehicle Charging Stations (EVCSs),"The demand for electric vehicles (EVs) is growing rapidly. This requires an ecosystem that meets the user’s needs while preserving security. The rich data obtained from electric vehicle stations are powered by the Internet of Things (IoT) ecosystem. This is achieved through us of electric vehicle charging station management systems (EVCSMSs). However, the risks associated with cyber-attacks on IoT systems are also increasing at the same pace. To help in finding malicious traffic, intrusion detection systems (IDSs) play a vital role in traditional IT systems. This paper proposes a classifier algorithm for detecting malicious traffic in the IoT environment using machine learning. The proposed system uses a real IoT dataset derived from real IoT traffic. Multiple classifying algorithms are evaluated. Results were obtained on both binary and multiclass traffic models. Using the proposed algorithm in the IoT-based IDS engine that serves electric vehicle charging stations will bring stability and eliminate",6
10a1ca20692a9f40cf0fdea523d5a02ebeba15cb,Exploring perceptions of decision-makers and specialists in defensive machine learning cybersecurity applications: The need for a standardised approach,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
36d9d8cffea6ff522979fd486c427e36383f4c93,Digital inclusion initiatives: Bridging the connectivity gap in Africa and the USA – A review,"This paper provides a comprehensive overview of digital inclusion initiatives aimed at mitigating the connectivity gap in Africa and the United States. As the world becomes increasingly reliant on digital technologies, the importance of ensuring equitable access to information and communication technologies (ICTs) has become a global priority. This review explores the current state of digital inclusion efforts in two distinct regions, Africa and the USA, to understand the challenges, successes, and lessons learned in bridging the digital divide. The first section of the review focuses on Africa, where disparities in digital access are particularly pronounced. Examining various initiatives, policies, and strategies implemented by governments, non-governmental organizations, and international partners, the review delves into the multifaceted approaches taken to extend connectivity to underserved populations. It highlights the role of innovative solutions such as community networks, mobile technologies, and public-private partnerships in fostering digital inclusion across diverse socio-economic landscapes. In the",2
2a79c2e43f6770c18dbb3df1726bc47d725bfb2f,Computational-Intelligence-Inspired Adaptive Opportunistic Clustering Approach for Industrial IoT Networks,"The major issues and challenges of the Industrial Internet of Things (IIoT) include network resource management, self-organization; routing, mobility, scalability, security, and data aggregation. Resource management in IIoT is a challenging issue, starting from the deployment and design of sensor nodes, networking at cross-layer, networking software development, application types, environmental conditions, monitoring user decisions, querying process, etc. In this article, computational intelligence (CI) and its computing, such as neural networks and fuzzy logic, are used to tackle the challenges of resource management in the IIoT. The incorporation of the neuro-fuzzy technique into the IIoT contributes to the self-managing intelligence systems’ self-organizing and self-sustaining capabilities, offering real-time computations and services in a pervasive networking environment. Most of the problems in IIoT are real-time based; they require fast computation, real-time optimal solutions, and the need to be adaptive to the situation of the events and data traffic to achieve the desired goals.",2
30c5c481ded2686e21ce108925d4ecf9d0c62d05,The impact of generative artificial intelligence on socioeconomic inequalities and policy making,"Abstract Generative artificial intelligence (AI) has the potential to both exacerbate and ameliorate existing socioeconomic inequalities. In this article, we provide a state-of-the-art interdisciplinary overview of the potential impacts of generative AI on (mis)information and three information-intensive domains: work, education, and healthcare. Our goal is to highlight how generative AI could worsen existing inequalities while illuminating how AI may help mitigate pervasive social problems. In the information domain, generative AI can democratize content creation and access but may dramatically expand the production and proliferation of misinformation. In the workplace, it can boost productivity and create new jobs, but the benefits will likely be distributed unevenly. In education, it offers personalized learning, but may widen the digital divide. In healthcare, it might improve diagnostics and accessibility, but could deepen pre-existing inequalities. In each section, we cover a specific topic, evaluate existing research, identify critical gaps, and recommend research directions, including explicit",3
808cf4971fa5d2f6f27868872801fcdb4a55a1e9,Cybersecurity in the context of industry 4.0: A structured classification of critical assets and business impacts,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
c5901cfb6689d504ebbb99d833a8b9cfa760b0b5,Effective framework to tackle urban unemployment by e-government: an IoT solution for smart/metro cities in developing nation,"Purpose With the advancement in technology, the day-to-day life of people has gone through an immense transformation. The use of smart devices for day-to-day life is greater than before, and people are moving towards smart work rather than doing hard work. In this paper, a novel framework is proposed named Online Service Provider in Metro City (OSPMC) for IoT. The purpose of this study is to provide a theoretical framework for the E-Government in order to sustain or minimize the unemployment rate. Design/methodology/approach The utilization of the Web in the upcoming years would create further opportunities for smart work. Internet of Things (IoT) plays an essential part in a system of multiple networks that aims to connect all things in the world that are capable of being connected through the internet. OSPMC framework can be developed on ASP.NET through (visual C#) 3.0 and Microsoft SQL Server with frontend and backend",3
eaf141fe8e8fd1108360a85862e690f4ae7c496a,Identification of Faulty Sensor Nodes in WBAN Using Genetically Linked Artificial Neural Network,"Wireless Body Area Networks (WBANs) have risen as a promising innovation for checking humanphysiological parameters in real time. Be that as it may, the unwavering quality and precision of WBANs dependon the right working of sensor hubs. The distinguishing proof of defective sensor hubs is vital for guaranteeing thequality of information collected by WBANs. In this paper, we propose a novel approach to recognizing faultysensor hubs in WBAN employing a hereditarily linked artificial neural organize (GLANN). The GLANN isprepared to employ a crossbreed fuzzy-genetic calculation to optimize its execution in distinguishing defectivesensor hubs. The proposed approach is assessed employing a dataset collected from a real-world WBAN. Thecomes about appears that the GLANN-based approach beats existing strategies in terms of exactness andproficiency. The proposed approach has potential applications within the field of healthcare, where exact and solidobserving of human physiological parameters is basic for conclusion and treatment. By and large, this",4
b8a9600502090cfa55b98323967cc02c21c8bed4,Investigating the impact of cybersecurity policy awareness on employees' cybersecurity behavior,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
9f15855fd5d48430abd741463959d1bfad02515a,Multi-Strategy Fusion for Enhancing Localization in Wireless Sensor Networks (WSNs),"Localization in wireless sensor networks (WSNs) plays a crucial role in various applications thatrely on spatial information. This paper introduces the Multi-Strategy Fusion for Localization model, whichintegrates optimization techniques (ABO, DSA, EHO, and KNN) and neurocomputing techniques (BP, MTLSTM,BILSTM, and Autoencoder) to enhance localization accuracy in WSNs. The work is divided into three phases: datacollection, model building, and implementation. The first and the last are carried out in the field, while the secondis made in the laboratory. The three phases involve a few general steps. The (1) Data Collection Phase includesfour steps: (a) Deploy three anchors at known locations, forming an equilateral triangle. (b) Each anchor startsbroadcasting its location. (c) Using an ordinary sensor, the RSSI of each anchor is measured at every possiblelocation where the signal of the three anchors can reach it. (d) Data is logged to a CSV file containing themeasuring location and the RSSI of the",4
da8c2fae9ab6751ff7f8a49ea15f94ddf4a87ab3,Impact of Cyber-Attacks on Banking Institutions in India: A Study of Safety Mechanisms and Preventive Measures,"This study intends to investigate the disastrous effects of cybercrime on financial institutions, as well as the creation of a strong cybersecurity mechanism and attempts to mitigate its effects. Banks are its direct target as of late. Many banks in India are frequently the target of widespread malware attacks, which not only expose private and sensitive data but also result in significant financial losses. This study’s goals are to determine which company sectors are more vulnerable to cyberattacks and to guarantee that cyber security protocols are developed and customized. The report includes case study examination of numerous cyberthreats and crimes that have previously resulted in significant financial loss, as well as secondary data analysis from a variety of online resources, including government websites, journals, and research papers. This essay will offer cyber regime insights that will be advantageous to financial institutions, banks, and society at general.",5
8fcc5dc9563d3b0d2b88987e8a8c4710e800aab2,Making Large Language Models Better Knowledge Miners for Online Marketing with Progressive Prompting Augmentation,"Nowadays, the rapid development of mobile economy has promoted the flourishing of online marketing campaigns, whose success greatly hinges on the efficient matching between user preferences and desired marketing campaigns where a well-established Marketing-oriented Knowledge Graph (dubbed as MoKG) could serve as the critical""bridge""for preference propagation. In this paper, we seek to carefully prompt a Large Language Model (LLM) with domain-level knowledge as a better marketing-oriented knowledge miner for marketing-oriented knowledge graph construction, which is however non-trivial, suffering from several inevitable issues in real-world marketing scenarios, i.e., uncontrollable relation generation of LLMs,insufficient prompting ability of a single prompt, the unaffordable deployment cost of LLMs. To this end, we propose PAIR, a novel Progressive prompting Augmented mIning fRamework for harvesting marketing-oriented knowledge graph with LLMs. In particular, we reduce the pure relation generation to an LLM based adaptive relation filtering process through the knowledge-empowered prompting technique. Next, we steer LLMs for",3
2f0a06188d594b0c209613a4d7c8530b1bcbfc69,Layered structures of robustness and resilience: Evidence from cybersecurity projects for critical infrastructures in Central Europe,"The article studies cybersecurity projects from the perspective of social systems theory. Measures taken to increase cybersecurity are aimed at the robustness and resilience of specific systemic entities in society. We argue that this does not necessarily mean that systems in which these entities are embedded become more robust or resilient. The article investigates the objectives of 20 projects funded by different public organizations to increase cybersecurity of critical infrastructures. The findings show that robustness and resilience are addressed by these projects on different layers of systems in society, without a clear picture of how they are supposed to fit together in a wider effort to protect society against disruption. The detailed analysis of the different facets of robustness and resilience addressed in cybersecurity projects paves the way for a better understanding of this problem. The research shows how organizations may avoid the negative consequences of measures to secure specific",3
3f390c36297b363d72b8a760453d44a6bdd6f954,CYBERSECURITY RISK ASSESSMENT IN BANKING: METHODOLOGIES AND BEST PRACTICES,"Cybersecurity risk assessment in banking is the process of identifying, analyzing, and evaluating the cyber threats and vulnerabilities that may affect the confidentiality, integrity, and availability of the information systems and data of banks and their customers. Cybersecurity risk assessment in banking helps banks to prioritize and implement appropriate controls and measures to mitigate the cyber risks and to comply with the relevant regulations and standards. This study focusses on identifying effective risk assessment strategies, highlighting how they can be adapted and applied in various banking environments, especially in developing economies like Nigeria. As the banking industry continues to evolve in the digital era, the significance of robust cybersecurity measures cannot be overstated. This paper delves into the critical domain of Cybersecurity Risk Assessment in Banking, exploring various methodologies and best practices employed to safeguard financial institutions against evolving cyber threats. The dynamic landscape of cyber risks faced by banks,",2
ac675900f7c6c14c8488e09a2a6e8525bcf9d45a,Generative AI,"Recent advancements in generative artificial intelligence (AI) have made it possible for machines to independently produce a variety of creative content. In the context of producing creative content, this essay examines the developments, difficulties, and ethical issues relating to generative AI. It looks into how generative models, such Generative Adversarial Networks (GANs) and Variational Auto encoders (VAEs), can produce realistic artwork like music, literature, and visuals. However, it is frequently discovered that GAN training is extremely unstable and frequently experiences non-convergence, mode collapse, and hyperparameter sensitivity [1]. The technical details of developing and optimizing generative models to produce desired results are covered in detail in this work. It also looks at the difficulties in guaranteeing the variety, creativity, and coherence of generated content. Additionally, the use of generative AI in the creation of original material raises ethical questions. Included in this are concerns about intellectual property, plagiarism, and possible effects",7
03209448d7950fd575ac27676c0ff1deb9c55e8f,Diabetes Monitoring System in Smart Health Cities Based on Big Data Intelligence,"Diabetes is a metabolic disorder in which the body is unable to properly regulate blood sugar levels. It can occur when the body does not produce enough insulin or when cells become resistant to insulin’s effects. There are two main types of diabetes, Type 1 and Type 2, which have different causes and risk factors. Early detection of diabetes allows for early intervention and management of the condition. This can help prevent or delay the development of serious complications associated with diabetes. Early diagnosis also allows for individuals to make lifestyle changes to prevent the progression of the disease. Healthcare systems play a vital role in the management and treatment of diabetes. They provide access to diabetes education, regular check-ups, and necessary medications for individuals with diabetes. They also provide monitoring and management of diabetes-related complications, such as heart disease, kidney failure, and neuropathy. Through early detection, prevention and management",5
99a01c9c3815d835c202723bf5d1ad9094ba20e3,REvil Ransomware,"A computer network is a valuable resource in today’s digital world, and it supports businesses in carrying out their operations within an increasingly intricate environment. These networks face significant danger from cyber criminals who execute ransomware attacks among other cyberattacks. In such attacks, vital business data gets encrypted and can, therefore, not be accessed without a decryption key. Ransomware was the most rampant malware threat at the time when 60% of managed service providers were attacked in the first half of 2020. Many victims had no option other than paying the demanded ransom hoping that this would make hackers decrypt their files again. We see once again how crucial it is to have strong protection against cyber threats, as organizations increasingly rely on information technology systems. They cannot afford to lose everything due to a virus or a hacker attack. It is worth mentioning, however, that ransomware has evolved with",4
cdafb1628ed1893d731e69fe0b76bac3ecc28e81,Cybersecurity Risks in a Pandemic,"Cybersecurity threats are estimated to cost the world US $6 trillion a year by 2021, and the number of attacks has increased five-fold after COVID-19. Although there is substantial literature on the threats technological vulnerabilities have on the health care industry, less research exists on how pandemics like COVID-19 are opportunistic for cybercriminals. This paper outlines why cyberattacks have been particularly problematic during COVID-19 and ways that health care industries can better protect patient data. The Office for Civil Rights has loosened enforcement of the Health Insurance Portability and Accountability Act, which, although useful in using new platforms like Zoom, has also loosened physical and technical safeguards to cyberattacks. This is especially problematic given that 90% of health care providers had already encountered data breaches. Companies must implement well-defined software upgrade procedures, should use secure networks like virtual local area networks, and conduct regular penetration tests of their systems. By",5
5500de6cc455310f9363a3b1cfccaeea0ce20dc6,A model-based approach for vulnerability analysis of IoT security protocols: The Z-Wave case study,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
54906484f42e871f7c47bbfe784a358b1448231f,Variational Graph Auto-Encoders,"We introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.",45
189b79cda928d58f695cf8323b9ce2196fc22409,Graph-based genome alignment and genotyping with HISAT2 and HISAT-genotype,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
967a21a111757d6af7f7a25ca7ea2bdf6d505098,Deep Graph Infomax,"We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs---both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. In contrast to most prior approaches to unsupervised learning with GCNs, DGI does not rely on random walk objectives, and is readily applicable to both transductive and inductive learning setups. We demonstrate competitive performance on a variety of node classification benchmarks, which at times even exceeds the performance of supervised learning.",16
1d81e7f428fea2b2e15ee3a96fe843ca603acc4c,Simple and Deep Graph Convolutional Networks,"Graph convolutional networks (GCNs) are a powerful deep learning approach for graph-structured data. Recently, GCNs and subsequent variants have shown superior performance in various application areas on real-world datasets. Despite their success, most of the current GCN models are shallow, due to the {\em over-smoothing} problem. In this paper, we study the problem of designing and analyzing deep graph convolutional networks. We propose the GCNII, an extension of the vanilla GCN model with two simple yet effective techniques: {\em Initial residual} and {\em Identity mapping}. We provide theoretical and empirical evidence that the two techniques effectively relieves the problem of over-smoothing. Our experiments show that the deep GCNII model outperforms the state-of-the-art methods on various semi- and full-supervised tasks. Code is available at this https URL .",2
6c96c2d4a3fbd572fef2d59cb856521ee1746789,Graph Convolutional Neural Networks for Web-Scale Recommender Systems,"Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains an unsolved challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. Overall,",31
63a513832f56addb67be81a2fa399b233f3030fc,Fast Graph Representation Learning with PyTorch Geometric,"We introduce PyTorch Geometric, a library for deep learning on irregularly structured input data such as graphs, point clouds and manifolds, built upon PyTorch. In addition to general graph data structures and processing methods, it contains a variety of recently published methods from the domains of relational learning and 3D data processing. PyTorch Geometric achieves high data throughput by leveraging sparse GPU acceleration, by providing dedicated CUDA kernels and by introducing efficient mini-batch handling for input examples of different size. In this work, we present the library in detail and perform a comprehensive comparative study of the implemented methods in homogeneous evaluation scenarios.",29
00b7efbf14a54cced4b9f19e663b70ffbd01324b,Heterogeneous Graph Attention Network,"Graph neural network, as a powerful graph representation technique based on deep learning, has shown superior performance and attracted considerable research interest. However, it has not been fully considered in graph neural network for heterogeneous graph which contains different types of nodes and links. The heterogeneity and rich semantic information bring great challenges for designing a graph neural network for heterogeneous graph. Recently, one of the most exciting advancements in deep learning is the attention mechanism, whose great potential has been well demonstrated in various areas. In this paper, we first propose a novel heterogeneous graph neural network based on the hierarchical attention, including node-level and semantic-level attentions. Specifically, the node-level attention aims to learn the importance between a node and its meta-path based neighbors, while the semantic-level attention is able to learn the importance of different meta-paths. With the learned importance from both node-level and semantic-level attention, the importance",9
3efd851140aa28e95221b55fcc5659eea97b172d,The Graph Neural Network Model,"Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.",68
30321b036607a7936221235ea8ec7cf7c1627100,Knowledge Graph Embedding: A Survey of Approaches and Applications,"Knowledge graph (KG) embedding is to embed components of a KG including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the KG. It can benefit a variety of downstream tasks such as KG completion and relation extraction, and hence has quickly gained massive attention. In this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. Particularly, we make the review based on the type of information used in the embedding task. Techniques that conduct embedding using only facts observed in the KG are first introduced. We describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. After that, we discuss techniques that further incorporate additional information besides facts. We focus specifically on the use of entity types, relation paths,",8
b07c157e7d40e06a4f2d486b16d5180d8b24acb9,Algebraic Graph Theory,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
597bd2e45427563cdf025e53a3239006aa364cfc,Open Graph Benchmark: Datasets for Machine Learning on Graphs,"We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale (up to 100+ million nodes and 1+ billion edges), encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup,",16
69906b74ee369cd25522ec432ecbc601a77c9d87,Spectral graph theory,"Spectral graph theory is a vast and expanding area of combinatorics. We start these notes by introducing and motivating classical matrices associated with a graph, and then show how to derive combinatorial properties of a graph from the eigenvalues of these matrices. We then examine more modern results such as polynomial interlacing and high dimensional expanders",12
62ed9bf1d83c8db1f9cbf92ea2f57ea90ef683d9,How Powerful are Graph Neural Networks?,"Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically",49
492f57ee9ceb61fb5a47ad7aebfec1121887a175,Gated Graph Sequence Neural Networks,"Abstract: Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures.",67
d08a0eb7024dff5c4fabd58144a38031633d4e1a,Benchmarking Graph Neural Networks,"Graph neural networks (GNNs) have become the standard toolkit for analyzing and learning from data on graphs. As the field grows, it becomes critical to identify key architectures and validate new ideas that generalize to larger, more complex datasets. Unfortunately, it has been increasingly difficult to gauge the effectiveness of new models in the absence of a standardized benchmark with consistent experimental settings. In this paper, we introduce a reproducible GNN benchmarking framework, with the facility for researchers to add new models conveniently for arbitrary datasets. We demonstrate the usefulness of our framework by presenting a principled investigation into the recent Weisfeiler-Lehman GNNs (WL-GNNs) compared to message passing-based graph convolutional networks (GCNs) for a variety of graph tasks, i.e. graph regression/classification and node/link prediction, with medium-scale datasets.",10
ea5dd6a3d8f210d05e53a7b6fa5e16f1b115f693,Graph Neural Networks: A Review of Methods and Applications,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",12
d18b48f77eb5c517a6d2c1fa434d2952a1b0a825,Hierarchical Graph Representation Learning with Differentiable Pooling,"Recently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs---a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DiffPool, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DiffPool learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DiffPool yields an average improvement of",33
fae129338c0899576524506008427f64477d3967,Graph WaveNet for Deep Spatial-Temporal Graph Modeling,"Spatial-temporal graph modeling is an important task to analyze the spatial relations and temporal trends of components in a system. Existing approaches mostly capture the spatial dependency on a fixed graph structure, assuming that the underlying relation between entities is pre-determined. However, the explicit graph structure (relation) does not necessarily reflect the true dependency and genuine relation may be missing due to the incomplete connections in the data. Furthermore, existing methods are ineffective to capture the temporal trends as the RNNs or CNNs employed in these methods cannot capture long-range temporal sequences. To overcome these limitations, we propose in this paper a novel graph neural network architecture, {Graph WaveNet}, for spatial-temporal graph modeling. By developing a novel adaptive dependency matrix and learn it through node embedding, our model can precisely capture the hidden spatial dependency in the data. With a stacked dilated 1D convolution component whose receptive field grows exponentially",6
385742fffcf113656f0d3cf6c06ef95cb8439dc6,Depth-First Search and Linear Graph Algorithms,"The value of depth-first search or “backtracking” as a technique for solving problems is illustrated by two examples. An improved version of an algorithm for finding the strongly connected components of a directed graph and at algorithm for finding the biconnected components of an undirect graph are presented. The space and time requirements of both algorithms are bounded by $k_1 V + k_2 E + k_3 $ for some constants $k_1 ,k_2 $, and $k_3 $, where V is the number of vertices and E is the number of edges of the graph being examined.",3
f412bb31ec9ef8bbef70eefc7ffd04420c1365d9,Graph-Based Visual Saliency,"A new bottom-up visual saliency model, Graph-Based Visual Saliency (GBVS), is proposed. It consists of two steps: first forming activation maps on certain feature channels, and then normalizing them in a way which highlights conspicuity and admits combination with other maps. The model is simple, and biologically plausible insofar as it is naturally parallelized. This model powerfully predicts human fixations on 749 variations of 108 natural images, achieving 98% of the ROC area of a human-based control, whereas the classical algorithms of Itti & Koch ([2], [3], [4]) achieve only 84%.",5
36eff562f65125511b5dfab68ce7f7a943c27478,Semi-Supervised Classification with Graph Convolutional Networks,We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.,158
75e924bd79d27a23f3f93d9b1ab62a779505c8d2,Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks,"Modeling multivariate time series has long been a subject that has attracted researchers from a diverse range of fields including economics, finance, and traffic. A basic assumption behind multivariate time series forecasting is that its variables depend on one another but, upon looking closely, it is fair to say that existing methods fail to fully exploit latent spatial dependencies between pairs of variables. In recent years, meanwhile, graph neural networks (GNNs) have shown high capability in handling relational dependencies. GNNs require well-defined graph structures for information propagation which means they cannot be applied directly for multivariate time series where the dependencies are not known in advance. In this paper, we propose a general graph neural network framework designed specifically for multivariate time series data. Our approach automatically extracts the uni-directed relations among variables through a graph learning module, into which external knowledge like variable attributes can be easily integrated. A",2
1976c9eeccc7115d18a04f1e7fb5145db6b96002,Freebase: a collaboratively created graph database for structuring human knowledge,"Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.",34
6bc77c4dc6075ee81c05f0f5f43e44b2a34a5876,Graph Theory with Applications,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",0
3a58efcc4558727cc5c131c44923635da4524f33,"Relational inductive biases, deep learning, and graph networks","Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between ""hand-engineering"" and ""end-to-end"" learning, and instead advocate for an approach which benefits from their complementary strengths.",29
26aa6fe2028b5eefbaa40ab54ef725bbbe7d9810,ConceptNet 5.5: An Open Multilingual Graph of General Knowledge,"Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings. ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert-created resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use. When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this",5
36652428740cd30d245d55889f01a7fb04a91c93,Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning,"Many interesting problems in machine learning are being revisited with new deep learning tools. For graph-based semi-supervised learning, a recent important development is graph convolutional networks (GCNs), which nicely integrate local vertex features and graph topology in the convolutional layers. Although the GCN model compares favorably with other state-of-the-art methods, its mechanisms are not clear and it still requires considerable amount of labeled data for validation and model selection. In this paper, we develop deeper insights into the GCN model and address its fundamental limits. First, we show that the graph convolution of the GCN model is actually a special form of Laplacian smoothing, which is the key reason why GCNs work, but it also brings potential concerns of over-smoothing with many convolutional layers. Second, to overcome the limits of the GCN model with shallow architectures, we propose both co-training and self-training approaches to train GCNs. Our approaches significantly improve",27
c5f5f179d80a3bf9b4f29750283a87eaca42e91b,Neural Graph Collaborative Filtering,"Learning vector representations (aka. embeddings) of users and items lies at the core of modern recommender systems. Ranging from early matrix factorization to recently emerged deep learning based methods, existing efforts typically obtain a user's (or an item's) embedding by mapping from pre-existing features that describe the user (or the item), such as ID and attributes. We argue that an inherent drawback of such methods is that, the collaborative signal, which is latent in user-item interactions, is not encoded in the embedding process. As such, the resultant embeddings may not be sufficient to capture the collaborative filtering effect. In this work, we propose to integrate the user-item interactions - more specifically the bipartite graph structure - into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. This leads to the expressive modeling of high-order",9
b8d9b10cf54629364523ec065e6307ab87f7d4f0,iRun: Horizontal and Vertical Shape of a Region-Based Graph Compression,"Graph data are pervasive worldwide, e.g., social networks, citation networks, and web graphs. A real-world graph can be huge and requires heavy computational and storage resources for processing. Various graph compression techniques have been presented to accelerate the processing time and utilize memory efficiently. SOTA approaches decompose a graph into fixed-size submatrices and compress it by applying the existing graph compression algorithm. This approach is promising if the input graph is dense. Otherwise, an optimal graph compression ratio cannot be achieved. Graphs such as those used by social networks exhibit a power-law distribution. Thus, applying compression to the fixed-size block of a matrix could lead to the empty cell processing of that matrix. In this paper, we solve the problem of ordered matrix compression on a deep level, dividing the block into sub-blocks to achieve the best compression ratio. We observe that the ordered matrix compression ratio could be improved",5
cd8a9914d50b0ac63315872530274d158d6aff09,Modeling Relational Data with Graph Convolutional Networks,"Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to handle the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved through the use of an R-GCN encoder model to accumulate evidence over multiple inference steps in the graph, demonstrating a large improvement of 29.8% on",32
2d867297dfe0d3ce2ed5b1d0f2dff88cac46ee94,Pregel: a system for large-scale graph processing,"Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs - in some cases billions of vertices, trillions of edges - poses challenges to their efficient processing. In this paper we present a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertex-centric approach is flexible enough to express a broad set of algorithms. The model has been designed for efficient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier. Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs",8
415224a9aff759f6972189df8b7761dfd6a81154,Introduction to graph theory,"In graph theory, the term graph refers to a set of vertices and a set of edges. A vertex can be used to represent any object. Graphs may contain undirected or directed edges. An undirected edge is a set of two vertices. A directed edge is an ordered pair of two vertices where the edge goes from the first vertex to the second vertex. Graphs that contain directed edges are called directed graphs or digraphs.",1
59cdf849049627e4c30f3bd866e3a7e03e893251,Complex brain networks: graph theoretical analysis of structural and functional systems,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
789a7069d1a2d02d784e4821685b216cc63e6ec8,Strategies for Pre-training Graph Neural Networks,"Many applications of machine learning require a model to make accurate pre-dictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that naive strategies, which",11
994afdf0db0cb0456f4f76468380822c2f532726,Learning Entity and Relation Embeddings for Knowledge Graph Completion,"Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant",29
8f096071a09701012c9c279aee2a88143a295935,RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space,"We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.",9
7e71eedb078181873a56f2adcfef9dddaeb95602,Simplifying Graph Convolutional Networks,"Graph Convolutional Networks (GCNs) and their variants have experienced significant attention and have become the de facto methods for learning graph representations. GCNs derive inspiration primarily from recent deep learning approaches, and as a result, may inherit unnecessary complexity and redundant computation. In this paper, we reduce this excess complexity through successively removing nonlinearities and collapsing weight matrices between consecutive layers. We theoretically analyze the resulting linear model and show that it corresponds to a fixed low-pass filter followed by a linear classifier. Notably, our experimental evaluation demonstrates that these simplifications do not negatively impact accuracy in many downstream applications. Moreover, the resulting model scales to larger datasets, is naturally interpretable, and yields up to two orders of magnitude speedup over FastGCN.",28
9697d32ed0a16da167f2bdba05ef96d0da066eb5,Convolutional 2D Knowledge Graph Embeddings,"Link prediction for knowledge graphs is the task of predicting missing relationships between entities. Previous work on link prediction has focused on shallow, fast models which can scale to large knowledge graphs. However, these models learn less expressive features than deep, multi-layer models — which potentially limits performance. In this work we introduce ConvE, a multi-layer convolutional network model for link prediction, and report state-of-the-art results for several established datasets. We also show that the model is highly parameter efficient, yielding the same performance as DistMult and R-GCN with 8x and 17x fewer parameters. Analysis of our model suggests that it is particularly effective at modelling nodes with high indegree — which are common in highly-connected, complex knowledge graphs such as Freebase and YAGO3. In addition, it has been noted that the WN18 and FB15k datasets suffer from test set leakage, due to inverse relations from the training set being",10
2a9fbca9dc6badbeedc591ad829c5c6e0f950fd6,Graph Contrastive Learning with Augmentations,"Generalizable, transferrable, and robust representation learning on graph-structured data remains a challenge for current graph neural networks (GNNs). Unlike what has been developed for convolutional neural networks (CNNs) for image data, self-supervised learning and pre-training are less explored for GNNs. In this paper, we propose a graph contrastive learning (GraphCL) framework for learning unsupervised representations of graph data. We first design four types of graph augmentations to incorporate various priors. We then systematically study the impact of various combinations of graph augmentations on multiple datasets, in four different settings: semi-supervised, unsupervised, and transfer learning as well as adversarial attacks. The results show that, even without tuning augmentation extents nor using sophisticated GNN architectures, our GraphCL framework can produce graph representations of similar or better generalizability, transferrability, and robustness compared to state-of-the-art methods. We also investigate the impact of parameterized graph augmentation extents and patterns, and observe further performance gains in",5
aeeffe327e6c93e9010c7b1e401caa9113723851,Efficient Graph-Based Image Segmentation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
81a4fd3004df0eb05d6c1cef96ad33d5407820df,A Comprehensive Survey on Graph Neural Networks,"Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes,",31
2a3f862199883ceff5e3c74126f0c80770653e05,Knowledge Graph Embedding by Translating on Hyperplanes,"We deal with embedding a large scale knowledge graph composed of entities and relations into a continuous vector space. TransE is a promising method proposed recently, which is very efficient while achieving state-of-the-art predictive performance. We discuss some mapping properties of relations which should be considered in embedding, such as reflexive, one-to-many, many-to-one, and many-to-many. We note that TransE does not do well in dealing with these properties. Some complex models are capable of preserving these mapping properties but sacrifice efficiency in the process. To make a good trade-off between model capacity and efficiency, in this paper we propose TransH which models a relation as a hyperplane together with a translation operation on it. In this way, we can well preserve the above mapping properties of relations with almost the same model complexity of TransE. Additionally, as a practical knowledge graph is often far from completed, how to construct negative",24
8ea9cb53779a8c1bb0e53764f88669bd7edf38f0,E(n) Equivariant Graph Neural Networks,"This paper introduces a new model to learn graph neural networks equivariant to rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. In addition, whereas existing methods are limited to equivariance on 3 dimensional spaces, our model is easily scaled to higher-dimensional spaces. We demonstrate the effectiveness of our method on dynamical systems modelling, representation learning in graph autoencoders and predicting molecular properties.",4
3120324069ec20eed853d3f9bbbceb32e4173b93,Fast approximate energy minimization via graph cuts,"In this paper we address the problem of minimizing a large class of energy functions that occur in early vision. The major restriction is that the energy function's smoothness term must only involve pairs of pixels. We propose two algorithms that use graph cuts to compute a local minimum even when very large moves are allowed. The first move we consider is an /spl alpha/-/spl beta/-swap: for a pair of labels /spl alpha/,/spl beta/, this move exchanges the labels between an arbitrary set of pixels labeled a and another arbitrary set labeled /spl beta/. Our first algorithm generates a labeling such that there is no swap move that decreases the energy. The second move we consider is an /spl alpha/-expansion: for a label a, this move assigns an arbitrary set of pixels the label /spl alpha/. Our second algorithm, which requires the smoothness term to be a metric, generates a",12
3024f58826a5bce3378af94f677e8fb90cbb49e0,LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation,"Graph Convolution Network (GCN) has become new state-of-the-art for collaborative filtering. Nevertheless, the reasons of its effectiveness for recommendation are not well understood. Existing work that adapts GCN to recommendation lacks thorough ablation analyses on GCN, which is originally designed for graph classification tasks and equipped with many neural network operations. However, we empirically find that the two most common designs in GCNs -- feature transformation and nonlinear activation -- contribute little to the performance of collaborative filtering. Even worse, including them adds to the difficulty of training and degrades recommendation performance. In this work, we aim to simplify the design of GCN to make it more concise and appropriate for recommendation. We propose a new model named LightGCN, including only the most essential component in GCN -- neighborhood aggregation -- for collaborative filtering. Specifically, LightGCN learns user and item embeddings by linearly propagating them on the user-item interaction graph,",7
72edcb3788f9c141a3ed28e6d36f75ca4977d27e,Spatio-temporal Graph Convolutional Neural Network: A Deep Learning Framework for Traffic Forecasting,"Timely accurate traffic forecast is crucial for urban traffic control and guidance. Due to the high nonlinearity and complexity of traffic flow, traditional methods cannot satisfy the requirements of mid-and-long term prediction tasks and often neglect spatial and temporal dependencies. In this paper, we propose a novel deep learning framework, Spatio-Temporal Graph Convolutional Networks (STGCN), to tackle the time series prediction problem in traffic domain. Instead of applying regular convolutional and recurrent units, we formulate the problem on graphs and build the model with complete convolutional structures, which enable much faster training speed with fewer parameters. Experiments show that our model STGCN effectively captures comprehensive spatio-temporal correlations through modeling multi-scale traffic networks and consistently outperforms state-of-the-art baselines on various real-world traffic datasets.",16
de02ec03f6a71246e505862a7195894601fbab99,KGAT: Knowledge Graph Attention Network for Recommendation,"To provide more accurate, diverse, and explainable recommendation, it is compulsory to go beyond modeling user-item interactions and take side information into account. Traditional methods like factorization machine (FM) cast it as a supervised learning problem, which assumes each interaction as an independent instance with side information encoded. Due to the overlook of the relations among instances or items (e.g., the director of a movie is also an actor of another movie), these methods are insufficient to distill the collaborative signal from the collective behaviors of users. In this work, we investigate the utility of knowledge graph (KG), which breaks down the independent interaction assumption by linking items with their attributes. We argue that in such a hybrid structure of KG and user-item graph, high-order relations --- which connect two items with one or multiple linked attributes --- are an essential factor for successful recommendation. We propose a new method",6
1ee0abcb8f0afd74d602255d529d7c2a036a8f02,Graph Theory,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
c00ca876af5af23a6fc1ce9bcdc8ce0a31663a42,λOpt: Learn to Regularize Recommender Models in Finer Levels,"Recommendation models mainly deal with categorical variables, such as user/item ID and attributes. Besides the high-cardinality issue, the interactions among such categorical variables are usually long-tailed, with the head made up of highly frequent values and a long tail of rare ones. This phenomenon results in the data sparsity issue, making it essential to regularize the models to ensure generalization. The common practice is to employ grid search to manually tune regularization hyperparameters based on the validation data. However, it requires non-trivial efforts and large computation resources to search the whole candidate space; even so, it may not lead to the optimal choice, for which different parameters should have different regularization strengths. In this paper, we propose a hyperparameter optimization method, lambdaOpt, which automatically and adaptively enforces regularization during training. Specifically, it updates the regularization coefficients based on the performance of validation data. With lambdaOpt, the notorious tuning of regularization",4
4dbf5ab853c74d30ce118a13d83cc2a8ccaecada,Techniques for Inverted Index Compression,"The data structure at the core of large-scale search engines is the inverted index, which is essentially a collection of sorted integer sequences called inverted lists. Because of the many documents indexed by such engines and stringent performance requirements imposed by the heavy load of queries, the inverted index stores billions of integers that must be searched efficiently. In this scenario, index compression is essential because it leads to a better exploitation of the computer memory hierarchy for faster query processing and, at the same time, allows reducing the number of storage machines. The aim of this article is twofold: first, surveying the encoding algorithms suitable for inverted index compression and, second, characterizing the performance of the inverted index through experimentation.",5
9653d5c2c7844347343d073bbedd96e05d52f69b,Pointer Networks,"We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence. Such problems cannot be trivially addressed by existent approaches such as sequence-to-sequence [1] and Neural Turing Machines [2], because the number of target classes in each step of the output depends on the length of the input, which is variable. Problems such as sorting variable sized sequences, and various combinatorial optimization problems belong to this class. Our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention. It differs from the previous attention attempts in that, instead of using attention to blend hidden units of an encoder to a context vector at each decoder step, it uses attention as a pointer to select a member of the input sequence as the output. We call this",12
22d606ae7351aa4e9598ed6194797d03557abe12,Computing visual correspondence with occlusions using graph cuts,"Several new algorithms for visual correspondence based on graph cuts have recently been developed. While these methods give very strong results in practice, they do not handle occlusions properly. Specifically, they treat the two input images asymmetrically, and they do not ensure that a pixel corresponds to at most one pixel in the other image. In this paper, we present a new method which properly addresses occlusions, while preserving the advantages of graph cut algorithms. We give experimental results for stereo as well as motion, which demonstrate that our method performs well both at detecting occlusions and computing disparities.",4
ecf6c42d84351f34e1625a6a2e4cc6526da45c74,Representation Learning on Graphs: Methods and Applications,"Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a",29
a043ccc8da48061265fb34c6b3279e6eea5af76d,"Mengerian properties, hamiltonicity, and claw-free graphs","In relation to the Property Pd,m, we define two parameters generalizing the diameter and the independence number of a graph, study their behaviors, and find new conditions depending on those parameters for a claw-free graph to be Hamiltonian. © 1994 by John Wiley & Sons, Inc.",9
2cefe5adb11295b830ce27176c6d84b66fb20c2c,Jointly Embedding Knowledge Graphs and Logical Rules,",",6
c41eb895616e453dcba1a70c9b942c5063cc656c,Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering,"In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.",106
e0f4e6a1368263582df142b025a0bc14d8a2b6dc,Broadband Criticality of Human Brain Network Synchronization,"Self-organized criticality is an attractive model for human brain dynamics, but there has been little direct evidence for its existence in large-scale systems measured by neuroimaging. In general, critical systems are associated with fractal or power law scaling, long-range correlations in space and time, and rapid reconfiguration in response to external inputs. Here, we consider two measures of phase synchronization: the phase-lock interval, or duration of coupling between a pair of (neurophysiological) processes, and the lability of global synchronization of a (brain functional) network. Using computational simulations of two mechanistically distinct systems displaying complex dynamics, the Ising model and the Kuramoto model, we show that both synchronization metrics have power law probability distributions specifically when these systems are in a critical state. We then demonstrate power law scaling of both pairwise and global synchronization metrics in functional MRI and magnetoencephalographic data recorded from normal volunteers under resting conditions. These results",3
3ebbd75ab128c863e3b655efe104e1c47af13096,A Pixel Dissimilarity Measure That Is Insensitive to Image Sampling,"Because of image sampling, traditional measures of pixel dissimilarity can assign a large value to two corresponding pixels in a stereo pair, even in the absence of noise and other degrading effects. We propose a measure of dissimilarity that is provably insensitive to sampling because it uses the linearly interpolated intensity functions surrounding the pixels. Experiments on real images show that our measure alleviates the problem of sampling with little additional computational overhead.",5
4b25ceab8abceec1040e53ae1476f6b909794d39,Distributed representation learning for knowledge graphs with entity descriptions,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
0e692f1cab6a37c312fa58596aafa340d41b6cdc,Compression-aware graph computation,"Many recent work has focused on graph algorithms via parallelization including PowerGraph [9] and Ligra [14]. The frameworks process large graphs in shared memory, requiring a terabyte of memory and expensive maintenance cost. Reducing graph size to fit in memory thus is crucial in cutting the cost of large-scale graph computation. Compression has been widely used to reduce graph size. However, it could meanwhile compromise graph computation efficiency caused by nontrivial decompression overhead before graph computation. In this paper, we propose a simple and yet efficient coding scheme. It not only leads to smaller size of compressed graphs; meanwhile we can perform graph computation directly on the compressed graphs with no or partial decompression, namely compression-aware computation, leading to faster running time. Our experiments validate that the coding scheme achieves 2.99X compression ratio, and three compression-aware graph algorithms achieve 7.02X, 2.88X and 2.34X faster running time than the graph algorithms",3
153b1a4325706f0918a436f174b7db7d69fe562d,A transitive closure algorithm,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
3302081b8878de505b69900e22b8137c5d931be7,TUDataset: A collection of benchmark datasets for learning with graphs,"Recently, there has been an increasing interest in (supervised) learning with graph data, especially using graph neural networks. However, the development of meaningful benchmark datasets and standardized evaluation procedures is lagging, consequently hindering advancements in this area. To address this, we introduce the TUDataset for graph classification and regression. The collection consists of over 120 datasets of varying sizes from a wide range of applications. We provide Python-based data loaders, kernel and graph neural network baseline implementations, and evaluation tools. Here, we give an overview of the datasets, standardized evaluation procedures, and provide baseline experiments. All datasets are available at this http URL. The experiments are fully reproducible from the code available at this http URL.",7
4ce9c20642dce5eb7930966053a1e3da4ef617f2,Graph Neural Networks Exponentially Lose Expressive Power for Node Classification,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
9ba0186ed40656329c421f55ada7313293e13f17,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",18
3da4626411d83c19c9919bb41dba94fff88da90e,Scaling Graph Neural Networks with Approximate PageRank,"Graph neural networks (GNNs) have emerged as a powerful approach for solving many network mining tasks. However, learning on large graphs remains a challenge -- many recently proposed scalable GNN approaches rely on an expensive message-passing procedure to propagate information through the graph. We present the PPRGo model which utilizes an efficient approximation of information diffusion in GNNs resulting in significant speed gains while maintaining state-of-the-art prediction performance. In addition to being faster, PPRGo is inherently scalable, and can be trivially parallelized for large datasets like those found in industry settings. We demonstrate that PPRGo outperforms baselines in both distributed and single-machine training environments on a number of commonly used academic graphs. To better analyze the scalability of large-scale graph learning methods, we introduce a novel benchmark graph with 12.4 million nodes, 173 million edges, and 2.8 million node features. We show that training PPRGo from scratch and predicting labels",7
c567fbea2f82a3133159ccf1cc8176b0aec29318,Advanced Shortest Paths Algorithms on a Massively-Multithreaded Architecture,"We present a study of multithreaded implementations of Thorup's algorithm for solving the single source shortest path (SSSP) problem for undirected graphs. Our implementations leverage the fledgling multithreaded graph library (MTGL) to perform operations such as finding connected components and extracting induced subgraphs. To achieve good parallel performance from this algorithm, we deviate from several theoretically optimal algorithmic steps. In this paper, we present simplifications that perform better in practice, and we describe details of the multithreaded implementation that were necessary for scalability. We study synthetic graphs that model unstructured networks, such as social networks and economic transaction networks. Most of the recent progress in shortest path algorithms relies on structure that these networks do not have. In this work, we take a step back and explore the synergy between an elegant theoretical algorithm and an elegant computer architecture. Finally, we conclude with a prediction that this work will become",4
67ab606526f914d474b88ffb9c95a28de38aab52,Predicting human resting-state functional connectivity from structural connectivity,"In the cerebral cortex, the activity levels of neuronal populations are continuously fluctuating. When neuronal activity, as measured using functional MRI (fMRI), is temporally coherent across 2 populations, those populations are said to be functionally connected. Functional connectivity has previously been shown to correlate with structural (anatomical) connectivity patterns at an aggregate level. In the present study we investigate, with the aid of computational modeling, whether systems-level properties of functional networks—including their spatial statistics and their persistence across time—can be accounted for by properties of the underlying anatomical network. We measured resting state functional connectivity (using fMRI) and structural connectivity (using diffusion spectrum imaging tractography) in the same individuals at high resolution. Structural connectivity then provided the couplings for a model of macroscopic cortical dynamics. In both model and data, we observed (i) that strong functional connections commonly exist between regions with no direct structural connection, rendering the inference of",1
cebc494c81f85fa9739b049a9930df6cbd68b587,Mean shift analysis and applications,"A nonparametric estimator of density gradient, the mean shift, is employed in the joint, spatial-range (value) domain of gray level and color images for discontinuity preserving filtering and image segmentation. Properties of the mean shift are reviewed and its convergence on lattices is proven. The proposed filtering method associates with each pixel in the image the closest local mode in the density distribution of the joint domain. Segmentation into a piecewise constant structure requires only one more step, fusion of the regions associated with nearby modes. The proposed technique has two parameters controlling the resolution in the spatial and range domains. Since convergence is guaranteed, the technique does not require the intervention of the user to stop the filtering at the desired image quality. Several examples, for gray and color images, show the versatility of the method and compare favorably with results described in the literature for the same images.",5
796918285116a29537489bb7dc1778f2b1f3e4e8,Irreflexive and Hierarchical Relations as Translations,"We consider the problem of embedding entities and relations of knowledge bases in lowdimensional vector spaces. Unlike most existing approaches, which are primarily efficient for modeling equivalence relations, our approach is designed to explicitly model irreflexive relations, such as hierarchies, by interpreting them as translations operating on the low-dimensional embeddings of the entities. Preliminary experiments show that, despite its simplicity and a smaller number of parameters than previous approaches, our approach achieves state-of-the-art performance according to standard evaluation protocols on data from WordNet and Freebase.",5
f503e9e864f3faec3f627d2653d81b664e14390e,Altered small‐world brain functional networks in children with attention‐deficit/hyperactivity disorder,"In this study, we investigated the changes in topological architectures of brain functional networks in attention‐deficit/hyperactivity disorder (ADHD). Functional magnetic resonance images (fMRI) were obtained from 19 children with ADHD and 20 healthy controls during resting state. Brain functional networks were constructed by thresholding the correlation matrix between 90 cortical and subcortical regions and further analyzed by applying graph theoretical approaches. Experimental results showed that, although brain networks of both groups exhibited economical small‐world topology, altered functional networks were demonstrated in the brain of ADHD when compared with the normal controls. In particular, increased local efficiencies combined with a decreasing tendency in global efficiencies found in ADHD suggested a disorder‐related shift of the topology toward regular networks. Additionally, significant alterations in nodal efficiency were also found in ADHD, involving prefrontal, temporal, and occipital cortex regions, which were compatible with previous ADHD studies. The present study provided the first evidence for",9
9606ff5bdeb6b9bde63c5bf6ad22edeca51d35db,Distributional Semantics Beyond Words: Supervised Learning of Analogy and Paraphrase,"There have been several efforts to extend distributional semantics beyond individual words, to measure the similarity of word pairs, phrases, and sentences (briefly, tuples; ordered sets of words, contiguous or noncontiguous). One way to extend beyond words is to compare two tuples using a function that combines pairwise similarities between the component words in the tuples. A strength of this approach is that it works with both relational similarity (analogy) and compositional similarity (paraphrase). However, past work required hand-coding the combination function for different tasks. The main contribution of this paper is that combination functions are generated by supervised learning. We achieve state-of-the-art results in measuring relational similarity between word pairs (SAT analogies and SemEval 2012 Task 2) and measuring compositional similarity between noun-modifier phrases and unigrams (multiple-choice paraphrase questions).",6
cd89cc9a83ac2dd0639d7b452de1f9540271f274,Relational Collaborative Filtering: Modeling Multiple Item Relations for Recommendation,"Existing item-based collaborative filtering (ICF) methods leverage only the relation of collaborative similarity - i.e., the item similarity evidenced by user interactions like ratings and purchases. Nevertheless, there exist multiple relations between items in real-world scenarios, e.g., two movies share the same director, two products complement with each other, etc. Distinct from the collaborative similarity that implies co-interact patterns from the user's perspective, these relations reveal fine-grained knowledge on items from different perspectives of meta-data, functionality, etc. However, how to incorporate multiple item relations is less explored in recommendation research. In this work, we propose Relational Collaborative Filtering (RCF) to exploit multiple item relations in recommender systems. We find that both the relation type (e.g., shared director) and the relation value (e.g., Steven Spielberg) are crucial in inferring user preference. To this end, we develop a two-level hierarchical attention mechanism to model user preference - the first-level attention discriminates which",3
8731369a707046f3f8dd463d1fd107de31d40a24,Relation Extraction with Multi-instance Multi-label Convolutional Neural Networks,"Distant supervision is an efficient approach that automatically generates labeled data for relation extraction (RE). Traditional distantly supervised RE systems rely heavily on handcrafted features, and hence suffer from error propagation. Recently, a neural network architecture has been proposed to automatically extract features for relation classification. However, this approach follows the traditional expressed-at-least-once assumption, and fails to make full use of information across different sentences. Moreover, it ignores the fact that there can be multiple relations holding between the same entity pair. In this paper, we propose a multi-instance multi-label convolutional neural network for distantly supervised RE. It first relaxes the expressed-at-least-once assumption, and employs cross-sentence max-pooling so as to enable information sharing across different sentences. Then it handles overlapping relations by multi-label learning with a neural network classifier. Experimental results show that our approach performs significantly and consistently better than state-of-the-art methods.",5
52ba3eaf0b72b41f219315a3044fb63e398d205c,Minimal permutation sets for decoding the binary Golay codes,"For permutation decoding of an e error-correcting linear code, a set of permutations which move all error vectors of weight \leq e out of the information places is needed. A method of finding minimal decoding sets is given, along with minimal sets obtained with this method for the binary Golay codes.",4
0933564925aee8e761db53657033182f65a46735,RecWalk: Nearly Uncoupled Random Walks for Top-N Recommendation,"Random walks can provide a powerful tool for harvesting the rich network of interactions captured within item-based models for top-n recommendation. They can exploit indirect relations between the items, mitigate the effects of sparsity, ensure wider itemspace coverage, as well as increase the diversity of recommendation lists. Their potential however, is hindered by the tendency of the walks to rapidly concentrate towards the central nodes of the graph, thereby significantly restricting the range of K-step distributions that can be exploited for personalized recommendations. In this work we introduce RecWalk; a novel random walk-based method that leverages the spectral properties of nearly uncoupled Markov chains to provably lift this limitation and prolong the influence of users' past preferences on the successive steps of the walk--allowing the walker to explore the underlying network more fruitfully. A comprehensive set of experiments on real-world datasets verify the theoretically predicted properties of the proposed approach",5
a73531abe4cafbccd5b3e949e84410a50016bd33,SplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels,"We present Spline-based Convolutional Neural Networks (SplineCNNs), a variant of deep neural networks for irregular structured and geometric input, e.g., graphs or meshes. Our main contribution is a novel convolution operator based on B-splines, that makes the computation time independent from the kernel size due to the local support property of the B-spline basis functions. As a result, we obtain a generalization of the traditional CNN convolution operator by using continuous kernel functions parametrized by a fixed number of trainable weights. In contrast to related approaches that filter in the spectral domain, the proposed method aggregates features purely in the spatial domain. In addition, SplineCNN allows entire end-to-end training of deep architectures, using only the geometric structure as input, instead of handcrafted feature descriptors. For validation, we apply our method on tasks from the fields of image graph classification, shape correspondence and graph node classification, and show that it outperforms",11
abb33d75dc297993fcc3fb75e0f4498f413eb4f6,Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks,"One long-term goal of machine learning research is to produce methods that are applicable to reasoning and natural language, in particular building an intelligent dialogue agent. To measure progress towards that goal, we argue for the usefulness of a set of proxy tasks that evaluate reading comprehension via question answering. Our tasks measure understanding in several ways: whether a system is able to answer questions via chaining facts, simple induction, deduction and many more. The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human. We believe many existing learning systems can currently not solve them, and hence our aim is to classify these tasks into skill sets, so that researchers can identify (and then rectify) the failings of their systems. We also extend and improve the recently introduced Memory Networks model, and show it is able to solve some, but",6
29f68a9512a16c6db526fb166a6433be72ad005c,A reference data set of 5.4 million phased human variants validated by genetic inheritance from sequencing a three-generation 17-member pedigree,"Improvement of variant calling in next-generation sequence data requires a comprehensive, genome-wide catalogue of high-confidence variants called in a set of genomes for use as a benchmark. We generated deep, whole-genome sequence data of seventeen individuals in a three-generation pedigree and called variants in each genome using a range of currently available algorithms. We used haplotype transmission information to create a phased “platinum” variant catalogue of 4.7 million single nucleotide variants (SNVs) plus 0.7 million small (1-50bp) insertions and deletions (indels) that are consistent with the pattern of inheritance in the parents and eleven children of this pedigree. Platinum genotypes are highly concordant with the current catalogue of the National Institute of Standards and Technology for both SNVs (>99.99%) and indels (99.92%), and add a validated truth catalogue that has 26% more SNVs and 45% more indels. Analysis of 334,652 SNVs that were consistent between informatics pipelines yet inconsistent with",4
5e49c80f8b12a100c5f4518897c4cbf72710c252,Relational Deep Reinforcement Learning,"We introduce an approach for deep reinforcement learning (RL) that improves upon the efficiency, generalization capacity, and interpretability of conventional approaches through structured perception and relational reasoning. It uses self-attention to iteratively reason about the relations between entities in a scene and to guide a model-free policy. Our results show that in a novel navigation and planning task called Box-World, our agent finds interpretable solutions that improve upon baselines in terms of sample complexity, ability to generalize to more complex scenes than experienced during training, and overall performance. In the StarCraft II Learning Environment, our agent achieves state-of-the-art performance on six mini-games -- surpassing human grandmaster performance on four. By considering architectural inductive biases, our work opens new directions for overcoming important, but stubborn, challenges in deep RL.",5
f778186c42aac4822385ce43ebaeb79ac2ea5c1f,Spectral collaborative filtering,"Despite the popularity of Collaborative Filtering (CF), CF-based methods are haunted by the cold-start problem, which has a significantly negative impact on users' experiences with Recommender Systems (RS). In this paper, to overcome the aforementioned drawback, we first formulate the relationships between users and items as a bipartite graph. Then, we propose a new spectral convolution operation directly performing in the spectral domain, where not only the proximity information of a graph but also the connectivity information hidden in the graph are revealed. With the proposed spectral convolution operation, we build a deep recommendation model called Spectral Collaborative Filtering (SpectralCF). Benefiting from the rich information of connectivity existing in the spectral domain, SpectralCF is capable of discovering deep connections between users and items and therefore, alleviates the cold-start problem for CF. To the best of our knowledge, SpectralCF is the first CF-based method directly learning from the spectral domains of",4
50de83b8a00f448b3e344701a60dfdcfd84881f4,STransE: a novel embedding model of entities and relationships in knowledge bases,"Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform link prediction or knowledge base completion, i.e., predict whether a relationship not in the knowledge base is likely to be true. This paper combines insights from several previous link prediction models into a new embedding model STransE that represents each entity as a low-dimensional vector, and each relation by two matrices and a translation vector. STransE is a simple combination of the SE and TransE models, but it obtains better link prediction performance on two benchmark datasets than previous embedding models. Thus, STransE can serve as a new baseline for the more complex models in the link prediction task.",8
a1d70956de04935a0cc8f3b2f5b04bffabace669,Hierarchical functional modularity in the resting‐state human brain,"Functional magnetic resonance imaging (fMRI) studies have shown that anatomically distinct brain regions are functionally connected during the resting state. Basic topological properties in the brain functional connectivity (BFC) map have highlighted the BFC's small‐world topology. Modularity, a more advanced topological property, has been hypothesized to be evolutionary advantageous, contributing to adaptive aspects of anatomical and functional brain connectivity. However, current definitions of modularity for complex networks focus on nonoverlapping clusters, and are seriously limited by disregarding inclusive relationships. Therefore, BFC's modularity has been mainly qualitatively investigated. Here, we introduce a new definition of modularity, based on a recently improved clustering measurement, which overcomes limitations of previous definitions, and apply it to the study of BFC in resting state fMRI of 53 healthy subjects. Results show hierarchical functional modularity in the brain. Hum Brain Mapp, 2009. © 2008 Wiley‐Liss, Inc.",5
b94c7ff9532ab26c3aedbee3988ec4c7a237c173,Normalized cuts and image segmentation,"We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging.",23
aa5741c74b7fac10680c1cfbdd49d9ffb5751a68,Using Pre-Training Can Improve Model Robustness and Uncertainty,"He et al. (2018) have called into question the utility of pre-training by showing that training from scratch can often yield similar performance to pre-training. We show that although pre-training may not improve performance on traditional classification metrics, it improves model robustness and uncertainty estimates. Through extensive experiments on adversarial examples, label corruption, class imbalance, out-of-distribution detection, and confidence calibration, we demonstrate large gains from pre-training and complementary effects with task-specific methods. We introduce adversarial pre-training and show approximately a 10% absolute improvement over the previous state-of-the-art in adversarial robustness. In some cases, using pre-training without task-specific methods also surpasses the state-of-the-art, highlighting the need for pre-training when evaluating future methods on robustness and uncertainty tasks.",3
590ab5940a4d3e9d80821f90491c0c985ec26a9f,Optimal state-determination by mutually unbiased measurements,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
0cfac458b176a1e81879aff4344c5278114cc171,Leveraging Meta-path based Context for Top- N Recommendation with A Neural Co-Attention Model,"Heterogeneous information network (HIN) has been widely adopted in recommender systems due to its excellence in modeling complex context information. Although existing HIN based recommendation methods have achieved performance improvement to some extent, they have two major shortcomings. First, these models seldom learn an explicit representation for path or meta-path in the recommendation task. Second, they do not consider the mutual effect between the meta-path and the involved user-item pair in an interaction. To address these issues, we develop a novel deep neural network with the co-attention mechanism for leveraging rich meta-path based context for top-N recommendation. We elaborately design a three-way neural interaction model by explicitly incorporating meta-path based context. To construct the meta-path based context, we propose to use a priority based sampling technique to select high-quality path instances. Our model is able to learn effective representations for users, items and meta-path based context for implementing a powerful",8
a6cb366736791bcccc5c8639de5a8f9636bf87e8,Adam: A Method for Stochastic Optimization,"We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant",175
cddf8a10c7f48df67a797808a615be0d4acf9a8e,Semi-supervised Learning with Ladder Networks,"We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pre-training. Our work builds on top of the Ladder network proposed by Valpola [1] which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in semi-supervised MNIST and CIFAR-10 classification in addition to permutation-invariant MNIST classification with all labels.",8
5f5dc5b9a2ba710937e2c413b37b053cd673df02,Auto-Encoding Variational Bayes,"Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.",40
5863d7b35ea317c19f707376978ef1cc53e3534c,Rethinking Graph Transformers with Spectral Attention,"In recent years, the Transformer architecture has proven to be very successful in sequence processing, but its application to other data structures, such as graphs, has remained limited due to the difficulty of properly defining positions. Here, we present the $\textit{Spectral Attention Network}$ (SAN), which uses a learned positional encoding (LPE) that can take advantage of the full Laplacian spectrum to learn the position of each node in a given graph. This LPE is then added to the node features of the graph and passed to a fully-connected Transformer. By leveraging the full spectrum of the Laplacian, our model is theoretically powerful in distinguishing graphs, and can better detect similar sub-structures from their resonance. Further, by fully connecting the graph, the Transformer does not suffer from over-squashing, an information bottleneck of most GNNs, and enables better modeling of physical phenomenons such as heat transfer and electric interaction. When tested empirically",6
49c0ebbd20630a5811513217f9be1d210c742ae8,Isometric Transformation Invariant and Equivariant Graph Convolutional Networks,"Graphs are one of the most important data structures for representing pairwise relations between objects. Specifically, a graph embedded in a Euclidean space is essential to solving real problems, such as object detection, structural chemistry analyses, and physical simulation. A crucial requirement to applying a graph in a Euclidean space is learning the isometric transformation invariant and equivariant features. In the present paper, we propose a set of transformation invariant and equivariant models based on graph convolutional networks (GCNs), called IsoGCNs. We demonstrate that the proposed model outperforms state-of-the-art methods on tasks related with geometrical and physical data. Moreover, the proposed model can scale up to the graphs with 1M vertices and conduct an inference faster than a conventional finite element analysis.",2
521796dbbcc65c8e7b5163e40163e380df90db2b,Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture,"In this paper, we show that every $(2^{n-1}+1)$-vertex induced subgraph of the $n$-dimensional cube graph has maximum degree at least $\sqrt{n}$. This result is best possible, and improves a logarithmic lower bound shown by Chung, Furedi, Graham and Seymour in 1988. As a direct consequence, we prove that the sensitivity and degree of a boolean function are polynomially related, solving an outstanding foundational problem in theoretical computer science, the Sensitivity Conjecture of Nisan and Szegedy.",1
99db9cc963d8de90074e6364c12e1961a57e2017,Identification of Upstream Transcriptional Regulators of Ischemic Cardiomyopathy Using Cardiac RNA-Seq Meta-Analysis,"Ischemic cardiomyopathy (ICM), characterized by pre-existing myocardial infarction or severe coronary artery disease, is the major cause of heart failure (HF). Identification of novel transcriptional regulators in ischemic HF can provide important biomarkers for developing new diagnostic and therapeutic strategies. In this study, we used four RNA-seq datasets from four different studies, including 41 ICM and 42 non-failing control (NF) samples of human left ventricle tissues, to perform the first RNA-seq meta-analysis in the field of clinical ICM, in order to identify important transcriptional regulators and their targeted genes involved in ICM. Our meta-analysis identified 911 differentially expressed genes (DEGs) with 582 downregulated and 329 upregulated. Interestingly, 54 new DEGs were detected only by meta-analysis but not in individual datasets. Upstream regulator analysis through Ingenuity Pathway Analysis (IPA) identified three key transcriptional regulators. TBX5 was identified as the only inhibited regulator (z-score = −2.89). F2R and SFRP4 were identified as",3
6acf0d7b24a93953269a4d52c6b2f0c7d11f9ae4,Hoppity: Learning Graph Transformations to Detect and Fix Bugs in Programs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
2503dff90685857ce7295e37d0045e2eef41c8b8,FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling,"The graph convolutional networks (GCN) recently proposed by Kipf and Welling are an effective graph model for semi-supervised learning. This model, however, was originally designed to be learned with the presence of both training and test data. Moreover, the recursive neighborhood expansion across layers poses time and memory challenges for training with large, dense graphs. To relax the requirement of simultaneous availability of test data, we interpret graph convolutions as integral transforms of embedding functions under probability measures. Such an interpretation allows for the use of Monte Carlo approaches to consistently estimate the integrals, which in turn leads to a batched training scheme as we propose in this work---FastGCN. Enhanced with importance sampling, FastGCN not only is efficient for training but also generalizes well for inference. We show a comprehensive set of experiments to demonstrate its effectiveness compared with GCN and related models. In particular, training is orders of magnitude",29
b8da4337c92acda632e8138be1b525a3aef54b85,Semi-supervised Learning on Graphs with Generative Adversarial Nets,"We investigate how generative adversarial nets (GANs) can help semi-supervised learning on graphs. We first provide insights on working principles of adversarial learning over graphs and then present GraphSGAN, a novel approach to semi-supervised learning on graphs. In GraphSGAN, generator and classifier networks play a novel competitive game. At equilibrium, generator generates fake samples in low-density areas between subgraphs. In order to discriminate fake samples from the real, classifier implicitly takes the density property of subgraph into consideration. An efficient adversarial learning algorithm has been developed to improve traditional normalized graph Laplacian regularization with a theoretical guarantee. Experimental results on several different genres of datasets show that the proposed GraphSGAN significantly outperforms several state-of-the-art methods. GraphSGAN can be also trained using mini-batch, thus enjoys the scalability advantage.",4
fdc708aaa0d18c791f878ff2214201410fa52439,Graph Convolutional Matrix Completion,"We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.",18
04faf433934486c41d082e8d75ccfe5dc2f69fef,GPT-GNN: Generative Pre-Training of Graph Neural Networks,"Graph neural networks (GNNs) have been demonstrated to be powerful in modeling graph-structured data. However, training GNNs requires abundant task-specific labeled data, which is often arduously expensive to obtain. One effective way to reduce the labeling effort is to pre-train an expressive GNN model on unlabelled data with self-supervision and then transfer the learned model to downstream tasks with only a few labels. In this paper, we present the GPT-GNN framework to initialize GNNs by generative pre-training. GPT-GNN introduces a self-supervised attributed graph generation task to pre-train a GNN so that it can capture the structural and semantic properties of the graph. We factorize the likelihood of graph generation into two components: 1) attribute generation and 2) edge generation. By modeling both components, GPT-GNN captures the inherent dependency between node attributes and graph structure during the generative process. Comprehensive experiments on the billion-scale open academic graph and Amazon recommendation data",7
facf11419e149a03bd4a9bffdda2ebb433a59d85,Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks,"Graph neural networks (GNN) have shown great advantages in many graph-based learning tasks but often fail to predict accurately for a task-based on sets of nodes such as link/motif prediction and so on. Many works have recently proposed to address this problem by using random node features or node distance features. However, they suffer from either slow convergence, inaccurate prediction, or high complexity. In this work, we revisit GNNs that allow using positional features of nodes given by positional encoding (PE) techniques such as Laplacian Eigenmap, Deepwalk, etc. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable. Here, we study these issues in a principled way and propose a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. PEG uses separate channels to update the original node features and positional features. PEG imposes permutation equivariance w.r.t. the original",4
f37e1b62a767a307c046404ca96bc140b3e68cb5,GloVe: Global Vectors for Word Representation,"Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",36
5aadc803228b70c3cc6b31e332770d47d7fb1e6e,Joint Representation Learning of Cross-lingual Words and Entities via Attentive Distant Supervision,"Jointly representation learning of words and entities benefits many NLP tasks, but has not been well explored in cross-lingual settings. In this paper, we propose a novel method for joint representation learning of cross-lingual words and entities. It captures mutually complementary knowledge, and enables cross-lingual inferences among knowledge bases and texts. Our method does not require parallel corpus, and automatically generates comparable data via distant supervision using multi-lingual knowledge bases. We utilize two types of regularizers to align cross-lingual words and entities, and design knowledge attention and cross-lingual attention to further reduce noises. We conducted a series of experiments on three tasks: word translation, entity relatedness, and cross-lingual entity linking. The results, both qualitative and quantitative, demonstrate the significance of our method.",4
3f9df5c77af49d5b1b19eac9b82cb430b50f482d,Leveraging social media networks for classification,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
fcd24f925ee7f110bf63947f871367aabcc5fdc9,Towards Sparse Hierarchical Graph Classifiers,"Recent advances in representation learning on graphs, mainly leveraging graph convolutional networks, have brought a substantial improvement on many graph-based benchmark tasks. While novel approaches to learning node embeddings are highly suitable for node classification and link prediction, their application to graph classification (predicting a single label for the entire graph) remains mostly rudimentary, typically using a single global pooling step to aggregate node features or a hand-designed, fixed heuristic for hierarchical coarsening of the graph structure. An important step towards ameliorating this is differentiable graph coarsening---the ability to reduce the size of the graph in an adaptive, data-dependent manner within a graph neural network pipeline, analogous to image downsampling within CNNs. However, the previous prominent approach to pooling has quadratic memory requirements during training and is therefore not scalable to large graphs. Here we combine several recent advances in graph neural network design to demonstrate that competitive hierarchical graph",6
76528d368e36e43fdcac977e042dfa663f2ec158,The early evolution of the H-free process,"The H-free process, for some fixed graph H, is the random graph process defined by starting with an empty graph on n vertices and then adding edges one at a time, chosen uniformly at random subject to the constraint that no H subgraph is formed. Let G be the random maximal H-free graph obtained at the end of the process. When H is strictly 2-balanced, we show that for some c>0, with high probability as n→∞, the minimum degree in G is at least $cn^{1-(v_{H}-2)/(e_{H}-1)}(\log n)^{1/(e_{H}-1)}$. This gives new lower bounds for the Turán numbers of certain bipartite graphs, such as the complete bipartite graphs Kr,r with r≥5. When H is a complete graph Ks with s≥5 we show that for some C>0, with high probability the independence number of G is at most $Cn^{2/(s+1)}(\log n)^{1-1/(e_{H}-1)}$. This gives new lower bounds for Ramsey numbers R(s,t) for fixed s≥5 and t",6
a7dbaa06dc6948847b44fde69cc1f53b00bea328,Graph Embedding for Combinatorial Optimization: A Survey,"Graphs have been widely used to represent complex data in many applications, such as e-commerce, social networks, and bioinformatics. Efficient and effective analysis of graph data is important for graph-based applications. However, most graph analysis tasks are combinatorial optimization (CO) problems, which are NP-hard. Recent studies have focused a lot on the potential of using machine learning (ML) to solve graph-based CO problems. Using ML- based CO methods, a graph has to be represented in numerical vectors, which is known as graph embedding. In this survey, we provide a thorough overview of recent graph embedding methods that have been used to solve CO problems. Most graph embedding methods have two stages: graph preprocessing and ML model learning. This survey classifies graph embedding works from the perspective of graph preprocessing tasks and ML models. Furthermore, this survey summarizes recent graph-based CO methods that exploit graph embedding. In particular, graph embedding can",4
4f68caebe510a0d737759ee648daa3de4fc98627,Self-supervised Learning on Graphs: Deep Insights and New Direction,"The success of deep learning notoriously requires larger amounts of costly annotated data. This has led to the development of self-supervised learning (SSL) that aims to alleviate this limitation by creating domain specific pretext tasks on unlabeled data. Simultaneously, there are increasing interests in generalizing deep learning to the graph domain in the form of graph neural networks (GNNs). GNNs can naturally utilize unlabeled nodes through the simple neighborhood aggregation that is unable to thoroughly make use of unlabeled nodes. Thus, we seek to harness SSL for GNNs to fully exploit the unlabeled data. Different from data instances in the image and text domains, nodes in graphs present unique structure information and they are inherently linked indicating not independent and identically distributed (or i.i.d.). Such complexity is a double-edged sword for SSL on graphs. On the one hand, it determines that it is challenging to adopt solutions from the image",6
dcdf7774ee9b2de1ec307f2a53e3f44036dff6a1,PME: Projected Metric Embedding on Heterogeneous Networks for Link Prediction,"Heterogenous information network embedding aims to embed heterogenous information networks (HINs) into low dimensional spaces, in which each vertex is represented as a low-dimensional vector, and both global and local network structures in the original space are preserved. However, most of existing heterogenous information network embedding models adopt the dot product to measure the proximity in the low dimensional space, and thus they can only preserve the first-order proximity and are insufficient to capture the global structure. Compared with homogenous information networks, there are multiple types of links (i.e., multiple relations) in HINs, and the link distribution w.r.t relations is highly skewed. To address the above challenging issues, we propose a novel heterogenous information network embedding model PME based on the metric learning to capture both first-order and second-order proximities in a unified way. To alleviate the potential geometrical inflexibility of existing metric learning approaches, we propose to build object",2
e012d6bc0e511dca63e70efb2748dc0d12944f89,Logical and Relational Learning: From ILP to MRDM (Cognitive Technologies),"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
e33bc0cd79d92d6868989a29c3ab06b75f808590,Deep Nets: What have They Ever Done for Vision?,"This is an opinion paper about the strengths and weaknesses of Deep Nets for vision. They are at the heart of the enormous recent progress in artificial intelligence and are of growing importance in cognitive science and neuroscience. They have had many successes but also have several limitations and there is limited understanding of their inner workings. At present Deep Nets perform very well on specific visual tasks with benchmark datasets but they are much less general purpose, flexible, and adaptive than the human visual system. We argue that Deep Nets in their current form are unlikely to be able to overcome the fundamental problem of computer vision, namely how to deal with the combinatorial explosion, caused by the enormous complexity of natural images, and obtain the rich understanding of visual scenes that the human visual achieves. We argue that this combinatorial explosion takes us into a regime where “big",1
3db5fcb595492dcd64663c00d56f004dfafa689c,A Fair Comparison of Graph Neural Networks for Graph Classification,"Experimental reproducibility and replicability are critical topics in machine learning. Authors have often raised concerns about their lack in scientific publications to improve the quality of the field. Recently, the graph representation learning field has attracted the attention of a wide research community, which resulted in a large stream of works. As such, several Graph Neural Network models have been developed to effectively tackle graph classification. However, experimental procedures often lack rigorousness and are hardly reproducible. Motivated by this, we provide an overview of common practices that should be avoided to fairly compare with the state of the art. To counter this troubling trend, we ran more than 47000 experiments in a controlled and uniform framework to re-evaluate five popular models across nine common benchmarks. Moreover, by comparing GNNs with structure-agnostic baselines we provide convincing evidence that, on some datasets, structural information has not been exploited yet. We believe that",10
fc41d75288a81dd7e30087480f51821fc6572d95,GMAN: A Graph Multi-Attention Network for Traffic Prediction,"Long-term traffic prediction is highly challenging due to the complexity of traffic systems and the constantly changing nature of many impacting factors. In this paper, we focus on the spatio-temporal factors, and propose a graph multi-attention network (GMAN) to predict traffic conditions for time steps ahead at different locations on a road network graph. GMAN adapts an encoder-decoder architecture, where both the encoder and the decoder consist of multiple spatio-temporal attention blocks to model the impact of the spatio-temporal factors on traffic conditions. The encoder encodes the input traffic features and the decoder predicts the output sequence. Between the encoder and the decoder, a transform attention layer is applied to convert the encoded traffic features to generate the sequence representations of future time steps as the input of the decoder. The transform attention mechanism models the direct relationships between historical and future time steps that helps to alleviate the error",6
5d1d53c671b20db116ba8c91c6446bb4757614da,Temporal pattern attention for multivariate time series forecasting,"Forecasting of multivariate time series data, for instance the prediction of electricity consumption, solar power production, and polyphonic piano pieces, has numerous valuable applications. However, complex and non-linear interdependencies between time steps and series complicate this task. To obtain accurate prediction, it is crucial to model long-term dependency in time series data, which can be achieved by recurrent neural networks (RNNs) with an attention mechanism. The typical attention mechanism reviews the information at each previous time step and selects relevant information to help generate the outputs; however, it fails to capture temporal patterns across multiple time steps. In this paper, we propose using a set of filters to extract time-invariant temporal patterns, similar to transforming time series data into its “frequency domain”. Then we propose a novel attention mechanism to select relevant time series, and use its frequency domain information for multivariate forecasting. We apply the proposed model on several",4
844d502387a3996f167b04e2e83117c30c22e752,RDF2Vec: RDF Graph Embeddings for Data Mining,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
dedb4db1790ee4ec5e753824aefc85276ccf1ebc,"Self-Organization in Vision: Stochastic Clustering for Image Segmentation, Perceptual Grouping, and Image Database Organization","We present a stochastic clustering algorithm which uses pairwise similarity of elements and show how it can be used to address various problems in computer vision, including the low-level image segmentation, mid-level perceptual grouping, and high-level image database organization. The clustering problem is viewed as a graph partitioning problem, where nodes represent data elements and the weights of the edges represent pairwise similarities. We generate samples of cuts in this graph, by using Karger's contraction algorithm (1996), and compute an ""average"" cut which provides the basis for our solution to the clustering problem. The stochastic nature of our method makes it robust against noise, including accidental edges and small spurious clusters. The complexity of our algorithm is very low: O(|E| log/sup 2/ N) for N objects, |E| similarity relations, and a fixed accuracy level. In addition, and without additional computational cost, our algorithm provides a hierarchy of nested partitions. We",5
efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf,Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition,"Dynamics of human body skeletons convey significant information for human action recognition. Conventional approaches for modeling skeletons usually rely on hand-crafted parts or traversal rules, thus resulting in limited expressive power and difficulties of generalization. In this work, we propose a novel model of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks (ST-GCN), which moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data. This formulation not only leads to greater expressive power but also stronger generalization capability. On two large datasets, Kinetics and NTU-RGBD, it achieves substantial improvements over mainstream methods.",5
6c44f8e62d824bcda4f291c679a5518bbd4225f6,Adversarial Attacks on Neural Networks for Graph Data,"Deep learning models for graphs have achieved strong performance for the task of node classification. Despite their proliferation, currently there is no study of their robustness to adversarial attacks. Yet, in domains where they are likely to be used, e.g. the web, adversaries are common. Can deep learning models for graphs be easily fooled? In this work, we introduce the first study of adversarial attacks on attributed graphs, specifically focusing on models exploiting ideas of graph convolutions. In addition to attacks at test time, we tackle the more challenging class of poisoning/causative attacks, which focus on the training phase of a machine learning model.We generate adversarial perturbations targeting the node's features and the graph structure, thus, taking the dependencies between instances in account. Moreover, we ensure that the perturbations remain unnoticeable by preserving important data characteristics. To cope with the underlying discrete domain we propose an efficient algorithm Nettack exploiting",7
cfe2ae8886119c7ddeb4e1917838b60ae15a0ee8,Mapping anatomical connectivity patterns of human cerebral cortex using in vivo diffusion tensor imaging tractography.,"The characterization of the topological architecture of complex networks underlying the structural and functional organization of the brain is a basic challenge in neuroscience. However, direct evidence for anatomical connectivity networks in the human brain remains scarce. Here, we utilized diffusion tensor imaging deterministic tractography to construct a macroscale anatomical network capturing the underlying common connectivity pattern of human cerebral cortex in a large sample of subjects (80 young adults) and further quantitatively analyzed its topological properties with graph theoretical approaches. The cerebral cortex was divided into 78 cortical regions, each representing a network node, and 2 cortical regions were considered connected if the probability of fiber connections exceeded a statistical criterion. The topological parameters of the established cortical network (binarized) resemble that of a ""small-world"" architecture characterized by an exponentially truncated power-law distribution. These characteristics imply high resilience to localized damage. Furthermore, this cortical network was characterized by major",3
bb17ff968ae1dbd772ac337f469d1ca915cb4c03,MINE: Mutual Information Neural Estimation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
6a86696974d5d49b4b9be6bd10ffcf92f996f4db,Hierarchical Random Walk Inference in Knowledge Graphs,"Relational inference is a crucial technique for knowledge base population. The central problem in the study of relational inference is to infer unknown relations between entities from the facts given in the knowledge bases. Two popular models have been put forth recently to solve this problem, which are the latent factor models and the random-walk models, respectively. However, each of them has their pros and cons, depending on their computational efficiency and inference accuracy. In this paper, we propose a hierarchical random-walk inference algorithm for relational learning in large scale graph-structured knowledge bases, which not only maintains the computational simplicity of the random-walk models, but also provides better inference accuracy than related works. The improvements come from two basic assumptions we proposed in this paper. Firstly, we assume that although a relation between two entities is syntactically directional, the information conveyed by this relation is equally shared between the connected",4
63fa5751ba9dfb5e9d545b538a84e675a263ac03,StarZIP: Streaming Graph Compression Technique for Data Archiving,"The size of a streaming graph is possibly unbounded, and it is updated by a continuous sequence of edges over time. Due to numerous types of real-world interactions, the nature of edge arrival in a streaming graph is dynamic and holds different types of temporal subgraphs, such as stars, bipartite forms, cliques, and chains. The most current techniques find such subgraphs in each snapshot of a dynamic graph and use a dictionary or hash-based summary to compress the graph before applying a stitching technique to demonstrate its temporal behavior. However, it remains difficult to discover those subgraph structures from the continuous stream of edges found in large and rapidly changing dynamic graphs. In this paper, we propose a streaming graph compression algorithm, StarZIP, that uses a new encoding scheme. Our motivational factor is real-world graphs that contain an overwhelmingly large number of stars and a few other structures. We have",2
554aabebf17b11046ac734aac8ef5a71872e93e3,Semi-Supervised Learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
6b1793ece5993523855ce67c646de408318d1b12,Structured Sequence Modeling with Graph Convolutional Recurrent Networks,"This paper introduces Graph Convolutional Recurrent Network (GCRN), a deep learning model able to predict structured sequences of data. Precisely, GCRN is a generalization of classical recurrent neural networks (RNN) to data structured by an arbitrary graph. The structured sequences can represent series of frames in videos, spatio-temporal measurements on a network of sensors, or random walks on a vocabulary graph for natural language modeling. The proposed model combines convolutional neural networks (CNN) on graphs to identify spatial structures and RNN to find dynamic patterns. We study two possible architectures of GCRN, and apply the models to two practical problems: predicting moving MNIST data, and modeling natural language with the Penn Treebank dataset. Experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed.",12
0834e74304b547c9354b6d7da6fa78ef47a48fa8,LINE: Large-scale Information Network Embedding,"This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,'' which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn",51
955fe2ee26d888ae22749b0853981b8b581b133d,Holographic Embeddings of Knowledge Graphs,"Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator, HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. Experimentally, we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction on knowledge graphs and relational learning benchmark datasets.",23
b7b951e0eee7b1ce913fbf99f2b497491054b8ee,Vertex Reordering for Real-World Graphs and Applications: An Empirical Evaluation,"Vertex reordering is a way to improve locality in graph computations. Given an input (or “natural”) order, reordering aims to compute an alternate permutation of the vertices that is aimed at maximizing a locality-based objective. Given decades of research on this topic, there are tens of graph reordering schemes, and there are also several linear arrangement “gap” measures for treatment as objectives. However, a comprehensive empirical analysis of the efficacy of the ordering schemes against the different gap measures, and against real-world applications is currently lacking. In this study, we present an extensive empirical evaluation of up to 11 ordering schemes, taken from different classes of approaches, on a set of 34 real-world graphs emerging from different application domains. Our study is presented in two parts: a) a thorough comparative evaluation of the different ordering schemes on their effectiveness to optimize different linear arrangement gap measures, relevant to preserving locality;",5
51a2bc2e8fb8ed47a085df33dd965e57335080a0,Adaptive Graph Convolutional Neural Networks,"Graph Convolutional Neural Networks (Graph CNNs) are generalizations of classical CNNs to handle graph data such as molecular data, point could and social networks. Current filters in graph CNNs are built for fixed and shared graph structure. However, for most real data, the graph structures varies in both size and connectivity. The paper proposes a generalized and flexible graph CNN taking data of arbitrary graph structure as input. In that way a task-driven adaptive graph is learned for each graph data while training. To efficiently learn the graph, a distance metric learning is proposed. Extensive experiments on nine graph-structured datasets have demonstrated the superior performance improvement on both convergence speed and predictive accuracy.",17
7b4b801de1ba8a4456adcde7b1a9c5bc5cf09fc3,A saliency-based search mechanism for overt and covert shifts of visual attention,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
eaaf7b9166934e379f10a038ac5610d3360c12b3,Adversarial Contrastive Estimation,"Learning by contrasting positive and negative samples is a general strategy adopted by many methods. Noise contrastive estimation (NCE) for word embeddings and translating embeddings for knowledge graphs are examples in NLP employing this approach. In this work, we view contrastive learning as an abstraction of all such methods and augment the negative sampler into a mixture distribution containing an adversarially learned sampler. The resulting adaptive sampler finds harder negative examples, which forces the main model to learn a better representation of the data. We evaluate our proposal on learning word embeddings, order embeddings and knowledge graph embeddings and observe both faster convergence and improved results on multiple metrics.",3
23d31d6c75a3c62ee2cedd22308c5c0ba34217e7,A Factorization Approach to Grouping,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
241a7b3525dbe0132ab0559233e0a14a4b7e6ad9,Fast and accurate genomic analyses using genome graphs,"The human reference genome serves as the foundation for genomics by providing a scaffold for alignment of sequencing reads, but currently only reflects a single consensus haplotype, thus impairing analysis accuracy. Here we present a graph reference genome implementation that enables read alignment across 2,800 diploid genomes encompassing 12.6 million SNPs and 4.0 million insertions and deletions (indels). The pipeline processes one whole-genome sequencing sample in 6.5 h using a system with 36 CPU cores. We show that using a graph genome reference improves read mapping sensitivity and produces a 0.5% increase in variant calling recall, with unaffected specificity. Structural variations incorporated into a graph genome can be genotyped accurately under a unified framework. Finally, we show that iterative augmentation of graph genomes yields incremental gains in variant calling accuracy. Our implementation is an important advance toward fulfilling the promise of graph genomes to radically enhance the scalability and accuracy",4
0a6a9e6d4e3efd7c69357769305b70097281655f,DropEdge: Towards Deep Graph Convolutional Networks on Node Classification,"Over-fitting and over-smoothing are two main obstacles of developing deep Graph Convolutional Networks (GCNs) for node classification. In particular, over-fitting weakens the generalization ability on small dataset, while over-smoothing impedes model training by isolating output representations from the input features with the increase in network depth. This paper proposes DropEdge, a novel and flexible technique to alleviate both issues. At its core, DropEdge randomly removes a certain number of edges from the input graph at each training epoch, acting like a data augmenter and also a message passing reducer. Furthermore, we theoretically demonstrate that DropEdge either retards the convergence speed of over-smoothing or relieves the information loss caused by it. More importantly, our DropEdge is a general skill that can be equipped with many other backbone models (e.g. GCN, ResGCN, GraphSAGE, and JKNet) for enhanced performance. Extensive experiments on several benchmarks verify that DropEdge consistently improves the performance on a",7
18b47b83a373f33d6b902a3615f42c10f7600d72,Diffusion-Convolutional Neural Networks,"We present diffusion-convolutional neural networks (DCNNs), a new model for graph-structured data. Through the introduction of a diffusion-convolution operation, we show how diffusion-based representations can be learned from graph-structured data and used as an effective basis for node classification. DCNNs have several attractive qualities, including a latent representation for graphical data that is invariant under isomorphism, as well as polynomial-time prediction and learning that can be represented as tensor operations and efficiently implemented on the GPU. Through several experiments with real structured datasets, we demonstrate that DCNNs are able to outperform probabilistic relational models and kernel-on-graph methods at relational node classification tasks.",36
40cd779cb417c9e665ec29fdccc73a6499c5ae5e,Towards a theoretical foundation for Laplacian-based manifold methods,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
521fc80ac1ee85527386e5354cc0efcf95a70572,Learning to rank networked entities,"Several algorithms have been proposed to learn to rank entities modeled as feature vectors, based on relevance feedback. However, these algorithms do not model network connections or relations between entities. Meanwhile, Pagerank and variants find the stationary distribution of a reasonable but arbitrary Markov walk over a network, but do not learn from relevance feedback. We present a framework for ranking networked entities based on Markov walks with parameterized conductance values associated with the network edges. We propose two flavors of conductance learning problems in our framework. In the first setting, relevance feedback comparing node-pairs hints that the user has one or more hidden preferred communities with large edge conductance, and the algorithm must discover these communities. We present a constrained maximum entropy network flow formulation whose dual can be solved efficiently using a cutting-plane approach and a quasi-Newton optimizer. In the second setting, edges have types, and relevance feedback",3
692e0bb9f4656166f44b338245153957076a8add,Learning to Decipher the Heap for Program Verification,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
5889e9afbcc3935867f9ae16fe46c71b9f2b071f,End-to-end Differentiable Proving,"We introduce neural networks for end-to-end differentiable proving of queries to knowledge bases by operating on dense vector representations of symbols. These neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in Prolog. Specifically, we replace symbolic unification with a differentiable computation on vector representations of symbols using a radial basis function kernel, thereby combining symbolic reasoning with learning subsymbolic vector representations. By using gradient descent, the resulting neural network can be trained to infer facts from a given incomplete knowledge base. It learns to (i) place representations of similar symbols in close proximity in a vector space, (ii) make use of such similarities to prove queries, (iii) induce logical rules, and (iv) use provided and induced logical rules for multi-hop reasoning. We demonstrate that this architecture outperforms ComplEx, a state-of-the-art neural link prediction model, on three out of four benchmark knowledge bases while",4
5aea95e1ae78a66474051a330ded374e199b658c,Representation Learning on Graphs with Jumping Knowledge Networks,"Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure. We analyze some important properties of these models, and propose a strategy to overcome those. In particular, the range of ""neighboring"" nodes that a node's representation draws from strongly depends on the graph structure, analogous to the spread of a random walk. To adapt to local neighborhood properties and tasks, we explore an architecture -- jumping knowledge (JK) networks -- that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation. In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance. Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models' performance.",34
a882e89c43f5b7d21e122663fdac5dd9c473784a,Equiangular lines with a fixed angle,"Solving a longstanding problem on equiangular lines, we determine, for each given fixed angle and in all sufficiently large dimensions, the maximum number of lines pairwise separated by the given angle. Fix $0 < \alpha < 1$. Let $N_\alpha(d)$ denote the maximum number of lines in $\mathbb{R}^d$ with pairwise common angle $\arccos \alpha$. Let $k$ denote the minimum number (if it exists) of vertices of a graph whose adjacency matrix has spectral radius exactly $(1-\alpha)/(2\alpha)$. If $k < \infty$, then $N_\alpha(d) = \lfloor k(d-1)/(k-1) \rfloor$ for all sufficiently large $d$, and otherwise $N_\alpha(d) = d + o(d)$. In particular, $N_{1/(2k-1)}(d) = \lfloor k(d-1)/(k-1) \rfloor$ for every integer $k\geq 2$ and all sufficiently large $d$. A key ingredient is a new result in spectral graph theory: the adjacency matrix of a connected bounded degree graph has sublinear second eigenvalue multiplicity.",3
43879cf527f4918955fd55128baa6745174d8555,Graph networks as learnable physics engines for inference and control,"Understanding and interacting with everyday physical scenes requires rich knowledge about the structure of the world, represented either implicitly in a value or policy function, or explicitly in a transition model. Here we introduce a new class of learnable models--based on graph networks--which implement an inductive bias for object- and relation-centric representations of complex, dynamical systems. Our results show that as a forward model, our approach supports accurate predictions from real and simulated data, and surprisingly strong and efficient generalization, across eight distinct physical systems which we varied parametrically and structurally. We also found that our inference model can perform system identification. Our models are also differentiable, and support online planning via gradient-based trajectory optimization, as well as offline policy optimization. Our framework offers new opportunities for harnessing and exploiting rich knowledge about the world, and takes a key step toward building machines with more human-like representations of the world.",9
37298e7734119f3dbd4c5b4d8977b57a44574a50,MMM: Multi-source Multi-net Micro-video Recommendation with Clustered Hidden Item Representation Learning,"Unlike traditional video recommendations, micro-video inherits the characteristics of social platforms, such as social relation. A large amount of micro-videos showing explosive growth is badly affecting the user’s choice. In this paper, we propose a multi-source multi-net micro-video recommendation model that recommends micro-videos fitting users’ best interests. Different from existing works, as micro-video inherits the characteristics of social platforms, we simultaneously incorporate multi-source content data of items and multi-networks of users to learn user and item representations for recommendation. This information can be complementary to each other in a way that multi-modality data can bridge the semantic gap among items, while multi-type user networks, such as following and reposting, are able to propagate the preferences among users. Furthermore, to discover the hidden categories of micro-videos that properly match users’ interests, we interactively learn the user–item representations and perform the hidden item category clustering. The resulted categorical representations are interacted with",5
5bfe361afdfa98e2ea6053c0a3a35159e7867532,An efficient planarity algorithm,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
4600f2b2a143b7bcdf5dae83e456649deb1908de,A Collection of Benchmark Datasets for Systematic Evaluations of Machine Learning on the Semantic Web,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
5822490cf59df7f7ccb92b8901f244850b867a66,ETA Prediction with Graph Neural Networks in Google Maps,"Travel-time prediction constitutes a task of high importance in transportation networks, with web mapping services like Google Maps regularly serving vast quantities of travel time queries from users and enterprises alike. Further, such a task requires accounting for complex spatiotemporal interactions (modelling both the topological properties of the road network and anticipating events---such as rush hours---that may occur in the future). Hence, it is an ideal target for graph representation learning at scale. Here we present a graph neural network estimator for estimated time of arrival (ETA) which we have deployed in production at Google Maps. While our main architecture consists of standard GNN building blocks, we further detail the usage of training schedule methods such as MetaGradients in order to make our model robust and production-ready. We also provide prescriptive studies: ablating on various architectural decisions and training regimes, and qualitative analyses on real-world situations where our model provides",5
40f8ec2b554c501d5044b3e83bd40bdb7e5a2d8a,Alchemy: A Quantum Chemistry Dataset for Benchmarking AI Models,"We introduce a new molecular dataset, named Alchemy, for developing machine learning models useful in chemistry and material science. As of June 20th 2019, the dataset comprises of 12 quantum mechanical properties of 119,487 organic molecules with up to 14 heavy atoms, sampled from the GDB MedChem database. The Alchemy dataset expands the volume and diversity of existing molecular datasets. Our extensive benchmarks of the state-of-the-art graph neural network models on Alchemy clearly manifest the usefulness of new data in validating and developing machine learning models for chemistry and material science. We further launch a contest to attract attentions from researchers in the related fields. More details can be found on the contest website \footnote{this https URL}. At the time of benchamrking experiment, we have generated 119,487 molecules in our Alchemy dataset. More molecular samples are generated since then. Hence, we provide a list of molecules used in the reported",5
ae38ed953333fb39eb671fce0247db65a09b3a80,Visual correlates of fixation selection: effects of scale and time,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
d277a60f2904606193170131ffd0c1affc416c7b,Classifier and Exemplar Synthesis for Zero-Shot Learning,"Zero-shot learning (ZSL) enables solving a task without the need to see its examples. In this paper, we propose two ZSL frameworks that learn to synthesize parameters for novel unseen classes. First, we propose to cast the problem of ZSL as learning manifold embeddings from graphs composed of object classes, leading to a flexible approach that synthesizes “classifiers” for the unseen classes. Then, we define an auxiliary task of synthesizing “exemplars” for the unseen classes to be used as an automatic denoising mechanism for any existing ZSL approaches or as an effective ZSL model by itself. On five visual recognition benchmark datasets, we demonstrate the superior performances of our proposed frameworks in various scenarios of both conventional and generalized ZSL. Finally, we provide valuable insights through a series of empirical analyses, among which are a comparison of semantic representations on the full ImageNet benchmark as well as a comparison of",3
04b54d8c4a327f143c3d00fc432740e1183f2337,Point convolutional neural networks by extension operators,"This paper presents Point Convolutional Neural Networks (PCNN): a novel framework for applying convolutional neural networks to point clouds. The framework consists of two operators: extension and restriction, mapping point cloud functions to volumetric functions and vise-versa. A point cloud convolution is defined by pull-back of the Euclidean volumetric convolution via an extension-restriction mechanism. The point cloud convolution is computationally efficient, invariant to the order of points in the point cloud, robust to different samplings and varying densities, and translation invariant, that is the same convolution kernel is used at all points. PCNN generalizes image CNNs and allows readily adapting their architectures to the point cloud setting. Evaluation of PCNN on three central point cloud learning benchmarks convincingly outperform competing point cloud learning methods, and the vast majority of methods working with more informative shape representations such as surfaces and/or normals.",15
046c4ff0b08361b1ee84fecf1292d385d7bca277,Programmable Agents,"We build deep RL agents that execute declarative programs expressed in formal language. The agents learn to ground the terms in this language in their environment, and can generalize their behavior at test time to execute new programs that refer to objects that were not referenced during training. The agents develop disentangled interpretable representations that allow them to generalize to a wide variety of zero-shot semantic tasks.",6
387247374b28dbd4a89f231107c9cc55d748d1c0,Recurrent Event Network for Reasoning over Temporal Knowledge Graphs,"Recently, there has been a surge of interest in learning representation of graph-structured data that are dynamically evolving. However, current dynamic graph learning methods lack a principled way in modeling temporal, multi-relational, and concurrent interactions between nodes---a limitation that is especially problematic for the task of temporal knowledge graph reasoning, where the goal is to predict unseen entity relationships (i.e., events) over time. Here we present Recurrent Event Network (RE-Net)---a novel neural architecture for modeling complex event sequences---which consists of a recurrent event encoder and a neighborhood aggregator. The event encoder employs an RNN to capture (subject, relation) or (object, relation)-specific patterns from historical, multi-relational interactions between entities. The neighborhood aggregator summarizes concurrent, multi-hop entity interactions within each time stamp. An output layer is designed for predicting forthcoming events. Extensive experiments on temporal link prediction over four public TKG datasets demonstrate the effectiveness and strength of RE-Net, especially on multi-step",5
4e11ebdc3e4f30d774458fab9e4b45ff0d0aa971,Logical and relational learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
bd345877856dc83c2c10c125dbf0f41e2bde38b1,Knowledge Graph Representation with Jointly Structural and Textual Encoding,"The objective of knowledge graph embedding is to encode both entities and relations of knowledge graphs into continuous low-dimensional vector spaces. Previously, most works focused on symbolic representation of knowledge graph with structure information, which can not handle new entities or entities with few facts well. In this paper, we propose a novel deep architecture to utilize both structural and textual information of entities. Specifically, we introduce three neural models to encode the valuable information from text description of entity, among which an attentive model can select related information as needed. Then, a gating mechanism is applied to integrate representations of structure and text into a unified architecture. Experiments show that our models outperform baseline and obtain state-of-the-art results on link prediction and triplet classification tasks.",3
670941ccda31b4473943078e74011b5d54adaaf1,Multi-View Joint Graph Representation Learning for Urban Region Embedding,"The increasing amount of urban data enable us to investigate urban dynamics, assist urban planning, and eventually, make our cities more livable and sustainable. In this paper, we focus on learning an embedding space from urban data for urban regions. For the first time, we propose a multi-view joint learning model to learn comprehensive and representative urban region embeddings. We first model different types of region correlations based on both human mobility and inherent region properties. Then, we apply a graph attention mechanism in learning region representations from each view of the built correlations. Moreover, we introduce a joint learning module that boosts the region embedding learning by sharing cross-view information and fuses multi-view embeddings by learning adaptive weights. Finally, we exploit the learned embeddings in the downstream applications of land usage classification and crime prediction in urban areas with real-world data. Extensive experiment results demonstrate that by exploiting our",2
410abafed76d3ffd075b0e155e7b71e465efd126,Robust analysis of feature spaces: color image segmentation,"A general technique for the recovery of significant image features is presented. The technique is based on the mean shift algorithm, a simple nonparametric procedure for estimating density gradients. Drawbacks of the current methods (including robust clustering) are avoided. Feature space of any nature can be processed, and as an example, color image segmentation is discussed. The segmentation is completely autonomous, only its class is chosen by the user. Thus, the same program can produce a high quality edge image, or provide, by extracting all the significant colors, a preprocessor for content-based query systems. A 512/spl times/512 color image is analyzed in less than 10 seconds on a standard workstation. Gray level images are handled as color images having only the lightness coordinate.",6
c9538e13bd2a0e33948feb1fce2c56c0bc0eb5d9,Learning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference,"With the rapid development of urbanization and public transportation system, the number of traffic accidents have significantly increased globally over the past decades and become a big problem for human society. Facing these possible and unexpected traffic accidents, understanding what causes traffic accident and early alarms for some possible ones will play a critical role on planning effective traffic management. However, due to the lack of supported sensing data, research is very limited on the field of updating traffic accident risk in real-time. Therefore, in this paper, we collect big and heterogeneous data (7 months traffic accident data and 1.6 million users' GPS records) to understand how human mobility will affect traffic accident risk. By mining these data, we develop a deep model of Stack denoise Autoencoder to learn hierarchical feature representation of human mobility. And these features are used for efficient prediction of traffic accident risk level. Once the",6
b227f3e4c0dc96e5ac5426b85485a70f2175a205,Representation Learning with Contrastive Predictive Coding,"While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.",16
bbd384d538ba849f5c6a70d030f19fbf93f1dff7,Edge-colorability of graph bundles,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
dc7307f6e49f0ad2432be4eea92ae7f854c3cebb,Hierarchical Generation of Molecular Graphs using Structural Motifs,"Graph generation techniques are increasingly being adopted for drug discovery. Previous graph generation approaches have utilized relatively small molecular building blocks such as atoms or simple cycles, limiting their effectiveness to smaller molecules. Indeed, as we demonstrate, their performance degrades significantly for larger molecules. In this paper, we propose a new hierarchical graph encoder-decoder that employs significantly larger and more flexible graph motifs as basic building blocks. Our encoder produces a multi-resolution representation for each molecule in a fine-to-coarse fashion, from atoms to connected motifs. Each level integrates the encoding of constituents below with the graph at that level. Our autoregressive coarse-to-fine decoder adds one motif at a time, interleaving the decision of selecting a new motif with the process of resolving its attachments to the emerging molecule. We evaluate our model on multiple molecule generation tasks, including polymers, and show that our model significantly outperforms previous state-of-the-art baselines.",2
1bc2d0de52a77ad5e30d735be5a067c7bed24f9d,Recommendation,". An important task in recommender systems is suggesting relevant venues in a city to a user. These suggestions are usually created by exploiting the user’s history of preferences, which are, for example, collected in previously visited cities. In this paper, we ﬁrst introduce a user model based on venues’ categories and their descriptive keywords extracted from Foursquare tips. Then, we propose an enriched user model which leverages the users’ reviews from Yelp. Our participation in the TREC 2015 Contextual Suggestion track, conﬁrmed that our model out-performs other approaches by a signiﬁcant margin.",5
7b20de6209a318b2e36a59799098180cac37537a,Challenges and disparities in the application of personalized genomic medicine to populations with African ancestry,"To characterize the extent and impact of ancestry-related biases in precision genomic medicine, we use 642 whole-genome sequences from the Consortium on Asthma among African-ancestry Populations in the Americas (CAAPA) project to evaluate typical filters and databases. We find significant correlations between estimated African ancestry proportions and the number of variants per individual in all variant classification sets but one. The source of these correlations is highlighted in more detail by looking at the interaction between filtering criteria and the ClinVar and Human Gene Mutation databases. ClinVar’s correlation, representing African ancestry-related bias, has changed over time amidst monthly updates, with the most extreme switch happening between March and April of 2014 (r=0.733 to r=−0.683). We identify 68 SNPs as the major drivers of this change in correlation. As long as ancestry-related bias when using these clinical databases is minimally recognized, the genetics community will face challenges with implementation, interpretation and",5
2ca1abd015c72e7c04d63fa653b0a27d9592fc02,Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation,"Inductive transfer learning has had a big impact on computer vision and NLP domains but has not been used in the area of recommender systems. Even though there has been a large body of research on generating recommendations based on modeling user-item interaction sequences, few of them attempt to represent and transfer these models for serving downstream tasks where only limited data exists. In this paper, we delve on the task of effectively learning a single user representation that can be applied to a diversity of tasks, from cross-domain recommendations to user profile predictions. Fine-tuning a large pre-trained network and adapting it to downstream tasks is an effective way to solve such tasks. However, fine-tuning is parameter inefficient considering that an entire model needs to be re-trained for every new task. To overcome this issue, we develop a parameter-efficient transfer learning architecture, termed as PeterRec, which can be configured on-the-fly",4
7a5d1a7646ce1884ad76a0e177f956ae4d77c722,Group Equivariant Stand-Alone Self-Attention For Vision,"We provide a general self-attention formulation to impose group equivariance to arbitrary symmetry groups. This is achieved by defining positional encodings that are invariant to the action of the group considered. Since the group acts on the positional encoding directly, group equivariant self-attention networks (GSA-Nets) are steerable by nature. Our experiments on vision benchmarks demonstrate consistent improvements of GSA-Nets over non-equivariant self-attention networks.",2
aaf046c4da99ee6184f3fd31961a9967272152f9,Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network,"The prediction of organic reaction outcomes is a fundamental problem in computational chemistry. Since a reaction may involve hundreds of atoms, fully exploring the space of possible transformations is intractable. The current solution utilizes reaction templates to limit the space, but it suffers from coverage and efficiency issues. In this paper, we propose a template-free approach to efficiently explore the space of product molecules by first pinpointing the reaction center -- the set of nodes and edges where graph edits occur. Since only a small number of atoms contribute to reaction center, we can directly enumerate candidate products. The generated candidates are scored by a Weisfeiler-Lehman Difference Network that models high-order interactions between changes occurring at nodes across the molecule. Our framework outperforms the top-performing template-based approach with a 10\% margin, while running orders of magnitude faster. Finally, we demonstrate that the model accuracy rivals the performance of domain experts.",8
745d5b507583f7c7e101bc1cf14d957148285565,Evaluating graph neural networks under graph sampling scenarios,"Background It is often the case that only a portion of the underlying network structure is observed in real-world settings. However, as most network analysis methods are built on a complete network structure, the natural questions to ask are: (a) how well these methods perform with incomplete network structure, (b) which structural observation and network analysis method to choose for a specific task, and (c) is it beneficial to complete the missing structure. Methods In this paper, we consider the incomplete network structure as one random sampling instance from a complete graph, and we choose graph neural networks (GNNs), which have achieved promising results on various graph learning tasks, as the representative of network analysis methods. To identify the robustness of GNNs under graph sampling scenarios, we systemically evaluated six state-of-the-art GNNs under four commonly used graph sampling methods. Results We show that GNNs can still be applied on single",5
b87edd8d4583d1135428245548c68ba03c3fc6eb,Document Mining Using Graph Neural Network,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
6a116b897569fe4d6ea9ad4c3ba9a18825b96f49,Differentiable Learning of Logical Rules for Knowledge Base Completion,"Learned models composed of probabilistic logical rules are useful for many tasks, such as knowledge base completion. Unfortunately this learning problem is difficult, since determining the structure of the theory normally requires solving a discrete optimization problem. In this paper, we propose an alternative approach: a completely differentiable model for learning sets of first-order rules. The approach is inspired by a recently-developed differentiable logic, i.e. a subset of first-order logic for which inference tasks can be compiled into sequences of differentiable operations. Here we describe a neural controller system which learns how to sequentially compose the these primitive differentiable operations to solve reasoning tasks, and in particular, to perform knowledge base completion. The long-term goal of this work is to develop integrated, end-to-end systems that can learn to perform high-level logical reasoning as well as lower-level perceptual tasks.",4
5c57bb5630835a05eb1c3d0df3e12d6180d75de2,One-Shot Imitation Learning,"Imitation learning has been commonly applied to solve different tasks in isolation. This usually requires either careful feature engineering, or a significant number of samples. This is far from what we desire: ideally, robots should be able to learn from very few demonstrations of any given task, and instantly generalize to new situations of the same task, without requiring task-specific engineering. In this paper, we propose a meta-learning framework for achieving such capability, which we call one-shot imitation learning. Specifically, we consider the setting where there is a very large set of tasks, and each task has many instantiations. For example, a task could be to stack all blocks on a table into a single tower, another task could be to place all blocks on a table into two-block towers, etc. In each case, different instances of the task would consist of different sets of blocks with different initial states.",5
7f7942ca5bad4668eb2246fccc497095c6afcad7,Computing customized page ranks,"In this article, we present a new approach to page ranking. The page rank of a collection of Web pages can be represented in a parameterized model, and the user requirements can be represented by a set of constraints. For a particular parameterization, namely, a linear combination of the page ranks produced by different forcing functions, and user requirements represented by a set of linear constraints, the problem can be solved using a quadratic programming method. The solution to this problem produces a set of parameters which can be used for ranking all pages in the Web. We show that the method is suitable for building customized versions of PageRank which can be readily adapted to the needs of a vertical search engine or that of a single user.",8
6c9817b90cfc7cd78143f3749e602febd84d2a81,Segmentation by grouping junctions,"We propose a method for segmenting gray-value images. By segmentation, we mean a map from the set of pixels to a small set of levels such that each connected component of the set of pixels with the same level forms a relatively large and ""meaningful"" region. The method finds a set of levels with associated gray values by first finding junctions in the image and then seeking a minimum set of threshold values that preserves the junctions. Then it finds a segmentation map that maps each pixel to the level with the closest gray value to the pixel data, within a smoothness constraint. For a convex smoothing penalty, we show the global optimal solution for an energy function that fits the data can be obtained in a polynomial time, by a novel use of the maximum-flow algorithm. Our approach is in contrast to a view in computer vision where segmentation",10
7d4dcee4628745f79f5e352859172817fece3e83,Adaptive Graph Encoder for Attributed Graph Embedding,"Attributed graph embedding, which learns vector representations from graph topology and node features, is a challenging task for graph analysis. Recently, methods based on graph convolutional networks (GCNs) have made great progress on this task. However,existing GCN-based methods have three major drawbacks. Firstly,our experiments indicate that the entanglement of graph convolutional filters and weight matrices will harm both the performance and robustness. Secondly, we show that graph convolutional filters in these methods reveal to be special cases of generalized Laplacian smoothing filters, but they do not preserve optimal low-pass characteristics. Finally, the training objectives of existing algorithms are usually recovering the adjacency matrix or feature matrix, which are not always consistent with real-world applications. To address these issues, we propose Adaptive Graph Encoder (AGE), a novel attributed graph embedding framework. AGE consists of two modules: (1) To better alleviate the high-frequency noises in the node features, AGE first applies a",5
664967b5c542489881d7e48784a4b732ceee5e98,Age-related changes in modular organization of human brain functional networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
fee3596658a92832c3d8fcb46b07c7bcf3e25914,"Pregel: a system for large-scale graph processing - ""ABSTRACT""","Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs—in some cases billions of vertices, trillions of edges—poses challenges to their efficient processing. Despite the ubiquity of large graphs and their commercial importance, we know of no scalable general-purpose system for implementing graph algorithms in a distributed environment. To address distributed processing of real-life graphs, we defined a model of computation and realized it through a scalable and fault-tolerant system called Pregel, with an expressive and flexible API. The high-level organization of Pregel programs is inspired by Valiant’s Bulk Synchronous Parallel model. Pregel computations consist of a sequence of iterations, called superstep s. During a superstep the framework invokes a userdefined Compute() function for each vertex, conceptually in parallel. The function specifies behavior at a single vertex v and a single superstep S. It can read messages sent",7
b9c8c93c6112687d25525b996dc951fb845e8648,Self-supervised Training of Graph Convolutional Networks,"Graph Convolutional Networks (GCNs) have been successfully applied to analyze non-grid data, where the classical convolutional neural networks (CNNs) cannot be directly used. One similarity shared by GCNs and CNNs is the requirement of massive amount of labeled data for network training. In addition, GCNs need the adjacency matrix as input to define the relationship between those non-grid data, which leads to all of data including training, validation and test data typically forms only one graph structures data for training. Furthermore, the adjacency matrix is usually pre-defined and stationary, which makes the data augmentation strategies cannot be employed on the constructed graph structures data to augment the amount of training data. To further improve the learning capacity and model performance under the limited training data, in this paper, we propose two types of self-supervised learning strategies to exploit available information from the input graph structure data itself. Our proposed self-supervised",2
a156e15812ab648e0f455f08dbe50c3cdffade48,Globally Optimal Regions and Boundaries as Minimum Ratio Weight Cycles,"We describe a new form of energy functional for the modeling and identification of regions in images. The energy is defined on the space of boundaries in the image domain and can incorporate very general combinations of modeling information both from the boundary (intensity gradients, etc.) and from the interior of the region (texture, homogeneity, etc.). We describe two polynomial-time digraph algorithms for finding the global minima of this energy. One of the algorithms is completely general, minimizing the functional for any choice of modeling information. It runs in a few seconds on a 256/spl times/256 image. The other algorithm applies to a subclass of functionals, but has the advantage of being extremely parallelizable. Neither algorithm requires initialization.",3
af3825437b627db1a99f946f7aa773ba8b03befd,Learning deep representations by mutual information estimation and maximization,"This work investigates unsupervised learning of representations by maximizing mutual information between an input and the output of a deep neural network encoder. Importantly, we show that structure matters: incorporating knowledge about locality in the input into the objective can significantly improve a representation’s suitability for downstream tasks. We further control characteristics of the representation by matching to a prior distribution adversarially. Our method, which we call Deep InfoMax (DIM), outperforms a number of popular unsupervised learning methods and compares favorably with fully-supervised learning on several classification tasks in with some standard architectures. DIM opens new avenues for unsupervised learning of representations and is an important step towards flexible formulations of representation learning objectives for specific end-goals.",9
e9287b896a1c7360567915c3932b8df1ee4a81f7,An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge,"With the rapid growth of knowledge bases (KBs) on the web, how to take full advantage of them becomes increasingly important. Question answering over knowledge base (KB-QA) is one of the promising approaches to access the substantial knowledge. Meanwhile, as the neural network-based (NN-based) methods develop, NN-based KB-QA has already achieved impressive results. However, previous work did not put more emphasis on question representation, and the question is converted into a fixed vector regardless of its candidate answers. This simple representation strategy is not easy to express the proper information in the question. Hence, we present an end-to-end neural network model to represent the questions and their corresponding scores dynamically according to the various candidate answer aspects via cross-attention mechanism. In addition, we leverage the global knowledge inside the underlying KB, aiming at integrating the rich KB information into the representation of the answers. As a result, it could alleviates",11
015395cd36b17f30050c8f2449db669de172200c,Aspect-Level Deep Collaborative Filtering via Heterogeneous Information Networks,"Latent factor models have been widely used for recommendation. Most existing latent factor models mainly utilize the rating information between users and items, although some recently extended models add some auxiliary information to learn a unified latent factor between users and items. The unified latent factor only represents the latent features of users and items from the aspect of purchase history. However, the latent features of users and items may stem from different aspects, e.g., the brand-aspect and category-aspect of items. In this paper, we propose a Neural network based Aspect-level Collaborative Filtering model (NeuACF) to exploit different aspect latent factors. Through modelling rich objects and relations in recommender system as a heterogeneous information network, NeuACF first extracts different aspect-level similarity matrices of users and items through different meta-paths and then feeds an elaborately designed deep neural network with these matrices to learn aspect-level latent factors. Finally, the aspect-level latent",2
ca064483ce24c92b738a16a33d4eeb4541bdd9f6,Interpretable Fashion Matching with Rich Attributes,"Understanding the mix-and-match relationships of fashion items receives increasing attention in fashion industry. Existing methods have primarily utilized the visual content to learn the visual compatibility and performed matching in a latent space. Despite their effectiveness, these methods work like a black box and cannot reveal the reasons that two items match well. The rich attributes associated with fashion items, e.g.,off-shoulder dress and black skinny jean, which describe the semantics of items in a human-interpretable way, have largely been ignored. This work tackles the interpretable fashion matching task, aiming to inject interpretability into the compatibility modeling of items. Specifically, given a corpus of matched pairs of items, we not only can predict the compatibility score of unseen pairs, but also learn the interpretable patterns that lead to a good match, e.g., white T-shirt matches with black trouser. We propose a new solution named A ttribute-based I nterpretable C ompatibility (AIC)",8
a6a735f8e218f772e5b9dac411fa4abea87fdb9c,Recurrent knowledge graph embedding for effective recommendation,"Knowledge graphs (KGs) have proven to be effective to improve recommendation. Existing methods mainly rely on hand-engineered features from KGs (e.g., meta paths), which requires domain knowledge. This paper presents RKGE, a KG embedding approach that automatically learns semantic representations of both entities and paths between entities for characterizing user preferences towards items. Specifically, RKGE employs a novel recurrent network architecture that contains a batch of recurrent networks to model the semantics of paths linking a same entity pair, which are seamlessly fused into recommendation. It further employs a pooling operator to discriminate the saliency of different paths in characterizing user preferences towards items. Extensive validation on real-world datasets shows the superiority of RKGE against state-of-the-art methods. Furthermore, we show that RKGE provides meaningful explanations for recommendation results.",4
6667a57c8ffa3f3c0d724b1e8e986758995df2b8,Equivariant Subgraph Aggregation Networks,"Message-passing neural networks (MPNNs) are the leading architecture for deep learning on graph-structured data, in large part due to their simplicity and scalability. Unfortunately, it was shown that these architectures are limited in their expressive power. This paper proposes a novel framework called Equivariant Subgraph Aggregation Networks (ESAN) to address this issue. Our main observation is that while two graphs may not be distinguishable by an MPNN, they often contain distinguishable subgraphs. Thus, we propose to represent each graph as a set of subgraphs derived by some predefined policy, and to process it using a suitable equivariant architecture. We develop novel variants of the 1-dimensional Weisfeiler-Leman (1-WL) test for graph isomorphism, and prove lower bounds on the expressiveness of ESAN in terms of these new WL variants. We further prove that our approach increases the expressive power of both MPNNs and more expressive architectures. Moreover, we provide theoretical results that",2
6ca944ae76b4c71c5940c4172ef8222897d6cd51,Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting,"Traffic forecasting is of great importance to transportation management and public safety, and very challenging due to the complicated spatial-temporal dependency and essential uncertainty brought about by the road network and traffic conditions. Latest studies mainly focus on modeling the spatial dependency by utilizing graph convolutional networks (GCNs) throughout a fixed weighted graph. However, edges, i.e., the correlations between pair-wise nodes, are much more complicated and interact with each other. In this paper, we propose the Multi-Range Attentive Bicomponent GCN (MRA-BGCN), a novel deep learning model for traffic forecasting. We first build the node-wise graph according to the road network distance and the edge-wise graph according to various edge interaction patterns. Then, we implement the interactions of both nodes and edges using bicomponent graph convolution. The multi-range attention mechanism is introduced to aggregate information in different neighborhood ranges and automatically learn the importance of different ranges. Extensive experiments on two",5
2a6d160b529272964ce1a6707adf52f3d6ba4861,Diffusion Improves Graph Learning,"Graph convolution is the core of most Graph Neural Networks (GNNs) and usually approximated by message passing between direct (one-hop) neighbors. In this work, we remove the restriction of using only the direct neighbors by introducing a powerful, yet spatially localized graph convolution: Graph diffusion convolution (GDC). GDC leverages generalized graph diffusion, examples of which are the heat kernel and personalized PageRank. It alleviates the problem of noisy and often arbitrarily defined edges in real graphs. We show that GDC is closely related to spectral-based models and thus combines the strengths of both spatial (message passing) and spectral methods. We demonstrate that replacing message passing with graph diffusion convolution consistently leads to significant performance improvements across a wide range of models on both supervised and unsupervised tasks and a variety of datasets. Furthermore, GDC is not limited to GNNs but can trivially be combined with any graph-based model or algorithm",4
359fb7f6cac282bb0f98e9063565c532b73eab8d,Backtrack Programming,"A widely used method of efftcient search is examined in detail. This examination provides the opportunity to formulate its scope and methods in their full generality. In addL tion to a general exposition of the basic process, some important refinemertts are indicated. Examples are given which illustrate the salient features of this searching process.",7
26e7c671b37a65f6680815ad4c1e093a2e5a253c,Graph Policy Network for Transferable Active Learning on Graphs,"Graph neural networks (GNNs) have been attracting increasing popularity due to their simplicity and effectiveness in a variety of fields. However, a large number of labeled data is generally required to train these networks, which could be very expensive to obtain in some domains. In this paper, we study active learning for GNNs, i.e., how to efficiently label the nodes on a graph to reduce the annotation cost of training GNNs. We formulate the problem as a sequential decision process on graphs and train a GNN-based policy network with reinforcement learning to learn the optimal query strategy. By jointly training on several source graphs with full labels, we learn a transferable active learning policy which can directly generalize to unlabeled target graphs. Experimental results on multiple datasets from different domains prove the effectiveness of the learned policy in promoting active learning performance in both settings of transferring between graphs in",4
1fd404adf8c18a1cfc5e15efc84ae1b53cd9c8e0,Planarity Testing in V log V Steps: Extended Abstract,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
fff114cbba4f3ba900f33da574283e3de7f26c83,DeepWalk: online learning of social representations,"We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk's representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk's representations are able to outperform all baseline methods while using",75
de9550945b2f631c541c299114a770c4f47f9616,Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs,"We consider a simple and overarching representation for permutation-invariant functions of sequences (or multiset functions). Our approach, which we call Janossy pooling, expresses a permutation-invariant function as the average of a permutation-sensitive function applied to all reorderings of the input sequence. This allows us to leverage the rich and mature literature on permutation-sensitive functions to construct novel and flexible permutation-invariant functions. If carried out naively, Janossy pooling can be computationally prohibitive. To allow computational tractability, we consider three kinds of approximations: canonical orderings of sequences, functions with $k$-order interactions, and stochastic optimization algorithms with random permutations. Our framework unifies a variety of existing work in the literature, and suggests possible modeling and algorithmic extensions. We explore a few in our experiments, which demonstrate improved performance over current state-of-the-art methods.",3
47ae807cd511b35e78a2cd4e198283dea6dafd41,Do Transformers Really Perform Bad for Graph Representation?,"The Transformer architecture has become a dominant choice in many domains, such as natural language processing and computer vision. Yet, it has not achieved competitive performance on popular leaderboards of graph-level prediction compared to mainstream GNN variants. Therefore, it remains a mystery how Transformers could perform well for graph representation learning. In this paper, we solve this mystery by presenting Graphormer, which is built upon the standard Transformer architecture, and could attain excellent results on a broad range of graph representation learning tasks, especially on the recent OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the graph is the necessity of effectively encoding the structural information of a graph into the model. To this end, we propose several simple yet effective structural encoding methods to help Graphormer better model graph-structured data. Besides, we mathematically characterize the expressive power of Graphormer and exhibit that with our ways of encoding",7
54667e6bc8b370b41ffdc3310fa9b3e664e0cc94,Bilinear Graph Neural Network with Neighbor Interactions,"Graph Neural Network (GNN) is a powerful model to learn representations and make predictions on graph data. Existing efforts on GNN have largely defined the graph convolution as a weighted sum of the features of the connected nodes to form the representation of the target node. Nevertheless, the operation of weighted sum assumes the neighbor nodes are independent of each other, and ignores the possible interactions between them. When such interactions exist, such as the co-occurrence of two neighbor nodes is a strong signal of the target node's characteristics, existing GNN models may fail to capture the signal. In this work, we argue the importance of modeling the interactions between neighbor nodes in GNN. We propose a new graph convolution operator, which augments the weighted sum with pairwise interactions of the representations of neighbor nodes. We term this framework as Bilinear Graph Neural Network (BGNN), which improves GNN representation ability",4
ad7098af070e5d8fb6822b4eb3bb0bb485d3892a,Scientific Applications: An algorithm for identifying the ergodic subchains and transient states of a stochastic matrix,"An algorithm for identifying the ergodic subchains and transient states of a stochastic matrix is presented. Applications in Markov renewal programming and in the construction of variable length codes are reviewed, and an updating procedure for dealing with certain sequences of stochastic matrices is discussed. Computation times are investigated experimentally and compared with those of another recently proposed method.",4
ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649,Understanding the difficulty of training deep feedforward neural networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",36
ccb7ad8ea38991798172c33aee83f4d68a45d376,Generating 3D faces using Convolutional Mesh Autoencoders,"Learned 3D representations of human faces are useful for computer vision problems such as 3D face tracking and reconstruction from images, as well as graphics applications such as character generation and animation. Traditional models learn a latent representation of a face using linear subspaces or higher-order tensor generalizations. Due to this linearity, they can not capture extreme deformations and non-linear expressions. To address this, we introduce a versatile model that learns a non-linear representation of a face using spectral convolutions on a mesh surface. We introduce mesh sampling operations that enable a hierarchical mesh representation that captures non-linear variations in shape and expression at multiple scales within the model. In a variational setting, our model samples diverse realistic 3D faces from a multivariate Gaussian distribution. Our training data consists of 20,466 meshes of extreme expressions captured over 12 different subjects. Despite limited training data, our trained model outperforms state-of-the-art face",4
d8b96b98cd36bcbc94b0ffd4049305d62fbee7ea,Gotcha - Sly Malware!: Scorpion A Metagraph2vec Based Malware Detection System,"Due to its severe damages and threats to the security of the Internet and computing devices, malware detection has caught the attention of both anti-malware industry and researchers for decades. To combat the evolving malware attacks, in this paper, we first study how to utilize both content- and relation-based features to characterize sly malware; to model different types of entities (i.e., file, archive, machine, API, DLL ) and the rich semantic relationships among them (i.e., file-archive, file-machine, file-file, API-DLL, file-API relations), we then construct a structural heterogeneous information network (HIN) and present meta-graph based approach to depict the relatedness over files. To measure the relatedness over files on the constructed HIN, since malware detection is a cost-sensitive task, it calls for efficient methods to learn latent representations for HIN. To address this challenge, based on the built meta-graph schemes, we propose a new HIN embedding model metagraph2vec on the first",2
a92d7de31100a0fee816f0cb61b4a2a5a2d5e37a,Semi-Supervised Learning,"In the field of machine learning, semi-supervised learning (SSL) occupies the middle ground, between supervised learning (in which all training examples are labeled) and unsupervised learning (in which no label data are given). Interest in SSL has increased in recent years, particularly because of application domains in which unlabeled data are plentiful, such as images, text, and bioinformatics. This first comprehensive overview of SSL presents state-of-the-art algorithms, a taxonomy of the field, selected applications, benchmark experiments, and perspectives on ongoing and future research. Semi-Supervised Learning first presents the key assumptions and ideas underlying the field: smoothness, cluster or low-density separation, manifold structure, and transduction. The core of the book is the presentation of SSL methods, organized according to algorithmic strategies. After an examination of generative models, the book describes algorithms that implement the low-density separation assumption, graph-based methods, and algorithms that perform two-step learning. The book then discusses SSL applications",7
acc43abe319bca7652a91f7d4ca6187049fb82e4,Measuring abstract reasoning in neural networks,"Whether neural networks can learn abstract reasoning or whether they merely rely on superficial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation `regimes' in which the training and test data differ in clearly-defined ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with a structure designed to encourage reasoning, that does significantly better. When we vary the way in which the test questions and training data differ, we find that our model is notably proficient at certain forms of generalisation, but notably weak at others. We further show that the model's ability to generalise improves markedly if it is trained to predict symbolic",7
378f0a62471ef232c7730d8a67717afa5104ab21,Heterogeneous Information Network Embedding for Recommendation,"Due to the flexibility in modelling data heterogeneity, heterogeneous information network (HIN) has been adopted to characterize complex and heterogeneous auxiliary data in recommender systems, called HIN based recommendation. It is challenging to develop effective methods for HIN based recommendation in both extraction and exploitation of the information from HINs. Most of HIN based recommendation methods rely on path based similarity, which cannot fully mine latent structure features of users and items. In this paper, we propose a novel heterogeneous network embedding based approach for HIN based recommendation, called HERec. To embed HINs, we design a meta-path based random walk strategy to generate meaningful node sequences for network embedding. The learned node embeddings are first transformed by a set of fusion functions, and subsequently integrated into an extended matrix factorization (MF) model. The extended MF model together with fusion functions are jointly optimized for the rating prediction task. Extensive experiments",8
22f95fb555278ebe0ad2e5e18aaaf8be3e4e53fe,Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs,"The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge. Reasoning over time in such dynamic knowledge graphs is not yet well understood. To this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time. The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings. We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets. Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multi-relational setting.",4
b52b9b682d0ec79afed694e9b2c88127f5bfa48e,A simple yet effective baseline for non-attribute graph classification,"Graphs are complex objects that do not lend themselves easily to typical learning tasks. Recently, a range of approaches based on graph kernels or graph neural networks have been developed for graph classification and for representation learning on graphs in general. As the developed methodologies become more sophisticated, it is important to understand which components of the increasingly complex methods are necessary or most effective. As a first step, we develop a simple yet meaningful graph representation, and explore its effectiveness in graph classification. We test our baseline representation for the graph classification task on a range of graph datasets. Interestingly, this simple representation achieves similar performance as the state-of-the-art graph kernels and graph neural networks for non-attributed graph classification. Its performance on classifying attributed graphs is slightly weaker as it does not incorporate attributes. However, given its simplicity and efficiency, we believe that it still serves as an effective",6
a89e5bedebd4cc8df7b31408fc23ec9706ceaf12,Efficient algorithms for graph manipulation,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
6bc4004347cdf76d84597210796f38fcf7a01a80,Directional Message Passing for Molecular Graphs,"Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes) and not the spatial direction from one atom to another. However, directional information plays a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions to construct a theoretically well-founded, orthogonal radial basis that achieves better performance than the currently prevalent",8
839c4dd710ae7a234424aeda2f1423e0ce61bd5e,Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction,"Taxi demand prediction is an important building block to enabling intelligent transportation systems in a smart city. An accurate prediction model can help the city pre-allocate resources to meet travel demand and to reduce empty taxis on streets which waste energy and worsen the traffic congestion. With the increasing popularity of taxi requesting services such as Uber and Didi Chuxing (in China), we are able to collect large-scale taxi demand data continuously. How to utilize such big data to improve the demand prediction is an interesting and critical real-world problem. Traditional demand prediction methods mostly rely on time series forecasting techniques, which fail to model the complex non-linear spatial and temporal relations. Recent advances in deep learning have shown superior performance on traditionally challenging tasks such as image classification by learning the complex features and correlations from large-scale data. This breakthrough has inspired researchers to explore deep learning techniques on",7
41cbe3cdfee7539f8ff20144e6bd028ef762e00c,A Novel Embedding Model for Knowledge Base Completion Based on Convolutional Neural Network,"In this paper, we propose a novel embedding model, named ConvKB, for knowledge base completion. Our model ConvKB advances state-of-the-art models by employing a convolutional neural network, so that it can capture global relationships and transitional characteristics between entities and relations in knowledge bases. In ConvKB, each triple (head entity, relation, tail entity) is represented as a 3-column matrix where each column vector represents a triple element. This 3-column matrix is then fed to a convolution layer where multiple filters are operated on the matrix to generate different feature maps. These feature maps are then concatenated into a single feature vector representing the input triple. The feature vector is multiplied with a weight vector via a dot product to return a score. This score is then used to predict whether the triple is valid or not. Experiments show that ConvKB achieves better link prediction performance than previous state-of-the-art embedding models",5
5618bb2aff7ecdb0a2ae7c57838d156f731008ff,Graph Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting,"Spatiotemporal forecasting has significant implications in sustainability, transportation and health-care domain. Traffic forecasting is one canonical example of such learning task. This task is challenging due to (1) non-linear temporal dynamics with changing road conditions, (2) complex spatial dependencies on road networks topology and (3) inherent difficulty of long-term time series forecasting. To address these challenges, we propose Graph Convolutional Recurrent Neural Network to incorporate both spatial and temporal dependency in traffic flow. We further integrate the encoder-decoder framework and scheduled sampling to improve long-term forecasting. When evaluated on real-world road network traffic data, our approach can accurately capture spatiotemporal correlations and consistently outperforms state-of-the-art baselines by 12%- 15%.",7
36cf500079b82e3adf4a3afe3356c1c03426bdcd,Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting,"Forecasting the traffic flows is a critical issue for researchers and practitioners in the field of transportation. However, it is very challenging since the traffic flows usually show high nonlinearities and complex patterns. Most existing traffic flow prediction methods, lacking abilities of modeling the dynamic spatial-temporal correlations of traffic data, thus cannot yield satisfactory prediction results. In this paper, we propose a novel attention based spatial-temporal graph convolutional network (ASTGCN) model to solve traffic flow forecasting problem. ASTGCN mainly consists of three independent components to respectively model three temporal properties of traffic flows, i.e., recent, daily-periodic and weekly-periodic dependencies. More specifically, each component contains two major parts: 1) the spatial-temporal attention mechanism to effectively capture the dynamic spatialtemporal correlations in traffic data; 2) the spatial-temporal convolution which simultaneously employs graph convolutions to capture the spatial patterns and common standard convolutions to describe the temporal features. The output of the three",4
c4fd9c86b2b41df51a6fe212406dda81b1997fd4,Linguistic Regularities in Continuous Space Word Representations,"Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, “King Man + Woman” results in a vector very close to “Queen.” We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the",19
4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6,Saliency Based on Information Maximization,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
5808f5285bc60a73bc240621ad0fce606867ebc1,VAIN: Attentional Multi-agent Predictive Modeling,"Multi-agent predictive modeling is an essential step for understanding physical, social and team-play systems. Recently, Interaction Networks (INs) were proposed for the task of modeling multi-agent physical systems, INs scale with the number of interactions in the system (typically quadratic or higher order in the number of agents). In this paper we introduce VAIN, a novel attentional architecture for multi-agent predictive modeling that scales linearly with the number of agents. We show that VAIN is effective for multi-agent predictive modeling. Our method is evaluated on tasks from challenging multi-agent prediction domains: chess and soccer, and outperforms competing multi-agent approaches.",7
e9d7f589a3d368a3701832e28d90ca09ec9e5577,Segmentation using eigenvectors: a unifying view,"Automatic grouping and segmentation of images remains a challenging problem in computer vision. Recently, a number of authors have demonstrated good performance on this task using methods that are based on eigenvectors of the affinity matrix. These approaches are extremely attractive in that they are based on simple eigendecomposition algorithms whose stability is well understood. Nevertheless, the use of eigendecompositions in the context of segmentation is far from well understood. In this paper we give a unified treatment of these algorithms, and show the close connections between them while highlighting their distinguishing features. We then prove results on eigenvectors of block matrices that allow us to analyze the performance of these algorithms in simple grouping settings. Finally, we use our analysis to motivate a variation on the existing methods that combines aspects from different eigenvector segmentation algorithms. We illustrate our analysis with results on real and synthetic images.",6
6aa3d8bcca2ebdc52ef7cd786204c338f9d609f2,Improving Distributional Similarity with Lessons Learned from Word Embeddings,"Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distributional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter optimizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.",5
563ca4cda06665f4b90f8fce9bcb28c02e6872b9,Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data,"The translation equivariance of convolutional layers enables convolutional neural networks to generalize well on image problems. While translation equivariance provides a powerful inductive bias for images, we often additionally desire equivariance to other transformations, such as rotations, especially for non-image data. We propose a general method to construct a convolutional layer that is equivariant to transformations from any specified Lie group with a surjective exponential map. Incorporating equivariance to a new group requires implementing only the group exponential and logarithm maps, enabling rapid prototyping. Showcasing the simplicity and generality of our method, we apply the same model architecture to images, ball-and-stick molecular data, and Hamiltonian dynamical systems. For Hamiltonian systems, the equivariance of our models is especially impactful, leading to exact conservation of linear and angular momentum.",7
53f1779c4169b128072e6f50dc3f31bb2c530a70,Knowledge graph refinement: A survey of approaches and evaluation methods,"In the recent years, different Web knowledge graphs, both free and commercial, have been created. While Google coined the term ""Knowledge Graph"" in 2012, there are also a few openly available knowledge graphs, with DBpedia, YAGO, and Freebase being among the most prominent ones. Those graphs are often constructed from semi-structured knowledge, such as Wikipedia, or harvested from the web with a combination of statistical and linguistic methods. The result are large-scale knowledge graphs that try to make a good trade-off between completeness and correctness. In order to further increase the utility of such knowledge graphs, various refinement methods have been proposed, which try to infer and add missing knowledge to the graph, or identify erroneous pieces of information. In this article, we provide a survey of such knowledge graph refinement approaches, with a dual look at both the methods being proposed as well as the evaluation methodologies used.",6
1d9df46f672b1e22b6f210343be8684f88c0ccca,The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation,"State-of-the-art approaches for semantic image segmentation are built on Convolutional Neural Networks (CNNs). The typical segmentation architecture is composed of (a) a downsampling path responsible for extracting coarse semantic features, followed by (b) an upsampling path trained to recover the input image resolution at the output of the model and, optionally, (c) a post-processing module (e.g. Conditional Random Fields) to refine the model predictions.,,,,,, Recently, a new CNN architecture, Densely Connected Convolutional Networks (DenseNets), has shown excellent results on image classification tasks. The idea of DenseNets is based on the observation that if each layer is directly connected to every other layer in a feed-forward fashion then the network will be more accurate and easier to train.,,,,,, In this paper, we extend DenseNets to deal with the problem of semantic segmentation. We achieve state-of-the-art results on urban scene benchmark datasets such as CamVid and Gatech, without any further post-processing module",4
cfca1faca73f5c310ff669f27024b3182d5731e3,Encoding Social Information with Graph Convolutional Networks forPolitical Perspective Detection in News Media,"Identifying the political perspective shaping the way news events are discussed in the media is an important and challenging task. In this paper, we highlight the importance of contextualizing social information, capturing how this information is disseminated in social networks. We use Graph Convolutional Networks, a recently proposed neural architecture for representing relational information, to capture the documents’ social context. We show that social information can be used effectively as a source of distant supervision, and when direct supervision is available, even little social information can significantly improve performance.",6
a18ad95991db3f735d105ccc5caa246cd6b37d1b,Rabbit Order: Just-in-Time Parallel Reordering for Fast Graph Analysis,"Ahead-of-time data layout optimization by vertex reordering is a widely used technique to improve memory access locality in graph analysis. While reordered graphs yield better analysis performance, the existing reordering algorithms use significant amounts of computation time to provide efficient vertex ordering, hence, they fail to reduce end-to-end processing time. This paper presents a first algorithm for just-in-time parallel reordering, named Rabbit Order. It reduces end-to-end runtime by achieving high locality and fast reordering at the same time through two approaches. The first approach is hierarchical community-based ordering, which exploits the locality derived from hierarchical community structures in real-world graphs. Our ordering fully leverages low-latency cache levels by mapping hierarchical communities into hierarchical caches. The second approach is parallel incremental aggregation, which improves the runtime efficiency of reordering by decreasing the number of vertices to be processed. In addition, this approach utilizes lightweight atomic operations for concurrency control to avoid",8
750fbba3e7545ee8eb73c549a6f4d92ea0521386,Set2Graph: Learning Graphs From Sets,"Many problems in machine learning can be cast as learning functions from sets to graphs, or more generally to hypergraphs; in short, Set2Graph functions. Examples include clustering, learning vertex and edge features on graphs, and learning features on triplets in a collection. A natural approach for building Set2Graph models is to characterize all linear equivariant set-to-hypergraph layers and stack them with non-linear activations. This poses two challenges: (i) the expressive power of these networks is not well understood; and (ii) these models would suffer from high, often intractable computational and memory complexity, as their dimension grows exponentially. This paper advocates a family of neural network models for learning Set2Graph functions that is both practical and of maximal expressive power (universal), that is, can approximate arbitrary continuous Set2Graph functions over compact sets. Testing these models on different machine learning tasks, mainly an application to particle physics, we find them favorable to",3
d42d2a4112e0a751424624ac0b78980fa9fe9d96,GAKE: Graph Aware Knowledge Embedding,"Knowledge embedding, which projects triples in a given knowledge base to d-dimensional vectors, has attracted considerable research efforts recently. Most existing approaches treat the given knowledge base as a set of triplets, each of whose representation is then learned separately. However, as a fact, triples are connected and depend on each other. In this paper, we propose a graph aware knowledge embedding method (GAKE), which formulates knowledge base as a directed graph, and learns representations for any vertices or edges by leveraging the graph’s structural information. We introduce three types of graph context for embedding: neighbor context, path context, and edge context, each reflects properties of knowledge from different perspectives. We also design an attention mechanism to learn representative power of different vertices or edges. To validate our method, we conduct several experiments on two tasks. Experimental results suggest that our method outperforms several state-of-art knowledge embedding models.",6
046c4276b72e21731150c0655519ec717d8f5bad,Modeling polypharmacy side effects with graph convolutional networks,"Motivation: The use of drug combinations, termed polypharmacy, is common to treat patients with complex diseases or co-existing conditions. However, a major consequence of polypharmacy is a much higher risk of adverse side effects for the patient. Polypharmacy side effects emerge because of drug-drug interactions, in which activity of one drug may change, favorably or unfavorably, if taken with another drug. The knowledge of drug interactions is often limited because these complex relationships are rare, and are usually not observed in relatively small clinical testing. Discovering polypharmacy side effects thus remains an important challenge with significant implications for patient mortality and morbidity. Results: Here, we present Decagon, an approach for modeling polypharmacy side effects. The approach constructs a multimodal graph of protein-protein interactions, drug-protein target interactions, and the polypharmacy side effects, which are represented as drug-drug interactions, where each side effect is an edge of a different type. Decagon is",9
8cd7587e0fca14aa11779ed8e4268d024d410ec0,The Erdös-Ko-Rado theorem for vector spaces,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
3ac939c4ada416858e1c1bff9e6f18aaa98323f3,Pig latin: a not-so-foreign language for data processing,"There is a growing need for ad-hoc analysis of extremely large data sets, especially at internet companies where innovation critically depends on being able to analyze terabytes of data collected every day. Parallel database products, e.g., Teradata, offer a solution, but are usually prohibitively expensive at this scale. Besides, many of the people who analyze this data are entrenched procedural programmers, who find the declarative, SQL style to be unnatural. The success of the more procedural map-reduce programming model, and its associated scalable implementations on commodity hardware, is evidence of the above. However, the map-reduce paradigm is too low-level and rigid, and leads to a great deal of custom user code that is hard to maintain, and reuse. We describe a new language called Pig Latin that we have designed to fit in a sweet spot between the declarative style of SQL, and the low-level, procedural style of map-reduce. The",10
0811597b0851b7ebe21aadce7cb4daac4664b44f,One-Shot Generalization in Deep Generative Models,"Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our",7
7f40eba81644fdb356102a1d97a75fae4e7d3856,Unsupervised word embeddings capture latent knowledge from materials science literature,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
d0794c1a57cad9c35028427e6c084642346c720f,Approximation algorithms for classification problems with pairwise relationships: metric labeling and Markov random fields,"In a traditional classification problem, we wish to assign one of k labels (or classes) to each of n objects, in a way that is consistent with some observed data that we have about the problem. An active line of research in this area is concerned with classification when one has information about pairwise relationships among the objects to be classified; this issue is one of the principal motivations for the framework of Markov random fields, and it arises in areas such as image processing, biometry: and document analysis. In its most basic form, this style of analysis seeks a classification that optimizes a combinatorial function consisting of assignment costs-based on the individual choice of label we make for each object-and separation costs-based on the pair of choices we make for two ""related"" objects. We formulate a general classification problem of this type, the metric labeling problem; we show that",7
ac225094aab9e7b629bc5b3343e026dea0200c70,Predict then Propagate: Graph Neural Networks meet Personalized PageRank,"Neural message passing algorithms for semi-supervised classification on graphs have recently achieved great success. However, for classifying a node these methods only consider nodes that are a few propagation steps away and the size of this utilized neighborhood is hard to extend. In this paper, we use the relationship between graph convolutional networks (GCN) and PageRank to derive an improved propagation scheme based on personalized PageRank. We utilize this propagation procedure to construct a simple model, personalized propagation of neural predictions (PPNP), and its fast approximation, APPNP. Our model's training time is on par or faster and its number of parameters on par or lower than previous models. It leverages a large, adjustable neighborhood for classification and can be easily combined with any neural network. We show that this model outperforms several recently proposed methods for semi-supervised classification in the most thorough study done so far for GCN-like models. Our",21
781a8311c1e7811bd2a198e319be14020aee8699,GROVER: Self-supervised Message Passing Transformer on Large-scale Molecular Data,"How to obtain informative representations of molecules is a crucial prerequisite in AI-driven drug design and discovery. Recent researches abstract molecules as graphs and employ Graph Neural Networks (GNNs) for task-specific and data-driven molecular representation learning. Nevertheless, two ""dark clouds"" impede the usage of GNNs in real scenarios: (1) insufficient labeled molecules for supervised training; (2) poor generalization capabilities to new-synthesized molecules. To address them both, we propose a novel molecular representation framework, GROVER, which stands for Graph Representation frOm self-superVised mEssage passing tRansformer. With carefully designed self-supervised tasks in node, edge and graph-level, GROVER can learn rich structural and semantic information of molecules from enormous unlabelled molecular data. Rather, to encode such complex information, GROVER integrates Message Passing Networks with the Transformer-style architecture to deliver a class of more expressive encoders of molecules. The flexibility of GROVER allows it to be trained efficiently on large-scale molecular dataset without requiring",4
5098df13be6d1f2a31c9fbf85703336ef77a9665,LanczosNet: Multi-Scale Deep Graph Convolutional Networks,"We propose the Lanczos network (LanczosNet), which uses the Lanczos algorithm to construct low rank approximations of the graph Laplacian for graph convolution. Relying on the tridiagonal decomposition of the Lanczos algorithm, we not only efficiently exploit multi-scale information via fast approximated computation of matrix power but also design learnable spectral filters. Being fully differentiable, LanczosNet facilitates both graph kernel learning as well as learning node embeddings. We show the connection between our LanczosNet and graph based manifold learning methods, especially the diffusion maps. We benchmark our model against several recent deep graph networks on citation networks and QM8 quantum chemistry dataset. Experimental results show that our model achieves the state-of-the-art performance in most tasks. Code is released at: \url{this https URL}.",5
d0f1809dc696134fb8fb2a3ff5a982eeacdc7127,Neural Collective Entity Linking,"Entity Linking aims to link entity mentions in texts to knowledge bases, and neural models have achieved recent success in this task. However, most existing methods rely on local contexts to resolve entities independently, which may usually fail due to the data sparsity of local information. To address this issue, we propose a novel neural model for collective entity linking, named as NCEL. NCEL apply Graph Convolutional Network to integrate both local contextual features and global coherence information for entity linking. To improve the computation efficiency, we approximately perform graph convolution on a subgraph of adjacent entity mentions instead of those in the entire text. We further introduce an attention scheme to improve the robustness of NCEL to data noise and train the model on Wikipedia hyperlinks to avoid overfitting and domain bias. In experiments, we evaluate NCEL on five publicly available datasets to verify the linking performance as well",9
57e5f168536b536d3f2e84a8b5b7f9c112c90b43,Prototype Propagation Networks (PPN) for Weakly-supervised Few-shot Learning on Category Graph,"A variety of machine learning applications expect to achieve rapid learning from a limited number of labeled data. However, the success of most current models is the result of heavy training on big data. Meta-learning addresses this problem by extracting common knowledge across different tasks that can be quickly adapted to new tasks. However, they do not fully explore weakly-supervised information, which is usually free or cheap to collect. In this paper, we show that weakly-labeled data can significantly improve the performance of meta-learning on few-shot classification. We propose prototype propagation network (PPN) trained on few-shot tasks together with data annotated by coarse-label. Given a category graph of the targeted fine-classes and some weakly-labeled coarse-classes, PPN learns an attention mechanism which propagates the prototype of one class to another on the graph, so that the K-nearest neighbor (KNN) classifier defined on the propagated prototypes results in high accuracy across different",6
007112213ece771be72cbecfd59f048209facabd,A simple neural network module for relational reasoning,"Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Our work shows how a deep learning architecture equipped with an RN module can implicitly discover and learn to reason about entities and their relations.",17
b543d70d3e4fe6673a2e39832f005fa7ebc79cec,Markov random fields with efficient approximations,"Markov Random Fields (MRFs) can be used for a wide variety of vision problems. In this paper we focus on MRFs with two-valued clique potentials, which form a generalized Potts model. We show that the maximum a posteriori estimate of such an MRF can be obtained by solving a multiway minimum cut problem on a graph. We develop efficient algorithms for computing good approximations to the minimum multiway, cut. The visual correspondence problem can be formulated as an MRF in our framework; this yields quite promising results on real data with ground truth. We also apply our techniques to MRFs with linear clique potentials.",11
38ecaa5102f92ca12ea34cfc8b8b4c47a7a567a9,Joint Embedding of Meta-Path and Meta-Graph for Heterogeneous Information Networks,"Meta-graph is currently the most powerful tool for similarity search on heterogeneous information networks, where a meta-graph is a composition of meta-paths that captures the complex structural information. However, current relevance computing based on meta-graph only considers the complex structural information, but ignores its embedded meta-paths information. To address this problem, we proposeMEta-GrAph-based network embedding models, called MEGA and MEGA++, respectively. The MEGA model uses normalized relevance or similarity measures that are derived from a meta-graph and its embedded meta-paths between nodes simultaneously, and then leverages tensor decomposition method to perform node embedding. The MEGA++ further facilitates the use of coupled tensor-matrix decomposition method to obtain a joint embedding for nodes, which simultaneously considers the hidden relations of all meta information of a meta-graph. Extensive experiments on two real datasets demonstrate that MEGA and MEGA++ are more effective than state-of-the-art approaches.",3
43428880d75b3a14257c3ee9bda054e61eb869c0,Convolutional Sequence to Sequence Learning,"The prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks. We introduce an architecture based entirely on convolutional neural networks. Compared to recurrent models, computations over all elements can be fully parallelized during training and optimization is easier since the number of non-linearities is fixed and independent of the input length. Our use of gated linear units eases gradient propagation and we equip each decoder layer with a separate attention module. We outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14 English-German and WMT'14 English-French translation at an order of magnitude faster speed, both on GPU and CPU.",7
cd991591640fd5cf1cfb58027a9872184450b685,GraphWorld: Fake Graphs Bring Real Insights for GNNs,"Despite advances in the field of Graph Neural Networks (GNNs), only a small number (~5) of datasets are currently used to evaluate new models. This continued reliance on a handful of datasets provides minimal insight into the performance differences between models, and is especially challenging for industrial practitioners who are likely to have datasets which are very different from academic benchmarks. In the course of our work on GNN infrastructure and open-source software at Google, we have sought to develop benchmarks that are robust, tunable, scalable, and generalizable. In this work we introduce GraphWorld, a novel methodology and system for benchmarking GNN models on an arbitrarily-large population ofsynthetic graphs for any conceivable GNN task. GraphWorld allows a user to efficiently generate a world with millions of statistically diverse datasets. It is accessible, scalable, and easy to use. GraphWorld can be run on a single machine without specialized hardware, or it",1
c9e432023a240b22f385cf1cc76ab75fbe084ee7,Revisiting Graph based Collaborative Filtering: A Linear Residual Graph Convolutional Network Approach,"Graph Convolutional Networks~(GCNs) are state-of-the-art graph based representation learning models by iteratively stacking multiple layers of convolution aggregation operations and non-linear activation operations. Recently, in Collaborative Filtering~(CF) based Recommender Systems~(RS), by treating the user-item interaction behavior as a bipartite graph, some researchers model higher-layer collaborative signals with GCNs. These GCN based recommender models show superior performance compared to traditional works. However, these models suffer from training difficulty with non-linear activations for large user-item graphs. Besides, most GCN based models could not model deeper layers due to the over smoothing effect with the graph convolution operation. In this paper, we revisit GCN based CF models from two aspects. First, we empirically show that removing non-linearities would enhance recommendation performance, which is consistent with the theories in simple graph convolutional networks. Second, we propose a residual network structure that is specifically designed for CF with user-item interaction modeling, which alleviates the over",1
06214a0cf38875da38586e81539890f7ad8aeb1c,"Exploring Network Structure, Dynamics, and Function using NetworkX","NetworkX is a Python language package for exploration and analysis of networks and network algorithms. The core package provides data structures for representing many types of networks, or graphs, including simple graphs, directed graphs, and graphs with parallel edges and self-loops. The nodes in NetworkX graphs can be any (hashable) Python object and edges can contain arbitrary data; this flexibility makes NetworkX ideal for representing networks found in many different scientific fields. In addition to the basic data structures many graph algorithms are implemented for calculating network properties and structure measures: shortest paths, betweenness centrality, clustering, and degree distribution and many more. NetworkX can read and write various graph formats for easy exchange with existing data, and provides generators for many classic graphs and popular graph models, such as the Erdos-Renyi, Small World, and Barabasi-Albert models. The ease-of-use and flexibility of the Python programming language together with connection to the",7
4ec28212d571da349ac886039f8dcd2243c8d57c,Image segmentation by nested cuts,"We present a new image segmentation algorithm based on graph cuts. Our main tool is separation of each pixel p from a special point outside the image by a cut of a minimum cost. Such a cut creates a group of pixels C/sub p/ around each pixel. We show that these groups C/sub p/ are either disjoint or nested in each other and so they give a natural segmentation of the image. In addition this property allows an efficient implementation of the algorithms because for most pixels p the computation of C/sub p/ is not performed on the whole graph. We inspect all C/sub p/ and discard those which are not interesting, for example if they are too small. This procedure automatically groups small components together or merges them into nearby large clusters. Effectively, our segmentation is performed by extracting significant non-intersecting closed contours. We present interesting segmentation results on",5
2e64d0aa1a5e211e8884b73fa01f4606d2088b7a,Just Jump: Dynamic Neighborhood Aggregation in Graph Neural Networks,"We propose a dynamic neighborhood aggregation (DNA) procedure guided by (multi-head) attention for representation learning on graphs. In contrast to current graph neural networks which follow a simple neighborhood aggregation scheme, our DNA procedure allows for a selective and node-adaptive aggregation of neighboring embeddings of potentially differing locality. In order to avoid overfitting, we propose to control the channel-wise connections between input and output by making use of grouped linear projections. In a number of transductive node-classification experiments, we demonstrate the effectiveness of our approach.",4
5ad41f9ebbc6b6b02d61932a15ae254ba33a687f,Introduction to statistical relational learning,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
204e3073870fae3d05bcbc2f6a8e263d9b72e776,Attention is All you Need,"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other",105
4cc80844af0a9f72ef94283869504b995c122ab3,Distributed Word Representation Learning for Cross-Lingual Dependency Parsing,"This paper proposes to learn languageindependent word representations to address cross-lingual dependency parsing, which aims to predict the dependency parsing trees for sentences in the target language by training a dependency parser with labeled sentences from a source language. We first combine all sentences from both languages to induce real-valued distributed representation of words under a deep neural network architecture, which is expected to capture semantic similarities of words not only within the same language but also across different languages. We then use the induced interlingual word representation as augmenting features to train a delexicalized dependency parser on labeled sentences in the source language and apply it to the target sentences. To investigate the effectiveness of the proposed technique, extensive experiments are conducted on cross-lingual dependency parsing tasks with nine different languages. The experimental results demonstrate the superior cross-lingual generalizability of the word representation induced by the proposed approach, comparing",10
e9842f649578886801a3b4ce40a89b9125f51daf,MOTIFNET: A MOTIF-BASED GRAPH CONVOLUTIONAL NETWORK FOR DIRECTED GRAPHS,"Deep learning on graphs and in particular, graph convolutional neural networks, have recently attracted significant attention in the machine learning community. Many of such techniques explore the analogy between the graph Laplacian eigenvectors and the classical Fourier basis, allowing to formulate the convolution as a multiplication in the spectral domain. One of the key drawback of spectral CNNs is their explicit assumption of an undirected graph, leading to a symmetric Laplacian matrix with orthogonal eigendecomposition. In this work we propose MotifNet, a graph CNN capable of dealing with directed graphs by exploiting local graph motifs. We present experimental evidence showing the advantage of our approach on real data.",5
6075091294a0fe0fe5c6c7b7a0df9029b6a965cb,SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks,"We introduce the SE(3)-Transformer, a variant of the self-attention module for 3D point clouds, which is equivariant under continuous 3D roto-translations. Equivariance is important to ensure stable and predictable performance in the presence of nuisance transformations of the data input. A positive corollary of equivariance is increased weight-tying within the model, leading to fewer trainable parameters and thus decreased sample complexity (i.e. we need less training data). The SE(3)-Transformer leverages the benefits of self-attention to operate on large point clouds with varying number of points, while guaranteeing SE(3)-equivariance for robustness. We evaluate our model on a toy $N$-body particle simulation dataset, showcasing the robustness of the predictions under rotations of the input. We further achieve competitive performance on two real-world datasets, ScanObjectNN and QM9. In all cases, our model outperforms a strong, non-equivariant attention baseline and an equivariant model without attention.",5
307c5103c9ecbfc7f11f120d8ab9f33b24c6c650,Unsupervised Inductive Graph-Level Representation Learning via Graph-Graph Proximity,"We introduce a novel approach to graph-level representation learning, which is to embed an entire graph into a vector space where the embeddings of two graphs preserve their graph-graph proximity. Our approach, UGraphEmb, is a general framework that provides a novel means to performing graph-level embedding in a completely unsupervised and inductive manner. The learned neural network can be considered as a function that receives any graph as input, either seen or unseen in the training set, and transforms it into an embedding. A novel graph-level embedding generation mechanism called Multi-Scale Node Attention (MSNA), is proposed. Experiments on five real graph datasets show that UGraphEmb achieves competitive accuracy in the tasks of graph classification, similarity ranking, and graph visualization.",3
0a69c8815536a657668e089e3281ff2e963d947a,Design Space for Graph Neural Networks,"The rapid evolution of Graph Neural Networks (GNNs) has led to a growing number of new architectures as well as novel applications. However, current research focuses on proposing and evaluating specific architectural designs of GNNs, as opposed to studying the more general design space of GNNs that consists of a Cartesian product of different design dimensions, such as the number of layers or the type of the aggregation function. Additionally, GNN designs are often specialized to a single task, yet few efforts have been made to understand how to quickly find the best GNN design for a novel task or a novel dataset. Here we define and systematically study the architectural design space for GNNs which consists of 315,000 different designs over 32 different predictive tasks. Our approach features three key innovations: (1) A general GNN design space; (2) a GNN task space with a similarity metric, so that for",3
23ffaa0fe06eae05817f527a47ac3291077f9e58,Rethinking the Inception Architecture for Computer Vision,"Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost",23
55ad004bac6bb364a50f05a994524661083c4762,Fundamentals of Organic Chemistry,"Written for the short course-where content must be thorough, but to-the-point, FUNDAMENTALS OF ORGANIC CHEMISTRY, Fifth Edition provides an effective, clear, and readable introduction to the beauty and logic of organic chemistry. McMurry presents only those subjects needed for a brief course while maintaining the important pedagogical tools commonly found in larger books. With clear explanations, thought-provoking examples, and an innovative vertical format for explaining reaction mechanisms, FUNDAMENTALS takes a modern approach: primary organization is by functional group, beginning with the simple (alkanes) and progressing to the more complex. Within the primary organization, there is also an emphasis on explaining the fundamental mechanistic similarities of reactions. Through this approach, memorization is minimized and understanding is maximized. This new edition represents a major revision. The text has been revised at the sentence level to further improve clarity and readability; many new examples and topics of biological relevance have been added; and",2
2f39500bbfbbcfce89d5a1edba18ca76892ee93c,Image segmentation using local variation,"We present a new graph-theoretic approach to the problem of image segmentation. Our method uses local criteria and yet produces results that reflect global properties of the image. We develop a framework that provides specific definitions of what it means for an image to be under- or over-segmented. We then present an efficient algorithm for computing a segmentation that is neither under- nor over-segmented according to these definitions. Our segmentation criterion is based on intensity differences between neighboring pixels. An important characteristic of the approach is that it is able to preserve detail in low-variability regions while ignoring detail in high-variability regions, which we illustrate with several examples on both real and synthetic images.",5
c2d40522eaa5523d67a0de5e4098e7031fdccb3d,Pitfalls of Graph Neural Network Evaluation,"Semi-supervised node classification in graphs is a fundamental problem in graph mining, and the recently proposed graph neural networks (GNNs) have achieved unparalleled results on this task. Due to their massive success, GNNs have attracted a lot of attention, and many novel architectures have been put forward. In this paper we show that existing evaluation strategies for GNN models have serious shortcomings. We show that using the same train/validation/test splits of the same datasets, as well as making significant changes to the training procedure (e.g. early stopping criteria) precludes a fair comparison of different architectures. We perform a thorough empirical evaluation of four prominent GNN models and show that considering different splits of the data leads to dramatically different rankings of models. Even more importantly, our findings suggest that simpler GNN architectures are able to outperform the more sophisticated ones if the hyperparameters and the training procedure are tuned fairly",19
a6337d9ebb0b7de84588806110157806f9c0383b,GraphiT: Encoding Graph Structure in Transformers,"We show that viewing graphs as sets of node features and incorporating structural and positional information into a transformer architecture is able to outperform representations learned with classical graph neural networks (GNNs). Our model, GraphiT, encodes such information by (i) leveraging relative positional encoding strategies in self-attention scores based on positive definite kernels on graphs, and (ii) enumerating and encoding local sub-structures such as paths of short length. We thoroughly evaluate these two ideas on many classification and regression tasks, demonstrating the effectiveness of each of them independently, as well as their combination. In addition to performing well on standard benchmarks, our model also admits natural visualization mechanisms for interpreting graph motifs explaining the predictions, making it a potentially strong candidate for scientific applications where interpretation is important. Code available at https://github.com/inria-thoth/GraphiT.",9
04f3203f1214063436d81ce0c2ad7623204da488,Geom-GCN: Geometric Graph Convolutional Networks,"Message-passing neural networks (MPNNs) have been successfully applied in a wide variety of applications in the real world. However, two fundamental weaknesses of MPNNs' aggregators limit their ability to represent graph-structured data: losing the structural information of nodes in neighborhoods and lacking the ability to capture long-range dependencies in disassortative graphs. Few studies have noticed the weaknesses from different perspectives. From the observations on classical neural network and network geometry, we propose a novel geometric aggregation scheme for graph neural networks to overcome the two weaknesses. The behind basic idea is the aggregation on a graph can benefit from a continuous space underlying the graph. The proposed aggregation scheme is permutation-invariant and consists of three modules, node embedding, structural neighborhood, and bi-level aggregation. We also present an implementation of the scheme in graph convolutional networks, termed Geom-GCN, to perform transductive learning on graphs. Experimental results show the proposed Geom-GCN achieved",9
f1ed01a2c0aa47b4e010861ef884980561ddb542,Self-supervised Learning of Dense Shape Correspondence,"We introduce the first completely unsupervised correspondence learning approach for deformable 3D shapes. Key to our model is the understanding that natural deformations (such as changes in pose) approximately preserve the metric structure of the surface, yielding a natural criterion to drive the learning process toward distortion-minimizing predictions. On this basis, we overcome the need for annotated data and replace it by a purely geometric criterion. The resulting learning model is class-agnostic, and is able to leverage any type of deformable geometric data for the training phase. In contrast to existing supervised approaches which specialize on the class seen at training time, we demonstrate stronger generalization as well as applicability to a variety of challenging settings. We showcase our method on a wide selection of correspondence benchmarks, where we outperform other methods in terms of accuracy, generalization, and efficiency.",2
05c4eb154ad9512a69569c18d68bc4428ee8bb83,Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks,"Graph convolutional network (GCN) has been successfully applied to many graph-based applications; however, training a large-scale GCN remains challenging. Current SGD-based algorithms suffer from either a high computational cost that exponentially grows with number of GCN layers, or a large space requirement for keeping the entire graph and the embedding of each node in memory. In this paper, we propose Cluster-GCN, a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure. Cluster-GCN works as the following: at each step, it samples a block of nodes that associate with a dense subgraph identified by a graph clustering algorithm, and restricts the neighborhood search within this subgraph. This simple but effective strategy leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with previous algorithms. To test the scalability of our algorithm, we create a new Amazon2M data with 2",14
57820e6f974d198bf4bbdf26ae7e1063bac190c3,"The Semantic Web"" in Scientific American","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
ac2e6afbadc3428eb5dff167b52025e64525441e,When Does Self-Supervision Help Graph Convolutional Networks?,"Self-supervision as an emerging technique has been employed to train convolutional neural networks (CNNs) for more transferrable, generalizable, and robust representation learning of images. Its introduction to graph convolutional networks (GCNs) operating on graph data is however rarely explored. In this study, we report the first systematic exploration and assessment of incorporating self-supervision into GCNs. We first elaborate three mechanisms to incorporate self-supervision into GCNs, analyze the limitations of pretraining & finetuning and self-training, and proceed to focus on multi-task learning. Moreover, we propose to investigate three novel self-supervised learning tasks for GCNs with theoretical rationales and numerical comparisons. Lastly, we further integrate multi-task self-supervision into graph adversarial training. Our results show that, with properly designed task forms and incorporation mechanisms, self-supervision benefits GCNs in gaining more generalizability and robustness. Our codes are available at https://github.com/Shen-Lab/SS-GCNs.",7
f0bfcda65e04d481767dba40eade6c7001ee908d,Modeling Complex Spatial Patterns with Temporal Features via Heterogenous Graph Embedding Networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
83040001210751239553269727b9ea53e152af71,Building Machines that Learn and Think Like People,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
74c2878df89fcc2be28eae8523757d6d491457ea,Explainable Reasoning over Knowledge Graphs for Recommendation,"Incorporating knowledge graph into recommender systems has attracted increasing attention in recent years. By exploring the interlinks within a knowledge graph, the connectivity between users and items can be discovered as paths, which provide rich and complementary information to user-item interactions. Such connectivity not only reveals the semantics of entities and relations, but also helps to comprehend a user’s interest. However, existing efforts have not fully explored this connectivity to infer user preferences, especially in terms of modeling the sequential dependencies within and holistic semantics of a path.In this paper, we contribute a new model named Knowledgeaware Path Recurrent Network (KPRN) to exploit knowledge graph for recommendation. KPRN can generate path representations by composing the semantics of both entities and relations. By leveraging the sequential dependencies within a path, we allow effective reasoning on paths to infer the underlying rationale of a user-item interaction. Furthermore, we design a new weighted",4
815c84ab906e43f3e6322f2ca3fd5e1360c64285,Human-level concept learning through probabilistic program induction,"Handwritten characters drawn by a model Not only do children learn effortlessly, they do so quickly and with a remarkable ability to use what they have learned as the raw material for creating new stuff. Lake et al. describe a computational model that learns in a similar fashion and does so better than current deep learning algorithms. The model classifies, parses, and recreates handwritten characters, and can generate new letters of the alphabet that look “right” as judged by Turing-like tests of the model's output in comparison to what real humans produce. Science, this issue p. 1332 Combining the capacity to handle noise with probabilistic learning yields humanlike performance in a computational model. People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer",11
861d72c7b1685c2bd5e72215807acdae30d9139f,Stochastic Training of Graph Convolutional Networks,"Graph convolutional networks (GCNs) are powerful deep neural networks for graph-structured data. However, GCN computes nodes' representation recursively from their neighbors, making the receptive field size grow exponentially with the number of layers. Previous attempts on reducing the receptive field size by subsampling neighbors do not have any convergence guarantee, and their receptive field size per node is still in the order of hundreds. In this paper, we develop a preprocessing strategy and two control variate based algorithms to further reduce the receptive field size. Our algorithms are guaranteed to converge to GCN's local optimum regardless of the neighbor sampling size. Empirical results show that our algorithms have a similar convergence speed per epoch with the exact algorithm even using only two neighbors per node. The time consumption of our algorithm on the Reddit dataset is only one fifth of previous neighbor sampling algorithms.",7
eb2ae9f753c4318c0a052218af0a2ba1fdfd8969,Deep Item-based Collaborative Filtering for Top-N Recommendation,"Item-based Collaborative Filtering (ICF) has been widely adopted in recommender systems in industry, owing to its strength in user interest modeling and ease in online personalization. By constructing a user’s profile with the items that the user has consumed, ICF recommends items that are similar to the user’s profile. With the prevalence of machine learning in recent years, significant processes have been made for ICF by learning item similarity (or representation) from data. Nevertheless, we argue that most existing works have only considered linear and shallow relationships between items, which are insufficient to capture the complicated decision-making process of users. In this article, we propose a more expressive ICF solution by accounting for the nonlinear and higher-order relationships among items. Going beyond modeling only the second-order interaction (e.g., similarity) between two items, we additionally consider the interaction among all interacted item pairs by using nonlinear neural networks. By doing this,",10
1a8ee9382e79b92986f9d780a929fc2d2be2f47b,Graph Capsule Convolutional Neural Networks,"Graph Convolutional Neural Networks (GCNNs) are the most recent exciting advancement in deep learning field and their applications are quickly spreading in multi-cross-domains including bioinformatics, chemoinformatics, social networks, natural language processing and computer vision. In this paper, we expose and tackle some of the basic weaknesses of a GCNN model with a capsule idea presented in \cite{hinton2011transforming} and propose our Graph Capsule Network (GCAPS-CNN) model. In addition, we design our GCAPS-CNN model to solve especially graph classification problem which current GCNN models find challenging. Through extensive experiments, we show that our proposed Graph Capsule Network can significantly outperforms both the existing state-of-art deep learning methods and graph kernels on graph classification benchmark datasets.",7
6ea57a2aea08ce0628c93f77bdc24c2f3e9cc6da,Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks,"In recent years, graph neural networks (GNNs) have emerged as a powerful neural architecture to learn vector representations of nodes and graphs in a supervised, end-to-end fashion. Up to now, GNNs have only been evaluated empirically—showing promising results. The following work investigates GNNs from a theoretical point of view and relates them to the 1-dimensional Weisfeiler-Leman graph isomorphism heuristic (1-WL). We show that GNNs have the same expressiveness as the 1-WL in terms of distinguishing non-isomorphic (sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on this, we propose a generalization of GNNs, so-called k-dimensional GNNs (k-GNNs), which can take higher-order graph structures at multiple scales into account. These higher-order structures play an essential role in the characterization of social networks and molecule graphs. Our experimental evaluation confirms our theoretical findings as well as confirms that higher-order information is useful in the task of graph classification and regression.",18
4efb9a950f252138a30eeb942ed02663a3ea29d1,MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing,"Existing popular methods for semi-supervised learning with Graph Neural Networks (such as the Graph Convolutional Network) provably cannot learn a general class of neighborhood mixing relationships. To address this weakness, we propose a new model, MixHop, that can learn these relationships, including difference operators, by repeatedly mixing feature representations of neighbors at various distances. Mixhop requires no additional memory or computational complexity, and outperforms on challenging baselines. In addition, we propose sparsity regularization that allows us to visualize how the network prioritizes neighborhood information across different graph datasets. Our analysis of the learned architectures reveals that neighborhood mixing varies per datasets.",11
2426098c33ad0f897f29725b2b7bf02fa8e128e7,GraphGrind: addressing load imbalance of graph partitioning,"We investigate how graph partitioning adversely affects the performance of graph analytics. We demonstrate that graph partitioning induces extra work during graph traversal and that graph partitions have markedly different connectivity than the original graph. By consequence, increasing the number of partitions reaches a tipping point after which overheads quickly dominate performance gains. Moreover, we show that the heuristic to balance CPU load between graph partitions by balancing the number of edges is inappropriate for a range of graph analyses. However, even when it is appropriate, it is sub-optimal due to the skewed degree distribution of social networks. Based on these observations, we propose GraphGrind, a new graph analytics system that addresses the limitations incurred by graph partitioning. We moreover propose a NUMA-aware extension to the Cilk programming language and obtain a scale-free yet NUMA-aware parallel programming environment which underpins NUMA-aware scheduling in GraphGrind. We demonstrate that Graph-Grind outperforms state-of-the-art",4
ed8f6a72bd8903078cfaef866ca7d71e12c5b8f1,Dryad: distributed data-parallel programs from sequential building blocks,"Dryad is a general-purpose distributed execution engine for coarse-grain data-parallel applications. A Dryad application combines computational ""vertices"" with communication ""channels"" to form a dataflow graph. Dryad runs the application by executing the vertices of this graph on a set of available computers, communicating as appropriate through flies, TCP pipes, and shared-memory FIFOs. The vertices provided by the application developer are quite simple and are usually written as sequential programs with no thread creation or locking. Concurrency arises from Dryad scheduling vertices to run simultaneously on multiple computers, or on multiple CPU cores within a computer. The application can discover the size and placement of data at run time, and modify the graph as the computation progresses to make efficient use of the available resources. Dryad is designed to scale from powerful multi-core single computers, through small clusters of computers, to data centers with thousands of computers. The Dryad execution engine",12
6195b623a13e861741ac1e80a7a8b774d5332236,Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules,"Many important tasks in chemistry revolve around molecules during reactions. This requires predictions far from the equilibrium, while most recent work in machine learning for molecules has been focused on equilibrium or near-equilibrium states. In this paper we aim to extend this scope in three ways. First, we propose the DimeNet++ model, which is 8x faster and 10% more accurate than the original DimeNet on the QM9 benchmark of equilibrium molecules. Second, we validate DimeNet++ on highly reactive molecules by developing the challenging COLL dataset, which contains distorted configurations of small molecules during collisions. Finally, we investigate ensembling and mean-variance estimation for uncertainty quantification with the goal of accelerating the exploration of the vast space of non-equilibrium structures. Our DimeNet++ implementation as well as the COLL dataset are available online.",1
337bb008eb531c4e8152d6c99423e715ce0d9b05,PEGASUS: A Peta-Scale Graph Mining System Implementation and Observations,"In this paper, we describe PEGASUS, an open source Peta Graph Mining library which performs typical graph mining tasks such as computing the diameter of the graph, computing the radius of each node and finding the connected components. As the size of graphs reaches several Giga-, Tera- or Peta-bytes, the necessity for such a library grows too. To the best of our knowledge, PEGASUS is the first such library, implemented on the top of the Hadoop platform, the open source version of MapReduce. Many graph mining operations (PageRank, spectral clustering, diameter estimation, connected components etc.) are essentially a repeated matrix-vector multiplication. In this paper we describe a very important primitive for PEGASUS, called GIM-V (Generalized Iterated Matrix-Vector multiplication). GIM-V is highly optimized, achieving (a) good scale-up on the number of available machines (b) linear running time on the number of edges, and (c) more than 5 times faster performance over",4
840d5e4fc06454f939bc5e5b8eed07d662105d7c,Differences of monkey and human overt attention under natural conditions,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
ae62f2ec96e34a773b62f13a67639209090b2eef,The Connectivity of Strongly Regular Graphs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
5df0ced15b18103c9517805c4c0447e2af72e217,SBH: Super byte-aligned hybrid bitmap compression,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
cb2722b202b2b0b1b9b87eb4a984dee9040f34c3,Graph Warp Module: an Auxiliary Module for Boosting the Power of Graph Neural Networks,"Recently, Graph Neural Networks (GNNs) are trending in the machine learning community as a family of architectures that specializes in capturing the features of graph-related datasets, such as those pertaining to social networks and chemical structures. Unlike for other families of the networks, the representation power of GNNs has much room for improvement, and many graph networks to date suffer from the problem of underfitting. In this paper we will introduce a Graph Warp Module, a supernode-based auxiliary network module that can be attached to a wide variety of existing GNNs in order to improve the representation power of the original networks. Through extensive experiments on molecular graph datasets, we will show that our GWM indeed alleviates the underfitting problem for various existing networks, and that it can even help create a network with the state-of-the-art generalization performance.",5
c4366c9e70de60d9ce4365422189f4eb470e4d92,HIGH DIMENSIONAL EXPANDERS,"Expander graphs have been, during the last five decades, the subject of a most fruitful interaction between pure mathematics and computer science, with influence and applications going both ways (cf. [Lub94], [HLW06], [Lub12] and the references therein). In the last decade, a theory of ""high dimensional expanders"" has begun to emerge. The goal of the current paper is to describe some paths of this new area of study.",9
53ab89807caead278d3deb7b6a4180b277d3cb77,Better Word Representations with Recursive Neural Networks for Morphology,"Vector-space word representations have been very successful in recent years at improving performance across a variety of NLP tasks. However, common to most existing work, words are regarded as independent entities without any explicit relationship among morphologically related words being modeled. As a result, rare and complex words are often poorly estimated, and all unknown words are represented in a rather crude way using only one or a few vectors. This paper addresses this shortcoming by proposing a novel model that is capable of building representations for morphologically complex words from their morphemes. We combine recursive neural networks (RNNs), where each morpheme is a basic unit, with neural language models (NLMs) to consider contextual information in learning morphologicallyaware word representations. Our learned models outperform existing word representations by a good margin on word similarity tasks across many datasets, including a new dataset we introduce focused on rare words to complement",8
10a597d9f26856507b88fb528a074a7f197d964b,The influence of ageing on complex brain networks: A graph theoretical analysis,To determine the functional connectivity of different EEG bands at the “baseline” situation (rest) and during mathematical thinking in children and young adults to study the maturation effect on brain networks at rest and during a cognitive task.,5
ea9a516d5cb0b298f0df50e82b3e0400b72fcdff,Microsoft Academic Graph: When experts are not enough,"Abstract An ongoing project explores the extent to which artificial intelligence (AI), specifically in the areas of natural language processing and semantic reasoning, can be exploited to facilitate the studies of science by deploying software agents equipped with natural language understanding capabilities to read scholarly publications on the web. The knowledge extracted by these AI agents is organized into a heterogeneous graph, called Microsoft Academic Graph (MAG), where the nodes and the edges represent the entities engaging in scholarly communications and the relationships among them, respectively. The frequently updated data set and a few software tools central to the underlying AI components are distributed under an open data license for research and commercial applications. This paper describes the design, schema, and technical and business motivations behind MAG and elaborates how MAG can be used in analytics, search, and recommendation scenarios. How AI plays an important role in avoiding various biases",7
e15d062ef07abab8fae65244f64ccd2aac8d2b94,Analogical Inference for Multi-relational Embeddings,"Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledge-based inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the \textit{analogical} properties of the embedded entities and relations. By formulating the learning objective in a differentiable fashion, our model enjoys both theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework.",5
c8c21f8f7d427446c11967ac967dcf500ae74078,On the Equivalence of Holographic and Complex Embeddings for Link Prediction,"We show the equivalence of two state-of-the-art models for link prediction/knowledge graph completion: Nickel et al’s holographic embeddings and Trouillon et al.’s complex embeddings. We first consider a spectral version of the holographic embeddings, exploiting the frequency domain in the Fourier transform for efficient computation. The analysis of the resulting model reveals that it can be viewed as an instance of the complex embeddings with a certain constraint imposed on the initial vectors upon training. Conversely, any set of complex embeddings can be converted to a set of equivalent holographic embeddings.",7
6bc3ef19eec3ebbdb2ad81231062090e60c38c52,An Ensemble Method to Produce High-Quality Word Embeddings,"A currently successful approach to computational semantics is to represent words as embeddings in a machine-learned vector space. We present an ensemble method that combines embeddings produced by GloVe (Pennington et al., 2014) and word2vec (Mikolov et al., 2013) with structured knowledge from the semantic networks ConceptNet (Speer and Havasi, 2012) and PPDB (Ganitkevitch et al., 2013), merging their information into a common representation with a large, multilingual vocabulary. The embeddings it produces achieve state-of-the-art performance on many word-similarity evaluations. Its score of $\rho = .596$ on an evaluation of rare words (Luong et al., 2013) is 16% higher than the previous best known system.",4
9fdc2566c2603b1cd9f78421fadcd593fdfb407e,Parcellation‐dependent small‐world brain functional networks: A resting‐state fMRI study,"Recent studies have demonstrated small‐world properties in both functional and structural brain networks that are constructed based on different parcellation approaches. However, one fundamental but vital issue of the impact of different brain parcellation schemes on the network topological architecture remains unclear. Here, we used resting‐state functional MRI (fMRI) to investigate the influences of different brain parcellation atlases on the topological organization of brain functional networks. Whole‐brain fMRI data were divided into ninety and seventy regions of interest according to two predefined anatomical atlases, respectively. Brain functional networks were constructed by thresholding the correlation matrices among the parcellated regions and further analyzed using graph theoretical approaches. Both atlas‐based brain functional networks were found to show robust small‐world properties and truncated power‐law connectivity degree distributions, which are consistent with previous brain functional and structural networks studies. However, more importantly, we found that there were significant differences in multiple topological parameters (e.g.,",2
a04f10120ebc59bebf3a5af0c8045b3b269a669f,Comparative Genomics Unveils Regionalized Evolution of the Faustovirus Genomes,"Faustovirus is a recently discovered genus of large DNA virus infecting the amoeba Vermamoeba vermiformis, which is phylogenetically related to Asfarviridae. To better understand the diversity and evolution of this viral group, we sequenced six novel Faustovirus strains, mined published metagenomic datasets and performed a comparative genomic analysis. Genomic sequences revealed three consistent phylogenetic groups, within which genetic diversity was moderate. The comparison of the major capsid protein (MCP) genes unveiled between 13 and 18 type-I introns that likely evolved through a still-active birth and death process mediated by intron-encoded homing endonucleases that began before the Faustovirus radiation. Genome-wide alignments indicated that despite genomes retaining high levels of gene collinearity, the central region containing the MCP gene together with the extremities of the chromosomes evolved at a faster rate due to increased indel accumulation and local rearrangements. The fluctuation of the nucleotide composition along the Faustovirus (FV) genomes is mostly",4
961073143d3cfe662e9e820d24c0a88f0ae94c83,Document Context Language Models,"Text documents are structured on multiple levels of detail: individual words are related by syntax, but larger units of text are related by discourse structure. Existing language models generally fail to account for discourse structure, but it is crucial if we are to have language models that reward coherence and generate coherent texts. We present and empirically evaluate a set of multi-level recurrent neural network language models, called Document-Context Language Models (DCLM), which incorporate contextual information both within and beyond the sentence. In comparison with word-level recurrent neural network language models, the DCLM models obtain slightly better predictive likelihoods, and considerably better assessments of document coherence.",1
50d53cc562225549457cbc782546bfbe1ac6f0cf,Reasoning With Neural Tensor Networks for Knowledge Base Completion,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",27
12d8c11f3006b09130fdd5007e30f10b09687fbe,Survey and Taxonomy of Lossless Graph Compression and Space-Efficient Graph Representations,"Various graphs such as web or social networks may contain up to trillions of edges. Compressing such datasets can accelerate graph processing by reducing the amount of I/O accesses and the pressure on the memory subsystem. Yet, selecting a proper compression method is challenging as there exist a plethora of techniques, algorithms, domains, and approaches in compressing graphs. To facilitate this, we present a survey and taxonomy on lossless graph compression that is the first, to the best of our knowledge, to exhaustively analyze this domain. Moreover, our survey does not only categorize existing schemes, but also explains key ideas, discusses formal underpinning in selected works, and describes the space of the existing compression schemes using three dimensions: areas of research (e.g., compressing web graphs), techniques (e.g., gap encoding), and features (e.g., whether or not a given scheme targets dynamic graphs). Our survey can be used as a guide to",4
41071dbbbcbb27af3fec70de045f19c28535f5b7,Feature Denoising for Improving Adversarial Robustness,"Adversarial attacks to image classification systems present challenges to convolutional networks and opportunities for understanding them. This study suggests that adversarial perturbations on images lead to noise in the features constructed by these networks. Motivated by this observation, we develop new network architectures that increase adversarial robustness by performing feature denoising. Specifically, our networks contain blocks that denoise the features using non-local means or other filters; the entire networks are trained end-to-end. When combined with adversarial training, our feature denoising networks substantially improve the state-of-the-art in adversarial robustness in both white-box and black-box attack settings. On ImageNet, under 10-iteration PGD white-box attacks where prior art has 27.9% accuracy, our method achieves 55.7%; even under extreme 2000-iteration PGD white-box attacks, our method secures 42.6% accuracy. Our method was ranked first in Competition on Adversarial Attacks and Defenses (CAAD) 2018 --- it achieved 50.6% classification accuracy on a secret, ImageNet-like test dataset",6
88b1f417c9581d9ddb8083e591c2310fb4e24796,A survey on graph kernels,"Graph kernels have become an established and widely-used technique for solving classification tasks on graphs. This survey gives a comprehensive overview of techniques for kernel-based graph classification developed in the past 15 years. We describe and categorize graph kernels based on properties inherent to their design, such as the nature of their extracted graph features, their method of computation and their applicability to problems in practice. In an extensive experimental evaluation, we study the classification accuracy of a large suite of graph kernels on established benchmarks as well as new datasets. We compare the performance of popular kernels with several baseline methods and study the effect of applying a Gaussian RBF kernel to the metric induced by a graph kernel. In doing so, we find that simple baselines become competitive after this transformation on some datasets. Moreover, we study the extent to which existing graph kernels agree in their predictions",2
e84b50da644a624f9bc7e51f96db2fbf656c0357,Multi-Relational Latent Semantic Analysis,"We present Multi-Relational Latent Semantic Analysis (MRLSA) which generalizes Latent Semantic Analysis (LSA). MRLSA provides an elegant approach to combining multiple relations between words by constructing a 3-way tensor. Similar to LSA, a lowrank approximation of the tensor is derived using a tensor decomposition. Each word in the vocabulary is thus represented by a vector in the latent semantic space and each relation is captured by a latent square matrix. The degree of two words having a specific relation can then be measured through simple linear algebraic operations. We demonstrate that by integrating multiple relations from both homogeneous and heterogeneous information sources, MRLSA achieves stateof-the-art performance on existing benchmark datasets for two relations, antonymy and is-a.",6
9fa3e53b5937a0ec92499ed415e339ede6c92010,DeepInf: Social Influence Prediction with Deep Learning,"Social and information networking activities such as on Facebook, Twitter, WeChat, and Weibo have become an indispensable part of our everyday life, where we can easily access friends' behaviors and are in turn influenced by them. Consequently, an effective social influence prediction for each user is critical for a variety of applications such as online recommendation and advertising. Conventional social influence prediction approaches typically design various hand-crafted rules to extract user- and network-specific features. However, their effectiveness heavily relies on the knowledge of domain experts. As a result, it is usually difficult to generalize them into different domains. Inspired by the recent success of deep neural networks in a wide range of computing applications, we design an end-to-end framework, DeepInf, to learn users' latent feature representation for predicting social influence. In general, DeepInf takes a user's local network as the input to a graph neural network for learning her latent",11
452059171226626718eb677358836328f884298e,Ask Me Anything: Dynamic Memory Networks for Natural Language Processing,"Most tasks in natural language processing can be cast into question answering (QA) problems over language input. We introduce the dynamic memory network (DMN), a neural network architecture which processes input sequences and questions, forms episodic memories, and generates relevant answers. Questions trigger an iterative attention process which allows the model to condition its attention on the inputs and the result of previous iterations. These results are then reasoned over in a hierarchical recurrent sequence model to generate answers. The DMN can be trained end-to-end and obtains state-of-the-art results on several types of tasks and datasets: question answering (Facebook's bAbI dataset), text classification for sentiment analysis (Stanford Sentiment Treebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). The training for these different tasks relies exclusively on trained word vector representations and input-question-answer triplets.",7
484ad17c926292fbe0d5211540832a8c8a8e958b,Stochastic Backpropagation and Approximate Inference in Deep Generative Models,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",18
7c6de5a9e02a779e24504619050c6118f4eac181,Learning Convolutional Neural Networks for Graphs,"Numerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.",48
0df63cbd6f8bb0b325d780c9c2fcef8f6670c588,Improving Graph Attention Networks with Large Margin-based Constraints,"Graph Attention Networks (GATs) are the state-of-the-art neural architecture for representation learning with graphs. GATs learn attention functions that assign weights to nodes so that different nodes have different influences in the feature aggregation steps. In practice, however, induced attention functions are prone to over-fitting due to the increasing number of parameters and the lack of direct supervision on attention weights. GATs also suffer from over-smoothing at the decision boundary of nodes. Here we propose a framework to address their weaknesses via margin-based constraints on attention during training. We first theoretically demonstrate the over-smoothing behavior of GATs and then develop an approach using constraint on the attention weights according to the class boundary and feature aggregation pattern. Furthermore, to alleviate the over-fitting problem, we propose additional constraints on the graph structure. Extensive experiments and ablation studies on common benchmark datasets demonstrate the effectiveness of our method, which leads to significant",2
73047a0f0192a35d3b5c6f5ebeadf3706b17e4dc,KBGAN: Adversarial Learning for Knowledge Graph Embeddings,"We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models. Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a nontrivial task. Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training. Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs. This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks. In experiments, we adversarially train two",8
2582ab7c70c9e7fcb84545944eba8f3a7f253248,Translating Embeddings for Modeling Multi-relational Data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",50
6e7013f7e3801a5b56e12fc3f8dc1656f5d010bb,Small‐world properties of nonlinear brain activity in schizophrenia,"A disturbance in the interactions between distributed cortical regions may underlie the cognitive and perceptual dysfunction associated with schizophrenia. In this article, nonlinear measures of cortical interactions and graph‐theoretical metrics of network topography are combined to investigate this schizophrenia “disconnection hypothesis.” This is achieved by analyzing the spatiotemporal structure of resting state scalp EEG data previously acquired from 40 young subjects with a recent first episode of schizophrenia and 40 healthy matched controls. In each subject, a method of mapping the topography of nonlinear interactions between cortical regions was applied to a widely distributed array of these data. The resulting nonlinear correlation matrices were converted to weighted graphs. The path length (a measure of large‐scale network integration), clustering coefficient (a measure of “cliquishness”), and hub structure of these graphs were used as metrics of the underlying brain network activity. The graphs of both groups exhibited high levels of local clustering",5
4930de1aff4b1948157a15ac9cdb02364bee97bb,Graph Convolution over Pruned Dependency Trees Improves Relation Extraction,"Dependency trees help relation extraction models capture long-range relations between words. However, existing dependency-based models either neglect crucial information (e.g., negation) by pruning the dependency trees too aggressively, or are computationally inefficient because it is difficult to parallelize over different tree structures. We propose an extension of graph convolutional networks that is tailored for relation extraction, which pools information over arbitrary dependency structures efficiently in parallel. To incorporate relevant information while maximally removing irrelevant content, we further apply a novel pruning strategy to the input trees by keeping words immediately around the shortest path between the two entities among which a relation might hold. The resulting model achieves state-of-the-art performance on the large-scale TACRED dataset, outperforming existing sequence and dependency-based neural models. We also show through detailed analysis that this model has complementary strengths to sequence models, and combining them further improves the state of the art.",5
75d6b55e8b9146e3d9dce9091cfb03211a664b3a,MMGCN: Multi-modal Graph Convolution Network for Personalized Recommendation of Micro-video,"Personalized recommendation plays a central role in many online content sharing platforms. To provide quality micro-video recommendation service, it is of crucial importance to consider the interactions between users and items (i.e. micro-videos) as well as the item contents from various modalities (e.g. visual, acoustic, and textual). Existing works on multimedia recommendation largely exploit multi-modal contents to enrich item representations, while less effort is made to leverage information interchange between users and items to enhance user representations and further capture user's fine-grained preferences on different modalities. In this paper, we propose to exploit user-item interactions to guide the representation learning in each modality, and further personalized micro-video recommendation. We design a Multi-modal Graph Convolution Network (MMGCN) framework built upon the message-passing idea of graph neural networks, which can yield modal-specific representations of users and micro-videos to better capture user preferences. Specifically, we construct a user-item bipartite graph in each modality,",2
36ee2c8bd605afd48035d15fdc6b8c8842363376,node2vec: Scalable Feature Learning for Networks,"Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning",58
9d9d33843d018a77bad7f40da8f27671d29cd776,HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning,"In this paper, we propose a novel representation learning framework, namely HIN2Vec, for heterogeneous information networks (HINs). The core of the proposed framework is a neural network model, also called HIN2Vec, designed to capture the rich semantics embedded in HINs by exploiting different types of relationships among nodes. Given a set of relationships specified in forms of meta-paths in an HIN, HIN2Vec carries out multiple prediction training tasks jointly based on a target set of relationships to learn latent vectors of nodes and meta-paths in the HIN. In addition to model design, several issues unique to HIN2Vec, including regularization of meta-path vectors, node type selection in negative sampling, and cycles in random walks, are examined. To validate our ideas, we learn latent vectors of nodes using four large-scale real HIN datasets, including Blogcatalog, Yelp, DBLP and U.S. Patents, and use them as features for multi-label node classification and link prediction",7
834cb8e1e738b8d2c6d24e652ac966d6e7089a46,Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction,"This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on scoring functions that operate by learning low-dimensional embeddings of words, entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over methods that rely on text features alone.",13
62b1ec1a065f98bb17e79783fff24374150cbe5a,A V² Algorithm for Determining Isomorphism of Planar Graphs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
a702a8d2dfa922c30d1393a40c9ae20319bd73d0,Variation graph toolkit improves read mapping by representing genetic variation in the reference,"Reference genomes guide our interpretation of DNA sequence data. However, conventional linear references represent only one version of each locus, ignoring variation in the population. Poor representation of an individual′s genome sequence impacts read mapping and introduces bias. Variation graphs are bidirected DNA sequence graphs that compactly represent genetic variation across a population, including large-scale structural variation such as inversions and duplications. Previous graph genome software implementations have been limited by scalability or topological constraints. Here we present vg, a toolkit of computational methods for creating, manipulating, and using these structures as references at the scale of the human genome. vg provides an efficient approach to mapping reads onto arbitrary variation graphs using generalized compressed suffix arrays, with improved accuracy over alignment to a linear reference, and effectively removing reference bias. These capabilities make using variation graphs as references for DNA sequencing practical at a gigabase scale, or at the",5
086bd32d9192632be3b63af92a1bf4b0dc17c4e0,Heritability of “small‐world” networks in the brain: A graph theoretical analysis of resting‐state EEG functional connectivity,"Recent studies have shown that resting‐state functional networks as studied with fMRI, EEG, and MEG may be so‐called small‐world networks. We investigated to what extent the characteristic features of small‐world networks are genetically determined. To represent functional connectivity between brain areas, we measured resting EEG in 574 twins and their siblings and calculated the synchronization likelihood between each pair of electrodes. We applied a threshold to obtain a binary graph from which we calculated the clustering coefficient C (describing local interconnectedness) and average path length L (describing global interconnectedness) for each individual. Modeling of MZ and DZ twin and sibling resemblance indicated that across various frequency bands 46–89% of the individual differences in C and 37–62% of the individual differences in L are heritable. It is asserted that C, L, and a small‐world organization are viable markers of genetic differences in brain organization. Hum Brain Mapp, 2008. © 2007 Wiley‐Liss,",6
74606b052a17dd425bcc6cd1d05db153633c742a,Discriminative Gaifman Models,"We present discriminative Gaifman models, a novel family of relational machine learning models. Gaifman models learn feature representations bottom up from representations of locally connected and bounded-size regions of knowledge bases (KBs). Considering local and bounded-size neighborhoods of knowledge bases renders logical inference and learning tractable, mitigates the problem of overfitting, and facilitates weight sharing. Gaifman models sample neighborhoods of knowledge bases so as to make the learned relational models more robust to missing objects and relations which is a common situation in open-world KBs. We present the core ideas of Gaifman models and apply them to large-scale relational learning problems. We also discuss the ways in which Gaifman models relate to some existing relational machine learning approaches.",7
09c5293b647fca40fde28ac6c38737f07e873e41,DryadLINQ: A System for General-Purpose Distributed Data-Parallel Computing Using a High-Level Language,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",8
4e1d97d3c4ef5e217f3bd7ab95aa251a10a748b0,DGL-KE: Training Knowledge Graph Embeddings at Scale,"Knowledge graphs have emerged as a key abstraction for organizing information in diverse domains and their embeddings are increasingly used to harness their information in various information retrieval and machine learning tasks. However, the ever growing size of knowledge graphs requires computationally efficient algorithms capable of scaling to graphs with millions of nodes and billions of edges. This paper presents DGL-KE, an open-source package to efficiently compute knowledge graph embeddings. DGL-KE introduces various novel optimizations that accelerate training on knowledge graphs with millions of nodes and billions of edges using multi-processing, multi-GPU, and distributed parallelism. These optimizations are designed to increase data locality, reduce communication overhead, overlap computations with memory accesses, and achieve high operation efficiency. Experiments on knowledge graphs consisting of over 86M nodes and 338M edges show that DGL-KE can compute embeddings in 100 minutes on an EC2 instance with 8 GPUs and 30 minutes on an EC2",5
6b010e07618eb36abe6def23d94488b2c81ecbf7,Position-aware Graph Neural Networks,"Learning node embeddings that capture a node's position within the broader graph structure is crucial for many prediction tasks on graphs. However, existing Graph Neural Network (GNN) architectures have limited power in capturing the position/location of a given node with respect to all other nodes of the graph. Here we propose Position-aware Graph Neural Networks (P-GNNs), a new class of GNNs for computing position-aware node embeddings. P-GNN first samples sets of anchor nodes, computes the distance of a given target node to each anchor-set,and then learns a non-linear distance-weighted aggregation scheme over the anchor-sets. This way P-GNNs can capture positions/locations of nodes with respect to the anchor nodes. P-GNNs have several advantages: they are inductive, scalable,and can incorporate node feature information. We apply P-GNNs to multiple prediction tasks including link prediction and community detection. We show that P-GNNs consistently outperform state of the art GNNs, with up to 66% improvement",13
29258e7c8a2d43c77933900f4b66e8bdc002943e,Non-negative Matrices and Markov Chains,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
99f319ab72ae43f0ac94fe7ff1891be524611483,Relevance of Rotationally Equivariant Convolutions for Predicting Molecular Properties,"Equivariant neural networks (ENNs) are graph neural networks embedded in $\mathbb{R}^3$ and are well suited for predicting molecular properties. The ENN library e3nn has customizable convolutions, which can be designed to depend only on distances between points, or also on angular features, making them rotationally invariant, or equivariant, respectively. This paper studies the practical value of including angular dependencies for molecular property prediction using the QM9 data set. We find that for fixed network depth, adding angular features improves the accuracy on most targets. For most, but not all, molecular properties, distance-only e3nns (L0Nets) can compensate by increasing convolutional layer depth. Our angular-feature e3nn (L1Net) architecture beats previous state-of-the-art results on the global electronic properties dipole moment, isotropic polarizability, and electronic spatial extent.",4
6addf8bddf2fd2e194a662a8a7f0ea001f2a29a7,Is bottom-up attention useful for object recognition?,"A key problem in learning multiple objects from unlabeled images is that it is a priori impossible to tell which part of the image corresponds to each individual object, and which part is irrelevant clutter which is not associated to the objects. We investigate empirically to what extent pure bottom-up attention can extract useful information about the location, size and shape of objects from images and demonstrate how this information can be utilized to enable unsupervised learning of objects from unlabeled images. Our experiments demonstrate that the proposed approach to using bottom-up attention is indeed useful for a variety of applications.",5
b3cbe851a041fb82a2caf73e3a3aa60713275fda,Does luminance‐contrast contribute to a saliency map for overt visual attention?,"In natural environments, humans select a subset of visual stimuli by directing their gaze to locations attended. In previous studies it has been found that at fixation points luminance‐contrast is higher than average. This led to the hypothesis that luminance‐contrast makes a major contribution to a saliency map of visual overt attention, consistent with a computation of stimulus saliency in early visual cortical areas. We re‐evaluate this hypothesis by using natural and modified natural images to uncover the causal effects of luminance‐contrast to human overt visual attention and: (i) we confirm that when viewing natural images, contrasts are elevated at fixation points. This, however, only holds for low spatial frequencies and in a limited temporal window after stimulus onset; (ii) however, despite this correlation between overt attention and luminance‐contrast, moderate modifications of contrast in natural images do not measurably affect the selection of fixation points. Furthermore, strong local reductions of",5
e4715a13f6364b1c81e64f247651c3d9e80b6808,Link Prediction Based on Graph Neural Networks,"Link prediction is a key problem for network-structured data. Link prediction heuristics use some score functions, such as common neighbors and Katz index, to measure the likelihood of links. They have obtained wide practical uses due to their simplicity, interpretability, and for some of them, scalability. However, every heuristic has a strong assumption on when two nodes are likely to link, which limits their effectiveness on networks where these assumptions fail. In this regard, a more reasonable way should be learning a suitable heuristic from a given network instead of using predefined ones. By extracting a local subgraph around each target link, we aim to learn a function mapping the subgraph patterns to link existence, thus automatically learning a `heuristic' that suits the current network. In this paper, we study this heuristic learning paradigm for link prediction. First, we develop a novel $\gamma$-decaying heuristic theory. The theory unifies a wide",20
2c03df8b48bf3fa39054345bafabfeff15bfd11d,Deep Residual Learning for Image Recognition,"Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due",150
65a94e7163d4836a93222ac5537e26e77dadeede,Modelling gaze shift as a constrained random walk,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e,End-To-End Memory Networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",11
eb984b142db9965b10a3b5ae5813eeb3e0f6e676,Sign and Basis Invariant Networks for Spectral Graph Representation Learning,"We introduce SignNet and BasisNet -- new neural architectures that are invariant to two key symmetries displayed by eigenvectors: (i) sign flips, since if $v$ is an eigenvector then so is $-v$; and (ii) more general basis symmetries, which occur in higher dimensional eigenspaces with infinitely many choices of basis eigenvectors. We prove that under certain conditions our networks are universal, i.e., they can approximate any continuous function of eigenvectors with the desired invariances. When used with Laplacian eigenvectors, our networks are provably more expressive than existing spectral methods on graphs; for instance, they subsume all spectral graph convolutions, certain spectral graph invariants, and previously proposed graph positional encodings as special cases. Experiments show that our networks significantly outperform existing baselines on molecular graph regression, learning expressive graph representations, and learning neural fields on triangle meshes. Our code is available at https://github.com/cptq/SignNet-BasisNet .",4
c1040296c9aa7a5c5651749f0e98ba768fe4e68b,L2-GCN: Layer-Wise and Learned Efficient Training of Graph Convolutional Networks,"Graph convolution networks (GCN) are increasingly popular in many applications, yet remain notoriously hard to train over large graph datasets. They need to compute node representations recursively from their neighbors. Current GCN training algorithms suffer from either high computational costs that grow exponentially with the number of layers, or high memory usage for loading the entire graph and node embeddings. In this paper, we propose a novel efficient layer-wise training framework for GCN (L-GCN), that disentangles feature aggregation and feature transformation during training, hence greatly reducing time and memory complexities. We present theoretical analysis for L-GCN under the graph isomorphism framework, that L-GCN leads to as powerful GCNs as the more costly conventional training algorithm does, under mild conditions. We further propose L^2-GCN, which learns a controller for each layer that can automatically adjust the training epochs per layer in L-GCN. Experiments show that L-GCN is faster than state-of-the-arts by",6
4c75b748911ddcd888c5122f7672f69caa5d661f,Statistical Learning Theory,"A machine learning system, in general, learns from the environment, but statistical machine learning programs (systems) learn from the data. This chapter presents techniques for statistical machine learning using Support Vector Machines (SVM) to recognize the patterns and classify them, predicting structured objects using SVM, k-nearest neighbor method for classification, and Naive Bayes classifiers. The artificial neural networks are presented with brief introduction to error-correction rules, Boltzmann learning, Hebbian rule, competitive learning rule, and deep learning. The instance-based learning is treated in details with its algorithm and learning task. The chapter concludes with a summary, and a set of practice exercises.",6
9ae75ab09a9c0db08c5ec6a02ae940128f41e016,A Neural Influence Diffusion Model for Social Recommendation,"Precise user and item embedding learning is the key to building a successful recommender system. Traditionally, Collaborative Filtering (CF) provides a way to learn user and item embeddings from the user-item interaction history. However, the performance is limited due to the sparseness of user behavior data. With the emergence of online social networks, social recommender systems have been proposed to utilize each user's local neighbors' preferences to alleviate the data sparsity for better user embedding modeling. We argue that, for each user of a social platform, her potential embedding is influenced by her trusted users, with these trusted users are influenced by the trusted users' social connections. As social influence recursively propagates and diffuses in the social network, each user's interests change in the recursive process. Nevertheless, the current social recommendation models simply developed static models by leveraging the local neighbors of each user without simulating the recursive diffusion in",4
b7c4570d7d97f327e7f82fe28100172ec5e94cac,Predicting multicellular function through multi-layer tissue networks,"Motivation: Understanding functions of proteins in specific human tissues is essential for insights into disease diagnostics and therapeutics, yet prediction of tissue‐specific cellular function remains a critical challenge for biomedicine. Results: Here, we present OhmNet, a hierarchy‐aware unsupervised node feature learning approach for multi‐layer networks. We build a multi‐layer network, where each layer represents molecular interactions in a different human tissue. OhmNet then automatically learns a mapping of proteins, represented as nodes, to a neural embedding‐based low‐dimensional space of features. OhmNet encourages sharing of similar features among proteins with similar network neighborhoods and among proteins activated in similar tissues. The algorithm generalizes prior work, which generally ignores relationships between tissues, by modeling tissue organization with a rich multiscale tissue hierarchy. We use OhmNet to study multicellular function in a multi‐layer protein interaction network of 107 human tissues. In 48 tissues with known tissue‐specific cellular functions, OhmNet provides more accurate predictions",13
9510dcc7063c8d459c9f6dc2bb3dab07085f778d,Binary Codes of Strongly Regular Graphs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
c52b77c18700e9625c885a824a0c8b95c3e9cf21,Short-term traffic flow forecasting with spatial-temporal correlation in a hybrid deep learning framework,"Deep learning approaches have reached a celebrity status in artificial intelligence field, its success have mostly relied on Convolutional Networks (CNN) and Recurrent Networks. By exploiting fundamental spatial properties of images and videos, the CNN always achieves dominant performance on visual tasks. And the Recurrent Networks (RNN) especially long short-term memory methods (LSTM) can successfully characterize the temporal correlation, thus exhibits superior capability for time series tasks. Traffic flow data have plentiful characteristics on both time and space domain. However, applications of CNN and LSTM approaches on traffic flow are limited. In this paper, we propose a novel deep architecture combined CNN and LSTM to forecast future traffic flow (CLTFP). An 1-dimension CNN is exploited to capture spatial features of traffic flow, and two LSTMs are utilized to mine the short-term variability and periodicities of traffic flow. Given those meaningful features, the feature-level fusion is performed to achieve short-term forecasting.",9
0e2fdbfd7b4699743010ddf2aa52b8aedf1d496d,"Occlusions, Discontinuities, and Epipolar Lines in Stereo","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",9
fbe358ce706371b93c10c4395cab9a78ad3aef67,Multi-instance Multi-label Learning for Relation Extraction,"Distant supervision for relation extraction (RE) -- gathering training data by aligning a database of facts with text -- is an efficient approach to scale RE to thousands of different relations. However, this introduces a challenging learning scenario where the relation expressed by a pair of entities found in a sentence is unknown. For example, a sentence containing Balzac and France may express BornIn or Died, an unknown relation, or no relation at all. Because of this, traditional supervised learning, which assumes that each example is explicitly mapped to a label, is not appropriate. We propose a novel approach to multi-instance multi-label learning for RE, which jointly models all the instances of a pair of entities in text and all their labels using a graphical model with latent variables. Our model performs competitively on two difficult domains.",11
6b7d6e6416343b2a122f8416e69059ce919026ef,Inductive Representation Learning on Large Graphs,"Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of",99
b9f00b6abf2a928aaad32bc236ca9cf6cac96eb1,Attention activates winner-take-all competition among visual filters,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
5b636d61b978860c914e999d7ff242f97df08b11,Design and Implementation of a Practical I/O-efficient Shortest Paths Algorithm,"We report on initial experimental results for a practical I/O-efficient Single-Source Shortest-Paths (SSSP) algorithm on general undirected sparse graphs where the ratio between the largest and the smallest edge weight is reasonably bounded (for example integer weights in {1, . . ., 232}) and the realistic assumption holds that main memory is big enough to keep one bit per vertex. While our implementation only guarantees average-case efficiency, i.e., assuming randomly chosen edge-weights, it turns out that its performance on real-world instances with non-random edge weights is actually even better than on the respective inputs with random weights. Furthermore, compared to the currently best implementation for external-memory BFS [6], which in a sense constitutes a lower bound for SSSP, the running time of our approach always stayed within a factor of five, for the most difficult graph classes the difference was even less than a factor of two. We are not",2
d542456075b2e7148ad905b38f09e373af1b3758,Visual Saliency and Attention as Random Walks on Complex Networks,"The current article shows how concepts from the areas of random walks, Markov chains, complex networks and image analysis can be naturally combined in order to provide a unified and biologically plausible model relating saliency and visual attention. Two types of models are proposed: (i) images are converted into complex networks by considering pixels as nodes while connections are established in terms of fields of influence defined by visual features such as tangent fields induced by gray-level contrasts and distance; and (ii) image pixels exhibiting particularly distinctive values of visual properties such as gray-level intensity, contrast, size of objects, orientation and texture are mapped into nodes and the weights of links are defined in order to favor transitions between regions with similar or different visual features, also taking the distance between the nodes into account. Preferential random walks are performed on such networks in order to emulate attentional shifts and",4
1f4b6049b2ae8e536e1f93097792743936de558c,Complexity and approximation: combinatorial optimization problems and their approximability properties,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
e1cef464322243feb12ac3f81873c912e071a1a6,GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models,"Modeling and generating graphs is fundamental for studying networks in biology, engineering, and social sciences. However, modeling complex distributions over graphs and then efficiently sampling from these distributions is challenging due to the non-unique, high-dimensional nature of graphs and the complex, non-local dependencies that exist between edges in a given graph. Here we propose GraphRNN, a deep autoregressive model that addresses the above challenges and approximates any distribution of graphs with minimal assumptions about their structure. GraphRNN learns to generate graphs by training on a representative set of graphs and decomposes the graph generation process into a sequence of node and edge formations, conditioned on the graph structure generated so far. In order to quantitatively evaluate the performance of GraphRNN, we introduce a benchmark suite of datasets, baselines and novel evaluation metrics based on Maximum Mean Discrepancy, which measure distances between sets of graphs. Our experiments show that GraphRNN significantly",12
acc8645eaf02c793dab94e4852d1f560aca90c22,Multivariate Pólya–Schur classification problems in the Weyl algebra,"A multivariate polynomial is stable if it is nonvanishing whenever all variables have positive imaginary parts. We classify all linear partial differential operators in the Weyl algebra 𝒜n that preserve stability. An important tool that we develop in the process is the higher‐dimensional generalization of Pólya–Schur's notion of multiplier sequence. We characterize all multivariate multiplier sequences as well as those of finite order. Next, we establish a multivariate extension of the Cauchy–Poincaré interlacing theorem and prove a natural analog of the Lax conjecture for real stable polynomials in two variables. Using the latter we describe all operators in 𝒜1 that preserve univariate hyperbolic polynomials by means of determinants and homogenized symbols. Our methods also yield homotopical properties for symbols of linear stability preservers and a duality theorem showing that an operator in 𝒜n preserves stability if and only if its Fischer–Fock adjoint does. These are powerful multivariate extensions of the",5
24a473700894dbfab0bfd9dc3d542acfeef66bca,Cross-Domain Recommendation via Preference Propagation GraphNet,"Recommendation can be framed as a graph link prediction task naturally. The user-item interaction graph built within a single domain often suffers from high sparsity. Thus, there has been a surge of approaches to alleviate the sparsity issue via cross-domain mutual augmentation. The SOTA cross-domain recommendation algorithms all try to bridge the gap via knowledge transfer in the latent space. We find there are mainly three problems in their formulations: 1) their knowledge transfer is unaware of the cross-domain graph structure. 2) their framework cannot capture high-order information propagation on the graph. 3) their cross-domain transfer formulations are generally more complicated to be optimized than the unified methods. In this paper, we propose the Preference Propagation GraphNet (PPGN) to address the above problems. Specifically, we construct a Cross-Domain Preference Matrix (CDPM) to model the interactions of different domains as a whole. Through the propagation layer of PPGN, we try to",5
fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5,Neural Machine Translation by Jointly Learning to Align and Translate,"Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based",44
1f3c381eedfe8914b81e93070bfdb00cf86ac943,Contrastive Multi-View Representation Learning on Graphs,"We introduce a self-supervised approach for learning node and graph level representations by contrasting structural views of graphs. We show that unlike visual representation learning, increasing the number of views to more than two or contrasting multi-scale encodings do not improve performance, and the best performance is achieved by contrasting encodings from first-order neighbors and a graph diffusion. We achieve new state-of-the-art results in self-supervised learning on 8 out of 8 node and graph classification benchmarks under the linear evaluation protocol. For example, on Cora (node) and Reddit-Binary (graph) classification benchmarks, we achieve 86.8% and 84.5% accuracy, which are 5.5% and 2.4% relative improvements over previous state-of-the-art. When compared to supervised baselines, our approach outperforms them in 4 out of 8 benchmarks. Source code is released at: this https URL",4
54575fec0a24ea3daf1512e209ba4fab4c3d53f0,HOP-rec: high-order proximity for implicit recommendation,"Recommender systems are vital ingredients for many e-commerce services. In the literature, two of the most popular approaches are based on factorization and graph-based models; the former approach captures user preferences by factorizing the observed direct interactions between users and items, and the latter extracts indirect preferences from the graphs constructed by user-item interactions. In this paper we present HOP-Rec, a unified and efficient method that incorporates the two approaches. The proposed method involves random surfing on a graph to harvest high-order information among neighborhood items for each user. Instead of factorizing a transition matrix, our method introduces a confidence weighting parameter to simulate all high-order information simultaneously, for which we maintain a sparse user-item interaction matrix and enrich the matrix for each user using random walks. Experimental results show that our approach significantly outperforms the state of the art on a range of large-scale real-world datasets.",7
e6ea85add58fb25448042edb9af16f0d955c17da,MGAE: Marginalized Graph Autoencoder for Graph Clustering,"Graph clustering aims to discovercommunity structures in networks, the task being fundamentally challenging mainly because the topology structure and the content of the graphs are difficult to represent for clustering analysis. Recently, graph clustering has moved from traditional shallow methods to deep learning approaches, thanks to the unique feature representation learning capability of deep learning. However, existing deep approaches for graph clustering can only exploit the structure information, while ignoring the content information associated with the nodes in a graph. In this paper, we propose a novel marginalized graph autoencoder (MGAE) algorithm for graph clustering. The key innovation of MGAE is that it advances the autoencoder to the graph domain, so graph representation learning can be carried out not only in a purely unsupervised setting by leveraging structure and content information, it can also be stacked in a deep fashion to learn effective representation. From a technical viewpoint, we propose",11
f09f7888aa5aeaf88a2a44aea768d9a8747e97d2,Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs,"Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed",57
06b8e82542d1873928d007548a23d3b77daa11f8,Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning,"Predicting urban traffic is of great importance to intelligent transportation systems and public safety, yet is very challenging because of two aspects: 1) complex spatio-temporal correlations of urban traffic, including spatial correlations between locations along with temporal correlations among timestamps; 2) diversity of such spatio-temporal correlations, which vary from location to location and depend on the surrounding geographical information, e.g., points of interests and road networks. To tackle these challenges, we proposed a deep-meta-learning based model, entitled ST-MetaNet, to collectively predict traffic in all location at once. ST-MetaNet employs a sequence-to-sequence architecture, consisting of an encoder to learn historical information and a decoder to make predictions step by step. In specific, the encoder and decoder have the same network structure, consisting of a recurrent neural network to encode the traffic, a meta graph attention network to capture diverse spatial correlations, and a meta recurrent neural network to consider diverse temporal",2
dc89b23a629b05017f71bbd68235cf8e7e6e7de5,Embedding Logical Queries on Knowledge Graphs,"Learning low-dimensional embeddings of knowledge graphs is a powerful approach used to predict unobserved or missing edges between entities. However, an open challenge in this area is developing techniques that can go beyond simple edge prediction and handle more complex logical queries, which might involve multiple unobserved edges, entities, and variables. For instance, given an incomplete biological knowledge graph, we might want to predict ""em what drugs are likely to target proteins involved with both diseases X and Y?"" -- a query that requires reasoning about all possible proteins that might interact with diseases X and Y. Here we introduce a framework to efficiently make predictions about conjunctive logical queries -- a flexible but tractable subset of first-order logic -- on incomplete knowledge graphs. In our approach, we embed graph nodes in a low-dimensional space and represent logical operators as learned geometric operations (e.g., translation, rotation) in this embedding space.",8
127af6effc74f073ac2442f6d82c944f562e2c0f,GeniePath: Graph Neural Networks with Adaptive Receptive Paths,"We present, GeniePath, a scalable approach for learning adaptive receptive fields of neural networks defined on permutation invariant graph data. In GeniePath, we propose an adaptive path layer consists of two complementary functions designed for breadth and depth exploration respectively, where the former learns the importance of different sized neighborhoods, while the latter extracts and filters signals aggregated from neighbors of different hops away. Our method works in both transductive and inductive settings, and extensive experiments compared with competitive methods show that our approaches yield state-of-the-art results on large graphs.",10
e24cdf73b3e7e590c2fe5ecac9ae8aa983801367,Neural Message Passing for Quantum Chemistry,"Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with",87
c2e4d8f97d85783895db2c7066b6f3199c08c68c,Knowledge Base Completion: Baselines Strike Back,Many papers have been published on the knowledge base completion task in the past few years. Most of these introduce novel architectures for relation learning that are evaluated on standard datasets like FB15k and WN18. This paper shows that the accuracy of almost all models published on the FB15k can be outperformed by an appropriately tuned baseline — our reimplementation of the DistMult model. Our findings cast doubt on the claim that the performance improvements of recent models are due to architectural changes as opposed to hyper-parameter tuning or different training objectives. This should prompt future research to re-consider how the performance of models is evaluated and reported.,3
a99bc3f0d52bf01fd4daa8d0c72e346ac293be63,DAGCN: Dual Attention Graph Convolutional Networks,"Graph convolutional networks (GCNs) have recently become one of the most powerful tools for graph analytics tasks in numerous applications, ranging from social networks and natural language processing to bioinformatics and chemoinformatics, thanks to their ability to capture the complex relationships between concepts. At present, the vast majority of GCNs use a neighborhood aggregation framework to learn a continuous and compact vector, then performing a pooling operation to generalize graph embedding for the classification task. These approaches have two disadvantages in the graph classification task: (1)when only the largest sub-graph structure (k-hop neighbor) is used for neighborhood aggregation, a large amount of early-stage information is lost during the graph convolution step; (2) simple average/sum pooling or max pooling utilized, which loses the characteristics of each node and the topology between nodes. In this paper, we propose a novel framework called, dual attention graph convolutional networks (DAGCN) to address these problems.",3
a0c8080df526ebe6118d601e81fdef41965959dc,Behavior Is Everything: Towards Representing Concepts with Sensorimotor Contingencies,"AI has seen remarkable progress in recent years, due to a switch from hand-designed shallow representations, to learned deep representations. While these methods excel with plentiful training data, they are still far from the human ability to learn concepts from just a few examples by reusing previously learned conceptual knowledge in new contexts. We argue that this gap might come from a fundamental misalignment between human and typical AI representations: while the former are grounded in rich sensorimotor experience, the latter are typically passive and limited to a few modalities such as vision and text. We take a step towards closing this gap by proposing an interactive, behavior-based model that represents concepts using sensorimotor contingencies grounded in an agent's experience. On a novel conceptual learning and benchmark suite, we demonstrate that conceptually meaningful behaviors can be learned, given supervision via training curricula.",6
6c6e4b6a53c7f1692e4d4df54eb47509d871ef9a,Integrated Computational Pipeline for Single-Cell Genomic Profiling,"PURPOSE Copy-number profiling of multiple individual cells from sparse sequencing may be used to reveal a detailed picture of genomic heterogeneity and clonal organization in a tissue biopsy specimen. We sought to provide a comprehensive computational pipeline for single-cell genomics, to facilitate adoption of this molecular technology for basic and translational research. MATERIALS AND METHODS The pipeline comprises software tools programmed in Python and in R and depends on Bowtie, HISAT2, Matplotlib, and Qt. It is installed and used with Anaconda. RESULTS Here we describe a complete pipeline for sparse single-cell genomic data, encompassing all steps of single-nucleus DNA copy-number profiling, from raw sequence processing to clonal structure analysis and visualization. For the latter, a specialized graphical user interface termed the single-cell genome viewer (SCGV) is provided. With applications to cancer diagnostics in mind, the SCGV allows for zooming and linkage to the University of California at Santa Cruz Genome",3
7bf34d65eec494a0b758f4ab3f58db8a89815e1f,Leveraging Knowledge Bases in LSTMs for Improving Machine Reading,"This paper focuses on how to take advantage of external knowledge bases (KBs) to improve recurrent neural networks for machine reading. Traditional methods that exploit knowledge from KBs encode knowledge as discrete indicator features. Not only do these features generalize poorly, but they require task-specific feature engineering to achieve good performance. We propose KBLSTM, a novel neural model that leverages continuous representations of KBs to enhance the learning of recurrent neural networks for machine reading. To effectively integrate background knowledge with information from the currently processed text, our model employs an attention mechanism with a sentinel to adaptively decide whether to attend to background knowledge and which information from KBs is useful. Experimental results show that our model achieves accuracies that surpass the previous state-of-the-art results for both entity extraction and event extraction on the widely used ACE2005 dataset.",7
08a83d48f24e2dea1ac7cb96ba2308e0b4076c3a,Attentional Modulation of Human Pattern Discrimination Psychophysics Reproduced by a Quantitative Model,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
1fc91b9b1c3eac8cc1d82779aeb9b1dc04a39d84,Transcriptomic Analysis of circRNAs and mRNAs Reveals a Complex Regulatory Network That Participate in Follicular Development in Chickens,"Follicular development plays a key role in poultry reproduction, affecting clutch traits and thus egg production. Follicular growth is determined by granulosa cells (GCs), theca cells (TCs), and oocyte at the transcription, translation, and secretion levels. With the development of bioinformatic and experimental techniques, non-coding RNAs have been shown to participate in many life events. In this study, we investigated the transcriptomes of GCs and TCs in three different physiological stages: small yellow follicle (SYF), smallest hierarchical follicle (F6), and largest hierarchical follicle (F1) stages. A differential expression (DE) analysis, weighted gene co-expression network analysis (WGCNA), and bioinformatic analyses were performed. A total of 18,016 novel circular RNAs (circRNAs) were detected in GCs and TCs, 8127 of which were abundantly expressed in both cell types. and more circRNAs were differentially expressed between GCs and TCs than mRNAs. Enrichment analysis showed that the DE transcripts were mainly involved in cell growth,",8
42b1d2f74a6fcdd9e45b64a4acabddafb43d7426,Kourami: graph-guided assembly for novel human leukocyte antigen allele discovery,"Accurate typing of human leukocyte antigen (HLA) is important because HLA genes play important roles in immune responses and disease genesis. Previously available computational methods are database-matching approaches and their outputs are inherently limited by the completeness of already known types, making them unsuitable for discovery of novel alleles. We have developed a graph-guided assembly technique for classical HLA genes, which can construct allele sequences given high-coverage whole-genome sequencing data. Our method delivers highly accurate HLA typing, comparable to the current state-of-the-art methods. Using various data, we also demonstrate that our method can type novel alleles.",1
135334ea7fdef8eef0367e862797cac7dcd232a4,Multi-scale Attributed Node Embedding,"We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighbourhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE). Capturing attribute-neighbourhood relationships over multiple scales is useful for a range of applications, including latent feature identification across disconnected networks with similar features. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are computationally efficient and outperform comparable models on social networks and web graphs.",4
454304628bf10f02aba1c2cfc95891e94d09208e,Graph Neural Networks with Learnable Structural and Positional Representations,"Graph neural networks (GNNs) have become the standard learning architectures for graphs. GNNs have been applied to numerous domains ranging from quantum chemistry, recommender systems to knowledge graphs and natural language processing. A major issue with arbitrary graphs is the absence of canonical positional information of nodes, which decreases the representation power of GNNs to distinguish e.g. isomorphic nodes and other graph symmetries. An approach to tackle this issue is to introduce Positional Encoding (PE) of nodes, and inject it into the input layer, like in Transformers. Possible graph PE are Laplacian eigenvectors. In this work, we propose to decouple structural and positional representations to make easy for the network to learn these two essential properties. We introduce a novel generic architecture which we call LSPE (Learnable Structural and Positional Encodings). We investigate several sparse and fully-connected (Transformer-like) GNNs, and observe a performance increase for molecular datasets, from 1.79% up",5
0d57ba12a6d958e178d83be4c84513f7e42b24e5,"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour","Deep learning thrives with large neural networks and large datasets. However, larger networks and larger datasets result in longer training times that impede research and development progress. Distributed synchronous SGD offers a potential solution to this problem by dividing SGD minibatches over a pool of parallel workers. Yet to make this scheme efficient, the per-worker workload must be large, which implies nontrivial growth in the SGD minibatch size. In this paper, we empirically show that on the ImageNet dataset large minibatches cause optimization difficulties, but when these are addressed the trained networks exhibit good generalization. Specifically, we show no loss of accuracy when training with large minibatch sizes up to 8192 images. To achieve this result, we adopt a hyper-parameter-free linear scaling rule for adjusting learning rates as a function of minibatch size and develop a new warmup scheme that overcomes optimization challenges early in training. With these simple techniques,",10
c751ab01aedc2888a7fe6e8b4f77ab1afa94072f,Protein Interface Prediction using Graph Convolutional Networks,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",10
7e9af8a6081dc00187bd4a6727751d1721bd7816,Evaluating Logical Generalization in Graph Neural Networks,"Recent research has highlighted the role of relational inductive biases in building learning agents that can generalize and reason in a compositional manner. However, while relational learning algorithms such as graph neural networks (GNNs) show promise, we do not understand how effectively these approaches can adapt to new tasks. In this work, we study the task of logical generalization using GNNs by designing a benchmark suite grounded in first-order logic. Our benchmark suite, GraphLog, requires that learning algorithms perform rule induction in different synthetic logics, represented as knowledge graphs. GraphLog consists of relation prediction tasks on 57 distinct logical domains. We use GraphLog to evaluate GNNs in three different setups: single-task supervised learning, multi-task pretraining, and continual learning. Unlike previous benchmarks, our approach allows us to precisely control the logical relationship between the different tasks. We find that the ability for models to generalize and adapt is strongly determined by",3
1a7a678bf59eaf9490dcec4b1343a1dedef69c8c,Ramanujan Graphs in Polynomial Time,"Recent work by Marcus, Spielman and Srivastava proves the existence of bipartite Ramanujan (multi) graphs of all degrees and all sizes. However, that paper did not provide a polynomial time algorithm to actually compute such graphs. Here, we provide a polynomial time algorithm to compute certain expected characteristic polynomials related to this construction. This leads to a deterministic polynomial time algorithm to compute bipartite Ramanujan (multi) graphs of all degrees and all sizes.",5
0ca7d8c3250d43d14fdde46bf6fc299654d861ef,Heterogeneous Graph Transformer,"Recent years have witnessed the emerging success of graph neural networks (GNNs) for modeling structured data. However, most GNNs are designed for homogeneous graphs, in which all nodes and edges belong to the same types, making it infeasible to represent heterogeneous structures. In this paper, we present the Heterogeneous Graph Transformer (HGT) architecture for modeling Web-scale heterogeneous graphs. To model heterogeneity, we design node- and edge-type dependent parameters to characterize the heterogeneous attention over each edge, empowering HGT to maintain dedicated representations for different types of nodes and edges. To handle Web-scale graph data, we design the heterogeneous mini-batch graph sampling algorithm—HGSampling—for efficient and scalable training. Extensive experiments on the Open Academic Graph of 179 million nodes and 2 billion edges show that the proposed HGT model consistently outperforms all the state-of-the-art GNN baselines by 9–21 on various downstream tasks. The dataset and source code of HGT are publicly available",9
71bab0bb655a9bf7a7ef8a2308db1097111fd7d1,Easing Embedding Learning by Comprehensive Transcription of Heterogeneous Information Networks,"Heterogeneous information networks (HINs) are ubiquitous in real-world applications. In the meantime, network embedding has emerged as a convenient tool to mine and learn from networked data. As a result, it is of interest to develop HIN embedding methods. However, the heterogeneity in HINs introduces not only rich information but also potentially incompatible semantics, which poses special challenges to embedding learning in HINs. With the intention to preserve the rich yet potentially incompatible information in HIN embedding, we propose to study the problem of comprehensive transcription of heterogeneous information networks. The comprehensive transcription of HINs also provides an easy-to-use approach to unleash the power of HINs, since it requires no additional supervision, expertise, or feature engineering. To cope with the challenges in the comprehensive transcription of HINs, we propose the HEER algorithm, which embeds HINs via edge representations that are further coupled with properly-learned heterogeneous metrics. To corroborate the efficacy",7
5d1bfeed240709725c78bc72ea40e55410b373dc,Convolutional Networks on Graphs for Learning Molecular Fingerprints,"We introduce a convolutional neural network that operates directly on graphs. These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints. We show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks.",76
30de3c20bbe9562e1fbce162d84de593a073bc15,Prefrontal cortex as a meta-reinforcement learning system,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",1
077436a29bb8e49d97687f2901f166ac245a6868,A framework for learning query concepts in image classification,"In this paper, we adapt the Multiple Instance Learning paradigm using the Diverse Density algorithm as a way of modeling the ambiguity in images in order to learn ""visual concepts"" that can be used to classify new images. In this framework, a user labels an image as positive if the image contains the concept. Each example image is a bag of instances (sub-images) where only the bag is labeled-not the individual instances (sub-images). From a small collection of positive and negative examples, the system learns the concept and uses it to retrieve images that contain the concept from a large database. The learned ""concepts"" are simple templates that capture the color, texture and spatial properties of the class of images. We introduced this method earlier in the domain of natural scene classification using simple, low resolution sub-images as instances. In this paper, we extend the bag generator (the mechanism which",2
e9c2950df970aa076c1225e789dcb542777dbdf1,"A Platform for Scalable, Collaborative, Structured Information Integration","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
ace1059fd85bbb8b41874a47a029bba7899124a5,Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks,"Matrix completion models are among the most common formulations of recommender systems. Recent works have showed a boost of performance of these techniques when introducing the pairwise relationships between users/items in the form of graphs, and imposing smoothness priors on these graphs. However, such techniques do not fully exploit the local stationarity structures of user/item graphs, and the number of parameters to learn is linear w.r.t. the number of users and items. We propose a novel approach to overcome these limitations by using geometric deep learning on graphs. Our matrix completion architecture combines graph convolutional neural networks and recurrent neural networks to learn meaningful statistical graph-structured patterns and the non-linear diffusion process that generates the known ratings. This neural network system requires a constant number of parameters independent of the matrix size. We apply our method on both synthetic and real datasets, showing that it outperforms state-of-the-art techniques.",15
5bf31dc4bd54b623008c13f8bc8954dc7c9a2d80,SchNet: A continuous-filter convolutional neural network for modeling quantum interactions,"Deep learning has the potential to revolutionize quantum chemistry as it is ideally suited to learn representations for structured data and speed up the exploration of chemical space. While convolutional neural networks have proven to be the first choice for images, audio and video data, the atoms in molecules are not restricted to a grid. Instead, their precise locations contain essential physical information, that would get lost if discretized. Thus, we propose to use continuous-filter convolutional layers to be able to model local correlations without requiring the data to lie on a grid. We apply those layers in SchNet: a novel deep learning architecture modeling quantum interactions in molecules. We obtain a joint model for the total energy and interatomic forces that follows fundamental quantum-chemical principles. This includes rotationally invariant energy predictions and a smooth, differentiable potential energy surface. Our architecture achieves state-of-the-art performance for benchmarks of equilibrium molecules and",17
2335a95bfed617953675b5227cc881707746f53b,Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preferences,"Incorporating knowledge graph (KG) into recommender system is promising in improving the recommendation accuracy and explainability. However, existing methods largely assume that a KG is complete and simply transfer the ”knowledge” in KG at the shallow level of entity raw data or embeddings. This may lead to suboptimal performance, since a practical KG can hardly be complete, and it is common that a KG has missing facts, relations, and entities. Thus, we argue that it is crucial to consider the incomplete nature of KG when incorporating it into recommender system. In this paper, we jointly learn the model of recommendation and knowledge graph completion. Distinct from previous KG-based recommendation methods, we transfer the relation information in KG, so as to understand the reasons that a user likes an item. As an example, if a user has watched several movies directed by (relation) the same person (entity), we can infer that",5
c097be22f1e87a846385047346b73610d91fea4e,GaAN: Gated Attention Networks for Learning on Large and Spatiotemporal Graphs,"We propose a new network architecture, Gated Attention Networks (GaAN), for learning on graphs. Unlike the traditional multi-head attention mechanism, which equally consumes all attention heads, GaAN uses a convolutional sub-network to control each attention head's importance. We demonstrate the effectiveness of GaAN on the inductive node classification problem. Moreover, with GaAN as a building block, we construct the Graph Gated Recurrent Unit (GGRU) to address the traffic speed forecasting problem. Extensive experiments on three real-world datasets show that our GaAN framework achieves state-of-the-art results on both tasks.",12
def1049b5aae96c8e1eab0ca58d77ac9c2f0e3e9,MolGAN: An implicit generative model for small molecular graphs,"eep generative models for graph-structured data offer a new angle on the problem of chemical synthesis: by optimizing differentiable models that directly generate molecular graphs, it is pos-sible to side-step expensive search procedures in the discrete and vast space of chemical structures. We introduce MolGAN, an implicit, likelihood-free generative model for small molecular graphs that circumvents the need for expensive graph matching procedures or node ordering heuris-tics of previous likelihood-based methods. Our method adapts generative adversarial networks (GANs) to operate directly on graph-structured data. We combine our approach with a reinforce-ment learning objective to encourage the genera-tion of molecules with specific desired chemical properties. In experiments on the QM9 chemi-cal database, we demonstrate that our model is capable of generating close to 100% valid com-pounds. MolGAN compares favorably both to recent proposals that use string-based (SMILES) representations of molecules and to a likelihood-based method that directly generates graphs, al-beit being",11
079bba129e135941492b1ab1f8d48c25f05cce96,Hippocampal transcriptome analysis following maternal separation implicates altered RNA processing in a mouse model of fetal alcohol spectrum disorder,"Background Fetal alcohol spectrum disorders (FASD) are common, seen in 1–5% of the population in the USA and Canada. Children diagnosed with FASD are not likely to remain with their biological parents, facing early maternal separation and foster placements throughout childhood. Methods We model FASD in mice via prenatal alcohol exposure and further induce early life stress through maternal separation. We use RNA-seq followed by clustering of expression profiles through weighted gene co-expression network analysis (WGCNA) to analyze transcriptomic changes that result from the treatments. We use reverse transcription qPCR to validate these changes in the mouse hippocampus. Results We report an association between adult hippocampal gene expression and prenatal ethanol exposure followed by postnatal separation stress that is related to behavioral changes. Expression profile clustering using WGCNA identifies a set of transcripts, module 19, associated with anxiety-like behavior ( r = 0.79, p = 0.002) as well as treatment",3
cd3fcd5fcab961ee32acc962fc15cc8a7412ca32,An algorithm for the blocks and cutnodes of a graph,"An efficient method is presented for finding blocks and cutnodes of an arbitrary undirected graph. The graph may be represented either (i) as an ordered list of edges or (ii) as a packed adjacency matrix. If w denotes the word length of the machine employed, the storage (in machine words) required for a graph with n nodes and m edges increases essentially as 2(m + n) in case (i), or n2/w in case (ii). A spanning tree with labeled edges is grown, two edges finally bearing different labels if and only if they belong to different blocks. For both representations the time required to analyze a graph on n nodes increases as n&ggr; where &ggr; depends on the type of graph, 1 ≤ &ggr; ≤ 2, and both bounds are attained. Values of &ggr; are derived for each of several suitable families of test graphs, generated by an extension of",5
4aa8e316bc1c5959537517ed16b4bf81b4bd73ed,Graph Partition Neural Networks for Semi-Supervised Classification,"We present graph partition neural networks (GPNN), an extension of graph neural networks (GNNs) able to handle extremely large graphs. GPNNs alternate between locally propagating information between nodes in small subgraphs and globally propagating information between the subgraphs. To efficiently partition graphs, we experiment with several partitioning algorithms and also propose a novel variant for fast processing of large scale graphs. We extensively test our model on a variety of semi-supervised node classification tasks. Experimental results indicate that GPNNs are either superior or comparable to state-of-the-art methods on a wide variety of datasets for graph-based semi-supervised classification. We also show that GPNNs can achieve similar performance as standard GNNs with fewer propagation steps.",8
39b68545a1f36a8316eb131121310901e2e2206a,Data denoising with transfer learning in single-cell transcriptomics,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",7
b155ef07c0d664d3f2f4d6071410649f87a210f3,Graph Twiddling in a MapReduce World,"As the size of graphs for analysis continues to grow, methods of graph processing that scale well have become increasingly important. One way to handle large datasets is to disperse them across an array of networked computers, each of which implements simple sorting and accumulating, or MapReduce, operations. This cloud computing approach offers many attractive features. If decomposing useful graph operations in terms of MapReduce cycles is possible, it provides incentive for seriously considering cloud computing. Moreover, it offers a way to handle a large graph on a single machine that can't hold the entire graph as well as enables streaming graph processing. This article examines this possibility.",3
fd075bcdf2d7e13d23f7c249a8eded343d5bbe3b,Deep Graph Library: Towards Efficient and Scalable Deep Learning on Graphs,"Accelerating research in the emerging field of deep graph learning requires new tools. Such systems should support graph as the core abstraction and take care to maintain both forward (i.e. supporting new research ideas) and backward (i.e. integration with existing components) compatibility. In this paper, we present Deep Graph Library (DGL). DGL enables arbitrary message handling and mutation operators, flexible propagation rules, and is framework agnostic so as to leverage high-performance tensor, autograd operations, and other feature extraction modules already available in existing frameworks. DGL carefully handles the sparse and irregular graph structure, deals with graphs big and small which may change dynamically, fuses operations, and performs auto-batching, all to take advantages of modern hardware. DGL has been tested on a variety of models, including but not limited to the popular Graph Neural Networks (GNN) and its variants, with promising speed, memory footprint and scalability.",11
32de44f01a96d4473d21099d15e25bc2b9f08e2f,Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks,"Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).",16
204a4a70428f3938d2c538a4d74c7ae0416306d8,A Structured Self-attentive Sentence Embedding,"This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.",12
7867578988f79c552d25ff50bdac1cf398fa8324,Enhancing the LexVec Distributed Word Representation Model Using Positional Contexts and External Memory,"In this paper we take a state-of-the-art model for distributed word representation that explicitly factorizes the positive pointwise mutual information (PPMI) matrix using window sampling and negative sampling and address two of its shortcomings. We improve syntactic performance by using positional contexts, and solve the need to store the PPMI matrix in memory by working on aggregate data in external memory. The effectiveness of both modifications is shown using word similarity and analogy tasks.",5
5e7d57cd826801f626eb399a9254bd8c90427559,A Graph-Based Push Service Platform,"Learning users’ preference and making recommendations is critical in information-exploded environment. There are two typical modes for recommendation, known as pull and push, which respectively account for recommendation inside and outside the item market. While previously most recommender systems adopt only pull-mode, push-mode becomes popular in today’s mobile environment. This paper presents a push recommendation platform successfully deployed for Huawei App Store, which has reached 0.3 billion registered users and 1.2 million Apps by 2016. Among the various modules in developing this push platform, we recognized the task of target user group discovery to be most essential in terms of CTR. We explored various algorithmic choices for mining target user group, and highlighted one based on recent advance in graph mining, the Partially Absorbing Random Walk [13], which leads to substantial improvement for our push recommendation, compared to the state-of-the-art including the popular PageRank. We also covered our practice in",1
d6ca0a9ea0e51ad099644dcbb6fe226cb7d28eeb,iTri: Index-based triangle listing in massive graphs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
6b59f34c8b1c6f44996eb305577478dd54f54249,Traffic speed prediction using deep learning method,"Successful traffic speed prediction is of great importance for the benefits of both road users and traffic management agencies. To solve the problem, traffic scientists have developed a number of time-series speed prediction approaches, including traditional statistical models and machine learning techniques. However, existing methods are still unsatisfying due to the difficulty to reflect the stochastic traffic flow characteristics. Recently, various deep learning models have been introduced to the prediction field. In this paper, a deep learning method, the Deep Belief Network (DBN) model, is proposed for short-term traffic speed information prediction. The DBN model is trained in a greedy unsupervised method and fine-tuned by labeled data. Based on traffic speed data collected from one arterial in Beijing, China, the model is trained and tested for different prediction time horizons. From experiment analysis, it is concluded that the DBN can outperform Back Propagation Neural Network (BPNN) and Auto-Regressive Integrated Moving",4
adc17f3e150555dcebb59bd29f4fce73176e2e12,Learning Translation Models from Monolingual Continuous Representations,"Translation models often fail to generate good translations for infrequent words or phrases. Previous work attacked this problem by inducing new translation rules from monolingual data with a semi-supervised algorithm. However, this approach does not scale very well since it is very computationally expensive to generate new translation rules for only a few thousand sentences. We propose a much faster and simpler method that directly hallucinates translation rules for infrequent phrases based on phrases with similar continuous representations for which a translation is known. To speed up the retrieval of similar phrases, we investigate approximated nearest neighbor search with redundant bit vectors which we find to be three times faster and significantly more accurate than locality sensitive hashing. Our approach of learning new translation rules improves a phrase-based baseline by up to 1.6 BLEU on Arabic-English translation, it is three-orders of magnitudes faster than existing semi-supervised methods and 0.5 BLEU",2
4117c25b74e8df14daf828e5853210f1ca3a1024,An n log n algorithm for isomorphism of planar triply connected graphs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
48d5588afd24c7a12ae54d6ef13008ee3b7a0e8c,General E(2)-Equivariant Steerable CNNs,"The big empirical success of group equivariant networks has led in recent years to the sprouting of a great variety of equivariant network architectures. A particular focus has thereby been on rotation and reflection equivariant CNNs for planar images. Here we give a general description of E(2)-equivariant convolutions in the framework of Steerable CNNs. The theory of Steerable CNNs thereby yields constraints on the convolution kernels which depend on group representations describing the transformation laws of feature spaces. We show that these constraints for arbitrary group representations can be reduced to constraints under irreducible representations. A general solution of the kernel space constraint is given for arbitrary representations of the Euclidean group E(2) and its subgroups. We implement a wide range of previously proposed and entirely new equivariant network architectures and extensively compare their performances. E(2)-steerable convolutions are further shown to yield remarkable gains on CIFAR-10, CIFAR-100 and STL-10 when",5
85b68477a6e031d88b963833e15a4b4fc6855264,A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories,"Representation and learning of commonsense knowledge is one of the foundational problems in the quest to enable deep language understanding. This issue is particularly challenging for understanding casual and correlational relationships between events. While this topic has received a lot of interest in the NLP community, research has been hindered by the lack of a proper evaluation framework. This paper attempts to address this problem with a new framework for evaluating story understanding and script learning: the 'Story Cloze Test'. This test requires a system to choose the correct ending to a four-sentence story. We created a new corpus of ~50k five-sentence commonsense stories, ROCStories, to enable this evaluation. This corpus is unique in two ways: (1) it captures a rich set of causal and temporal commonsense relations between daily events, and (2) it is a high quality collection of everyday life stories that can also be used for story",4
44ee7dbae6ad53cb13e49e7e641b54089ca5788d,Graph Warp Module: an Auxiliary Module for Boosting the Power of Graph Neural Networks in Molecular Graph Analysis,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",3
1546b92b145220240e802358c0d94ce621370128,SSE: Semantically Smooth Embedding for Knowledge Graphs,"This paper considers the problem of embedding Knowledge Graphs (KGs) consisting of entities and relations into low-dimensional vector spaces. Most of the existing methods perform this task based solely on observed facts. The only requirement is that the learned embeddings should be compatible within each individual fact. In this paper, aiming at further discovering the intrinsic geometric structure of the embedding space, we propose Semantically Smooth Embedding (SSE). The key idea of SSE is to take full advantage of additional semantic information and enforce the embedding space to be semantically smooth, i.e., entities belonging to the same semantic category will lie close to each other in the embedding space. Two manifold learning algorithms Laplacian Eigenmaps and Locally Linear Embedding are used to model the smoothness assumption. Both are formulated as geometrically based regularization terms to constrain the embedding task. Two lines of embedding strategies are tested, i.e., strategies based on",3
b30481dd5467a187b7e1a5a2dd326d97cafd95ac,Explicit Semantic Ranking for Academic Search via Knowledge Graph Embedding,"This paper introduces Explicit Semantic Ranking (ESR), a new ranking technique that leverages knowledge graph embedding. Analysis of the query log from our academic search engine, SemanticScholar.org, reveals that a major error source is its inability to understand the meaning of research concepts in queries. To addresses this challenge, ESR represents queries and documents in the entity space and ranks them based on their semantic connections from their knowledge graph embedding. Experiments demonstrate ESR's ability in improving Semantic Scholar's online production system, especially on hard queries where word-based ranking fails.",3
2218e2e1df2c3adfb70e0def2e326a39928aacfc,Complex Embeddings for Simple Link Prediction,"In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.",24
1f4a4769e4d2fb846e59c2f185e0377190739f18,Learning Structured Embeddings of Knowledge Bases,"Many Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigorous symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like nat- ural language processing (word-sense disambiguation, natural language understanding, ...), vision (scene classification, image semantic annotation, ...) or collaborative filtering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent",25
990334cf76845e2da64d3baa10b0a671e433d4b6,TorusE: Knowledge Graph Embedding on a Lie Group,"Knowledge graphs are useful for many artificial intelligence (AI) tasks. However, knowledge graphs often have missing facts. To populate the graphs, knowledge graph embedding models have been developed. Knowledge graph embedding models map entities and relations in a knowledge graph to a vector space and predict unknown triples by scoring candidate triples. TransE is the first translation-based method and it is well known because of its simplicity and efficiency for knowledge graph completion. It employs the principle that the differences between entity embeddings represent their relations. The principle seems very simple, but it can effectively capture the rules of a knowledge graph. However, TransE has a problem with its regularization. TransE forces entity embeddings to be on a sphere in the embedding vector space. This regularization warps the embeddings and makes it difficult for them to fulfill the abovementioned principle. The regularization also affects adversely the accuracies of the link",2
83d585082a8ccc617f288c0ea984d360832f92e0,The Tractability of Segmentation and Scene Analysis,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",2
ddab225c61734c8f620704e9be8915c93cb39fa1,Interlacing Families I: Bipartite Ramanujan Graphs of All Degrees,"We prove that there exist infinite families of regular bipartite Ramanujan graphs of every degree bigger than 2. We do this by proving a variant of a conjecture of Bilu and Linial about the existence of good 2-lifts of every graph. We also establish the existence of infinite families of `irregular Ramanujan' graphs, whose eigenvalues are bounded by the spectral radius of their universal cover. Such families were conjectured to exist by Linial and others. In particular, we prove the existence of infinite families of (c, d)-biregular bipartite graphs with all non-trivial eigenvalues bounded by √c-1+√d-1, for all c, d ≥ q 3. Our proof exploits a new technique for demonstrating the existence of useful combinatorial objects that we call the ""method of interlacing polynomials"".",3
c3b4ea5d103d7c6991937035398d5ca9fb3aea83,"The $25,000,000,000 Eigenvector: The Linear Algebra behind Google","Google's success derives in large part from its PageRank algorithm, which ranks the importance of web pages according to an eigenvector of a weighted link matrix. Analysis of the PageRank formula provides a wonderful applied topic for a linear algebra course. Instructors may assign this article as a project to more advanced students or spend one or two lectures presenting the material with assigned homework from the exercises. This material also complements the discussion of Markov chains in matrix algebra. Maple and Mathematica files supporting this material can be found at www.rose-hulman.edu/~bryan.",3
4a18affba68096f53a8a884e4a9ebd34e65d305f,Relational inductive bias for physical construction in humans and machines,"While current deep learning systems excel at tasks such as object classification, language processing, and gameplay, few can construct or modify a complex system such as a tower of blocks. We hypothesize that what these systems lack is a ""relational inductive bias"": a capacity for reasoning about inter-object relations and making choices over a structured description of a scene. To test this hypothesis, we focus on a task that involves gluing pairs of blocks together to stabilize a tower, and quantify how well humans perform. We then introduce a deep reinforcement learning agent which uses object- and relation-centric scene and policy representations and apply it to the task. Our results show that these structured representations allow the agent to outperform both humans and more naive approaches, suggesting that relational inductive bias is an important component in solving structured reasoning problems and for building more intelligent, flexible machines.",6
09e48adf1a3f012ec56fbb4f92acae975ee43d87,A Deep Learning Approach to Antibiotic Discovery,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",10
0f8ba94096247e6ffec960acafbc18b08ed1ff17,Unsupervised Inductive Whole-Graph Embedding by Preserving Graph Proximity,"We introduce a novel approach to graph-level representation learning, which is to embed an entire graph into a vector space where the embeddings of two graphs preserve their graph-graph proximity. Our approach, UGRAPHEMB, is a general framework that provides a novel means to performing graph-level embedding in a completely unsupervised and inductive manner. The learned neural network can be considered as a function that receives any graph as input, either seen or unseen in the training set, and transforms it into an embedding. A novel graph-level embedding generation mechanism called Multi-Scale Node Attention (MSNA), is proposed. Experiments on five real graph datasets show that UGRAPHEMB achieves competitive accuracy in the tasks of graph classification, similarity ranking, and graph visualization.",6
97f7ef7a5332218e0e9ce75ad5cf77048466ca83,Column Networks for Collective Classification,"Relational learning deals with data that are characterized by relational structures. An important task is collective classification, which is to jointly classify networked objects. While it holds a great promise to produce a better accuracy than non-collective classifiers, collective classification is computationally challenging and has not leveraged on the recent breakthroughs of deep learning. We present Column Network (CLN), a novel deep learning model for collective classification in multi-relational domains. CLN has many desirable theoretical properties: (i) it encodes multi-relations between any two instances; (ii) it is deep and compact, allowing complex functions to be approximated at the network level with a small set of free parameters; (iii) local and relational features are learned simultaneously; (iv) long-range, higher-order dependencies between instances are supported naturally; and (v) crucially, learning and inference are efficient with linear complexity in the size of the network and the number of relations. We evaluate CLN on",11
296e32a86e1711269289004b140f6d3e0f250348,Equivariant Flows: exact likelihood generative learning for symmetric densities,"Normalizing flows are exact-likelihood generative neural networks which approximately transform samples from a simple prior distribution to samples of the probability distribution of interest. Recent work showed that such generative models can be utilized in statistical mechanics to sample equilibrium states of many-body systems in physics and chemistry. To scale and generalize these results, it is essential that the natural symmetries in the probability density - in physics defined by the invariances of the target potential - are built into the flow. We provide a theoretical sufficient criterion showing that the distribution generated by equivariant normalizing flows is invariant with respect to these symmetries by design. Furthermore, we propose building blocks for flows which preserve symmetries which are usually found in physical/chemical many-body particle systems. Using benchmark systems motivated from molecular physics, we demonstrate that those symmetry preserving flows can provide better generalization capabilities and sampling efficiency.",5
91fb815361fdbf80ff15ce4d783a41846bd99232,GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training,"Graph representation learning has emerged as a powerful technique for addressing real-world problems. Various downstream graph learning tasks have benefited from its recent developments, such as node classification, similarity search, and graph classification. However, prior arts on graph representation learning focus on domain specific problems and train a dedicated model for each graph dataset, which is usually non-transferable to out-of-domain data. Inspired by the recent advances in pre-training from natural language processing and computer vision, we design Graph Contrastive Coding (GCC) --- a self-supervised graph neural network pre-training framework --- to capture the universal network topological properties across multiple networks. We design GCC's pre-training task as subgraph instance discrimination in and across networks and leverage contrastive learning to empower graph neural networks to learn the intrinsic and transferable structural representations. We conduct extensive experiments on three graph learning tasks and ten graph datasets. The results show that GCC pre-trained on",6
833a6052983fa55181b92516d0e1097d74585c58,NAIS: Neural Attentive Item Similarity Model for Recommendation,"Item-to-item collaborative filtering (aka.item-based CF) has been long used for building recommender systems in industrial settings, owing to its interpretability and efficiency in real-time personalization. It builds a user's profile as her historically interacted items, recommending new items that are similar to the user's profile. As such, the key to an item-based CF method is in the estimation of item similarities. Early approaches use statistical measures such as cosine similarity and Pearson coefficient to estimate item similarities, which are less accurate since they lack tailored optimization for the recommendation task. In recent years, several works attempt to learn item similarities from data, by expressing the similarity as an underlying model and estimating model parameters by optimizing a recommendation-aware objective function. While extensive efforts have been made to use shallow linear models for learning item similarities, there has been relatively less work exploring nonlinear neural network models for item-based CF. In",6
61c8169aba4e754976f012fd056bf9076c5b7421,KB4Rec: A Data Set for Linking Knowledge Bases with Recommender Systems,"To develop a knowledge-aware recommender system, a key issue is how to obtain rich and structured knowledge base (KB) information for recommender system (RS) items. Existing data sets or methods either use side information from original RSs (containing very few kinds of useful information) or utilize a private KB. In this paper, we present KB4Rec v1.0, a data set linking KB information for RSs. It has linked three widely used RS data sets with two popular KBs, namely Freebase and YAGO. Based on our linked data set, we first preform qualitative analysis experiments, and then we discuss the effect of two important factors (i.e., popularity and recency) on whether a RS item can be linked to a KB entity. Finally, we compare several knowledge-aware recommendation algorithms on our linked data set.",2
ad4fd2c149f220a62441576af92a8a669fe81246,Scikit-learn: Machine Learning in Python,"Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.",38
3d846cb01f6a975554035d2210b578ca61344b22,Revisiting Semi-Supervised Learning with Graph Embeddings,"We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.",27
f6b51c8753a871dc94ff32152c00c01e94f90f09,Efficient Estimation of Word Representations in Vector Space,"We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.",47
51060b1737535ae2bec20770d680b3c049bd9402,Isomorphism of Planar Graphs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
a6fbefbee8b814dc3183e26ef37a44fc5015600d,An Experimental Comparison of Stereo Algorithms,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
ee8b1603c79a4f9c3bdc0d6633b595aa93ff3a0f,Self-Attention Graph Pooling,"Advanced methods of applying deep learning to structured data such as graphs have been proposed in recent years. In particular, studies have focused on generalizing convolutional neural networks to graph data, which includes redefining the convolution and the downsampling (pooling) operations for graphs. The method of generalizing the convolution operation to graphs has been proven to improve performance and is widely used. However, the method of applying downsampling to graphs is still difficult to perform and has room for improvement. In this paper, we propose a graph pooling method based on self-attention. Self-attention using graph convolution allows our pooling method to consider both node features and graph topology. To ensure a fair comparison, the same training procedures and model architectures were used for the existing pooling methods and our method. The experimental results demonstrate that our method achieves superior graph classification performance on the benchmark datasets using a reasonable number",6
a8b382ced2293e3b191e73eca8e6c1e5a2eb11f3,A Deep Learning Approach to Antibiotic Discovery,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",5
f71f8087c20c6d6fd78de522aeab35e82c5b61cf,Reinforced Negative Sampling for Recommendation with Exposure Data,"In implicit feedback-based recommender systems, user exposure data, which record whether or not a recommended item has been interacted by a user, provide an important clue on selecting negative training samples. In this work, we improve the negative sampler by integrating the exposure data. We propose to generate high-quality negative instances by adversarial training to favour the difﬁcult instances, and by optimizing additional objective to favour the real negatives in exposure data. However, this idea is non-trivial to implement since the distribution of exposure data is latent and the item space is discrete. To this end, we design a novel RNS method (short for Reinforced Negative Sampler) that generates exposure-alike negative instances through feature matching technique instead of directly choosing from exposure data. Optimized under the reinforcement learning framework, RNS is able to integrate user preference signals in exposure data and hard negatives. Extensive experiments on two real-world datasets demonstrate",5
ce840188f3395815201b7da49f9bb40d24fc046a,A Survey on Network Embedding,"Network embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a significant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We first summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information, and the advanced information preserving network embedding methods. Moreover, several evaluation approaches for network embedding and some useful online resources, including the network data sets and softwares, are reviewed, too. Finally, we discuss the framework of exploiting these network",10
beeeb5b4d48afd55fd9f35504b20ea90b42b12c9,A Construction for Clique-Free Pseudorandom Graphs,A construction of Alon and Krivelevich gives highly pseudorandom Kk-free graphs on n vertices with edge density equal to Θ(n−1=(k−2)). In this short note we improve their result by constructing an infinite family of highly pseudorandom Kk-free graphs with a higher edge density of Θ(n−1=(k−1)).,3
639206a9a32d91386924f1c94e9760dfb43df72e,Towards Deeper Graph Neural Networks,"Graph neural networks have shown significant success in the field of graph representation learning. Graph convolutions perform neighborhood aggregation and represent one of the most important graph operations. Nevertheless, one layer of these neighborhood aggregation methods only consider immediate neighbors, and the performance decreases when going deeper to enable larger receptive fields. Several recent studies attribute this performance deterioration to the over-smoothing issue, which states that repeated propagation makes node representations of different classes indistinguishable. In this work, we study this observation systematically and develop new insights towards deeper graph neural networks. First, we provide a systematical analysis on this issue and argue that the key factor compromising the performance significantly is the entanglement of representation transformation and propagation in current graph convolution operations. After decoupling these two operations, deeper graph neural networks can be used to learn graph node representations from larger receptive fields. We further provide a theoretical",3
b120a10310645df329c691b782dea9ceb7dfe786,Pixie: A System for Recommending 3+ Billion Items to 200+ Million Users in Real-Time,"User experience in modern content discovery applications critically depends on high-quality personalized recommendations. However, building systems that provide such recommendations presents a major challenge due to a massive pool of items, a large number of users, and requirements for recommendations to be responsive to user actions and generated on demand in real-time. Here we present Pixie, a scalable graph-based real-time recommender system that we developed and deployed at Pinterest. Given a set of user-specific pins as a query, Pixie selects in real-time from billions of possible pins those that are most related to the query. To generate recommendations, we develop Pixie Random Walk algorithm that utilizes the Pinterest object graph of 3 billion nodes and 17 billion edges. Experiments show that recommendations provided by Pixie lead up to 50% higher user engagement when compared to the previous Hadoop-based production system. Furthermore, we develop a graph pruning strategy at that leads",5
93808ce258f4556df9a58a145c73b872392339ed,Efficient Compression on Real World Directed Graphs,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",6
04cc04457e09e17897f9256c86b45b92d70a401f,A latent factor model for highly multi-relational data,"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",16
8573393e8b14e3011ae6ee91dc7bbde7077633c1,Label Efficient Semi-Supervised Learning via Graph Filtering,"Graph-based methods have been demonstrated as one of the most effective approaches for semi-supervised learning, as they can exploit the connectivity patterns between labeled and unlabeled data samples to improve learning performance. However, existing graph-based methods either are limited in their ability to jointly model graph structures and data features, such as the classical label propagation methods, or require a considerable amount of labeled data for training and validation due to high model complexity, such as the recent neural-network-based methods. In this paper, we address label efficient semi-supervised learning from a graph filtering perspective. Specifically, we propose a graph filtering framework that injects graph similarity into data features by taking them as signals on the graph and applying a low-pass graph filter to extract useful data representations for classification, where label efficiency can be achieved by conveniently adjusting the strength of the graph filter. Interestingly, this framework unifies two seemingly",2
ebff4eb2f94dcf38171a5ca6a24ee95bc8e88c10,Hyperbolic Attention Networks,"We introduce hyperbolic attention networks to endow neural networks with enough capacity to match the complexity of data with hierarchical and power-law structure. A few recent approaches have successfully demonstrated the benefits of imposing hyperbolic geometry on the parameters of shallow networks. We extend this line of work by imposing hyperbolic geometry on the activations of neural networks. This allows us to exploit hyperbolic geometry to reason about embeddings produced by deep networks. We achieve this by re-expressing the ubiquitous mechanism of soft attention in terms of operations defined for hyperboloid and Klein models. Our method shows improvements in terms of generalization on neural machine translation, learning on graphs and visual question answering tasks while keeping the neural representations compact.",5
0e779fd59353a7f1f5b559b9d65fa4bfe367890c,Geometric Deep Learning: Going beyond Euclidean data,"Many scientific fields study data with an underlying structure that is non-Euclidean. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them.",56
eb87afe815676589e11e8ded3f3d96667ebd4bcd,Unsupervised image segmentation,"We present an unsupervised segmentation algorithm comprising an annealing process to select the maximum a posteriori (MAP) realization of a hierarchical Markov random field (MRF) model. The algorithm consists of a sampling framework which unifies the processes of model selection, parameter estimation and image segmentation, in a single Markov chain. To achieve this, reversible jumps are incorporated into the Markov chain to allow movement between model spaces. By using partial decoupling to segment the MRF it is possible to generate jump proposals efficiently while providing a mechanism for the use of deterministic methods, such as Gabor filtering, to speed up convergence.",3
70cd2b984c8aa738e872b33c11924be877c54465,"Lifts, Discrepancy and Nearly Optimal Spectral Gap*","Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exerreference ullamco laboris nisi ut aliquip ex ea commodo consequat",4
eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82,A semantic matching energy function for learning with multi-relational data,"Large-scale relational learning becomes crucial for handling the huge amounts of structured data generated daily in many application domains ranging from computational biology or information retrieval, to natural language processing. In this paper, we present a new neural network architecture designed to embed multi-relational graphs into a flexible continuous vector space in which the original data is kept and enhanced. The network is trained to encode the semantics of these graphs in order to assign high probabilities to plausible components. We empirically show that it reaches competitive performance in link prediction on standard datasets from the literature as well as on data from a real-world knowledge base (WordNet). In addition, we present how our method can be applied to perform word-sense disambiguation in a context of open-text semantic parsing, where the goal is to learn to assign a structured meaning representation to almost any sentence of free text, demonstrating that",18
4a751d520534771593d359069f99d7c4621a861a,Learning Graph Embedding With Adversarial Training Methods,"Graph embedding aims to transfer a graph into vectors to facilitate subsequent graph-analytics tasks like link prediction and graph clustering. Most approaches on graph embedding focus on preserving the graph structure or minimizing the reconstruction errors for graph data. They have mostly overlooked the embedding distribution of the latent codes, which unfortunately may lead to inferior representation in many cases. In this article, we present a novel adversarially regularized framework for graph embedding. By employing the graph convolutional network as an encoder, our framework embeds the topological information and node content into a vector representation, from which a graph decoder is further built to reconstruct the input graph. The adversarial training principle is applied to enforce our latent codes to match a prior Gaussian or uniform distribution. Based on this framework, we derive two variants of the adversarial models, the adversarially regularized graph autoencoder (ARGA) and its variational version, and",2
d81fc968196e06ccafd7ea4c008b13e1cad1be64,An End-to-End Deep Learning Architecture for Graph Classification,"Neural networks are typically designed to deal with data in tensor forms. In this paper, we propose a novel neural network architecture accepting graphs of arbitrary structure. Given a dataset containing graphs in the form of (G,y) where G is a graph and y is its class, we aim to develop neural networks that read the graphs directly and learn a classification function. There are two main challenges: 1) how to extract useful features characterizing the rich information encoded in a graph for classification purpose, and 2) how to sequentially read a graph in a meaningful and consistent order. To address the first challenge, we design a localized graph convolution model and show its connection with two graph kernels. To address the second challenge, we design a novel SortPooling layer which sorts graph vertices in a consistent order so that traditional neural networks can be trained on the graphs. Experiments",22
e51e557cf4701510916bb1444074f62e6a04f889,Anonymous Walk Embeddings,"The task of representing entire graphs has seen a surge of prominent results, mainly due to learning convolutional neural networks (CNNs) on graph-structured data. While CNNs demonstrate state-of-the-art performance in graph classification task, such methods are supervised and therefore steer away from the original problem of network representation in task-agnostic manner. Here, we coherently propose an approach for embedding entire graphs and show that our feature representations with SVM classifier increase classification accuracy of CNN algorithms and traditional graph kernels. For this we describe a recently discovered graph object, anonymous walk, on which we design task-independent algorithms for learning graph representations in explicit and distributed way. Overall, our work represents a new scalable unsupervised learning of state-of-the-art representations of entire graphs.",2
